{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d611666",
   "metadata": {},
   "source": [
    "## LM Studio ê¸°ë³¸ ì‚¬ìš©ë²•\n",
    "\n",
    "### 1. ì„¤ì¹˜ ë° ëª¨ë¸ ë‹¤ìš´ë¡œë“œ\n",
    "\n",
    "- [lmstudio.ai](https://lmstudio.ai)ì—ì„œ ë‹¤ìš´ë¡œë“œ\n",
    "- Windows, Mac, Linux ì§€ì›"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4e9aae",
   "metadata": {},
   "source": [
    "### 2. ë¡œì»¬ ì„œë²„ ì‹¤í–‰\n",
    "\n",
    "1. ì¢Œì¸¡ ë©”ë‰´ì—ì„œ **Local Server** í´ë¦­\n",
    "2. ìƒë‹¨ì—ì„œ ë‹¤ìš´ë¡œë“œí•œ ëª¨ë¸ ì„ íƒ\n",
    "3. **Status ë³€ê²½** ë²„íŠ¼ í´ë¦­ (ì‹œì‘ ëŒ€ê¸° ìƒíƒœë¡œ ë³€ê²½)\n",
    "4. ê¸°ë³¸ ì£¼ì†Œ: `http://localhost:14000`\n",
    "\n",
    "### 3. ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ì‚¬ìš©\n",
    "\n",
    "- ì¢Œì¸¡ ë©”ë‰´ì—ì„œ **Chat** í´ë¦­\n",
    "- ëª¨ë¸ ì„ íƒ í›„ ëŒ€í™” ì‹œì‘\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6538ac",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## LangChain ì—°ë™ ë°©ë²•\n",
    "\n",
    "- **OpenAI í˜¸í™˜ API ì‚¬ìš©**\n",
    "- LM StudioëŠ” OpenAI APIì™€ í˜¸í™˜ë˜ë¯€ë¡œ `ChatOpenAI` í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—°ê²°í•  ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "uwni74t8xs7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\miniconda3\\envs\\modu2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âœ“ ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c87a885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ LM Studio ì—°ê²° ì„¤ì • ì™„ë£Œ\n",
      "  - Base URL: http://localhost:14000/v1\n",
      "  - Temperature: 0.7\n"
     ]
    }
   ],
   "source": [
    "# LM Studio ë¡œì»¬ ì„œë²„ì™€ ì—°ê²°\n",
    "# ì£¼ì˜: LM Studioì—ì„œ Local Serverë¥¼ ë¨¼ì € ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤!\n",
    "\n",
    "try:\n",
    "    llm = ChatOpenAI(\n",
    "        base_url=\"http://localhost:14000/v1\",\n",
    "        api_key=\"lm-studio\",  # LM StudioëŠ” API í‚¤ê°€ í•„ìš”ì—†ì§€ë§Œ í˜•ì‹ìƒ ì…ë ¥\n",
    "        model=\"qwen/qwen3-4b-thinking-2507\",  # ì‹¤ì œ ëª¨ë¸ëª…ì€ ë¬´ê´€\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    print(\"âœ“ LM Studio ì—°ê²° ì„¤ì • ì™„ë£Œ\")\n",
    "    print(f\"  - Base URL: http://localhost:14000/v1\")\n",
    "    print(f\"  - Temperature: 0.7\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì—°ê²° ì„¤ì • ì˜¤ë¥˜: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b4655c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ ì‘ë‹µ ì„±ê³µ!\n",
      "\n",
      "ì§ˆë¬¸: ì•ˆë…•í•˜ì„¸ìš”! LangChainì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "\n",
      "ë‹µë³€:\n",
      "\n",
      "\n",
      "ì•ˆë…•í•˜ì„¸ìš”! LangChainì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ê¸°ë°˜ìœ¼ë¡œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•´ OpenAI, Hugging Face ë“± ë‹¤ì–‘í•œ LLMê³¼ ì—°ë™í•˜ì—¬ ì±„íŒ…ë´‡, ë¬¸ì„œ ë¶„ì„, ë°ì´í„° ì²˜ë¦¬ ë“±ì˜ ê¸°ëŠ¥ì„ ì‰½ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ê¸°ë³¸ ì‚¬ìš© ì˜ˆì‹œ - ê°„ë‹¨í•œ ì§ˆì˜ì‘ë‹µ\n",
    "try:\n",
    "    response = llm.invoke(\"ì•ˆë…•í•˜ì„¸ìš”! LangChainì€ ë¬´ì—‡ì¸ê°€ìš”?\")\n",
    "    print(\"âœ“ ì‘ë‹µ ì„±ê³µ!\")\n",
    "    print(f\"\\nì§ˆë¬¸: ì•ˆë…•í•˜ì„¸ìš”! LangChainì€ ë¬´ì—‡ì¸ê°€ìš”?\")\n",
    "    print(f\"\\në‹µë³€:\\n{response.content}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    print(\"\\nğŸ’¡ í•´ê²° ë°©ë²•:\")\n",
    "    print(\"  1. LM Studio ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸\")\n",
    "    print(\"  2. Local Server íƒ­ì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ì„œë²„ë¥¼ ì‹œì‘í–ˆëŠ”ì§€ í™•ì¸\")\n",
    "    print(\"  3. ì„œë²„ ì£¼ì†Œê°€ http://localhost:14000 ì¸ì§€ í™•ì¸\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1iwl74ccy12",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì‹¤ìŠµ 1: ë‹¤ì–‘í•œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "LM Studioë¡œ ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì§ˆë¬¸ì„ í…ŒìŠ¤íŠ¸í•´ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hn5fe70hqla",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ë‹¤ì–‘í•œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸\n",
      "================================================================================\n",
      "\n",
      "[ì§ˆë¬¸ 1] íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "\n",
      "[ë‹µë³€ 1]\n",
      "\n",
      "\n",
      "íŒŒì´ì¬ì—ì„œ **ë¦¬ìŠ¤íŠ¸**(list)ì™€ **íŠœí”Œ**(tuple)ì˜ ì£¼ìš” ì°¨ì´ì ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **ë¶ˆë³€ì„±(Immutability)**\n",
      "- **ë¦¬ìŠ¤íŠ¸**: **ê°€ë³€**(mutable)ì…ë‹ˆë‹¤.  \n",
      "  â†’ ìš”ì†Œë¥¼ ì¶”ê°€/ì‚­ì œ/ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
      "  ```python\n",
      "  my_list = [1, 2, 3]\n",
      "  my_list.appe...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[ì§ˆë¬¸ 2] ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
      "\n",
      "[ë‹µë³€ 2]\n",
      "\n",
      "\n",
      "ë¨¸ì‹ ëŸ¬ë‹ì€ ë°ì´í„°ì—ì„œ íŒ¨í„´ì„ í•™ìŠµí•´ ì˜ˆì¸¡í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ë”¥ëŸ¬ë‹ì€ ë¨¸ì‹ ëŸ¬ë‹ì˜ í•œ ë¶€ë¶„ìœ¼ë¡œ, ì—¬ëŸ¬ ì¸µì„ ê°€ì§„ ì‹ ê²½ë§ì„ ì‚¬ìš©í•´ ì´ë¯¸ì§€, ìŒì„±, í…ìŠ¤íŠ¸ ë“± ë³µì¡í•œ ë°ì´í„°ì—ì„œ ìë™ìœ¼ë¡œ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ì¦‰, ë”¥ëŸ¬ë‹ì€ ë¨¸ì‹ ëŸ¬ë‹ì˜ í•œ ì¢…ë¥˜ë¡œ ë” ë³µì¡í•œ ë¬¸ì œ í•´ê²°ì— íŠ¹í™”ëœ ê¸°ìˆ ì…ë‹ˆë‹¤....\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[ì§ˆë¬¸ 3] ETFë€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "\n",
      "[ë‹µë³€ 3]\n",
      "\n",
      "\n",
      "ETF(Exchange-Traded Fund)ëŠ” ì£¼ì‹ ê±°ë˜ì†Œì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ê±°ë˜ê°€ ê°€ëŠ¥í•œ í€ë“œë¡œ, íŠ¹ì • ì§€ìˆ˜, ì‚°ì—… ë¶„ì•¼, ìì‚° ë“±ì— íˆ¬ìí•œ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ì¶”ì í•˜ëŠ” íˆ¬ì ìƒí’ˆì…ë‹ˆë‹¤. ì£¼ë¡œ ì§€ìˆ˜ë¥¼ ì¶”ì í•˜ëŠ” 'ì§€ìˆ˜ ì¶”ì í˜• í€ë“œ'ë¡œ, ë¯¸êµ­ S&P 500 ì§€ìˆ˜ë¥¼ ì¶”ì í•˜ëŠ” SPYì™€ ê°™ì´ ë‹¤ì–‘í•œ ìì‚°ì„ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ETFëŠ” ì£¼ì‹ í€ë“œì™€ ë‹¬ë¦¬ ë§¤ì¼ í•œ ë²ˆ í‰...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ë‹¤ì–‘í•œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸\n",
    "questions = [\n",
    "    \"íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\",\n",
    "    \"ETFë€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ë‹¤ì–‘í•œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, question in enumerate(questions, 1):\n",
    "    try:\n",
    "        print(f\"\\n[ì§ˆë¬¸ {i}] {question}\")\n",
    "        response = llm.invoke(question)\n",
    "        print(f\"\\n[ë‹µë³€ {i}]\\n{response.content[:200]}...\")  # ì²˜ìŒ 200ìë§Œ ì¶œë ¥\n",
    "        print(\"-\" * 80)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ivk2sqyv6a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì‹¤ìŠµ 2: ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ\n",
    "\n",
    "ì‹¤ì‹œê°„ìœ¼ë¡œ ì‘ë‹µì„ ë°›ì•„ë³´ëŠ” ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "jhbl5igk7h",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í…ŒìŠ¤íŠ¸\n",
      "================================================================================\n",
      "ì§ˆë¬¸: ì¸ê³µì§€ëŠ¥ì˜ ì—­ì‚¬ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
      "\n",
      "ë‹µë³€: \n",
      "\n",
      "ì¸ê³µì§€ëŠ¥ì˜ ì—­ì‚¬  \n",
      "\n",
      "- **1950ë…„ëŒ€**: ì•¨ëŸ° íŠœë§ì´ íˆ¬ë§ í…ŒìŠ¤íŠ¸ë¥¼ ì œì•ˆí•˜ê³ , 1956ë…„ ë‹¤ë¥´íŠ¸ë¨¸ìŠ¤ íšŒì˜ì—ì„œ \"ì¸ê³µì§€ëŠ¥\" ìš©ì–´ê°€ ì°½ì•ˆë˜ì—ˆìŠµë‹ˆë‹¤. ì´ˆê¸° ì—°êµ¬ë¡œ ë¡œì§ í…Œì˜¤ë¦¬ìŠ¤íŠ¸ì™€ GPSê°€ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤.  \n",
      "- **1970ë…„ëŒ€**: ì²« ë²ˆì§¸ AI winter(ì—°êµ¬ ìê¸ˆ ê°ì†Œ)ê°€ ë°œìƒí–ˆìœ¼ë©°, MYCIN ë“± ì „ë¬¸ ì‹œìŠ¤í…œì´ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤.  \n",
      "- **1980ë…„ëŒ€~1990ë…„ëŒ€**: ê¸°ê³„ í•™ìŠµ, ë² ì´ì§€ì•ˆ ë„¤íŠ¸ì›Œí¬ê°€ ë°œì „í–ˆê³ , ì „ë¬¸ ì‹œìŠ¤í…œì´ ë„ë¦¬ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.  \n",
      "- **2010ë…„ëŒ€ ì´í›„**: ë”¥ëŸ¬ë‹(2012ë…„ AlexNet)ê³¼ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(GPT-3, GPT-4)ì´ ë“±ì¥í•´ í˜„ëŒ€ AIë¥¼ ì´ëŒì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "âœ“ ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì˜ˆì‹œ\n",
    "print(\"ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "question = \"ì¸ê³µì§€ëŠ¥ì˜ ì—­ì‚¬ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"\n",
    "print(f\"ì§ˆë¬¸: {question}\\n\")\n",
    "print(\"ë‹µë³€: \", end=\"\")\n",
    "\n",
    "try:\n",
    "    # ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì‘ë‹µ ë°›ê¸°\n",
    "    for chunk in llm.stream(question):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "    print(\"\\n\\nâœ“ ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ ì˜¤ë¥˜: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mffwuerxtii",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì‹¤ìŠµ 3: ëŒ€í™” ê¸°ë¡ ìœ ì§€ (ConversationChain)\n",
    "\n",
    "ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•˜ëŠ” ëŒ€í™”í˜• ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8fgacbkp5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëŒ€í™” ê¸°ë¡ ìœ ì§€ í…ŒìŠ¤íŠ¸\n",
      "================================================================================\n",
      "\n",
      "[ëŒ€í™” 1]\n",
      "ì‚¬ìš©ì: ì œ ì´ë¦„ì€ ê¹€ì² ìˆ˜ì…ë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaydash\\AppData\\Local\\Temp\\ipykernel_27048\\24991076.py:7: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n",
      "C:\\Users\\kaydash\\AppData\\Local\\Temp\\ipykernel_27048\\24991076.py:8: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "\n",
      "ì•ˆë…•í•˜ì„¸ìš”, ê¹€ì² ìˆ˜ë‹˜! ì €ëŠ” Qwenì´ì—ìš”. ì €ëŠ” 2024ë…„ê¹Œì§€ í•™ìŠµëœ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ë¡œ, í•œêµ­ì–´ë¥¼ í¬í•¨í•œ 100ê°œ ì´ìƒì˜ ì–¸ì–´ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. ì˜¤ëŠ˜ì€ ë²ˆì—­, ë¬¸ì¥ ì²´í¬, ì´ì•¼ê¸° ì‘ì„±, í˜¹ì€ ë‹¤ë¥¸ ì–¸ì–´ë¡œ ëŒ€í™”ë¥¼ ì›í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë„ì™€ë“œë¦´ê²Œìš”! ì˜ˆë¥¼ ë“¤ì–´, \"í•œêµ­ì–´ë¡œ 50ë‹¨ì–´ì˜ ê°„ë‹¨í•œ ì—¬í–‰ ì´ì•¼ê¸°ë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”\"ë¼ê³  í•´ë„ ì¢‹ì•„ìš”. ğŸ˜Š\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[ëŒ€í™” 2]\n",
      "ì‚¬ìš©ì: ì œê°€ ë°©ê¸ˆ ë­ë¼ê³  í–ˆì£ ?\n",
      "AI: \n",
      "\n",
      "ì €ëŠ” ë°©ê¸ˆ 'ì œ ì´ë¦„ì€ ê¹€ì² ìˆ˜ì…ë‹ˆë‹¤.'ë¼ê³  ë§ì”€í•˜ì…¨ìŠµë‹ˆë‹¤! ğŸ˜Š\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[ëŒ€í™” 3]\n",
      "ì‚¬ìš©ì: ì œ ì´ë¦„ì˜ ì„±ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "AI: \n",
      "\n",
      "ê¹€ì…ë‹ˆë‹¤. (ê¹€ì€ í•œêµ­ì–´ì—ì„œ ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ì²« ê¸€ìë¡œ, ê¹€ì² ìˆ˜ë‹˜ì˜ ì„±ì€ ê¹€ì…ë‹ˆë‹¤.) ğŸ˜Š\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "âœ“ ëŒ€í™” ì²´ì¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n",
      "\n",
      "ë©”ëª¨ë¦¬ì— ì €ì¥ëœ ëŒ€í™”:\n",
      "Human: ì œ ì´ë¦„ì€ ê¹€ì² ìˆ˜ì…ë‹ˆë‹¤.\n",
      "AI: \n",
      "\n",
      "ì•ˆë…•í•˜ì„¸ìš”, ê¹€ì² ìˆ˜ë‹˜! ì €ëŠ” Qwenì´ì—ìš”. ì €ëŠ” 2024ë…„ê¹Œì§€ í•™ìŠµëœ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ë¡œ, í•œêµ­ì–´ë¥¼ í¬í•¨í•œ 100ê°œ ì´ìƒì˜ ì–¸ì–´ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. ì˜¤ëŠ˜ì€ ë²ˆì—­, ë¬¸ì¥ ì²´í¬, ì´ì•¼ê¸° ì‘ì„±, í˜¹ì€ ë‹¤ë¥¸ ì–¸ì–´ë¡œ ëŒ€í™”ë¥¼ ì›í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë„ì™€ë“œë¦´ê²Œìš”! ì˜ˆë¥¼ ë“¤ì–´, \"í•œêµ­ì–´ë¡œ 50ë‹¨ì–´ì˜ ê°„ë‹¨í•œ ì—¬í–‰ ì´ì•¼ê¸°ë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”\"ë¼ê³  í•´ë„ ì¢‹ì•„ìš”. ğŸ˜Š\n",
      "Human: ì œê°€ ë°©ê¸ˆ ë­ë¼ê³  í–ˆì£ ?\n",
      "AI: \n",
      "\n",
      "ì €ëŠ” ë°©ê¸ˆ 'ì œ ì´ë¦„ì€ ê¹€ì² ìˆ˜ì…ë‹ˆë‹¤.'ë¼ê³  ë§ì”€í•˜ì…¨ìŠµë‹ˆë‹¤! ğŸ˜Š\n",
      "Human: ì œ ì´ë¦„ì˜ ì„±ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "AI: \n",
      "\n",
      "ê¹€ì…ë‹ˆë‹¤. (ê¹€ì€ í•œêµ­ì–´ì—ì„œ ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ì²« ê¸€ìë¡œ, ê¹€ì² ìˆ˜ë‹˜ì˜ ì„±ì€ ê¹€ì…ë‹ˆë‹¤.) ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "# ConversationChainì„ ì‚¬ìš©í•œ ëŒ€í™” ê¸°ë¡ ìœ ì§€\n",
    "print(\"ëŒ€í™” ê¸°ë¡ ìœ ì§€ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    # ë©”ëª¨ë¦¬ë¥¼ í¬í•¨í•œ ëŒ€í™” ì²´ì¸ ìƒì„±\n",
    "    memory = ConversationBufferMemory()\n",
    "    conversation = ConversationChain(\n",
    "        llm=llm,\n",
    "        memory=memory,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # ì—°ì†ëœ ëŒ€í™” í…ŒìŠ¤íŠ¸\n",
    "    conversations = [\n",
    "        \"ì œ ì´ë¦„ì€ ê¹€ì² ìˆ˜ì…ë‹ˆë‹¤.\",\n",
    "        \"ì œê°€ ë°©ê¸ˆ ë­ë¼ê³  í–ˆì£ ?\",\n",
    "        \"ì œ ì´ë¦„ì˜ ì„±ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "    ]\n",
    "    \n",
    "    for i, user_input in enumerate(conversations, 1):\n",
    "        print(f\"\\n[ëŒ€í™” {i}]\")\n",
    "        print(f\"ì‚¬ìš©ì: {user_input}\")\n",
    "        response = conversation.predict(input=user_input)\n",
    "        print(f\"AI: {response}\")\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    print(\"\\nâœ“ ëŒ€í™” ì²´ì¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "    print(f\"\\në©”ëª¨ë¦¬ì— ì €ì¥ëœ ëŒ€í™”:\")\n",
    "    print(memory.buffer)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì˜¤ë¥˜: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innd2lgnms",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì‹¤ìŠµ 4: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ í™œìš©\n",
    "\n",
    "í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°í™”ëœ ì§ˆì˜ì‘ë‹µì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hwc8tof3hdw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ í…ŒìŠ¤íŠ¸\n",
      "================================================================================\n",
      "\n",
      "[í…ŒìŠ¤íŠ¸ 1]\n",
      "ì—­í• : ê¸ˆìœµ, ìŠ¤íƒ€ì¼: ì‰½ê³  ê°„ë‹¨í•˜ê²Œ\n",
      "ì§ˆë¬¸: ETFê°€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "\n",
      "ë‹µë³€:\n",
      "\n",
      "\n",
      "ETFëŠ” ê±°ë˜ì†Œì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ê±°ë˜í•  ìˆ˜ ìˆëŠ” í€ë“œë¡œ, í•œ ë²ˆì— ì—¬ëŸ¬ ì£¼ì‹ì´ë‚˜ ì±„ê¶Œì„ íˆ¬ìí•´ íŠ¹ì • ì§€ìˆ˜ë¥¼ ì¶”ì í•˜ëŠ” ìƒí’ˆì…ë‹ˆë‹¤. ë¹„ìš©ì´ ì ê³  í¸ë¦¬í•´ìš”! ğŸ˜Š...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[í…ŒìŠ¤íŠ¸ 2]\n",
      "ì—­í• : í”„ë¡œê·¸ë˜ë°, ìŠ¤íƒ€ì¼: ê¸°ìˆ ì ìœ¼ë¡œ ìƒì„¸í•˜ê²Œ\n",
      "ì§ˆë¬¸: íŒŒì´ì¬ì˜ ë°ì½”ë ˆì´í„°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
      "\n",
      "ë‹µë³€:\n",
      "\n",
      "\n",
      "# Python Decorators: A Technical Explanation\n",
      "\n",
      "In Python, **decorators** are a powerful feature that allows you to modify or enhance the behavior of functions or methods *without permanently altering their source code*. They're implemented using **higher-order functions** (functions that take other...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "âœ“ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ í™œìš©\n",
    "print(\"í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ í¬í•¨í•œ í…œí”Œë¦¿ ìƒì„±\n",
    "    template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ì¹œì ˆí•œ {role} ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— {style}ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "    \n",
    "    # ì²´ì¸ ìƒì„±\n",
    "    chain = template | llm\n",
    "    \n",
    "    # ë‹¤ì–‘í•œ ì—­í• ê³¼ ìŠ¤íƒ€ì¼ë¡œ í…ŒìŠ¤íŠ¸\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"role\": \"ê¸ˆìœµ\",\n",
    "            \"style\": \"ì‰½ê³  ê°„ë‹¨í•˜ê²Œ\",\n",
    "            \"question\": \"ETFê°€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"í”„ë¡œê·¸ë˜ë°\",\n",
    "            \"style\": \"ê¸°ìˆ ì ìœ¼ë¡œ ìƒì„¸í•˜ê²Œ\",\n",
    "            \"question\": \"íŒŒì´ì¬ì˜ ë°ì½”ë ˆì´í„°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for i, test_case in enumerate(test_cases, 1):\n",
    "        print(f\"\\n[í…ŒìŠ¤íŠ¸ {i}]\")\n",
    "        print(f\"ì—­í• : {test_case['role']}, ìŠ¤íƒ€ì¼: {test_case['style']}\")\n",
    "        print(f\"ì§ˆë¬¸: {test_case['question']}\")\n",
    "        \n",
    "        response = chain.invoke(test_case)\n",
    "        print(f\"\\në‹µë³€:\\n{response.content[:300]}...\")  # ì²˜ìŒ 300ìë§Œ ì¶œë ¥\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    print(\"\\nâœ“ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì˜¤ë¥˜: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jixy1rbeseq",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì‹¤ìŠµ ì™„ë£Œ!\n",
    "\n",
    "ì¶•í•˜í•©ë‹ˆë‹¤! LM Studioì™€ LangChain ì—°ë™ì˜ ê¸°ë³¸ ì‚¬ìš©ë²•ì„ ëª¨ë‘ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### í•™ìŠµí•œ ë‚´ìš© ìš”ì•½\n",
    "\n",
    "1. **í™˜ê²½ ì„¤ì •**: LM Studio ë¡œì»¬ ì„œë²„ ì—°ê²° ë°©ë²•\n",
    "2. **ê¸°ë³¸ ì§ˆì˜ì‘ë‹µ**: `invoke()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•œ ê°„ë‹¨í•œ ì§ˆì˜ì‘ë‹µ\n",
    "3. **ë‹¤ì–‘í•œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸**: ì—¬ëŸ¬ ì£¼ì œì— ëŒ€í•œ ì§ˆë¬¸ ì²˜ë¦¬\n",
    "4. **ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ**: `stream()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ì‘ë‹µ\n",
    "5. **ëŒ€í™” ê¸°ë¡ ìœ ì§€**: `ConversationChain`ì„ ì‚¬ìš©í•œ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€\n",
    "6. **í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿**: êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ ë‹¤ì–‘í•œ ì—­í•  ìˆ˜í–‰\n",
    "\n",
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "- RAG (Retrieval-Augmented Generation) ì‹œìŠ¤í…œ êµ¬ì¶•\n",
    "- ì„ë² ë”© ëª¨ë¸ê³¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ í™œìš©\n",
    "- ë³µì¡í•œ ëŒ€í™” íë¦„ ê´€ë¦¬\n",
    "- í”„ë¡œë•ì…˜ í™˜ê²½ ë°°í¬\n",
    "\n",
    "### ì£¼ì˜ì‚¬í•­\n",
    "\n",
    "âš ï¸ **LM Studio ì„œë²„ë¥¼ ë¨¼ì € ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤!**\n",
    "- LM Studio ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰\n",
    "- Local Server íƒ­ì—ì„œ ëª¨ë¸ ë¡œë“œ\n",
    "- ì„œë²„ ì‹œì‘ (ê¸°ë³¸ ì£¼ì†Œ: http://localhost:14000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c9536f",
   "metadata": {},
   "source": [
    "**í™œìš© íŒ**:\n",
    "\n",
    "1. **ëª¨ë¸ ì„ íƒ**: LM Studioì—ì„œ ë¡œë“œí•œ ëª¨ë¸ì´ ì„œë²„ì— í™œì„±í™”ë˜ì–´ ìˆì–´ì•¼ í•¨\n",
    "2. **í¬íŠ¸ í™•ì¸**: ê¸°ë³¸ í¬íŠ¸ëŠ” 14000ì´ì§€ë§Œ, LM Studio ì„¤ì •ì—ì„œ ë³€ê²½ ê°€ëŠ¥\n",
    "3. **ì„ë² ë”©**: LM StudioëŠ” í…ìŠ¤íŠ¸ ìƒì„±ë§Œ ì§€ì›í•˜ë¯€ë¡œ, RAG êµ¬í˜„ ì‹œ ë³„ë„ ì„ë² ë”© ëª¨ë¸ í•„ìš” (HuggingFace, Ollama ë“±)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
