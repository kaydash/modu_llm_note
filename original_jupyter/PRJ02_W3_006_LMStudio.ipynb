{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d611666",
   "metadata": {},
   "source": [
    "## LM Studio 기본 사용법\n",
    "\n",
    "### 1. 설치 및 모델 다운로드\n",
    "\n",
    "- [lmstudio.ai](https://lmstudio.ai)에서 다운로드\n",
    "- Windows, Mac, Linux 지원"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4e9aae",
   "metadata": {},
   "source": [
    "### 2. 로컬 서버 실행\n",
    "\n",
    "1. 좌측 메뉴에서 **Local Server** 클릭\n",
    "2. 상단에서 다운로드한 모델 선택\n",
    "3. **Status 변경** 버튼 클릭 (시작 대기 상태로 변경)\n",
    "4. 기본 주소: `http://localhost:14000`\n",
    "\n",
    "### 3. 채팅 인터페이스 사용\n",
    "\n",
    "- 좌측 메뉴에서 **Chat** 클릭\n",
    "- 모델 선택 후 대화 시작\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6538ac",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## LangChain 연동 방법\n",
    "\n",
    "- **OpenAI 호환 API 사용**\n",
    "- LM Studio는 OpenAI API와 호환되므로 `ChatOpenAI` 클래스를 사용하여 연결할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "uwni74t8xs7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\miniconda3\\envs\\modu2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 라이브러리 import 완료\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 import\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "print(\"✓ 라이브러리 import 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c87a885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ LM Studio 연결 설정 완료\n",
      "  - Base URL: http://localhost:14000/v1\n",
      "  - Temperature: 0.7\n"
     ]
    }
   ],
   "source": [
    "# LM Studio 로컬 서버와 연결\n",
    "# 주의: LM Studio에서 Local Server를 먼저 시작해야 합니다!\n",
    "\n",
    "try:\n",
    "    llm = ChatOpenAI(\n",
    "        base_url=\"http://localhost:14000/v1\",\n",
    "        api_key=\"lm-studio\",  # LM Studio는 API 키가 필요없지만 형식상 입력\n",
    "        model=\"qwen/qwen3-4b-thinking-2507\",  # 실제 모델명은 무관\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    print(\"✓ LM Studio 연결 설정 완료\")\n",
    "    print(f\"  - Base URL: http://localhost:14000/v1\")\n",
    "    print(f\"  - Temperature: 0.7\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 연결 설정 오류: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b4655c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 응답 성공!\n",
      "\n",
      "질문: 안녕하세요! LangChain은 무엇인가요?\n",
      "\n",
      "답변:\n",
      "\n",
      "\n",
      "안녕하세요! LangChain은 대형 언어 모델(LLM)을 기반으로 애플리케이션을 개발하는 데 사용되는 오픈소스 프레임워크입니다. 이 프레임워크를 통해 OpenAI, Hugging Face 등 다양한 LLM과 연동하여 채팅봇, 문서 분석, 데이터 처리 등의 기능을 쉽게 구축할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 기본 사용 예시 - 간단한 질의응답\n",
    "try:\n",
    "    response = llm.invoke(\"안녕하세요! LangChain은 무엇인가요?\")\n",
    "    print(\"✓ 응답 성공!\")\n",
    "    print(f\"\\n질문: 안녕하세요! LangChain은 무엇인가요?\")\n",
    "    print(f\"\\n답변:\\n{response.content}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 오류 발생: {e}\")\n",
    "    print(\"\\n💡 해결 방법:\")\n",
    "    print(\"  1. LM Studio 애플리케이션이 실행 중인지 확인\")\n",
    "    print(\"  2. Local Server 탭에서 모델을 로드하고 서버를 시작했는지 확인\")\n",
    "    print(\"  3. 서버 주소가 http://localhost:14000 인지 확인\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1iwl74ccy12",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 실습 1: 다양한 질문 테스트\n",
    "\n",
    "LM Studio로 다양한 유형의 질문을 테스트해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hn5fe70hqla",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "다양한 질문 테스트\n",
      "================================================================================\n",
      "\n",
      "[질문 1] 파이썬에서 리스트와 튜플의 차이점은 무엇인가요?\n",
      "\n",
      "[답변 1]\n",
      "\n",
      "\n",
      "파이썬에서 **리스트**(list)와 **튜플**(tuple)의 주요 차이점은 다음과 같습니다:\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **불변성(Immutability)**\n",
      "- **리스트**: **가변**(mutable)입니다.  \n",
      "  → 요소를 추가/삭제/수정할 수 있습니다.  \n",
      "  ```python\n",
      "  my_list = [1, 2, 3]\n",
      "  my_list.appe...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[질문 2] 머신러닝과 딥러닝의 차이를 간단히 설명해주세요.\n",
      "\n",
      "[답변 2]\n",
      "\n",
      "\n",
      "머신러닝은 데이터에서 패턴을 학습해 예측하는 기술입니다. 딥러닝은 머신러닝의 한 부분으로, 여러 층을 가진 신경망을 사용해 이미지, 음성, 텍스트 등 복잡한 데이터에서 자동으로 특징을 추출하는 기술입니다. 즉, 딥러닝은 머신러닝의 한 종류로 더 복잡한 문제 해결에 특화된 기술입니다....\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[질문 3] ETF란 무엇인가요?\n",
      "\n",
      "[답변 3]\n",
      "\n",
      "\n",
      "ETF(Exchange-Traded Fund)는 주식 거래소에서 실시간으로 거래가 가능한 펀드로, 특정 지수, 산업 분야, 자산 등에 투자한 포트폴리오를 추적하는 투자 상품입니다. 주로 지수를 추적하는 '지수 추적형 펀드'로, 미국 S&P 500 지수를 추적하는 SPY와 같이 다양한 자산을 포함할 수 있습니다. ETF는 주식 펀드와 달리 매일 한 번 평...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 다양한 질문 테스트\n",
    "questions = [\n",
    "    \"파이썬에서 리스트와 튜플의 차이점은 무엇인가요?\",\n",
    "    \"머신러닝과 딥러닝의 차이를 간단히 설명해주세요.\",\n",
    "    \"ETF란 무엇인가요?\"\n",
    "]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"다양한 질문 테스트\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, question in enumerate(questions, 1):\n",
    "    try:\n",
    "        print(f\"\\n[질문 {i}] {question}\")\n",
    "        response = llm.invoke(question)\n",
    "        print(f\"\\n[답변 {i}]\\n{response.content[:200]}...\")  # 처음 200자만 출력\n",
    "        print(\"-\" * 80)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ivk2sqyv6a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 실습 2: 스트리밍 응답\n",
    "\n",
    "실시간으로 응답을 받아보는 스트리밍 방식을 테스트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "jhbl5igk7h",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스트리밍 응답 테스트\n",
      "================================================================================\n",
      "질문: 인공지능의 역사를 간단히 설명해주세요.\n",
      "\n",
      "답변: \n",
      "\n",
      "인공지능의 역사  \n",
      "\n",
      "- **1950년대**: 앨런 튜링이 투링 테스트를 제안하고, 1956년 다르트머스 회의에서 \"인공지능\" 용어가 창안되었습니다. 초기 연구로 로직 테오리스트와 GPS가 개발되었습니다.  \n",
      "- **1970년대**: 첫 번째 AI winter(연구 자금 감소)가 발생했으며, MYCIN 등 전문 시스템이 개발되었습니다.  \n",
      "- **1980년대~1990년대**: 기계 학습, 베이지안 네트워크가 발전했고, 전문 시스템이 널리 적용되었습니다.  \n",
      "- **2010년대 이후**: 딥러닝(2012년 AlexNet)과 대형 언어 모델(GPT-3, GPT-4)이 등장해 현대 AI를 이끌었습니다.\n",
      "\n",
      "✓ 스트리밍 완료!\n"
     ]
    }
   ],
   "source": [
    "# 스트리밍 응답 예시\n",
    "print(\"스트리밍 응답 테스트\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "question = \"인공지능의 역사를 간단히 설명해주세요.\"\n",
    "print(f\"질문: {question}\\n\")\n",
    "print(\"답변: \", end=\"\")\n",
    "\n",
    "try:\n",
    "    # 스트리밍 방식으로 응답 받기\n",
    "    for chunk in llm.stream(question):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "    print(\"\\n\\n✓ 스트리밍 완료!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ 오류: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mffwuerxtii",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 실습 3: 대화 기록 유지 (ConversationChain)\n",
    "\n",
    "이전 대화 내용을 기억하는 대화형 시스템을 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8fgacbkp5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대화 기록 유지 테스트\n",
      "================================================================================\n",
      "\n",
      "[대화 1]\n",
      "사용자: 제 이름은 김철수입니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaydash\\AppData\\Local\\Temp\\ipykernel_27048\\24991076.py:7: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n",
      "C:\\Users\\kaydash\\AppData\\Local\\Temp\\ipykernel_27048\\24991076.py:8: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "\n",
      "안녕하세요, 김철수님! 저는 Qwen이에요. 저는 2024년까지 학습된 대규모 언어 모델로, 한국어를 포함한 100개 이상의 언어를 지원합니다. 오늘은 번역, 문장 체크, 이야기 작성, 혹은 다른 언어로 대화를 원하시면 언제든지 도와드릴게요! 예를 들어, \"한국어로 50단어의 간단한 여행 이야기를 만들어 주세요\"라고 해도 좋아요. 😊\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[대화 2]\n",
      "사용자: 제가 방금 뭐라고 했죠?\n",
      "AI: \n",
      "\n",
      "저는 방금 '제 이름은 김철수입니다.'라고 말씀하셨습니다! 😊\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[대화 3]\n",
      "사용자: 제 이름의 성은 무엇인가요?\n",
      "AI: \n",
      "\n",
      "김입니다. (김은 한국어에서 성을 나타내는 첫 글자로, 김철수님의 성은 김입니다.) 😊\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✓ 대화 체인 테스트 완료!\n",
      "\n",
      "메모리에 저장된 대화:\n",
      "Human: 제 이름은 김철수입니다.\n",
      "AI: \n",
      "\n",
      "안녕하세요, 김철수님! 저는 Qwen이에요. 저는 2024년까지 학습된 대규모 언어 모델로, 한국어를 포함한 100개 이상의 언어를 지원합니다. 오늘은 번역, 문장 체크, 이야기 작성, 혹은 다른 언어로 대화를 원하시면 언제든지 도와드릴게요! 예를 들어, \"한국어로 50단어의 간단한 여행 이야기를 만들어 주세요\"라고 해도 좋아요. 😊\n",
      "Human: 제가 방금 뭐라고 했죠?\n",
      "AI: \n",
      "\n",
      "저는 방금 '제 이름은 김철수입니다.'라고 말씀하셨습니다! 😊\n",
      "Human: 제 이름의 성은 무엇인가요?\n",
      "AI: \n",
      "\n",
      "김입니다. (김은 한국어에서 성을 나타내는 첫 글자로, 김철수님의 성은 김입니다.) 😊\n"
     ]
    }
   ],
   "source": [
    "# ConversationChain을 사용한 대화 기록 유지\n",
    "print(\"대화 기록 유지 테스트\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    # 메모리를 포함한 대화 체인 생성\n",
    "    memory = ConversationBufferMemory()\n",
    "    conversation = ConversationChain(\n",
    "        llm=llm,\n",
    "        memory=memory,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # 연속된 대화 테스트\n",
    "    conversations = [\n",
    "        \"제 이름은 김철수입니다.\",\n",
    "        \"제가 방금 뭐라고 했죠?\",\n",
    "        \"제 이름의 성은 무엇인가요?\"\n",
    "    ]\n",
    "    \n",
    "    for i, user_input in enumerate(conversations, 1):\n",
    "        print(f\"\\n[대화 {i}]\")\n",
    "        print(f\"사용자: {user_input}\")\n",
    "        response = conversation.predict(input=user_input)\n",
    "        print(f\"AI: {response}\")\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    print(\"\\n✓ 대화 체인 테스트 완료!\")\n",
    "    print(f\"\\n메모리에 저장된 대화:\")\n",
    "    print(memory.buffer)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 오류: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innd2lgnms",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 실습 4: 프롬프트 템플릿 활용\n",
    "\n",
    "프롬프트 템플릿을 사용하여 구조화된 질의응답을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hwc8tof3hdw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프롬프트 템플릿 테스트\n",
      "================================================================================\n",
      "\n",
      "[테스트 1]\n",
      "역할: 금융, 스타일: 쉽고 간단하게\n",
      "질문: ETF가 무엇인가요?\n",
      "\n",
      "답변:\n",
      "\n",
      "\n",
      "ETF는 거래소에서 실시간으로 거래할 수 있는 펀드로, 한 번에 여러 주식이나 채권을 투자해 특정 지수를 추적하는 상품입니다. 비용이 적고 편리해요! 😊...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[테스트 2]\n",
      "역할: 프로그래밍, 스타일: 기술적으로 상세하게\n",
      "질문: 파이썬의 데코레이터는 무엇인가요?\n",
      "\n",
      "답변:\n",
      "\n",
      "\n",
      "# Python Decorators: A Technical Explanation\n",
      "\n",
      "In Python, **decorators** are a powerful feature that allows you to modify or enhance the behavior of functions or methods *without permanently altering their source code*. They're implemented using **higher-order functions** (functions that take other...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✓ 프롬프트 템플릿 테스트 완료!\n"
     ]
    }
   ],
   "source": [
    "# 프롬프트 템플릿 활용\n",
    "print(\"프롬프트 템플릿 테스트\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    # 시스템 메시지와 사용자 메시지를 포함한 템플릿 생성\n",
    "    template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"당신은 친절한 {role} 전문가입니다. 사용자의 질문에 {style}로 답변해주세요.\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "    \n",
    "    # 체인 생성\n",
    "    chain = template | llm\n",
    "    \n",
    "    # 다양한 역할과 스타일로 테스트\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"role\": \"금융\",\n",
    "            \"style\": \"쉽고 간단하게\",\n",
    "            \"question\": \"ETF가 무엇인가요?\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"프로그래밍\",\n",
    "            \"style\": \"기술적으로 상세하게\",\n",
    "            \"question\": \"파이썬의 데코레이터는 무엇인가요?\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for i, test_case in enumerate(test_cases, 1):\n",
    "        print(f\"\\n[테스트 {i}]\")\n",
    "        print(f\"역할: {test_case['role']}, 스타일: {test_case['style']}\")\n",
    "        print(f\"질문: {test_case['question']}\")\n",
    "        \n",
    "        response = chain.invoke(test_case)\n",
    "        print(f\"\\n답변:\\n{response.content[:300]}...\")  # 처음 300자만 출력\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    print(\"\\n✓ 프롬프트 템플릿 테스트 완료!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 오류: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jixy1rbeseq",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 실습 완료!\n",
    "\n",
    "축하합니다! LM Studio와 LangChain 연동의 기본 사용법을 모두 학습했습니다.\n",
    "\n",
    "### 학습한 내용 요약\n",
    "\n",
    "1. **환경 설정**: LM Studio 로컬 서버 연결 방법\n",
    "2. **기본 질의응답**: `invoke()` 메서드를 사용한 간단한 질의응답\n",
    "3. **다양한 질문 테스트**: 여러 주제에 대한 질문 처리\n",
    "4. **스트리밍 응답**: `stream()` 메서드를 사용한 실시간 응답\n",
    "5. **대화 기록 유지**: `ConversationChain`을 사용한 컨텍스트 유지\n",
    "6. **프롬프트 템플릿**: 구조화된 프롬프트로 다양한 역할 수행\n",
    "\n",
    "### 다음 단계\n",
    "\n",
    "- RAG (Retrieval-Augmented Generation) 시스템 구축\n",
    "- 임베딩 모델과 벡터 데이터베이스 활용\n",
    "- 복잡한 대화 흐름 관리\n",
    "- 프로덕션 환경 배포\n",
    "\n",
    "### 주의사항\n",
    "\n",
    "⚠️ **LM Studio 서버를 먼저 시작해야 합니다!**\n",
    "- LM Studio 애플리케이션 실행\n",
    "- Local Server 탭에서 모델 로드\n",
    "- 서버 시작 (기본 주소: http://localhost:14000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c9536f",
   "metadata": {},
   "source": [
    "**활용 팁**:\n",
    "\n",
    "1. **모델 선택**: LM Studio에서 로드한 모델이 서버에 활성화되어 있어야 함\n",
    "2. **포트 확인**: 기본 포트는 14000이지만, LM Studio 설정에서 변경 가능\n",
    "3. **임베딩**: LM Studio는 텍스트 생성만 지원하므로, RAG 구현 시 별도 임베딩 모델 필요 (HuggingFace, Ollama 등)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
