{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2217fa83",
      "metadata": {},
      "source": [
        "# **Langfuse 모니터링**: LLM Observability\n",
        "\n",
        "- Langfuse는 **LLM 애플리케이션의 관찰성(Observability)** 옵션을 제공하는 오픈소스 도구임.\n",
        "\n",
        "- 개발자가 LLM 체인과 에이전트를 **효과적으로 디버깅**하고 모니터링할 수 있도록 지원함.\n",
        "\n",
        "- 주요 기능으로는 체인 실행 **로깅 및 추적**이 포함됨.\n",
        "\n",
        "- **프롬프트 디버깅**과 성능 측정 및 분석 기능을 제공함."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bfd9328",
      "metadata": {
        "id": "8bfd9328"
      },
      "source": [
        "### Langfuse 환경 설정\n",
        "\n",
        "📦 계정 가입 및 설정\n",
        "\n",
        "- Langfuse 가입 필요 (https://cloud.langfuse.com) 또는 셀프 호스팅\n",
        "- 오픈소스 (무료) 및 클라우드 버전 (일부 유료)\n",
        "\n",
        "- .env 파일에 환경 변수 설정\n",
        "    ```\n",
        "    LANGFUSE_ENABLED=true\n",
        "    LANGFUSE_HOST=your_langfuse_host_url\n",
        "    LANGFUSE_SECRET_KEY=your_secret_key\n",
        "    LANGFUSE_PUBLIC_KEY=your_public_key\n",
        "    ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "id": "15ac3ddb",
      "metadata": {
        "id": "15ac3ddb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Langfuse 설정 확인:\n",
            "LANGFUSE_ENABLED: true\n",
            "LANGFUSE_HOST: http://reai.kro.kr:3000\n",
            "PUBLIC_KEY 존재 여부: Yes\n",
            "SECRET_KEY 존재 여부: Yes\n",
            "\n",
            "✅ Langfuse 클라이언트 초기화 완료\n",
            "✅ CallbackHandler 초기화 성공 (기본)\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# Langfuse 초기화 및 설정 확인\n",
        "import os\n",
        "\n",
        "print(\"Langfuse 설정 확인:\")\n",
        "print(f\"LANGFUSE_ENABLED: {os.getenv('LANGFUSE_ENABLED')}\")\n",
        "print(f\"LANGFUSE_HOST: {os.getenv('LANGFUSE_HOST')}\")\n",
        "print(f\"PUBLIC_KEY 존재 여부: {'Yes' if os.getenv('LANGFUSE_PUBLIC_KEY') else 'No'}\")\n",
        "print(f\"SECRET_KEY 존재 여부: {'Yes' if os.getenv('LANGFUSE_SECRET_KEY') else 'No'}\")\n",
        "\n",
        "# Langfuse 클라이언트 초기화 (init_langfuse.py 방식 참고)\n",
        "try:\n",
        "    from langfuse import Langfuse\n",
        "    from langfuse.langchain import CallbackHandler\n",
        "    \n",
        "    # 명시적 파라미터로 클라이언트 생성\n",
        "    langfuse_client = Langfuse(\n",
        "        public_key=os.getenv('LANGFUSE_PUBLIC_KEY'),\n",
        "        secret_key=os.getenv('LANGFUSE_SECRET_KEY'),\n",
        "        host=os.getenv('LANGFUSE_HOST')\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n✅ Langfuse 클라이언트 초기화 완료\")\n",
        "    \n",
        "    # CallbackHandler 여러 방법으로 시도 (init_langfuse.py와 동일한 방식)\n",
        "    langfuse_handler = None\n",
        "    \n",
        "    try:\n",
        "        # 방법 1: 기본 초기화 시도\n",
        "        langfuse_handler = CallbackHandler()\n",
        "        print(\"✅ CallbackHandler 초기화 성공 (기본)\")\n",
        "    except Exception as e1:\n",
        "        try:\n",
        "            # 방법 2: client 매개변수 사용\n",
        "            langfuse_handler = CallbackHandler(client=langfuse_client)\n",
        "            print(\"✅ CallbackHandler 초기화 성공 (client)\")\n",
        "        except Exception as e2:\n",
        "            try:\n",
        "                # 방법 3: 직접 매개변수 전달\n",
        "                langfuse_handler = CallbackHandler(\n",
        "                    public_key=os.getenv('LANGFUSE_PUBLIC_KEY'),\n",
        "                    secret_key=os.getenv('LANGFUSE_SECRET_KEY'),\n",
        "                    host=os.getenv('LANGFUSE_HOST')\n",
        "                )\n",
        "                print(\"✅ CallbackHandler 초기화 성공 (직접)\")\n",
        "            except Exception as e3:\n",
        "                print(f\"❌ CallbackHandler 초기화 실패: {e1}, {e2}, {e3}\")\n",
        "                langfuse_handler = None\n",
        "    \n",
        "    # 전역 변수로 저장\n",
        "    globals()['langfuse_handler'] = langfuse_handler\n",
        "    globals()['langfuse_client'] = langfuse_client\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Langfuse 초기화 실패: {e}\")\n",
        "    globals()['langfuse_handler'] = None\n",
        "    globals()['langfuse_client'] = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "id": "fd6cb589",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Langfuse 연결 및 추적 상태 진단\n",
            "==================================================\n",
            "✅ 서버 연결: 200 - http://reai.kro.kr:3000\n",
            "✅ 인증 정보: PUBLIC_KEY(pk-lf-b247...), SECRET_KEY(sk-lf-ce56...)\n",
            "❌ create_trace 실패: 'Langfuse' object has no attribute 'create_trace'\n",
            "❌ 구버전 trace도 실패: 'Langfuse' object has no attribute 'trace'\n",
            "❌ CallbackHandler 초기화 실패: LangchainCallbackHandler.__init__() got an unexpected keyword argument 'secret_key'\n",
            "\n",
            "==================================================\n",
            "진단 완료! CallbackHandler가 작동한다면 LLM 호출시 추적됩니다.\n"
          ]
        }
      ],
      "source": [
        "# Langfuse 연결 상태 및 추적 테스트 (개선된 버전)\n",
        "import requests\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"🔍 Langfuse 연결 및 추적 상태 진단\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 1. 서버 연결 테스트\n",
        "try:\n",
        "    host = os.getenv('LANGFUSE_HOST')\n",
        "    response = requests.get(f\"{host}/api/public/health\", timeout=10)\n",
        "    print(f\"✅ 서버 연결: {response.status_code} - {host}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ 서버 연결 실패: {e}\")\n",
        "\n",
        "# 2. 인증 정보 확인\n",
        "public_key = os.getenv('LANGFUSE_PUBLIC_KEY')\n",
        "secret_key = os.getenv('LANGFUSE_SECRET_KEY')\n",
        "\n",
        "if public_key and secret_key:\n",
        "    print(f\"✅ 인증 정보: PUBLIC_KEY({public_key[:10]}...), SECRET_KEY({secret_key[:10]}...)\")\n",
        "else:\n",
        "    print(\"❌ 인증 정보 누락\")\n",
        "\n",
        "# 3. 버전별 API 호출 테스트\n",
        "try:\n",
        "    from langfuse import Langfuse\n",
        "    \n",
        "    # 클라이언트 생성\n",
        "    client = Langfuse(\n",
        "        public_key=public_key,\n",
        "        secret_key=secret_key,\n",
        "        host=host\n",
        "    )\n",
        "    \n",
        "    # 새로운 API 방식으로 트레이스 생성\n",
        "    try:\n",
        "        trace = client.create_trace(\n",
        "            name=\"direct_api_test\",\n",
        "            metadata={\"test_time\": datetime.now().isoformat()}\n",
        "        )\n",
        "        print(f\"✅ create_trace API 호출 성공\")\n",
        "        print(f\"📍 트레이스 ID: {trace.id}\")\n",
        "        print(f\"🔗 웹에서 확인: {host}/trace/{trace.id}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ create_trace 실패: {e}\")\n",
        "        \n",
        "        # 구버전 방식 시도\n",
        "        try:\n",
        "            trace = client.trace(\n",
        "                name=\"direct_api_test_old\",\n",
        "                metadata={\"test_time\": datetime.now().isoformat()}\n",
        "            )\n",
        "            print(f\"✅ 구버전 trace API 호출 성공\")\n",
        "            print(f\"📍 트레이스 ID: {trace.id}\")\n",
        "        except Exception as e2:\n",
        "            print(f\"❌ 구버전 trace도 실패: {e2}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ Langfuse 클라이언트 생성 실패: {e}\")\n",
        "\n",
        "# 4. CallbackHandler 테스트\n",
        "try:\n",
        "    from langfuse.langchain import CallbackHandler\n",
        "    \n",
        "    handler = CallbackHandler(\n",
        "        public_key=public_key,\n",
        "        secret_key=secret_key,\n",
        "        host=host,\n",
        "        debug=True\n",
        "    )\n",
        "    print(f\"✅ CallbackHandler 초기화 성공\")\n",
        "    print(f\"🎯 LangChain을 통한 추적이 가능합니다\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ CallbackHandler 초기화 실패: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"진단 완료! CallbackHandler가 작동한다면 LLM 호출시 추적됩니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "129b8eee",
      "metadata": {
        "id": "129b8eee"
      },
      "source": [
        "---\n",
        "\n",
        "# LCEL(LangChain Expression Language) \n",
        "\n",
        "- **LCEL**은 `|` 연산자를 사용해 컴포넌트들을 순차적으로 연결하는 선언적 체이닝을 지원합니다\n",
        "\n",
        "- **재사용성**이 높아 정의된 체인을 다른 체인의 컴포넌트로 활용할 수 있습니다\n",
        "\n",
        "- **다양한 실행 방식**(.invoke(), .batch(), .stream(), .astream())으로 동기/비동기 처리가 가능합니다\n",
        "\n",
        "- **배치 처리**시 자동 최적화를 통해 효율적인 작업 수행이 가능합니다\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68074eb8",
      "metadata": {
        "id": "68074eb8"
      },
      "source": [
        "#### 1) **Prompt + LLM**\n",
        "\n",
        "* 기본 구조: `Prompt | LLM` 형태로, 파이프(|) 연산자를 사용해 프롬프트와 LLM을 순차적으로 연결합니다.\n",
        "\n",
        "* 데이터 흐름: 사용자 입력이 Prompt 템플릿을 통해 처리된 후, LLM에 전달되어 최종 응답이 생성됩니다.\n",
        "\n",
        "* 실행 순서: 파이프라인은 왼쪽에서 오른쪽으로 순차적으로 실행되며, 각 컴포넌트의 출력이 다음 컴포넌트의 입력으로 전달됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "id": "3722db67",
      "metadata": {
        "id": "3722db67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 저장된 Langfuse CallbackHandler 사용\n",
            "🎯 Langfuse 추적이 활성화된 LLM 생성 완료\n",
            "\n",
            "📝 LLM 호출 시작...\n",
            "✅ LLM 호출 완료\n",
            "📋 응답: 탄소의 원자 번호는 6입니다. 이는 탄소 원자가 6개의 양성자를 가지고 있음을 의미합니다.\n",
            "\n",
            "🔍 Langfuse 웹에서 확인: http://reai.kro.kr:3000/traces\n",
            "💡 몇 초 후 웹 인터페이스에 트레이스가 나타납니다.\n",
            "✅ LLM 호출 완료\n",
            "📋 응답: 탄소의 원자 번호는 6입니다. 이는 탄소 원자가 6개의 양성자를 가지고 있음을 의미합니다.\n",
            "\n",
            "🔍 Langfuse 웹에서 확인: http://reai.kro.kr:3000/traces\n",
            "💡 몇 초 후 웹 인터페이스에 트레이스가 나타납니다.\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "\n",
        "# 전역에서 langfuse_handler 가져오기\n",
        "try:\n",
        "    langfuse_handler = globals().get('langfuse_handler')\n",
        "    if langfuse_handler:\n",
        "        print(\"✅ 저장된 Langfuse CallbackHandler 사용\")\n",
        "    else:\n",
        "        print(\"❌ Langfuse CallbackHandler가 없습니다. 추적 없이 진행합니다.\")\n",
        "except:\n",
        "    print(\"❌ Langfuse CallbackHandler 로드 실패. 추적 없이 진행합니다.\")\n",
        "    langfuse_handler = None\n",
        "\n",
        "# LLM model with Langfuse tracking\n",
        "if langfuse_handler:\n",
        "    llm = ChatOpenAI(\n",
        "        model=\"gpt-4o-mini\", \n",
        "        temperature=0.3, \n",
        "        top_p=0.95,\n",
        "        callbacks=[langfuse_handler]\n",
        "    )\n",
        "    print(\"🎯 Langfuse 추적이 활성화된 LLM 생성 완료\")\n",
        "else:\n",
        "    llm = ChatOpenAI(\n",
        "        model=\"gpt-4o-mini\", \n",
        "        temperature=0.3, \n",
        "        top_p=0.95\n",
        "    )\n",
        "    print(\"⚪ 추적 없는 LLM 생성 완료\")\n",
        "\n",
        "# 모델에 프롬프트를 입력 (init_langfuse.py 방식처럼 config 사용)\n",
        "print(\"\\n📝 LLM 호출 시작...\")\n",
        "try:\n",
        "    if langfuse_handler:\n",
        "        response = llm.invoke(\n",
        "            \"탄소의 원자 번호는 무엇인가요?\",\n",
        "            config={\"callbacks\": [langfuse_handler]}\n",
        "        )\n",
        "    else:\n",
        "        response = llm.invoke(\"탄소의 원자 번호는 무엇인가요?\")\n",
        "        \n",
        "    print(\"✅ LLM 호출 완료\")\n",
        "    print(f\"📋 응답: {response.content}\")\n",
        "    \n",
        "    if langfuse_handler:\n",
        "        print(f\"\\n🔍 Langfuse 웹에서 확인: {os.getenv('LANGFUSE_HOST')}/traces\")\n",
        "        print(\"💡 몇 초 후 웹 인터페이스에 트레이스가 나타납니다.\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"❌ LLM 호출 실패: {e}\")\n",
        "\n",
        "# 전역 변수로 저장\n",
        "globals()['llm'] = llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "9e87eef4",
      "metadata": {
        "id": "9e87eef4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='탄소의 원자 번호는 6입니다. 이는 탄소 원자가 6개의 양성자를 가지고 있음을 의미합니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 18, 'total_tokens': 46, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C9tCpKusW5NhT2XlbahHyp3GEm3V0', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--a2dd77cc-676e-424d-88f8-380ef037ed4a-0', usage_metadata={'input_tokens': 18, 'output_tokens': 28, 'total_tokens': 46, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 응답 객체 확인\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "47ce51f7",
      "metadata": {
        "id": "47ce51f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'탄소의 원자 번호는 6입니다. 이는 탄소 원자가 6개의 양성자를 가지고 있음을 의미합니다.'"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 응답 객체의 텍스트를 확인\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "552cd7af",
      "metadata": {
        "id": "552cd7af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'token_usage': {'completion_tokens': 28,\n",
              "  'prompt_tokens': 18,\n",
              "  'total_tokens': 46,\n",
              "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
              "   'audio_tokens': 0,\n",
              "   'reasoning_tokens': 0,\n",
              "   'rejected_prediction_tokens': 0},\n",
              "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
              " 'model_name': 'gpt-4o-mini-2024-07-18',\n",
              " 'system_fingerprint': 'fp_560af6e559',\n",
              " 'id': 'chatcmpl-C9tCpKusW5NhT2XlbahHyp3GEm3V0',\n",
              " 'service_tier': 'default',\n",
              " 'finish_reason': 'stop',\n",
              " 'logprobs': None}"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 응답 객체의 메타데이터를 확인\n",
        "response.response_metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ef7d47a",
      "metadata": {},
      "source": [
        "**Langfuse에서 추적 결과 확인**\n",
        "\n",
        "- Langfuse 웹 인터페이스에서 LLM 호출이 추적됨\n",
        "- 프롬프트, 응답, 메타데이터가 모두 기록됨\n",
        "- 성능 및 비용 분석 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "0113cf90",
      "metadata": {
        "id": "0113cf90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "템플릿 변수:\n",
            "- 필수 변수: ['question', 'topic']\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# 템플릿 문자열 정의\n",
        "template = \"\"\"\n",
        "당신은 {topic} 분야의 전문가입니다. {topic}에 관한 다음 질문에 답변해주세요.\n",
        "질문: {question}\n",
        "답변: \"\"\"\n",
        "\n",
        "# PromptTemplate 객체 생성\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "print(\"템플릿 변수:\")\n",
        "print(f\"- 필수 변수: {prompt.input_variables}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "id": "c801f727",
      "metadata": {
        "id": "c801f727"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['question', 'topic'], input_types={}, partial_variables={}, template='\\n당신은 {topic} 분야의 전문가입니다. {topic}에 관한 다음 질문에 답변해주세요.\\n질문: {question}\\n답변: ')\n",
              "| ChatOpenAI(callbacks=[<langfuse.langchain.CallbackHandler.LangchainCallbackHandler object at 0x000001DEEC73D3D0>], client=<openai.resources.chat.completions.completions.Completions object at 0x000001DEEC4FD790>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001DEEC4FDE80>, root_client=<openai.OpenAI object at 0x000001DEEC4FDF10>, root_async_client=<openai.AsyncOpenAI object at 0x000001DEEC4FDFD0>, model_name='gpt-4o-mini', temperature=0.3, model_kwargs={}, openai_api_key=SecretStr('**********'), top_p=0.95)"
            ]
          },
          "execution_count": 149,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# chain을 구성\n",
        "chain = prompt | llm\n",
        "\n",
        "# chain 객체 확인\n",
        "chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "id": "6d4f916f",
      "metadata": {
        "id": "6d4f916f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'properties': {'question': {'title': 'Question', 'type': 'string'},\n",
              "  'topic': {'title': 'Topic', 'type': 'string'}},\n",
              " 'required': ['question', 'topic'],\n",
              " 'title': 'PromptInput',\n",
              " 'type': 'object'}"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# chain 객체의 입력 스키마를 확인\n",
        "chain.input_schema.model_json_schema() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "id": "6015e000",
      "metadata": {
        "id": "6015e000"
      },
      "outputs": [],
      "source": [
        "# chain 실행\n",
        "response = chain.invoke( \n",
        "    {\n",
        "        \"topic\": \"화학(Chemistry)\", \n",
        "        \"question\": \"탄소의 원자 번호는 무엇인가요?\"\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "id": "fa75f9ee",
      "metadata": {
        "id": "fa75f9ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='탄소의 원자 번호는 6입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 54, 'total_tokens': 65, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C9tCqxVruYw92FMmLNGDaxRRPrJSN', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--0121a642-531a-4aa0-9278-0afebdd20542-0', usage_metadata={'input_tokens': 54, 'output_tokens': 11, 'total_tokens': 65, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 응답 객체를 출력\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "id": "fb0a3843",
      "metadata": {
        "id": "fb0a3843"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'탄소의 원자 번호는 6입니다.'"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 응답 객체의 텍스트를 출력\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "id": "c6c5710c",
      "metadata": {
        "id": "c6c5710c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'token_usage': {'completion_tokens': 11,\n",
              "  'prompt_tokens': 54,\n",
              "  'total_tokens': 65,\n",
              "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
              "   'audio_tokens': 0,\n",
              "   'reasoning_tokens': 0,\n",
              "   'rejected_prediction_tokens': 0},\n",
              "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
              " 'model_name': 'gpt-4o-mini-2024-07-18',\n",
              " 'system_fingerprint': 'fp_560af6e559',\n",
              " 'id': 'chatcmpl-C9tCqxVruYw92FMmLNGDaxRRPrJSN',\n",
              " 'service_tier': 'default',\n",
              " 'finish_reason': 'stop',\n",
              " 'logprobs': None}"
            ]
          },
          "execution_count": 154,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 응답 객체의 메타데이터를 출력\n",
        "response.response_metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef365538",
      "metadata": {},
      "source": [
        "**Langfuse에서 체인 실행 추적**\n",
        "\n",
        "- 체인의 각 단계(Prompt → LLM → OutputParser)가 추적됨\n",
        "- 실행 시간과 토큰 사용량 분석 가능\n",
        "- 디버깅과 최적화에 유용한 정보 제공"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "983d4157",
      "metadata": {
        "id": "983d4157"
      },
      "source": [
        "#### **2) Prompt + LLM + Output Parser**\n",
        "\n",
        "* 데이터 파이프라인: `Prompt | LLM | OutputParser` 형태로 구성되어 LLM의 출력을 구조화된 형식으로 변환합니다.\n",
        "\n",
        "* Parser 종류: JSON, XML 등 다양한 형식의 파서를 지원하여 LLM 출력을 원하는 데이터 구조로 변환할 수 있습니다.\n",
        "\n",
        "* 유효성 검증: Parser가 출력 형식을 검증하여 잘못된 형식의 응답을 필터링하고 안정적인 데이터 처리를 보장합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "id": "7e6b7607",
      "metadata": {
        "id": "7e6b7607"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'탄소의 원자 번호는 6입니다.'"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### 문자열 출력 파서 \n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 출력 파서를 생성\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 출력 파서를 실행\n",
        "output_parser.invoke(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "id": "158608d9",
      "metadata": {
        "id": "158608d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'탄소의 원자 번호는 6입니다.'"
            ]
          },
          "execution_count": 156,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 출력 파서를 chain에 추가\n",
        "chain = prompt | llm | output_parser\n",
        "\n",
        "# chain을 실행\n",
        "response = chain.invoke(\n",
        "    {\n",
        "        \"topic\": \"화학(Chemistry)\", \n",
        "        \"question\": \"탄소의 원자 번호는 무엇인가요?\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# 응답 객체를 출력\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "id": "1e95ba99",
      "metadata": {
        "id": "1e95ba99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'properties': {'question': {'title': 'Question', 'type': 'string'},\n",
              "  'topic': {'title': 'Topic', 'type': 'string'}},\n",
              " 'required': ['question', 'topic'],\n",
              " 'title': 'PromptInput',\n",
              " 'type': 'object'}"
            ]
          },
          "execution_count": 157,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# input_schema (chain)\n",
        "chain.input_schema.model_json_schema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "id": "ba0d6997",
      "metadata": {
        "id": "ba0d6997"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'properties': {'question': {'title': 'Question', 'type': 'string'},\n",
              "  'topic': {'title': 'Topic', 'type': 'string'}},\n",
              " 'required': ['question', 'topic'],\n",
              " 'title': 'PromptInput',\n",
              " 'type': 'object'}"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# input_schema (prompt)\n",
        "prompt.input_schema.model_json_schema()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48c9d7e7",
      "metadata": {},
      "source": [
        "**Langfuse에서 파이프라인 추적**\n",
        "\n",
        "- Output Parser가 추가된 전체 파이프라인 추적\n",
        "- 각 컴포넌트의 입력/출력 데이터 확인 가능\n",
        "- 성능 병목 지점 식별 용이"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4456bde9",
      "metadata": {
        "id": "4456bde9"
      },
      "source": [
        "---\n",
        "# **Runnable**\n",
        "\n",
        "* 실행 인터페이스: 모든 LangChain 컴포넌트는 Runnable 인터페이스를 구현하여 일관된 방식으로 실행됩니다.\n",
        "\n",
        "* 실행 메서드: `.invoke()`, `.batch()`, `.stream()`, `.astream()` 등 다양한 실행 방식을 제공합니다.\n",
        "\n",
        "* 호환성: 모든 Runnable 컴포넌트는 파이프(|) 연산자를 통해 연결 가능하며, 재사용이 용이합니다.\n",
        "\n",
        "* Runnable의 주요 유형:\n",
        "\n",
        "    * `RunnableSequence`: 여러 Runnable을 순차적으로 실행\n",
        "    * `RunnablePassthrough`: 입력을 그대로 다음 단계로 전달    \n",
        "    * `RunnableParallel`: 여러 Runnable을 병렬로 실행\n",
        "    * `RunnableLambda`: 파이썬 함수를 Runnable로 래핑하여 체인에서 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "022d0cfd",
      "metadata": {},
      "source": [
        "#### 1) **RunnableSequence**\n",
        "\n",
        "- **RunnableSequence**는 컴포넌트들을 연결하여 순차적으로 데이터를 처리하는 체인입니다\n",
        "\n",
        "- `|` 연산자로 연결된 각 단계의 **출력이 다음 단계의 입력**으로 전달됩니다\n",
        "\n",
        "- **다양한 실행 방식**(동기/비동기, 배치/스트리밍)을 지원합니다\n",
        "\n",
        "- LLM 체인, 데이터 파이프라인, 자동화된 작업 등 **다단계 처리**에 활용됩니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "id": "ac7c9cd0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Langfuse 추적이 활성화된 번역 모델 생성\n",
            "🔗 번역 체인 생성 완료\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnableSequence\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "\n",
        "# 저장된 langfuse_handler 사용\n",
        "langfuse_handler = globals().get('langfuse_handler')\n",
        "\n",
        "# 컴포넌트 정의\n",
        "prompt = PromptTemplate.from_template(\"'{text}'를 영어로 번역해주세요. 번역된 문장만을 출력해주세요.\")\n",
        "\n",
        "# 모델 정의 (init_langfuse.py 방식으로 callbacks 설정)\n",
        "if langfuse_handler:\n",
        "    model = ChatOpenAI(\n",
        "        model=\"gpt-4o-mini\", \n",
        "        temperature=0.3, \n",
        "        top_p=0.95,\n",
        "        callbacks=[langfuse_handler]\n",
        "    )\n",
        "    print(\"✅ Langfuse 추적이 활성화된 번역 모델 생성\")\n",
        "else:\n",
        "    model = ChatOpenAI(\n",
        "        model=\"gpt-4o-mini\", \n",
        "        temperature=0.3, \n",
        "        top_p=0.95\n",
        "    )\n",
        "    print(\"⚪ 추적 없는 번역 모델 생성\")\n",
        "\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# RunnableSequence 생성 - 함수 사용 \n",
        "translation_chain = RunnableSequence(\n",
        "    first=prompt,\n",
        "    middle=[model],   # 리스트로 전달하는 점에 주의\n",
        "    last=output_parser\n",
        ")\n",
        "\n",
        "print(\"🔗 번역 체인 생성 완료\")\n",
        "\n",
        "# RunnableSequence 생성 - 연산자 사용\n",
        "# translation_chain = prompt | model | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "id": "ae5ff8cd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello\n"
          ]
        }
      ],
      "source": [
        "# 동기 실행\n",
        "result = translation_chain.invoke({\"text\": \"안녕하세요\"})\n",
        "print(result)  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e93eb560",
      "metadata": {},
      "source": [
        "**Langfuse에서 RunnableSequence 추적**\n",
        "\n",
        "- 순차적 실행되는 각 단계가 명확히 추적됨\n",
        "- 번역 작업의 전체 플로우 가시화\n",
        "- 각 단계별 실행 시간 및 성능 분석 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fb7e8bf",
      "metadata": {},
      "source": [
        "#### 2) **RunnableParallel**\n",
        "\n",
        "- **RunnableParallel**은 여러 컴포넌트를 딕셔너리 형태로 구성해 **동시 실행**합니다\n",
        "\n",
        "- 동일한 입력이 모든 병렬 컴포넌트에 전달되며, 결과는 **키-값 쌍**으로 반환됩니다\n",
        "\n",
        "- **데이터 변환**과 **파이프라인 구성**에 특화되어 있으며, 출력 형식을 다음 단계에 맞게 조정할 수 있습니다"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "625baaa0",
      "metadata": {},
      "source": [
        "`(1) 질문 분석 체인`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "id": "1f19926e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "분류 결과: 화학(Chemistry)\n"
          ]
        }
      ],
      "source": [
        "# 질문과 관련된 분야를 찾는 프롬프트\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 출력 파서 정의\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 질문 템플릿 정의\n",
        "question_template = \"\"\"\n",
        "다음 카테고리 중 하나로 입력을 분류하세요. 다른 불필요한 텍스트는 출력하지 마세요:\n",
        "- 화학(Chemistry)\n",
        "- 물리(Physics)\n",
        "- 생물(Biology)\n",
        "\n",
        "# 예시:\n",
        "Q: 사람의 염색체는 모두 몇개가 있나요?\n",
        "A: 생물(Biology)\n",
        "\n",
        "Q: {question}\n",
        "A: \"\"\"\n",
        "\n",
        "# 프롬프트 생성\n",
        "question_prompt = PromptTemplate.from_template(question_template)\n",
        "\n",
        "# 체인 구성\n",
        "question_chain = question_prompt | llm | output_parser\n",
        "\n",
        "# 체인 실행\n",
        "result = question_chain.invoke({\"question\": \"탄소의 원자 번호는 무엇인가요?\"})\n",
        "print(f\"분류 결과: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9afa45a8",
      "metadata": {},
      "source": [
        "`(2) 언어 감지 체인`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "id": "f5ce2883",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "입력: What is the atomic number of carbon?\n",
            "분류 결과: English\n",
            "\n",
            "입력: 탄소의 원자 번호는 무엇인가요?\n",
            "분류 결과: Korean\n",
            "\n",
            "입력: 탄소의 원자 번호는 무엇인가요?\n",
            "분류 결과: Korean\n",
            "\n",
            "입력: ¿Cuál es el número atómico del carbono?\n",
            "분류 결과: Others\n",
            "\n",
            "입력: ¿Cuál es el número atómico del carbono?\n",
            "분류 결과: Others\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 질문에 사용된 언어를 구분하는 프롬프트\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 출력 파서 정의\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 언어 분류 템플릿 정의\n",
        "language_template = \"\"\"\n",
        "입력된 텍스트의 언어를 다음 카테고리 중 하나로 분류하세요. 다른 불필요한 텍스트는 출력하지 마세요:\n",
        "- 영어(English)\n",
        "- 한국어(Korean)\n",
        "- 기타(Others)\n",
        "\n",
        "# 예시:\n",
        "Q: How many protons are in a carbon atom?\n",
        "A: English\n",
        "\n",
        "Q: 탄소의 원자 번호는 무엇인가요?\n",
        "A: Korean\n",
        "\n",
        "Q: ¿Cuál es el número atómico del carbono?\n",
        "A: Others\n",
        "\n",
        "입력: {question}\n",
        "답변: \"\"\"\n",
        "\n",
        "# 프롬프트 생성\n",
        "language_prompt = PromptTemplate.from_template(language_template)\n",
        "\n",
        "# 체인 구성\n",
        "language_chain = language_prompt | llm | output_parser\n",
        "\n",
        "# 체인 실행 예시\n",
        "examples = [\n",
        "    \"What is the atomic number of carbon?\",\n",
        "    \"탄소의 원자 번호는 무엇인가요?\",\n",
        "    \"¿Cuál es el número atómico del carbono?\"\n",
        "]\n",
        "\n",
        "for example in examples:\n",
        "    result = language_chain.invoke({\"question\": example})\n",
        "    print(f\"입력: {example}\")\n",
        "    print(f\"분류 결과: {result}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c273a56e",
      "metadata": {},
      "source": [
        "`(3) RunnableParallel을 사용한 병렬 실행 체인`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "id": "bf0b47c9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "처리 결과:\n",
            "답변: 탄소의 원자 번호는 6입니다. 이는 탄소 원자가 6개의 양성자를 가지고 있음을 의미합니다.\n"
          ]
        }
      ],
      "source": [
        "# 질문과 관련된 분야를 찾아서 질문에 대한 답변을 생성하는 프롬프트\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from operator import itemgetter\n",
        "\n",
        "# 답변 템플릿 정의\n",
        "answer_template = \"\"\"\n",
        "당신은 {topic} 분야의 전문가입니다. {topic}에 관한 질문에 {language}로 답변해주세요.\n",
        "질문: {question}\n",
        "답변: \"\"\"\n",
        "\n",
        "# 프롬프트 및 체인 구성\n",
        "answer_prompt = PromptTemplate.from_template(answer_template)\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 병렬 처리 체인 구성\n",
        "answer_chain = RunnableParallel({\n",
        "    \"topic\": question_chain,            # 주제 분류 체인\n",
        "    \"language\": language_chain,         # 언어 감지 체인\n",
        "    \"question\": itemgetter(\"question\")  # 원본 질문 추출\n",
        "}) | answer_prompt | llm | output_parser\n",
        "\n",
        "# 체인 실행 예시\n",
        "result = answer_chain.invoke({\n",
        "    \"question\": \"탄소의 원자 번호는 무엇인가요?\"\n",
        "})\n",
        "\n",
        "print(\"처리 결과:\")\n",
        "print(f\"답변: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fad2f4dc",
      "metadata": {},
      "source": [
        "**Langfuse에서 RunnableParallel 추적**\n",
        "\n",
        "- 병렬 실행되는 체인들(주제 분류, 언어 감지)이 동시에 추적됨\n",
        "- 각 병렬 작업의 실행 시간 비교 가능\n",
        "- 복잡한 파이프라인의 성능 최적화에 유용"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89ddb27f",
      "metadata": {},
      "source": [
        "#### 3) **RunnablePassthrough**\n",
        "\n",
        "- **RunnablePassthrough**는 입력값을 그대로 전달하여 원본 데이터를 보존합니다\n",
        "\n",
        "- **RunnableParallel**과 함께 사용되어 입력 데이터를 새로운 키로 매핑할 수 있습니다\n",
        "\n",
        "- **투명한 데이터 흐름**으로 파이프라인 디버깅과 구성이 용이합니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "id": "11de1469",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'passed': {'query': '탄소의 원자 번호는 6입니다.'}, 'modified': 6}"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "import re\n",
        "\n",
        "runnable = RunnableParallel(\n",
        "    passed=RunnablePassthrough(),\n",
        "    modified=lambda x: int(re.search(r'\\d+', x[\"query\"]).group()),\n",
        ")\n",
        "\n",
        "runnable.invoke({\"query\": '탄소의 원자 번호는 6입니다.'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "id": "346a12dc",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'passed': '탄소의 원자 번호는 6입니다.', 'modified': 6}"
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "runnable = RunnableParallel(\n",
        "    passed=RunnablePassthrough(),\n",
        "    modified=lambda x: int(re.search(r'\\d+', x).group()),\n",
        ")\n",
        "\n",
        "runnable.invoke('탄소의 원자 번호는 6입니다.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e888c65",
      "metadata": {
        "id": "2e888c65"
      },
      "source": [
        "#### 4) **RunnableLambda**\n",
        "\n",
        "- **RunnableLambda**는 일반 함수를 Runnable 객체로 변환하는 래퍼 컴포넌트입니다\n",
        "\n",
        "- 체인에 **커스텀 로직**을 쉽게 통합할 수 있어 데이터 전처리, 후처리에 유용합니다\n",
        "\n",
        "- `|` 연산자로 다른 컴포넌트들과 연결해 **복잡한 처리 흐름**을 구성할 수 있습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "id": "f7f8d92f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "\n",
        "# 텍스트에서 숫자를 추출하는 함수\n",
        "def extract_number(query):\n",
        "    return int(re.search(r'\\d+', query).group())\n",
        "\n",
        "# RunnablePassthrough로 입력을 그대로 전달하고, RunnableLambda로 숫자 추출 함수 실행\n",
        "runnable = RunnablePassthrough() | RunnableLambda(extract_number)\n",
        "\n",
        "# 입력 텍스트에서 6을 추출\n",
        "result = runnable.invoke('탄소의 원자 번호는 6입니다.')\n",
        "print(result)  # 출력: 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "id": "6704894c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "처리된 응답: ARTIFICIAL INTELLIGENCE REFERS TO THE SIMULATION OF HUMAN INTELLIGENCE IN MACHINES THAT ARE PROGRAMMED TO THINK, LEARN, AND PERFORM TASKS AUTONOMOUSLY.\n",
            "응답 길이: 151\n"
          ]
        }
      ],
      "source": [
        "from langchain.schema.runnable import RunnableLambda\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# 데이터 전처리 함수 정의\n",
        "def preprocess_text(text: str) -> str:\n",
        "    \"\"\" 입력 텍스트를 소문자로 변환하고 양쪽 공백을 제거합니다. \"\"\"\n",
        "    return text.strip().lower()\n",
        "\n",
        "# 후처리 함수 정의\n",
        "def postprocess_response(response: str) -> dict:\n",
        "    \"\"\" 응답 텍스트를 대문자로 변환하고 길이를 계산합니다. \"\"\"\n",
        "    response_text = response.content\n",
        "    return {\n",
        "        \"processed_response\": response_text.upper(),\n",
        "        \"length\": len(response_text)\n",
        "    }\n",
        "\n",
        "# 프롬프트 템플릿 생성\n",
        "prompt = ChatPromptTemplate.from_template(\"다음 주제에 대해 영어 한 문장으로 설명해주세요: {topic}\")\n",
        "\n",
        "# 처리 파이프라인 구성\n",
        "chain = (\n",
        "    RunnableLambda(preprocess_text) |  # 입력 전처리\n",
        "    prompt |                           # 프롬프트 포맷팅\n",
        "    llm |                              # LLM 추론\n",
        "    RunnableLambda(postprocess_response)  # 출력 후처리\n",
        ")\n",
        "\n",
        "# 체인 실행\n",
        "result = chain.invoke(\"  Artificial Intelligence  \")\n",
        "print(f\"처리된 응답: {result['processed_response']}\")\n",
        "print(f\"응답 길이: {result['length']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af924b54",
      "metadata": {},
      "source": [
        "**Langfuse에서 RunnableLambda 추적**\n",
        "\n",
        "- 커스텀 함수들(전처리, 후처리)도 추적됨\n",
        "- 전체 데이터 변환 과정의 가시화\n",
        "- 함수별 실행 시간 및 성능 분석 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "367d46b8",
      "metadata": {},
      "source": [
        "---\n",
        "# [실습]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd5b260a",
      "metadata": {},
      "source": [
        "- **다음과 같은 요구사항을 LCEL로 구현합니다**\n",
        "   1. 사용자 입력을 받아 내용을 요약하기\n",
        "   2. 요약된 내용을 기반으로 감정 분석하기 (긍정, 부정, 중립)\n",
        "   3. 요약된 문장과 감정 분석 결과를 출력하기 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "id": "43e424f7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Langfuse CallbackHandler 사용 (실습)\n",
            "\n",
            "📝 실습 체인 실행 시작...\n",
            "\n",
            "=== 처리 결과 ===\n",
            "요약: 시험에서 만점을 받아 기쁘고, 노력의 중요성을 다시 깨달았다.\n",
            "감정: 긍정\n",
            "\n",
            "=== Langfuse에서 추적 결과를 확인하세요! ===\n",
            "🔗 Langfuse 웹 인터페이스: http://reai.kro.kr:3000\n",
            "💡 잠시 후 웹 인터페이스에서 트레이스를 확인할 수 있습니다.\n",
            "✅ Langfuse 데이터 전송 완료\n",
            "\n",
            "=== 처리 결과 ===\n",
            "요약: 시험에서 만점을 받아 기쁘고, 노력의 중요성을 다시 깨달았다.\n",
            "감정: 긍정\n",
            "\n",
            "=== Langfuse에서 추적 결과를 확인하세요! ===\n",
            "🔗 Langfuse 웹 인터페이스: http://reai.kro.kr:3000\n",
            "💡 잠시 후 웹 인터페이스에서 트레이스를 확인할 수 있습니다.\n",
            "✅ Langfuse 데이터 전송 완료\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "from operator import itemgetter\n",
        "import os\n",
        "\n",
        "# 저장된 langfuse_handler 사용 (init_langfuse.py 방식)\n",
        "langfuse_handler = globals().get('langfuse_handler')\n",
        "\n",
        "if langfuse_handler:\n",
        "    print(\"✅ Langfuse CallbackHandler 사용 (실습)\")\n",
        "else:\n",
        "    print(\"❌ Langfuse CallbackHandler 없음 (추적 없이 진행)\")\n",
        "\n",
        "# 프롬프트 템플릿 정의\n",
        "summarize_prompt = PromptTemplate.from_template(\n",
        "    \"다음 텍스트를 핵심 내용만 간단히 요약해주세요:\\n\\n{text}\\n\\n요약:\"\n",
        ")\n",
        "\n",
        "sentiment_prompt = PromptTemplate.from_template(\n",
        "    \"다음 요약된 내용의 감정을 분석해주세요. '긍정', '부정', '중립' 중 하나로만 답변하세요:\\n\\n{summary}\\n\\n감정:\"\n",
        ")\n",
        "\n",
        "# 문자열 출력 파서\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 체인 구성 (init_langfuse.py 방식으로 콜백 설정)\n",
        "if langfuse_handler:\n",
        "    model = ChatOpenAI(\n",
        "        model=\"gpt-4o-mini\", \n",
        "        temperature=0.3, \n",
        "        top_p=0.95,\n",
        "        callbacks=[langfuse_handler]\n",
        "    )\n",
        "else:\n",
        "    model = ChatOpenAI(\n",
        "        model=\"gpt-4o-mini\", \n",
        "        temperature=0.3, \n",
        "        top_p=0.95\n",
        "    )\n",
        "\n",
        "# 요약 체인\n",
        "summarize_chain = summarize_prompt | model | output_parser\n",
        "\n",
        "# 감정 분석 체인\n",
        "sentiment_chain = sentiment_prompt | model | output_parser\n",
        "\n",
        "# 전체 체인 - RunnableParallel 사용\n",
        "chain = (\n",
        "    {\"text\": itemgetter(\"text\")} |  # 입력 텍스트 전달\n",
        "    {\"summary\": summarize_chain} |  # 요약 실행\n",
        "    RunnableParallel({\n",
        "        \"summary\": itemgetter(\"summary\"),  # 요약 결과 전달\n",
        "        \"sentiment\": sentiment_chain      # 감정 분석 실행\n",
        "    })\n",
        ")\n",
        "\n",
        "# 사용 예시 (인코딩 문제 해결을 위해 단순한 텍스트 사용)\n",
        "text = \"\"\"오늘 시험을 봤습니다. 준비를 열심히 했기 때문에 긴장했지만 문제를 잘 풀 수 있었습니다. \n",
        "결과적으로 만점을 받았고 매우 기뻤습니다. \n",
        "선생님께서도 칭찬해 주셔서 보람을 느꼈습니다. \n",
        "노력하면 좋은 결과가 따른다는 것을 다시 깨달았습니다.\"\"\"\n",
        "\n",
        "print(\"\\n📝 실습 체인 실행 시작...\")\n",
        "\n",
        "try:\n",
        "    # init_langfuse.py 방식으로 콜백 핸들러 사용\n",
        "    if langfuse_handler:\n",
        "        result = chain.invoke(\n",
        "            {\"text\": text}, \n",
        "            config={\"callbacks\": [langfuse_handler]}\n",
        "        )\n",
        "    else:\n",
        "        result = chain.invoke({\"text\": text})\n",
        "        \n",
        "    print(\"\\n=== 처리 결과 ===\")\n",
        "    print(f\"요약: {result['summary']}\")\n",
        "    print(f\"감정: {result['sentiment']}\")\n",
        "    print(\"\\n=== Langfuse에서 추적 결과를 확인하세요! ===\")\n",
        "    print(f\"🔗 Langfuse 웹 인터페이스: {os.getenv('LANGFUSE_HOST')}\")\n",
        "    print(\"💡 잠시 후 웹 인터페이스에서 트레이스를 확인할 수 있습니다.\")\n",
        "\n",
        "    # 명시적으로 flush 시도 (init_langfuse.py 방식)\n",
        "    try:\n",
        "        langfuse_client = globals().get('langfuse_client')\n",
        "        if langfuse_client:\n",
        "            langfuse_client.flush()\n",
        "            print(\"✅ Langfuse 데이터 전송 완료\")\n",
        "    except Exception as e:\n",
        "        print(f\"ℹ️  자동으로 데이터가 전송됩니다: {e}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ 체인 실행 실패: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "modu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
