{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP 기초: Tokenization + Embedding 이해\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tokenization (토큰화)\n",
    "\n",
    "### 개념\n",
    "텍스트를 분석 가능한 작은 단위로 나누는 과정이다. 컴퓨터가 자연어를 이해하기 위한 첫 번째 단계로, 의미 있는 최소 단위로 텍스트를 분할한다.\n",
    "\n",
    "- 단어 단위 토큰화 (Word Tokenization)\n",
    "- 서브워드 토큰화 (Subword Tokenization)\n",
    "\n",
    "### 1.1 **단어 단위 토큰화 (Word Tokenization)**\n",
    "\n",
    "**특징:**\n",
    "- 형태소 분석을 기반으로 의미 있는 최소 단위로 분리\n",
    "- 조사, 어미 등 문법적 요소도 개별 토큰으로 분리\n",
    "- 한국어의 교착어 특성을 잘 반영\n",
    "\n",
    "**활용 분야:**\n",
    "- 문장 분석, 품사 태깅\n",
    "- 텍스트 분류, 감성 분석\n",
    "- 구문 분석, 의존 구문 분석\n",
    "\n",
    "**예시:** `\"자연어처리는 재미있다\"` → `[\"자연어\", \"처리\", \"는\", \"재미\", \"있\", \"다\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **실습**: Kiwi 한글 형태소 분석기\n",
    "\n",
    "- 한국어 특성을 잘 반영한 형태소 분석기 (신조어 처리 능력이 우수)\n",
    "- 분석 속도가 빠름\n",
    "- 품사 태깅 정확도가 높음\n",
    "- 참조: https://bab2min.github.io/kiwipiepy/v0.20.2/kr/\n",
    "- 설치: pip install kiwipiepy 또는 uv add kiwipiepy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kiwipiepy import Kiwi\n",
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "def measure_time(func):\n",
    "    \"\"\"실행 시간 측정 데코레이터\"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print(f\"{func.__name__} 실행 시간: {end-start:.4f}초\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# Kiwi 형태소 분석기 로드\n",
    "kiwi = Kiwi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize_with_kiwi 실행 시간: 1.1888초\n",
      "토큰화 결과:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Token(form='자연어 처리', tag='NNP', start=0, len=5),\n",
       " Token(form='를', tag='JKO', start=5, len=1),\n",
       " Token(form='공부', tag='NNG', start=7, len=2),\n",
       " Token(form='하', tag='XSV', start=9, len=1),\n",
       " Token(form='는', tag='ETM', start=10, len=1),\n",
       " Token(form='것', tag='NNB', start=12, len=1),\n",
       " Token(form='은', tag='JX', start=13, len=1),\n",
       " Token(form='정말', tag='MAG', start=15, len=2),\n",
       " Token(form='흥미', tag='NNG', start=18, len=2),\n",
       " Token(form='롭', tag='XSA-I', start=20, len=1),\n",
       " Token(form='고', tag='EC', start=21, len=1),\n",
       " Token(form='유용', tag='XR', start=23, len=2),\n",
       " Token(form='하', tag='XSA', start=25, len=1),\n",
       " Token(form='ᆸ니다', tag='EF', start=25, len=3),\n",
       " Token(form='!', tag='SF', start=28, len=1)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@measure_time\n",
    "def tokenize_with_kiwi(text):\n",
    "    \"\"\"토큰화 함수\"\"\"\n",
    "    try:\n",
    "        return kiwi.tokenize(text)\n",
    "    except Exception as e:\n",
    "        print(f\"토큰화 오류: {e}\")\n",
    "        return []\n",
    "    \n",
    "# 토큰화 실행\n",
    "text = \"자연어처리를 공부하는 것은 정말 흥미롭고 유용합니다!\"\n",
    "tokens = tokenize_with_kiwi(text)\n",
    "\n",
    "print(\"토큰화 결과:\")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 번호    단어      품사태그      한국어품사       위치  \n",
      "---------------------------------------------\n",
      "  1  자연어 처리    NNP        고유명사      0-5  \n",
      "  2    를       JKO       목적격조사      5-6  \n",
      "  3    공부      NNG        일반명사      7-9  \n",
      "  4    하       XSV      동사파생접미사     9-10 \n",
      "  5    는       ETM      관형사형전성어미   10-11 \n",
      "  6    것       NNB        의존명사     12-13 \n",
      "  7    은        JX        보조사      13-14 \n",
      "  8    정말      MAG        일반부사     15-17 \n",
      "  9    흥미      NNG        일반명사     18-20 \n",
      " 10    롭      XSA-I      XSA-I     20-21 \n",
      " 11    고        EC        연결어미     21-22 \n",
      " 12    유용       XR         어근      23-25 \n",
      " 13    하       XSA      형용사파생접미사   25-26 \n",
      " 14   ᆸ니다       EF        종결어미     25-28 \n",
      " 15    !        SF        마침표류     28-29 \n"
     ]
    }
   ],
   "source": [
    "# 품사 태그를 한국어 명칭으로 매핑하는 딕셔너리\n",
    "pos_dict = {\n",
    "    # 체언\n",
    "    'NNG': '일반명사', 'NNP': '고유명사', 'NNB': '의존명사', 'NP': '대명사', 'NR': '수사',\n",
    "    # 용언\n",
    "    'VV': '동사', 'VA': '형용사', 'VX': '보조용언', 'VCP': '긍정지정사', 'VCN': '부정지정사',\n",
    "    # 관형사/부사\n",
    "    'MM': '관형사', 'MAG': '일반부사', 'MAJ': '접속부사',\n",
    "    # 조사\n",
    "    'JKS': '주격조사', 'JKC': '보격조사', 'JKG': '관형격조사', 'JKO': '목적격조사', \n",
    "    'JKB': '부사격조사', 'JKV': '호격조사', 'JKQ': '인용격조사', 'JX': '보조사', 'JC': '접속조사',\n",
    "    # 어미\n",
    "    'EP': '선어말어미', 'EF': '종결어미', 'EC': '연결어미', 'ETN': '명사형전성어미', 'ETM': '관형사형전성어미',\n",
    "    # 접사\n",
    "    'XPN': '체언접두사', 'XSN': '명사파생접미사', 'XSV': '동사파생접미사', 'XSA': '형용사파생접미사', 'XR': '어근',\n",
    "    # 기호\n",
    "    'SF': '마침표류', 'SP': '쉼표류', 'SS': '따옴표류', 'SE': '줄임표', 'SO': '붙임표',\n",
    "    'SL': '외국어', 'SH': '한자', 'SN': '숫자', 'SW': '기타기호'\n",
    "}\n",
    "\n",
    "# 결과 출력 \n",
    "print(f\"{'번호':>3} {'단어':^8} {'품사태그':^8} {'한국어품사':^12} {'위치':^6}\")\n",
    "print(\"-\" * 45)\n",
    "for i, token in enumerate(tokens, 1):\n",
    "    korean_pos = pos_dict.get(token.tag, token.tag)\n",
    "    pos_range = f\"{token.start}-{token.start + token.len}\"\n",
    "    print(f\"{i:>3} {token.form:^8} {token.tag:^8} {korean_pos:^12} {pos_range:^6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 **서브워드 토큰화 (Subword Tokenization)**\n",
    "\n",
    "**특징:**\n",
    "- 형태소보다 작은 의미 단위 사용\n",
    "- 자주 등장하는 문자열 패턴을 토큰으로 활용\n",
    "- OOV(Out-of-Vocabulary) 문제 해결에 효과적\n",
    "\n",
    "**활용 분야:**\n",
    "- 신조어, 전문용어 처리\n",
    "- 기계 번역, 언어 모델링\n",
    "- 다국어 NLP 모델\n",
    "\n",
    "**주요 알고리즘 비교:**\n",
    "\n",
    "| 알고리즘 | 특징 | 사용 모델 | 장점 |\n",
    "|---------|------|----------|------|\n",
    "| BPE (Byte Pair Encoding) | 빈도 기반 병합 | GPT 시리즈 | 단순하고 효율적 |\n",
    "| WordPiece | 확률 기반 분할 | BERT, ELECTRA | 언어학적 의미 보존 |\n",
    "| SentencePiece | 언어 독립적 | T5, mT5, XLM-R | 다국어 지원 우수 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **실습**: BERT 토크나이저 (WordPiece)\n",
    "\n",
    "- **Huggingface KcBERT 토크나이저** 활용 \n",
    "- 개념:\n",
    "    - SentencePiece 기반 서브워드 토크나이저 사용\n",
    "    - 한국어에 특화된 어휘 사전(vocab) 보유\n",
    "    - 특수 토큰: [CLS], [SEP], [MASK], [PAD], [UNK]\n",
    "- 특징:\n",
    "    - 문장 시작: [CLS] 토큰 추가\n",
    "    - 문장 구분: [SEP] 토큰 사용\n",
    "    - 서브워드 분리: '##' 접두어로 표시\n",
    "    - 예시: `\"자연어처리\"` → `['자연', '##어', '##처리']`\n",
    "    - 최대 길이 처리: max_length로 자동 truncation \n",
    "    - 참조: https://huggingface.co/beomi/kcbert-base\n",
    "- 설치:\n",
    "    - pip install torch transformers 또는 uv add torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='beomi/kcbert-base', vocab_size=30000, model_max_length=300, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 허깅페이스 트랜스포머 라이브러리에서 토크나이저 로드\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('beomi/kcbert-base')\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['자연', '##어', '##처리', '##를', '공부', '##합니다']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰화 수행 : 문장 -> 토큰들의 리스트\n",
    "text = \"자연어처리를 공부합니다\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. 원문: 자연어처리를 공부합니다\n",
      "   토큰 수: 6개\n",
      "   서브워드: 4개\n",
      "   토큰들: ['자연', '##어', '##처리', '##를', '공부', '##합니다']\n",
      "------------------------------\n",
      "\n",
      "2. 원문: 인공지능과 머신러닝은 미래기술이다\n",
      "   토큰 수: 11개\n",
      "   서브워드: 8개\n",
      "   토큰들: ['인공', '##지능', '##과', '머', '##신', '##러', '##닝', '##은', '미래', '##기술', '##이다']\n",
      "------------------------------\n",
      "\n",
      "3. 원문: COVID-19로 인한 비대면 수업이 증가했다\n",
      "   토큰 수: 15개\n",
      "   서브워드: 8개\n",
      "   토큰들: ['C', '##O', '##V', '##I', '##D', '-', '19', '##로', '인한', '비', '##대면', '수업', '##이', '증가', '##했다']\n",
      "------------------------------\n",
      "\n",
      "4. 원문: 스마트폰의 음성인식 기능이 발전했다\n",
      "   토큰 수: 8개\n",
      "   서브워드: 4개\n",
      "   토큰들: ['스마트폰', '##의', '음성', '##인식', '기능', '##이', '발전', '##했다']\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def analyze_tokenization(texts, tokenizer):\n",
    "    \"\"\"토큰화 분석 함수\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for text in texts:\n",
    "        try:\n",
    "            # 토큰화\n",
    "            tokens = tokenizer.tokenize(text)\n",
    "            token_ids = tokenizer.encode(text)\n",
    "            \n",
    "            # 특수 토큰 분석\n",
    "            special_tokens = [token for token in tokens if token in ['[CLS]', '[SEP]', '[MASK]', '[PAD]', '[UNK]']]\n",
    "            subword_tokens = [token for token in tokens if token.startswith('##')]\n",
    "            \n",
    "            results.append({\n",
    "                'text': text,\n",
    "                'token_count': len(tokens),\n",
    "                'subword_count': len(subword_tokens),\n",
    "                'special_count': len(special_tokens),\n",
    "                'tokens': tokens\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"토큰화 오류 - {text}: {e}\")\n",
    "            \n",
    "    return results\n",
    "\n",
    "# 테스트 문장들\n",
    "test_texts = [\n",
    "    \"자연어처리를 공부합니다\",\n",
    "    \"인공지능과 머신러닝은 미래기술이다\", \n",
    "    \"COVID-19로 인한 비대면 수업이 증가했다\",\n",
    "    \"스마트폰의 음성인식 기능이 발전했다\"\n",
    "]\n",
    "\n",
    "# 토큰화 분석\n",
    "results = analyze_tokenization(test_texts, tokenizer)\n",
    "\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"\\n{i}. 원문: {result['text']}\")\n",
    "    print(f\"   토큰 수: {result['token_count']}개\")\n",
    "    print(f\"   서브워드: {result['subword_count']}개\")\n",
    "    print(f\"   토큰들: {result['tokens']}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **실습**: SentencePiece 토크나이저 (bge-m3 모델)\n",
    "\n",
    "- **Huggingface Transformers** 라이브러리 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-m3\")\n",
    "model = AutoModel.from_pretrained(\"BAAI/bge-m3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁자연', '어', '처리', '를', '▁공부', '합니다']\n"
     ]
    }
   ],
   "source": [
    "text = \"자연어처리를 공부합니다\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. 원문: 자연어처리를 공부합니다\n",
      "   토큰 수: 6개\n",
      "   토큰들: ['▁자연', '어', '처리', '를', '▁공부', '합니다']\n",
      "------------------------------\n",
      "\n",
      "2. 원문: 인공지능과 머신러닝은 미래기술이다\n",
      "   토큰 수: 10개\n",
      "   토큰들: ['▁인공지능', '과', '▁머', '신', '러', '닝', '은', '▁미래', '기술', '이다']\n",
      "------------------------------\n",
      "\n",
      "3. 원문: COVID-19로 인한 비대면 수업이 증가했다\n",
      "   토큰 수: 12개\n",
      "   토큰들: ['▁CO', 'VID', '-19', '로', '▁인한', '▁비', '대', '면', '▁수업', '이', '▁증가', '했다']\n",
      "------------------------------\n",
      "\n",
      "4. 원문: 스마트폰의 음성인식 기능이 발전했다\n",
      "   토큰 수: 9개\n",
      "   토큰들: ['▁스마트폰', '의', '▁음성', '인', '식', '▁기능', '이', '▁발전', '했다']\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 토큰화 분석\n",
    "results = analyze_tokenization(test_texts, tokenizer)\n",
    "\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"\\n{i}. 원문: {result['text']}\")\n",
    "    print(f\"   토큰 수: {result['token_count']}개\")\n",
    "    print(f\"   토큰들: {result['tokens']}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Embedding (임베딩)\n",
    "\n",
    "### 개념\n",
    "텍스트를 컴퓨터가 이해할 수 있는 수치 벡터로 변환하는 기술이다. 의미적으로 유사한 텍스트는 벡터 공간에서 가까운 거리에 위치하도록 한다.\n",
    "\n",
    "### 2.1 **단어 임베딩 (Word Embedding)**\n",
    "\n",
    "- 개념:\n",
    "    - 자연어를 컴퓨터가 이해할 수 있는 벡터 형태로 변환하는 기술\n",
    "    - 각 단어를 고정된 크기의 실수 벡터로 표현\n",
    "    - 비슷한 의미를 가진 단어들은 벡터 공간에서 서로 가까운 거리에 위치\n",
    "\n",
    "- 기법: \n",
    "    - Bag of Words (BoW)\n",
    "    - TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "    - Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Bag of Words (BoW)\n",
    "\n",
    "**특징:**\n",
    "- 단어의 출현 빈도를 벡터로 표현\n",
    "- 단어 순서 정보는 무시\n",
    "- 희소(sparse) 벡터 생성\n",
    "\n",
    "* uv add scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize_with_kiwi 실행 시간: 0.0010초\n",
      "tokenize_with_kiwi 실행 시간: 0.0010초\n",
      "tokenize_with_kiwi 실행 시간: 0.0010초\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 한국어 텍스트 예제\n",
    "texts = [\n",
    "    \"자연어 처리를 공부합니다\",\n",
    "    \"자연어는 컴퓨터 언어가 아니라 인간의 언어입니다\", \n",
    "    \"자연어 수업 시간에 자연어 처리 방법을 배우고 있습니다\"\n",
    "]\n",
    "\n",
    "# BoW 벡터화\n",
    "def create_bow_vectors(texts):\n",
    "    # 토큰화된 텍스트로 변환\n",
    "    tokenized_texts = []\n",
    "    for text in texts:\n",
    "        tokens = tokenize_with_kiwi(text)\n",
    "        token_words = [token.form for token in tokens if token.tag not in ['SF', 'SP']]  # 구두점 제외\n",
    "        tokenized_texts.append(' '.join(token_words))\n",
    "    \n",
    "    # BoW 벡터화\n",
    "    vectorizer = CountVectorizer()\n",
    "    bow_matrix = vectorizer.fit_transform(tokenized_texts)\n",
    "    \n",
    "    return bow_matrix, vectorizer, tokenized_texts\n",
    "\n",
    "bow_matrix, vectorizer, tokenized_texts = create_bow_vectors(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ᆸ니다</th>\n",
       "      <th>공부</th>\n",
       "      <th>방법</th>\n",
       "      <th>배우</th>\n",
       "      <th>수업</th>\n",
       "      <th>습니다</th>\n",
       "      <th>시간</th>\n",
       "      <th>아니</th>\n",
       "      <th>언어</th>\n",
       "      <th>인간</th>\n",
       "      <th>자연어</th>\n",
       "      <th>처리</th>\n",
       "      <th>컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>문서1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>문서2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>문서3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ᆸ니다  공부  방법  배우  수업  습니다  시간  아니  언어  인간  자연어  처리  컴퓨터\n",
       "문서1    1   1   0   0   0    0   0   0   0   0    1   1    0\n",
       "문서2    1   0   0   0   0    0   0   1   2   1    1   0    1\n",
       "문서3    0   0   1   1   1    1   1   0   0   0    2   1    0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 정리\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray(), \n",
    "                     columns=feature_names,\n",
    "                     index=[f'문서{i+1}' for i in range(len(texts))])\n",
    "\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어휘 사전 크기: 13개\n"
     ]
    }
   ],
   "source": [
    "print(f\"어휘 사전 크기: {len(feature_names)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "\n",
    "**특징:**\n",
    "- 단어의 중요도를 고려한 가중치 부여\n",
    "- 희귀한 단어에 높은 가중치 부여\n",
    "- 문서 집합 내에서 단어의 상대적 중요성 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize_with_kiwi 실행 시간: 0.0000초\n",
      "tokenize_with_kiwi 실행 시간: 0.0010초\n",
      "tokenize_with_kiwi 실행 시간: 0.0010초\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def create_tfidf_vectors(texts):\n",
    "    # 토큰화\n",
    "    tokenized_texts = []\n",
    "    for text in texts:\n",
    "        tokens = tokenize_with_kiwi(text)\n",
    "        token_words = [token.form for token in tokens if token.tag not in ['SF', 'SP']]\n",
    "        tokenized_texts.append(' '.join(token_words))\n",
    "    \n",
    "    # TF-IDF 벡터화\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf.fit_transform(tokenized_texts)\n",
    "    \n",
    "    return tfidf_matrix, tfidf, tokenized_texts\n",
    "\n",
    "tfidf_matrix, tfidf, _ = create_tfidf_vectors(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ᆸ니다</th>\n",
       "      <th>공부</th>\n",
       "      <th>방법</th>\n",
       "      <th>배우</th>\n",
       "      <th>수업</th>\n",
       "      <th>습니다</th>\n",
       "      <th>시간</th>\n",
       "      <th>아니</th>\n",
       "      <th>언어</th>\n",
       "      <th>인간</th>\n",
       "      <th>자연어</th>\n",
       "      <th>처리</th>\n",
       "      <th>컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>문서1</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>문서2</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>문서3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ᆸ니다     공부     방법     배우     수업    습니다     시간     아니    언어     인간  \\\n",
       "문서1  0.48  0.632  0.000  0.000  0.000  0.000  0.000  0.000  0.00  0.000   \n",
       "문서2  0.27  0.000  0.000  0.000  0.000  0.000  0.000  0.355  0.71  0.355   \n",
       "문서3  0.00  0.000  0.379  0.379  0.379  0.379  0.379  0.000  0.00  0.000   \n",
       "\n",
       "       자연어     처리    컴퓨터  \n",
       "문서1  0.373  0.480  0.000  \n",
       "문서2  0.210  0.000  0.355  \n",
       "문서3  0.447  0.288  0.000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 정리\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), \n",
    "                       columns=feature_names,\n",
    "                       index=[f'문서{i+1}' for i in range(len(texts))])\n",
    "\n",
    "tfidf_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Word2Vec\n",
    "\n",
    "**특징:**\n",
    "- 단어의 의미적 관계를 벡터 공간에 표현\n",
    "- 문맥을 고려한 단어 표현\n",
    "- CBOW와 Skip-gram 두 가지 아키텍처\n",
    "- 임베딩 프로젝터: https://projector.tensorflow.org/\n",
    "- 참조: https://ko.wikipedia.org/wiki/Gensim\n",
    "- 설치: pip install gensim 또는 uv add gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def train_word2vec_model(texts, vector_size=100, window=3, min_count=1):\n",
    "    \"\"\"Word2Vec 모델 훈련\"\"\"\n",
    "    # 토큰화\n",
    "    tokenized_corpus = []\n",
    "    for text in texts:\n",
    "        tokens = tokenize_with_kiwi(text)\n",
    "        token_words = [token.form for token in tokens if len(token.form) > 1]  # 한 글자 단어 제외\n",
    "        tokenized_corpus.append(token_words)\n",
    "    \n",
    "    # 모델 훈련 (Skip-gram)\n",
    "    model = Word2Vec(\n",
    "        sentences=tokenized_corpus,\n",
    "        vector_size=vector_size,\n",
    "        window=window,\n",
    "        min_count=min_count,\n",
    "        workers=4,\n",
    "        sg=1,  # 1: Skip-gram, 0: CBOW\n",
    "        epochs=100\n",
    "    )\n",
    "    \n",
    "    return model, tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize_with_kiwi 실행 시간: 0.0010초\n",
      "tokenize_with_kiwi 실행 시간: 0.0010초\n",
      "tokenize_with_kiwi 실행 시간: 0.0000초\n",
      "tokenize_with_kiwi 실행 시간: 0.0010초\n",
      "tokenize_with_kiwi 실행 시간: 0.0000초\n",
      "어휘 사전 크기: 24개\n",
      "벡터 차원: 100차원\n"
     ]
    }
   ],
   "source": [
    "# 더 큰 코퍼스로 테스트\n",
    "word2vec_texts = [\n",
    "    \"자연어 처리는 인공지능의 중요한 분야입니다\",\n",
    "    \"머신러닝과 딥러닝이 자연어 처리에 활용됩니다\",\n",
    "    \"컴퓨터가 인간의 언어를 이해하는 기술입니다\",\n",
    "    \"텍스트 데이터를 분석하고 처리하는 방법을 학습합니다\",\n",
    "    \"단어의 의미와 문맥을 파악하는 것이 중요합니다\"\n",
    "]\n",
    "\n",
    "word2vec_model, tokenized_corpus = train_word2vec_model(word2vec_texts)\n",
    "\n",
    "print(f\"어휘 사전 크기: {len(word2vec_model.wv.key_to_index)}개\")\n",
    "print(f\"벡터 차원: {word2vec_model.vector_size}차원\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['자연어 처리', '인공', '지능', '중요', '분야', 'ᆸ니다'],\n",
       " ['머신', '러닝', '러닝', '자연어 처리', '활용', 'ᆸ니다'],\n",
       " ['컴퓨터', '인간', '언어', '이해', '기술', 'ᆸ니다'],\n",
       " ['텍스트', '데이터', '분석', '처리', '방법', '학습', 'ᆸ니다'],\n",
       " ['단어', '의미', '문맥', '파악', '중요', 'ᆸ니다']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'자연어 처리' 벡터 (처음 10차원): [-0.009  0.004  0.005  0.006  0.007 -0.006  0.001  0.006 -0.003 -0.006]\n",
      "'언어' 벡터 (처음 10차원): [-0.002 -0.006  0.008 -0.007 -0.009 -0.002 -0.008  0.001  0.002 -0.003]\n",
      "'데이터' 벡터 (처음 10차원): [ 0.001 -0.01   0.005 -0.     0.006  0.002 -0.003  0.008  0.001 -0.   ]\n",
      "'컴퓨터' 벡터 (처음 10차원): [ 0.007 -0.001  0.008 -0.01  -0.008 -0.007 -0.004  0.005 -0.004 -0.009]\n"
     ]
    }
   ],
   "source": [
    "# 단어별 임베딩 확인\n",
    "test_words = ['자연어 처리', '언어', '데이터', '컴퓨터']\n",
    "available_words = [word for word in test_words if word in word2vec_model.wv]\n",
    "\n",
    "for word in available_words:  \n",
    "    vector = word2vec_model.wv[word]\n",
    "    print(f\"'{word}' 벡터 (처음 10차원): {vector[:10].round(3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'자연어 처리'와 유사한 단어들:\n",
      "  의미: 0.192\n",
      "  기술: 0.168\n",
      "  처리: 0.165\n",
      "------------------------------\n",
      "\n",
      "'언어'와 유사한 단어들:\n",
      "  기술: 0.189\n",
      "  단어: 0.161\n",
      "  이해: 0.158\n",
      "------------------------------\n",
      "\n",
      "'데이터'와 유사한 단어들:\n",
      "  ᆸ니다: 0.243\n",
      "  분야: 0.188\n",
      "  지능: 0.177\n",
      "------------------------------\n",
      "\n",
      "'컴퓨터'와 유사한 단어들:\n",
      "  파악: 0.137\n",
      "  인간: 0.134\n",
      "  분야: 0.127\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 유사 단어 찾기\n",
    "def find_similar_words(word):\n",
    "    try:\n",
    "        similar_words = word2vec_model.wv.most_similar(word, topn=3)\n",
    "        print(f\"\\n'{word}'와 유사한 단어들:\")\n",
    "        for similar_word, similarity in similar_words:\n",
    "            print(f\"  {similar_word}: {similarity:.3f}\")\n",
    "    except:\n",
    "        print(f\"'{word}'의 유사 단어를 찾을 수 없습니다.\")\n",
    "\n",
    "for word in available_words:\n",
    "    find_similar_words(word)\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 **문장 임베딩 (Sentence Embedding)**\n",
    "\n",
    "\n",
    "- 개념:\n",
    "    - 단어 임베딩의 개념을 확장하여 문장 전체를 하나의 벡터로 표현하는 기술\n",
    "    - 문장의 의미적 특성을 보존하면서 고정된 크기의 벡터로 변환\n",
    "    - 비슷한 의미를 가진 문장들은 벡터 공간에서 서로 가까운 거리에 위치\n",
    "\n",
    "- 실습: \n",
    "    - **Option1**: Word2Vec 모델을 사용하여 단어를 벡터로 변환 -> 문장을 구성하는 단어 벡터를 평균 \n",
    "    - **Option2**: Sentence-BERT(SBERT) 등 문장 임베딩 모델을 사용하여 문장을 벡터로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 평균 기반 문장 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize_with_kiwi 실행 시간: 0.0010초\n",
      "문장: '자연어 처리를 공부합니다'\n",
      "임베딩 차원: 100\n",
      "임베딩 벡터 (처음 10차원): [-0.005  0.002  0.005  0.007 -0.001 -0.007  0.004  0.008 -0.004 -0.005]\n"
     ]
    }
   ],
   "source": [
    "def create_sentence_embedding_avg(sentence, word2vec_model):\n",
    "    \"\"\"Word2Vec 평균을 이용한 문장 임베딩\"\"\"\n",
    "    import numpy as np\n",
    "    tokens = tokenize_with_kiwi(sentence)\n",
    "    token_words = [token.form for token in tokens if token.form in word2vec_model.wv]\n",
    "    \n",
    "    if not token_words:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "    \n",
    "    # 단어 벡터들의 평균 계산\n",
    "    sentence_vector = np.zeros(word2vec_model.vector_size)\n",
    "    for word in token_words:\n",
    "        sentence_vector += word2vec_model.wv[word]\n",
    "    \n",
    "    return sentence_vector / len(token_words)\n",
    "\n",
    "# 문장 임베딩 생성\n",
    "test_sentence = \"자연어 처리를 공부합니다\"\n",
    "sentence_embed = create_sentence_embedding_avg(test_sentence, word2vec_model)\n",
    "\n",
    "print(f\"문장: '{test_sentence}'\")\n",
    "print(f\"임베딩 차원: {len(sentence_embed)}\")\n",
    "print(f\"임베딩 벡터 (처음 10차원): {sentence_embed[:10].round(3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 SBERT (Sentence-BERT) \n",
    "\n",
    "- 문장 임베딩 모델을 사용: 문장 텍스트를 벡터로 직접 변환\n",
    "- SBERT : https://sbert.net/\n",
    "- 설치 pip install sentence_transformers 또는 uv add sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1dd5aa801414350a1b7ffd87c31c40b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ba14469d094124bce753e020a974f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/123 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011a2c6ed0f945748e3117c4bfe63176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1074b885494f3db8d7c24f6e4c486d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d19924d32c7249e3bcbf989024f67cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/744 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a898e3c0034775a06d24066ef2cae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0acae84f7f5e4e019d26bdb1e514e933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/585 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4a6218ec7e470cbef5a0c2ec537e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621258550f144a9a9226eb917d978196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411f288d5ce44328bbef8216366871dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d149033e41476eba77e5a5bbf5e87f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93240df3d1d4bc8a050000e53d70168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/442M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 로드 완료: jhgan/ko-sroberta-multitask\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False, 'architecture': 'RobertaModel'})\n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한국어 최적화 모델들\n",
    "korean_models = {\n",
    "    'ko-sroberta': 'jhgan/ko-sroberta-multitask',  \n",
    "    'bge-m3': 'BAAI/bge-m3'\n",
    "}\n",
    "\n",
    "def load_sentence_transformer(model_key='ko-sroberta'):\n",
    "    \"\"\"SBERT 모델 로딩\"\"\"\n",
    "    try:\n",
    "        model_name = korean_models[model_key]\n",
    "        model = SentenceTransformer(model_name)\n",
    "        print(f\"모델 로드 완료: {model_name}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"모델 로딩 오류: {e}\")\n",
    "        return None\n",
    "\n",
    "@measure_time\n",
    "def create_sentence_embeddings(sentences, model):\n",
    "    \"\"\"배치 문장 임베딩 생성\"\"\"\n",
    "    try:\n",
    "        embeddings = model.encode(sentences, convert_to_tensor=False)\n",
    "        return embeddings\n",
    "    except Exception as e:\n",
    "        print(f\"임베딩 생성 오류: {e}\")\n",
    "        return None\n",
    "    \n",
    "# ko-sroberta 모델 로드\n",
    "sbert_model = load_sentence_transformer('ko-sroberta')\n",
    "sbert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_sentence_embeddings 실행 시간: 0.1144초\n",
      "임베딩 형태: (4, 768)\n",
      "임베딩 차원: 768\n",
      "\n",
      "첫 번째 문장 임베딩 (처음 10차원):\n",
      "'자연어 처리는 인공지능의 핵심 기술입니다'\n",
      "[ 0.031  0.567 -0.285 -0.219 -0.286 -0.005 -0.125 -0.039 -0.244 -0.52 ]\n"
     ]
    }
   ],
   "source": [
    "# 테스트 문장들\n",
    "test_sentences = [\n",
    "    \"자연어 처리는 인공지능의 핵심 기술입니다\",\n",
    "    \"머신러닝을 이용해서 텍스트를 분석합니다\",\n",
    "    \"오늘 날씨가 정말 좋네요\",\n",
    "    \"컴퓨터가 인간의 언어를 이해하는 방법을 연구합니다\"\n",
    "]\n",
    "\n",
    "# 임베딩 생성\n",
    "sbert_embeddings = create_sentence_embeddings(test_sentences, sbert_model)\n",
    "\n",
    "print(f\"임베딩 형태: {sbert_embeddings.shape}\")\n",
    "print(f\"임베딩 차원: {sbert_embeddings.shape[1]}\")\n",
    "\n",
    "# 첫 번째 문장의 임베딩 일부 출력\n",
    "print(f\"\\n첫 번째 문장 임베딩 (처음 10차원):\")\n",
    "print(f\"'{test_sentences[0]}'\")\n",
    "print(f\"{sbert_embeddings[0][:10].round(3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac573660bc184dbb8be934b8ccd9c531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25117572f7c34652b73c6d8318198c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/123 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2b8f2b0df54eec84bb88f7dd12a4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ac758571b84b4f9e48ec2ea1505e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2820a4e61144c80abbcdad6866ff257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 로드 완료: BAAI/bge-m3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 8192, 'do_lower_case': False, 'architecture': 'XLMRobertaModel'})\n",
       "  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BGE-M3 모델 로드\n",
    "bge_model = load_sentence_transformer('bge-m3')\n",
    "bge_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_sentence_embeddings 실행 시간: 0.3131초\n",
      "임베딩 형태: (4, 1024)\n",
      "임베딩 차원: 1024\n",
      "\n",
      "첫 번째 문장 임베딩 (처음 10차원):\n",
      "'자연어 처리는 인공지능의 핵심 기술입니다'\n",
      "[ 0.001  0.003  0.006 -0.023 -0.026 -0.001 -0.017 -0.007 -0.002 -0.002]\n"
     ]
    }
   ],
   "source": [
    "# 임베딩 생성\n",
    "bge_embeddings = create_sentence_embeddings(test_sentences, bge_model)  \n",
    "\n",
    "print(f\"임베딩 형태: {bge_embeddings.shape}\")\n",
    "print(f\"임베딩 차원: {bge_embeddings.shape[1]}\")\n",
    "\n",
    "# 첫 번째 문장의 임베딩 일부 출력\n",
    "print(f\"\\n첫 번째 문장 임베딩 (처음 10차원):\")\n",
    "print(f\"'{test_sentences[0]}'\")\n",
    "print(f\"{bge_embeddings[0][:10].round(3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. 텍스트 유사도 비교\n",
    "\n",
    "### 유사도 메트릭 비교표\n",
    "\n",
    "| 메트릭 | 수식 | 범위 | 해석 | 특징 | 주요 용도 |\n",
    "|--------|------|------|------|------|----------|\n",
    "| 유클리드 거리 | $\\sqrt{\\sum(a_i-b_i)^2}$ | [0, ∞) | 낮을수록 유사 | 절대 거리 | 클러스터링 |\n",
    "| 코사인 유사도 | $\\frac{a \\cdot b}{\\\\|a\\\\|\\\\|b\\\\|}$ | [-1, 1] | 1에 가까울수록 유사 | 방향성 중시 | 문서 검색 |\n",
    "| 내적 | $\\sum a_i \\cdot b_i$ | (-∞, ∞) | 클수록 유사 | 크기+방향 | 추천 시스템 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 유사도 비교 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class SimilarityCalculator:\n",
    "    \"\"\"텍스트 유사도 계산 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, sbert_model):\n",
    "        self.model = sbert_model\n",
    "    \n",
    "    def calculate_all_similarities(self, sentence1, sentence2):\n",
    "        \"\"\"모든 유사도 메트릭 계산\"\"\"\n",
    "        import numpy as np\n",
    "        \n",
    "        # 임베딩 생성\n",
    "        embeddings = self.model.encode([sentence1, sentence2])\n",
    "        emb1, emb2 = embeddings[0], embeddings[1]\n",
    "        \n",
    "        # 각종 유사도 계산\n",
    "        euclidean_dist = euclidean_distances([emb1], [emb2])[0][0]\n",
    "        cosine_sim = cosine_similarity([emb1], [emb2])[0][0]\n",
    "        dot_product = np.dot(emb1, emb2)\n",
    "        \n",
    "        # 정규화된 유클리드 거리 (0~1 범위)\n",
    "        normalized_euclidean = euclidean_dist / (np.linalg.norm(emb1) + np.linalg.norm(emb2))\n",
    "        \n",
    "        return {\n",
    "            'euclidean_distance': euclidean_dist,\n",
    "            'normalized_euclidean': normalized_euclidean,\n",
    "            'cosine_similarity': cosine_sim,\n",
    "            'dot_product': dot_product,\n",
    "            'embeddings': (emb1, emb2)\n",
    "        }\n",
    "    \n",
    "    def compare_sentence_pairs(self, sentence_pairs):\n",
    "        \"\"\"여러 문장 쌍 비교\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for pair in sentence_pairs:\n",
    "            sent1, sent2 = pair\n",
    "            similarities = self.calculate_all_similarities(sent1, sent2)\n",
    "            \n",
    "            result = {\n",
    "                'sentence1': sent1,\n",
    "                'sentence2': sent2,\n",
    "                'euclidean': similarities['euclidean_distance'],\n",
    "                'cosine': similarities['cosine_similarity'], \n",
    "                'dot_product': similarities['dot_product']\n",
    "            }\n",
    "            results.append(result)\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. 문장 비교:\n",
      "   A: 학생이 학교에서 공부한다\n",
      "   B: 학생이 도서관에서 공부한다\n",
      "   유클리드 거리: 9.1853\n",
      "   코사인 유사도: 0.7056\n",
      "   내적: 101.1005\n",
      "\n",
      "2. 문장 비교:\n",
      "   A: 자연어 처리를 배운다\n",
      "   B: 컴퓨터로 언어를 분석한다\n",
      "   유클리드 거리: 11.8214\n",
      "   코사인 유사도: 0.4919\n",
      "   내적: 67.6478\n",
      "\n",
      "3. 문장 비교:\n",
      "   A: 오늘 날씨가 좋다\n",
      "   B: 내일 비가 올 예정이다\n",
      "   유클리드 거리: 13.1881\n",
      "   코사인 유사도: 0.3953\n",
      "   내적: 56.8384\n",
      "\n",
      "4. 문장 비교:\n",
      "   A: 영화가 재미있다\n",
      "   B: 수학 문제를 푼다\n",
      "   유클리드 거리: 16.2850\n",
      "   코사인 유사도: 0.0807\n",
      "   내적: 11.6306\n"
     ]
    }
   ],
   "source": [
    "# sbert 모델 유사도 계산기 생성\n",
    "sbert_similarity_calc = SimilarityCalculator(sbert_model)\n",
    "\n",
    "# 테스트 문장 쌍들\n",
    "sentence_pairs = [\n",
    "    (\"학생이 학교에서 공부한다\", \"학생이 도서관에서 공부한다\"),    # 유사\n",
    "    (\"자연어 처리를 배운다\", \"컴퓨터로 언어를 분석한다\"),        # 유사  \n",
    "    (\"오늘 날씨가 좋다\", \"내일 비가 올 예정이다\"),             # 관련\n",
    "    (\"영화가 재미있다\", \"수학 문제를 푼다\")                   # 무관\n",
    "]\n",
    "\n",
    "# 유사도 비교 실행\n",
    "sbert_comparison_results = sbert_similarity_calc.compare_sentence_pairs(sentence_pairs)\n",
    "\n",
    "# 결과 출력\n",
    "for i, result in enumerate(sbert_comparison_results, 1):\n",
    "    print(f\"\\n{i}. 문장 비교:\")\n",
    "    print(f\"   A: {result['sentence1']}\")\n",
    "    print(f\"   B: {result['sentence2']}\")\n",
    "    print(f\"   유클리드 거리: {result['euclidean']:.4f}\")\n",
    "    print(f\"   코사인 유사도: {result['cosine']:.4f}\")\n",
    "    print(f\"   내적: {result['dot_product']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. 문장 비교:\n",
      "   A: 학생이 학교에서 공부한다\n",
      "   B: 학생이 도서관에서 공부한다\n",
      "   유클리드 거리: 0.5074\n",
      "   코사인 유사도: 0.8713\n",
      "   내적: 0.8713\n",
      "\n",
      "2. 문장 비교:\n",
      "   A: 자연어 처리를 배운다\n",
      "   B: 컴퓨터로 언어를 분석한다\n",
      "   유클리드 거리: 0.7779\n",
      "   코사인 유사도: 0.6975\n",
      "   내적: 0.6975\n",
      "\n",
      "3. 문장 비교:\n",
      "   A: 오늘 날씨가 좋다\n",
      "   B: 내일 비가 올 예정이다\n",
      "   유클리드 거리: 0.7633\n",
      "   코사인 유사도: 0.7087\n",
      "   내적: 0.7087\n",
      "\n",
      "4. 문장 비교:\n",
      "   A: 영화가 재미있다\n",
      "   B: 수학 문제를 푼다\n",
      "   유클리드 거리: 0.8183\n",
      "   코사인 유사도: 0.6652\n",
      "   내적: 0.6652\n"
     ]
    }
   ],
   "source": [
    "# bge-m3 모델 유사도 계산기 생성\n",
    "bge_similarity_calc = SimilarityCalculator(bge_model)\n",
    "\n",
    "# 유사도 비교 실행\n",
    "bge_comparison_results = bge_similarity_calc.compare_sentence_pairs(sentence_pairs)\n",
    "\n",
    "# 결과 출력\n",
    "for i, result in enumerate(bge_comparison_results, 1):\n",
    "    print(f\"\\n{i}. 문장 비교:\")\n",
    "    print(f\"   A: {result['sentence1']}\")\n",
    "    print(f\"   B: {result['sentence2']}\")\n",
    "    print(f\"   유클리드 거리: {result['euclidean']:.4f}\")\n",
    "    print(f\"   코사인 유사도: {result['cosine']:.4f}\")\n",
    "    print(f\"   내적: {result['dot_product']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 유사도 시각화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# # 한글 폰트 인식 - Windows\n",
    "# import matplotlib \n",
    "# font_name = matplotlib.font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "# matplotlib.rc('font', family=font_name)\n",
    "\n",
    "# 한글 폰트 인식 - Mac\n",
    "import matplotlib\n",
    "matplotlib.rc('font', family='Gulim')\n",
    "\n",
    "# 마이너스 부호 인식\n",
    "matplotlib.rc(\"axes\", unicode_minus = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_similarity_comparison(results):\n",
    "    \"\"\"유사도 비교 시각화\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # 데이터 준비\n",
    "    labels = [f\"쌍{i+1}\" for i in range(len(results))]\n",
    "    euclidean_scores = [r['euclidean'] for r in results]\n",
    "    cosine_scores = [r['cosine'] for r in results]\n",
    "    dot_scores = [r['dot_product'] for r in results]\n",
    "    \n",
    "    # 유클리드 거리 (낮을수록 유사)\n",
    "    axes[0].bar(labels, euclidean_scores, color='skyblue', alpha=0.7)\n",
    "    axes[0].set_title('유클리드 거리 (낮을수록 유사)')\n",
    "    axes[0].set_ylabel('거리')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 코사인 유사도 (높을수록 유사)\n",
    "    axes[1].bar(labels, cosine_scores, color='lightgreen', alpha=0.7)\n",
    "    axes[1].set_title('코사인 유사도 (높을수록 유사)')\n",
    "    axes[1].set_ylabel('유사도')\n",
    "    axes[1].set_ylim(0, 1)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 내적 (높을수록 유사)\n",
    "    axes[2].bar(labels, dot_scores, color='salmon', alpha=0.7)\n",
    "    axes[2].set_title('내적 (높을수록 유사)')\n",
    "    axes[2].set_ylabel('내적값')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sbert 모델 결과 시각화\n",
    "plot_similarity_comparison(sbert_comparison_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bge-m3 모델 결과 시각화\n",
    "plot_similarity_comparison(bge_comparison_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **[실습 프로젝트]**\n",
    "\n",
    "### **문제: 문서 유사도 비교 시스템 구현**\n",
    "\n",
    "**목표**: 주어진 문서들을 토큰화하고 임베딩한 후 유사도를 비교하는 시스템 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**예상 결과**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'most_similar_pair': ('문서1', '문서2'),\n",
       " 'similarity_score': 0.85,\n",
       " 'similarity_matrix': [[1.0, 0.8, Ellipsis], [Ellipsis]]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예시 결과 포맷\n",
    "{\n",
    "    'most_similar_pair': ('문서1', '문서2'),\n",
    "    'similarity_score': 0.85,\n",
    "    'similarity_matrix': [[1.0, 0.8, ...], [...]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 테스트용 샘플 문서\n",
    "documents = [\n",
    "    \"인공지능은 컴퓨터 과학의 중요한 분야입니다.\",\n",
    "    \"머신러닝은 인공지능의 하위 분야입니다.\",\n",
    "    \"딥러닝은 머신러닝의 한 종류입니다.\",\n",
    "    \"자연어 처리는 텍스트 데이터를 다룹니다.\"\n",
    "]\n",
    "\n",
    "\n",
    "# 문제 1: 문서를 토큰화하고 BoW 벡터로 변환하시오\n",
    "def tokenize_documents(docs):\n",
    "    # 이 부분을 구현하세요\n",
    "    pass\n",
    "\n",
    "# 문제 2: 문서를 임베딩으로 변환하시오\n",
    "def create_embeddings(docs):\n",
    "    # 이 부분을 구현하세요\n",
    "    pass\n",
    "\n",
    "# 문제 3: 문서들 간의 유사도를 계산하시오\n",
    "def calculate_similarity(embeddings):\n",
    "    # 이 부분을 구현하세요\n",
    "    pass\n",
    "\n",
    "# 문제 4: 가장 유사한 문서 쌍을 찾으시오\n",
    "def find_most_similar_pair(similarities, docs):\n",
    "    # 이 부분을 구현하세요\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNZEEAyNjgZJ4QQC2TsgHFB",
   "mount_file_id": "1H4ZNal5I8Do5dJ2hma7tKNChye0lsRrE",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "modu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
