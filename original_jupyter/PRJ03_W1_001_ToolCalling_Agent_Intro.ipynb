{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Tool Calling (Function Calling) + 에이전트(Agent) 개념\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정 및 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Tool Calling**\n",
    "\n",
    "- **Tool Calling**은 LLM이 외부 시스템과 상호작용하기 위한 **함수 호출 메커니즘**\n",
    "\n",
    "- LLM은 정의된 도구나 함수를 통해 **외부 시스템과 통신**하고 작업을 수행\n",
    "\n",
    "- **Tool calling**은 모델이 시스템과 직접 상호작용할 수 있게 하는 기능\n",
    "\n",
    "- **구조화된 출력**을 통해 API나 데이터베이스와 같은 시스템 요구사항 충족\n",
    "\n",
    "- **스키마 기반 응답**으로 시스템 간 효율적 통신 가능\n",
    "\n",
    "\n",
    "![Tool Calling Concept](https://python.langchain.com/assets/images/tool_calling_concept-552a73031228ff9144c7d59f26dedbbf.png)\n",
    "\n",
    "\n",
    "[참조] https://python.langchain.com/docs/concepts/tool_calling/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. **Tool Creation** (`@tool` 데코레이터 사용)\n",
    "\n",
    "- **@tool 데코레이터**로 함수에 스키마 정보 추가\n",
    "\n",
    "- **함수와 스키마** 간 자동 연결로 도구 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import Literal\n",
    "\n",
    "@tool\n",
    "def get_weather(city: Literal[\"서울\", \"부산\", \"대구\", \"인천\", \"광주\"]):\n",
    "    \"\"\"한국 주요 도시의 날씨 정보를 가져옵니다.\"\"\"\n",
    "    weather_data = {\n",
    "        \"서울\": \"맑음\",\n",
    "        \"부산\": \"흐림\",\n",
    "        \"대구\": \"맑음\",\n",
    "        \"인천\": \"비\",\n",
    "        \"광주\": \"구름많음\"\n",
    "    }\n",
    "    \n",
    "    if city in weather_data:\n",
    "        return f\"{city}은(는) {weather_data[city]}\"\n",
    "    else:\n",
    "        raise AssertionError(\"지원하지 않는 도시입니다\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **[실습]**\n",
    "\n",
    "- **크로마 DB 재사용**을 위해 **프로젝트 2**의 `chromadb` 디렉토리를 현재 프로젝트 폴더에 **복사하여 활용**\n",
    "\n",
    "- 이전 프로젝트의 **테슬라, 리비안 데이터**를 동일한 **임베딩 모델**로 검색 가능하도록 구성\n",
    "\n",
    "- 사용자 정의 **문서 검색 도구**를 구현 (`@tool` 데코레이터 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB에 저장된 문서 개수: 39\n",
      "쿼리: 리비안은 언제 사업을 시작했나요?\n",
      "검색 결과:\n",
      "- [출처] 이 문서는 리비안에 대한 문서입니다.\n",
      "----------------------------------\n",
      "- **회사 유형:** 상장\n",
      "- **거래소:** NASDAQ: RIVN\n",
      "- **설립:** 2009년 6월, 플로리다 주 록ledge\n",
      "- **설립자:** R. J. 스캐린지\n",
      "- **본사:** 미국 캘리포니아 주 어바인\n",
      "- **서비스 지역:** 북미\n",
      "- **주요 인물:** R. J. 스캐린지 (CEO)\n",
      "- **제품:** 전기 자동차, 배터리\n",
      "- **생산량 (2023):** 57,232대\n",
      "- **서비스:** 전기 자동차 충전, 자동차 보험\n",
      "- **수익 (2023):** 44억 3천만 미국 달러\n",
      "- **순이익 (2023):** -54억 미국 달러\n",
      "- **총 자산 (2023):** 168억 미국 달러 [출처: data/리비안_KR.md]\n",
      "- [출처] 이 문서는 리비안에 대한 문서입니다.\n",
      "----------------------------------\n",
      "Rivian Automotive, Inc.는 2009년에 설립된 미국의 전기 자동차 제조업체, 자동차 기술 및 야외 레크리에이션 회사입니다.\n",
      "\n",
      "**주요 정보:** [출처: data/리비안_KR.md]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# 검색기 지정하여 테스트 \\nretriever = chroma_db.as_retriever(search_kwargs={\"k\": 3})\\n\\n# 테스트 쿼리\\ntest_docs = retriever.invoke(\"테슬라의 전기차 기술은 어떤가요?\")\\nprint(f\"\\n검색된 문서 개수: {len(test_docs)}\")\\nprint(f\"첫 번째 문서 미리보기:\\n{test_docs[0].page_content[:200]}...\")\\n\\n# DB 검색하는 사용자 정의 도구 생성\\n@tool\\ndef search_documents(query: str) -> str:\\n    \\'\\'\\'ChromaDB 벡터 저장소에서 테슬라와 리비안 관련 문서를 검색합니다.\\n\\n    Args:\\n        query: 검색할 질문이나 키워드\\n\\n    Returns:\\n        검색된 문서 내용들을 결합한 문자열\\n    \\'\\'\\'\\n    retriever = chroma_db.as_retriever(search_kwargs={\"k\": 3})\\n    docs = retriever.invoke(query)\\n\\n    # 검색된 문서들을 하나의 문자열로 결합\\n    result = \"\\n\\n---\\n\\n\".join([doc.page_content for doc in docs])\\n    return result\\n\\n# 도구 테스트\\nprint(\"\\n=== 문서 검색 도구 테스트 ===\")\\nresult = search_documents.invoke(\"리비안의 주요 특징은?\")\\nprint(result[:300] + \"...\")\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 벡터 저장소 로드 \n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "chroma_db = Chroma(\n",
    "    collection_name=\"db_korean_cosine_metadata\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "print(f\"ChromaDB에 저장된 문서 개수: {chroma_db._collection.count()}\")\n",
    "\n",
    "\n",
    "\n",
    "# 검색기 지정하여 테스트 \n",
    "chroma_k_retriever = chroma_db.as_retriever(\n",
    "    search_kwargs={\"k\": 2},\n",
    ")\n",
    "\n",
    "query = \"리비안은 언제 사업을 시작했나요?\"\n",
    "retrieved_docs = chroma_k_retriever.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DB 검색하는 사용자 정의 도구 생성\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_db(query: str):\n",
    "    \"\"\"리비안, 테슬라 회사에 대한 정보를 관련 데이터베이스에서 검색합니다.\"\"\"\n",
    "    return chroma_k_retriever.invoke(query)\n",
    "\n",
    "# 도구 실행\n",
    "search_db.invoke(\"리비안은 언제 사업을 시작했나요?\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# 검색기 지정하여 테스트 \n",
    "retriever = chroma_db.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# 테스트 쿼리\n",
    "test_docs = retriever.invoke(\"테슬라의 전기차 기술은 어떤가요?\")\n",
    "print(f\"\\n검색된 문서 개수: {len(test_docs)}\")\n",
    "print(f\"첫 번째 문서 미리보기:\\n{test_docs[0].page_content[:200]}...\")\n",
    "\n",
    "# DB 검색하는 사용자 정의 도구 생성\n",
    "@tool\n",
    "def search_documents(query: str) -> str:\n",
    "    '''ChromaDB 벡터 저장소에서 테슬라와 리비안 관련 문서를 검색합니다.\n",
    "    \n",
    "    Args:\n",
    "        query: 검색할 질문이나 키워드\n",
    "        \n",
    "    Returns:\n",
    "        검색된 문서 내용들을 결합한 문자열\n",
    "    '''\n",
    "    retriever = chroma_db.as_retriever(search_kwargs={\"k\": 3})\n",
    "    docs = retriever.invoke(query)\n",
    "    \n",
    "    # 검색된 문서들을 하나의 문자열로 결합\n",
    "    result = \"\\n\\n---\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    return result\n",
    "\n",
    "# 도구 테스트\n",
    "print(\"\\n=== 문서 검색 도구 테스트 ===\")\n",
    "result = search_documents.invoke(\"리비안의 주요 특징은?\")\n",
    "print(result[:300] + \"...\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. **Tool Binding** (모델에 Tool 연결)\n",
    "\n",
    "- **모델-도구 연결**로 입력 스키마 자동 인식\n",
    "\n",
    "- **스키마 기반 검증**으로 올바른 입력 보장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom langchain_openai import ChatOpenAI\\n\\n# 모델\\nmodel = ChatOpenAI(model=\"gpt-4.1-nano\",temperature=0)\\n\\n# 도구 목록\\ntools = [get_weather]\\n\\n# 도구를 모델에 바인딩 (bind_tools 메소드 사용)\\nmodel_with_tools = model.bind_tools([get_weather])\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\n",
    "    \"openai:gpt-4.1-nano\",\n",
    "    # Kwargs passed to the model:\n",
    "    temperature=0.7,\n",
    "    timeout=30,\n",
    "    max_tokens=1000,\n",
    ")\n",
    "\n",
    "# 도구 목록\n",
    "tools = [get_weather, search_db]\n",
    "\n",
    "# 도구를 모델에 바인딩 (bind_tools 메소드 사용)\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "\"\"\"\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 모델\n",
    "model = ChatOpenAI(model=\"gpt-4.1-nano\",temperature=0)\n",
    "\n",
    "# 도구 목록\n",
    "tools = [get_weather]\n",
    "\n",
    "# 도구를 모델에 바인딩 (bind_tools 메소드 사용)\n",
    "model_with_tools = model.bind_tools([get_weather])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 109, 'total_tokens': 123, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_1f35c1788c', 'id': 'chatcmpl-CT6RicEbJFRgNtBSJGf7fns3LEQNb', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--a9fbcd6a-e048-43e8-a173-8bfd5004c816-0' tool_calls=[{'name': 'get_weather', 'args': {'city': '서울'}, 'id': 'call_DvSK2oX3eat9PVOr9JSL8obk', 'type': 'tool_call'}] usage_metadata={'input_tokens': 109, 'output_tokens': 14, 'total_tokens': 123, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# 사용자 쿼리를 모델에 전달\n",
    "result = model_with_tools.invoke(\"서울 날씨 어때?\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **[실습]**\n",
    "\n",
    "- 앞의 실습에서 정의한 도구를 llm 모델에 **바인딩** 처리\n",
    "- 사용자 쿼리를 입력하여 출력 결과를 search_result 변수에 저장하고 출력 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 모델 응답 결과 ===\n",
      "content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 68, 'total_tokens': 88, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_4c0b74f64c', 'id': 'chatcmpl-CT6RjQFv4m4CeL9EL7alWsjBq2sRf', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--deee2d46-4e73-442c-84dc-fbc32a271fc5-0' tool_calls=[{'name': 'search_db', 'args': {'query': '테슬라 배터리 기술'}, 'id': 'call_WxsDdwoMup19o9i1H5pEoJSF', 'type': 'tool_call'}] usage_metadata={'input_tokens': 68, 'output_tokens': 20, 'total_tokens': 88, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "=== Tool Calls 확인 ===\n",
      "[{'args': {'query': '테슬라 배터리 기술'},\n",
      "  'id': 'call_WxsDdwoMup19o9i1H5pEoJSF',\n",
      "  'name': 'search_db',\n",
      "  'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "# 도구를 모델에 바인딩\n",
    "model_with_search = model.bind_tools([search_db])\n",
    "\n",
    "# 도구를 사용하여 쿼리 실행\n",
    "search_result = model_with_search.invoke(\"테슬라의 배터리 기술에 대해 알려주세요\")\n",
    "\n",
    "# 결과 출력\n",
    "print(\"=== 모델 응답 결과 ===\")\n",
    "print(search_result)\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"\\n=== Tool Calls 확인 ===\")\n",
    "pprint(search_result.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. **Tool Calling** (모델이 Tool을 사용하는 경우)\n",
    "\n",
    "- **스키마 기반 응답** 생성으로 정확한 입력 형식 준수\n",
    "\n",
    "- **자동 유효성 검증**으로 오류 방지\n",
    "\n",
    "- **구조화된 출력** 생성으로 시스템 호환성 보장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content: \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "additional_kwargs: \n",
      "{'refusal': None}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "response_metadata: \n",
      "{'token_usage': {'completion_tokens': 14, 'prompt_tokens': 109, 'total_tokens': 123, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_1f35c1788c', 'id': 'chatcmpl-CT6RicEbJFRgNtBSJGf7fns3LEQNb', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "type: \n",
      "ai\n",
      "----------------------------------------------------------------------------------------------------\n",
      "name: \n",
      "None\n",
      "----------------------------------------------------------------------------------------------------\n",
      "id: \n",
      "lc_run--a9fbcd6a-e048-43e8-a173-8bfd5004c816-0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tool_calls: \n",
      "[{'name': 'get_weather', 'args': {'city': '서울'}, 'id': 'call_DvSK2oX3eat9PVOr9JSL8obk', 'type': 'tool_call'}]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "invalid_tool_calls: \n",
      "[]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "usage_metadata: \n",
      "{'input_tokens': 109, 'output_tokens': 14, 'total_tokens': 123, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "for k in dict(result).keys():\n",
    "    print(f\"{k}: \")\n",
    "    print(dict(result)[k])\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'args': {'city': '서울'},\n",
      "  'id': 'call_DvSK2oX3eat9PVOr9JSL8obk',\n",
      "  'name': 'get_weather',\n",
      "  'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "# tool_calls 출력\n",
    "pprint(result.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **[실습]**\n",
    "\n",
    "- search_result 변수에 저장된 tool call 내역을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== search_result의 모든 속성 ===\n",
      "\n",
      "content: \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "additional_kwargs: \n",
      "{'refusal': None}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "response_metadata: \n",
      "{'token_usage': {'completion_tokens': 20, 'prompt_tokens': 68, 'total_tokens': 88, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_4c0b74f64c', 'id': 'chatcmpl-CT6RjQFv4m4CeL9EL7alWsjBq2sRf', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "type: \n",
      "ai\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "name: \n",
      "None\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "id: \n",
      "lc_run--deee2d46-4e73-442c-84dc-fbc32a271fc5-0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "tool_calls: \n",
      "[{'name': 'search_db', 'args': {'query': '테슬라 배터리 기술'}, 'id': 'call_WxsDdwoMup19o9i1H5pEoJSF', 'type': 'tool_call'}]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "invalid_tool_calls: \n",
      "[]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "usage_metadata: \n",
      "{'input_tokens': 68, 'output_tokens': 20, 'total_tokens': 88, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "=== Tool Calls 상세 정보 ===\n",
      "[{'args': {'query': '테슬라 배터리 기술'},\n",
      "  'id': 'call_WxsDdwoMup19o9i1H5pEoJSF',\n",
      "  'name': 'search_db',\n",
      "  'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(\"=== search_result의 모든 속성 ===\")\n",
    "for k in dict(search_result).keys():\n",
    "    print(f\"\\n{k}: \")\n",
    "    print(dict(search_result)[k])\n",
    "    print(\"-\"*100)\n",
    "\n",
    "# tool_calls 출력\n",
    "print(\"\\n=== Tool Calls 상세 정보 ===\")\n",
    "pprint(search_result.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. **Tool Execution**  (Tool이 호출된 경우 실행)\n",
    "\n",
    "- **인자 기반 실행**으로 도구 기능 수행\n",
    "\n",
    "- **모델 제공 파라미터**로 자동화된 실행\n",
    "\n",
    "- **실행 결과** 처리 및 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'서울은(는) 맑음'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 함수의 인자를 직접 전달하는 방식으로 실행 -> 도구를 직접 호출\n",
    "get_weather.invoke(\"서울\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='서울은(는) 맑음', name='get_weather', tool_call_id='call_DvSK2oX3eat9PVOr9JSL8obk')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ToolCall 객체를 전달 전달하는 방식으로 실행 -> ToolMessage 객체를 반환\n",
    "get_weather.invoke(result.tool_calls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "###  Tool Calling 사용 시 **고려사항**\n",
    "\n",
    "- **모델 호환성**이 Tool Calling 성능에 직접 영향\n",
    "\n",
    "- **명확한 도구 정의**가 모델의 이해도와 활용도 향상\n",
    "\n",
    "- **단순한 기능**의 도구가 더 효과적으로 작동\n",
    "\n",
    "- **과다한 도구**는 모델 성능 저하 유발"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **[실습]**\n",
    "\n",
    "- search_result 변수에 저장된 tool call 내역을 직접 도구에 적용하여 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ToolMessage 객체 ===\n",
      "타입: <class 'langchain_core.messages.tool.ToolMessage'>\n",
      "\n",
      "도구 이름: search_db\n",
      "Tool Call ID: call_WxsDdwoMup19o9i1H5pEoJSF\n",
      "\n",
      "검색 결과 내용 (처음 500자):\n",
      "[Document(id='5f7b0a65-c409-47ab-84cb-d8b58229400c', metadata={'company': '테슬라', 'language': 'ko', 'source': 'data/테슬라_KR.md'}, page_content='[출처] 이 문서는 테슬라에 대한 문서입니다.\\n----------------------------------\\n## 비즈니스 전략\\n\\nTesla의 전략은 배터리 비용을 줄이기 위해 고가, 소량 차량으로 시작한 다음 더 저렴하고 대량 차량을 제공하는 것입니다. Tesla는 자동차의 하드웨어를 지속적으로 업데이트하고 웹사이트와 회사 소유 매장을 통해 직접 차량을 판매합니다. Tesla는 수직적으로 통합되어 많은 구성 요소를 자체 개발합니다. Tesla는 일반적으로 지속 가능한 에너지 채택을 촉진하기 위해 경쟁 업체가 자사 기술을 라이선스하도록 허용합니다.\\n\\n## 기술\\n\\n### 배터리\\n\\nTesla는 CATL, LG E...\n"
     ]
    }
   ],
   "source": [
    "# ToolCall 객체를 전달하는 방식으로 실행 -> ToolMessage 객체를 반환\n",
    "if search_result.tool_calls:\n",
    "    # 첫 번째 tool call을 사용하여 도구 실행\n",
    "    tool_message = search_db.invoke(search_result.tool_calls[0])\n",
    "    \n",
    "    print(\"=== ToolMessage 객체 ===\")\n",
    "    print(f\"타입: {type(tool_message)}\")\n",
    "    print(f\"\\n도구 이름: {tool_message.name}\")\n",
    "    print(f\"Tool Call ID: {tool_message.tool_call_id}\")\n",
    "    print(f\"\\n검색 결과 내용 (처음 500자):\\n{str(tool_message.content)[:500]}...\")\n",
    "else:\n",
    "    print(\"도구 호출이 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Agent**\n",
    "\n",
    "- **LLM(대규모 언어 모델)** 을 의사결정 엔진으로 사용하여 작업을 수행하는 시스템\n",
    "\n",
    "- 모델은 입력된 데이터를 분석하여 **맥락에 맞는 의사결정**을 수행\n",
    "\n",
    "- 시스템은 사용자의 요청을 이해하고 **적절한 해결책**을 제시\n",
    "\n",
    "- 복잡한 작업을 자동화하여 **업무 효율성**을 높일 수 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **create_agent** \n",
    "\n",
    "- **create_agent**는 LangChain v1.0의 표준 에이전트 생성 함수\n",
    "\n",
    "- LangGraph를 기반으로 구축되어 **영속성, 스트리밍, Human-in-the-loop** 등의 기능을 자동 지원\n",
    "\n",
    "- **미들웨어**를 통한 유연한 커스터마이징 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 추가 도구 정의`\n",
    "\n",
    "- **@tool 데코레이터**를 사용해 계산(파이썬 코드 실행) 기능을 가진 **커스텀 도구를 정의**\n",
    "\n",
    "- 데코레이터를 통해 함수가 **Tool Calling 시스템에 등록**되어 LLM이 호출 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculate(expression: str) -> float:\n",
    "    \"\"\"수학 계산을 수행합니다.\"\"\"\n",
    "    return eval(expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 도구 실행 \n",
    "calculate.invoke(\"3+2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) create_agent로 에이전트 생성`\n",
    "\n",
    "- **create_agent**는 모델, 도구, 시스템 프롬프트를 받아 에이전트를 생성\n",
    "\n",
    "- **system_prompt** 매개변수로 에이전트의 역할과 행동 방식을 정의\n",
    "\n",
    "- LangGraph 기반으로 구축되어 자동으로 메시지 기록, 도구 실행 루프 등을 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에이전트가 성공적으로 생성되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaydash\\AppData\\Local\\Temp\\ipykernel_41264\\2589284234.py:19: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent = create_react_agent(\n"
     ]
    }
   ],
   "source": [
    "# LangGraph의 create_react_agent 사용\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 모델 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 도구 목록\n",
    "tools = [get_weather, calculate]\n",
    "\n",
    "# 시스템 프롬프트를 포함한 프롬프트 템플릿 생성\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 사용자의 요청을 처리하는 AI Assistant입니다.\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# 에이전트 생성 (prompt 파라미터 사용)\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "print(\"에이전트가 성공적으로 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) 에이전트 실행`\n",
    "\n",
    "- **invoke** 메서드로 에이전트를 실행\n",
    "\n",
    "- **messages** 키에 대화 메시지 리스트를 전달\n",
    "\n",
    "- 에이전트는 자동으로 필요한 도구를 호출하고 최종 응답을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='서울의 날씨는 어떤가요?', additional_kwargs={}, response_metadata={}, id='c6008f62-3cbb-49a6-b903-8040f153eeac'),\n",
      "              AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 112, 'total_tokens': 126, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CT6RkA5KXoqcW6hXhO5Rt9jKrizXf', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--aefc7d63-c4f9-4b71-a1a9-5a28ec85b2f9-0', tool_calls=[{'name': 'get_weather', 'args': {'city': '서울'}, 'id': 'call_Kb0PQKayN2FCfdI9wpnrkY3a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 112, 'output_tokens': 14, 'total_tokens': 126, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='서울은(는) 맑음', name='get_weather', id='0ba875a4-6ffe-4c57-a2a8-1651d0b4bd09', tool_call_id='call_Kb0PQKayN2FCfdI9wpnrkY3a'),\n",
      "              AIMessage(content='서울의 날씨는 맑습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 142, 'total_tokens': 152, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CT6RmTF02FjG9ZpkciRQhTCvqYtUE', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--a2acc2a6-a862-455d-a07c-36f714540aab-0', usage_metadata={'input_tokens': 142, 'output_tokens': 10, 'total_tokens': 152, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "# 에이전트 실행\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"서울의 날씨는 어떤가요?\"}]},\n",
    ")\n",
    "\n",
    "# 에이전트 실행 결과 출력\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "서울의 날씨는 어떤가요?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (call_Kb0PQKayN2FCfdI9wpnrkY3a)\n",
      " Call ID: call_Kb0PQKayN2FCfdI9wpnrkY3a\n",
      "  Args:\n",
      "    city: 서울\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "서울은(는) 맑음\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "서울의 날씨는 맑습니다.\n"
     ]
    }
   ],
   "source": [
    "for msg in response['messages']:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "32 더하기 18은 얼마인가요?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  calculate (call_kkKFJpKXjbfWcrl2NE1qUsjo)\n",
      " Call ID: call_kkKFJpKXjbfWcrl2NE1qUsjo\n",
      "  Args:\n",
      "    expression: 32 + 18\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: calculate\n",
      "\n",
      "50\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "32 더하기 18은 50입니다.\n"
     ]
    }
   ],
   "source": [
    "# 계산 도구를 사용하는 예제\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"32 더하기 18은 얼마인가요?\"}]},\n",
    ")\n",
    "\n",
    "# 에이전트 실행 결과 출력\n",
    "for msg in response['messages']:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) 중간 단계 확인하기`\n",
    "\n",
    "- **stream_mode=\"values\"** 를 사용하여 에이전트의 실행 과정을 스트리밍으로 확인\n",
    "\n",
    "- 각 단계에서 모델의 사고 과정과 도구 호출 내역을 추적 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "32 곱하기 18은 얼마인가요?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  calculate (call_jK9jOWtyi0GefLc5TRicXwvx)\n",
      " Call ID: call_jK9jOWtyi0GefLc5TRicXwvx\n",
      "  Args:\n",
      "    expression: 32 * 18\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: calculate\n",
      "\n",
      "576\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "32 곱하기 18은 576입니다.\n"
     ]
    }
   ],
   "source": [
    "# 스트리밍 모드로 중간 단계 확인\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"32 곱하기 18은 얼마인가요?\"}]},\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "    # 각 단계의 메시지 출력\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **[실습]**\n",
    "\n",
    "- 이전 [실습]에서 구현한 **문서 검색 도구**를 사용하여 에이전트 구현 및 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 검색 에이전트가 생성되었습니다.\n",
      "\n",
      "=== 에이전트 실행 예제 1: 테슬라 관련 질문 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaydash\\AppData\\Local\\Temp\\ipykernel_41264\\453513859.py:22: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  doc_agent = create_react_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "테슬라의 주요 기술적 특징은 무엇인가요?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_db (call_zWiXdhcSQhqQjDi9SkYZZ4nH)\n",
      " Call ID: call_zWiXdhcSQhqQjDi9SkYZZ4nH\n",
      "  Args:\n",
      "    query: 테슬라 주요 기술적 특징\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_db\n",
      "\n",
      "[Document(id='03c822e1-b421-4811-b362-e68fec329fdf', metadata={'company': '테슬라', 'language': 'ko', 'source': 'data/테슬라_KR.md'}, page_content='[출처] 이 문서는 테슬라에 대한 문서입니다.\\n----------------------------------\\n### 소프트웨어\\n\\nTesla는 무선 업데이트를 사용하여 강력한 온보드 컴퓨터를 통해 기능을 추가하거나 문제를 해결합니다.\\n\\n### 모터\\n\\nTesla는 유도 모터와 동기 릴럭턴스 모터(SynRM) 특성을 가진 내부 영구 자석(IPM) 모터를 만듭니다.\\n\\n### 북미 충전 표준\\n\\n북미 충전 표준(NACS)은 Tesla에서 개발한 전기 자동차 충전 커넥터 시스템입니다.\\n\\n### Autopilot 및 완전 자율 주행\\n\\nTesla Autopilot은 Tesla에서 개발한 고급 운전자 지원 시스템(ADAS)으로, 부분적인 차량 자동화를 의미합니다.\\n\\n### 로봇 공학'), Document(id='b2eb6d62-9519-4875-8f22-ce6b4c69de50', metadata={'source': 'data/테슬라_KR.md', 'company': '테슬라', 'language': 'ko'}, page_content='[출처] 이 문서는 테슬라에 대한 문서입니다.\\n----------------------------------\\n- **Cybertruck:** 2019년 11월에 처음 발표된 풀사이즈 픽업 트럭. 후륜 구동, 듀얼 모터 전륜 구동, 트리 모터 전륜 구동의 세 가지 모델이 제공됩니다.')]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "테슬라의 주요 기술적 특징은 다음과 같습니다:\n",
      "\n",
      "1. **소프트웨어**: 테슬라는 무선 업데이트를 통해 차량의 기능을 추가하거나 문제를 해결할 수 있는 강력한 온보드 컴퓨터를 사용합니다. 이를 통해 차량의 성능과 기능이 지속적으로 개선됩니다.\n",
      "\n",
      "2. **모터**: 테슬라는 유도 모터와 동기 릴럭턴스 모터(SynRM) 특성을 가진 내부 영구 자석(IPM) 모터를 제작합니다. 이러한 모터는 높은 효율성과 성능을 제공합니다.\n",
      "\n",
      "3. **북미 충전 표준(NACS)**: 테슬라에서 개발한 전기 자동차 충전 커넥터 시스템으로, 북미 지역에서의 충전 인프라를 지원합니다.\n",
      "\n",
      "4. **Autopilot 및 완전 자율 주행**: 테슬라의 Autopilot은 고급 운전자 지원 시스템(ADAS)으로, 차량의 부분적인 자동화를 가능하게 합니다. 이는 운전자의 편의를 높이고 안전성을 향상시키는 데 기여합니다.\n",
      "\n",
      "5. **로봇 공학**: 테슬라는 로봇 공학 기술을 활용하여 생산 공정의 효율성을 높이고 있습니다.\n",
      "\n",
      "이러한 기술들은 테슬라가 전기차 시장에서 경쟁력을 유지하는 데 중요한 역할을 하고 있습니다.\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "=== 에이전트 실행 예제 2: 리비안 관련 질문 ===\n",
      "\n",
      "최종 답변:\n",
      "리비안 전기차의 주요 특징은 다음과 같습니다:\n",
      "\n",
      "1. **회사 정보**:\n",
      "   - 리비안(Rivian)은 2009년에 설립된 미국의 전기 자동차 제조업체입니다.\n",
      "   - 본사는 캘리포니아 주 어바인에 위치하고 있으며, NASDAQ에 상장되어 있습니다 (티커: RIVN).\n",
      "\n",
      "2. **제품 및 서비스**:\n",
      "   - 리비안은 전기 자동차와 배터리를 주요 제품으로 하고 있으며, 전기 자동차 충전 및 자동차 보험 서비스도 제공합니다.\n",
      "\n",
      "3. **생산량 및 재무 정보**:\n",
      "   - 2023년 기준으로 리비안은 57,232대의 전기차를 생산하였으며, 수익은 약 44억 3천만 달러에 달하지만, 순이익은 -54억 달러로 적자를 기록하고 있습니다.\n",
      "\n",
      "4. **특징적인 모델**:\n",
      "   - 리비안의 전기차는 주로 아웃도어 레크리에이션을 위한 SUV와 픽업트럭 모델에 중점을 두고 있습니다. 이들은 오프로드 성능과 혁신적인 기술을 갖추고 있습니다.\n",
      "\n",
      "리비안은 전기차 시장에서 독특한 위치를 차지하고 있으며, 특히 아웃도어 활동을 즐기는 소비자들을 겨냥한 제품 라인업을 가지고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 import\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 사용자 정의 시스템 프롬프트\n",
    "system_message = \"\"\"당신은 테슬라와 리비안 전기차에 대한 전문 상담 AI입니다.\n",
    "사용자의 질문에 대해 ChromaDB에 저장된 문서를 검색하여 정확한 정보를 제공하세요.\n",
    "\n",
    "검색된 문서 내용을 바탕으로:\n",
    "1. 질문에 대한 직접적인 답변을 제공하세요\n",
    "2. 관련된 세부 정보를 포함하세요\n",
    "3. 검색 결과가 없으면 솔직하게 알려주세요\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "doc_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_message),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# 에이전트 생성 (prompt 파라미터 사용)\n",
    "doc_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[search_db],\n",
    "    prompt=doc_prompt\n",
    ")\n",
    "\n",
    "print(\"문서 검색 에이전트가 생성되었습니다.\\n\")\n",
    "\n",
    "# 에이전트 실행\n",
    "print(\"=== 에이전트 실행 예제 1: 테슬라 관련 질문 ===\")\n",
    "response1 = doc_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"테슬라의 주요 기술적 특징은 무엇인가요?\"}]}\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "for msg in response1['messages']:\n",
    "    msg.pretty_print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"\\n=== 에이전트 실행 예제 2: 리비안 관련 질문 ===\")\n",
    "response2 = doc_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"리비안 전기차의 특징을 알려주세요\"}]}\n",
    ")\n",
    "\n",
    "# 최종 답변만 출력\n",
    "final_message = response2['messages'][-1]\n",
    "print(f\"\\n최종 답변:\\n{final_message.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modu3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
