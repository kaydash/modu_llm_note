{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ê¸°ë²• \n",
    "\n",
    "- ì¬ìˆœìœ„í™” (Re-rank)\n",
    "- ë§¥ë½ ì••ì¶•  (Contextural Compression)\n",
    "\n",
    "### **í•™ìŠµ ëª©í‘œ:** ì¬ìˆœìœ„í™”(Re-rank) ê¸°ë²•, ë§¥ë½ ì••ì¶•(Contextual Compression) ê¸°ë²•ì„ í™œìš©í•˜ì—¬ ìµœì¢… ê²€ìƒ‰ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•œë‹¤\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í™˜ê²½ ì„¤ì • ë° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env í™˜ê²½ë³€ìˆ˜`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) langfuase handler ì„¤ì •`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# LangChain ì½œë°± í•¸ë“¤ëŸ¬ ìƒì„±\n",
    "langfuse_handler = CallbackHandler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ \n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "chroma_db = Chroma(\n",
    "    collection_name=\"db_korean_cosine_metadata\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(5) ë°±í„° ê²€ìƒ‰ê¸° ìƒì„±`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "- **Cybertruck:** 2019ë…„ 11ì›”ì— ì²˜ìŒ ë°œí‘œëœ í’€ì‚¬ì´ì¦ˆ í”½ì—… íŠ¸ëŸ­. í›„ë¥œ êµ¬ë™, ë“€ì–¼ ëª¨í„° ì „ë¥œ êµ¬ë™, íŠ¸ë¦¬ ëª¨í„° ì „ë¥œ êµ¬ë™ì˜ ì„¸ ê°€ì§€ ëª¨ë¸ì´ ì œê³µë©ë‹ˆë‹¤. [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "| Tesla ëª¨ë¸ |          |       |                  |\n",
      "| :--------- | :------- | :---- | :--------------- |\n",
      "| ì´ë¦„       | ì œì¡°ë…„ë„ | ì¢Œì„  | ì°¸ê³              |\n",
      "| Roadster   | 2008     | 2     | 2012ë…„ì— ë‹¨ì¢…    |\n",
      "| Model S    | 2012     | 5/7   |                  |\n",
      "| Model X    | 2015     | 5/6/7 |                  |\n",
      "| Model 3    | 2017     | 5     |                  |\n",
      "| Model Y    | 2020     | 5/7   |                  |\n",
      "| Semi       | 2022     | 2     |                  |\n",
      "| Cybertruck | 2023     | 5     |                  |\n",
      "| Roadster 2 |          | 2/4   | 2025ë…„ ì¶œì‹œ ì˜ˆì • |\n",
      "| Cybercab   |          | 2     | 2026ë…„ ì¶œì‹œ ì˜ˆì • |\n",
      "| Robovan    |          | 20    | ëª…ì‹œëœ ê¸°ê°„ ì—†ìŒ |\n",
      "\n",
      "### ì‚¬ìš© ê°€ëŠ¥í•œ ì œí’ˆ [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "- **Model 3:** íŒ¨ìŠ¤íŠ¸ë°± ì°¨ì²´ ìŠ¤íƒ€ì¼ê³¼ ë“€ì–¼ ëª¨í„°, ì „ë¥œ êµ¬ë™ ë ˆì´ì•„ì›ƒ ë˜ëŠ” í›„ë¥œ ëª¨í„°, í›„ë¥œ êµ¬ë™ ë ˆì´ì•„ì›ƒì„ ê°–ì¶˜ ì¤‘í˜•ì°¨. ì´ ì°¨ëŸ‰ì€ ê³ ê¸‰ Model S ì„¸ë‹¨ë³´ë‹¤ ì €ë ´í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. Model 3 í”„ë¡œí† íƒ€ì…ì€ 2016ë…„ì— ì²˜ìŒ ê³µê°œë˜ì—ˆìœ¼ë©° ì¼ì£¼ì¼ ë§Œì— 325,000ê±´ ì´ìƒì˜ ìœ ë£Œ ì˜ˆì•½ì´ ì ‘ìˆ˜ë˜ì—ˆìŠµë‹ˆë‹¤. [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "- **Model S:** ë¦¬í”„íŠ¸ë°± ì°¨ì²´ ìŠ¤íƒ€ì¼ê³¼ ë“€ì–¼ ëª¨í„°, ì „ë¥œ êµ¬ë™ ë ˆì´ì•„ì›ƒì„ ê°–ì¶˜ í’€ì‚¬ì´ì¦ˆ ê³ ê¸‰ì°¨. Model S ê°œë°œì€ 2007ë…„ ì´ì „ì— ì‹œì‘ë˜ì—ˆìœ¼ë©° ë°°ì†¡ì€ 2012ë…„ 6ì›”ì— ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "- **Model X:** ë“€ì–¼ ëª¨í„° ë˜ëŠ” íŠ¸ë¦¬ ëª¨í„°, ì „ë¥œ êµ¬ë™ ë ˆì´ì•„ì›ƒì„ ê°–ì¶˜ 5ì¸ìŠ¹, 6ì¸ìŠ¹ ë° 7ì¸ìŠ¹ êµ¬ì„±ìœ¼ë¡œ ì œê³µë˜ëŠ” ì¤‘í˜• ê³ ê¸‰ í¬ë¡œìŠ¤ì˜¤ë²„ SUV. ë’·ì¢Œì„ ìŠ¹ê° ë¬¸ì€ ê´€ì ˆí˜• \"íŒ”ì½˜ ìœ™\" ë””ìì¸ìœ¼ë¡œ ìˆ˜ì§ìœ¼ë¡œ ì—´ë¦½ë‹ˆë‹¤. Model X í”„ë¡œí† íƒ€ì…ì€ 2012ë…„ 2ì›”ì— ì²˜ìŒ ê³µê°œë˜ì—ˆìœ¼ë©° ë°°ì†¡ì€ 2015ë…„ 9ì›”ì— ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "- **Model Y:** ì‹±ê¸€ ëª¨í„°, í›„ë¥œ êµ¬ë™ ë˜ëŠ” ë“€ì–¼ ëª¨í„°, ì „ë¥œ êµ¬ë™ ë ˆì´ì•„ì›ƒì„ ê°–ì¶˜ 5ì¸ìŠ¹ ë° 7ì¸ìŠ¹ êµ¬ì„±ìœ¼ë¡œ ì œê³µë˜ëŠ” ì¤‘í˜• í¬ë¡œìŠ¤ì˜¤ë²„ SUV. ì´ ì°¨ëŸ‰ì€ ê³ ê¸‰ Model X SUVë³´ë‹¤ ì €ë ´í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. Model Y í”„ë¡œí† íƒ€ì…ì€ 2019ë…„ 3ì›”ì— ì²˜ìŒ ê³µê°œë˜ì—ˆìœ¼ë©° ë°°ì†¡ì€ 2020ë…„ 3ì›”ì— ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "- **Tesla Semi:** Tesla SemiëŠ” Tesla, Inc.ì˜ í´ë˜ìŠ¤ 8 ì„¸ë¯¸ íŠ¸ëŸ­ìœ¼ë¡œ, íŠ¸ë¦¬ ëª¨í„°, í›„ë¥œ êµ¬ë™ ë ˆì´ì•„ì›ƒì„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤. TeslaëŠ” Semiê°€ ì¼ë°˜ì ì¸ ë””ì ¤ ì„¸ë¯¸ íŠ¸ëŸ­ë³´ë‹¤ ì•½ 3ë°° ë” ê°•ë ¥í•˜ê³  ì£¼í–‰ ê±°ë¦¬ê°€ 500ë§ˆì¼(800km)ì´ë¼ê³  ì£¼ì¥í•©ë‹ˆë‹¤. ì´ˆê¸° ë°°ì†¡ì€ 2022ë…„ 12ì›” 1ì¼ì— PepsiCoì— ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤. [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "========================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ê¸°ë³¸ retriever ì´ˆê¸°í™”\n",
    "chroma_k_retriever = chroma_db.as_retriever(\n",
    "    search_kwargs={\"k\": 5}\n",
    ")\n",
    "\n",
    "query = \"í…ŒìŠ¬ë¼ íŠ¸ëŸ­ ëª¨ë¸ì´ ìˆë‚˜ìš”?\"\n",
    "retrieved_docs = chroma_k_retriever.invoke(query, config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [ì¶œì²˜: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Re-rank** (ì¬ìˆœìœ„í™”)\n",
    "\n",
    "- **ì¬ìˆœìœ„í™”**ëŠ” ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¬ë¶„ì„í•˜ì—¬ ìµœì ì˜ ìˆœì„œë¡œ ì •ë ¬í•˜ëŠ” ê³ ë„í™”ëœ ê¸°ìˆ ì„\n",
    "\n",
    "- **ì´ì¤‘ ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤**ë¡œ ê¸°ë³¸ ê²€ìƒ‰ í›„ ì •êµí•œ ê¸°ì¤€ìœ¼ë¡œ ì¬í‰ê°€ë¥¼ ì§„í–‰í•¨\n",
    "    1. ë¨¼ì € ê¸°ë³¸ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œë“¤ì„ ì°¾ì€ í›„, \n",
    "    2. ë” ì •êµí•œ ê¸°ì¤€ìœ¼ë¡œ ì´ë“¤ì„ ì¬í‰ê°€í•˜ì—¬ ìµœì¢… ìˆœìœ„ë¥¼ ê²°ì •\n",
    "\n",
    "- ì‚¬ìš©ìì˜ ê²€ìƒ‰ ì˜ë„ì— ë§ëŠ” **ì •í™•ë„ í–¥ìƒ**ì„ í†µí•´ ê²€ìƒ‰ í’ˆì§ˆì„ ê°œì„ í•¨\n",
    "\n",
    "- ê²€ìƒ‰ ê²°ê³¼ì˜ í’ˆì§ˆì„ ë†’ì´ê¸° ìœ„í•œ ì²´ê³„ì ì¸ ìµœì í™” ë°©ë²•ë¡ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### 1) **Cross Encoder** Reranker\n",
    "\n",
    "- **Cross-Encoder** ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ì˜ ì •ë°€í•œ ì¬ì •ë ¬ì„ ìˆ˜í–‰í•¨\n",
    "- ë°ì´í„°ë¥¼ **ìŒ(pair) ë‹¨ìœ„**ë¡œ ì²˜ë¦¬í•˜ì—¬ ë¬¸ì„œì™€ ì¿¼ë¦¬ ê°„ì˜ ê´€ê³„ë¥¼ ë¶„ì„í•¨ (ì˜ˆ: ë‘ ê°œì˜ ë¬¸ì¥ ë˜ëŠ” ë¬¸ì„œ)\n",
    "- **í†µí•© ì¸ì½”ë”© ë°©ì‹**ìœ¼ë¡œ ê²€ìƒ‰ ì¿¼ë¦¬ì™€ ê²€ìƒ‰ëœ ë¬¸ì„œ ê°„ ìœ ì‚¬ë„ë¥¼ ë” ì •í™•í•˜ê²Œ ê³„ì‚°í•¨\n",
    "\n",
    "- ì°¸ê³ : https://www.sbert.net/examples/applications/cross-encoder/README.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) ëª¨ë¸ ì´ˆê¸°í™”`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "# CrossEncoderReranker ëª¨ë¸ ì´ˆê¸°í™” \n",
    "model = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-v2-m3\")\n",
    "\n",
    "# CrossEncoderReranker ëª¨ë¸ì„ ì‚¬ìš©í•œ re-ranker ì´ˆê¸°í™” (top_n: 3)\n",
    "re_ranker = CrossEncoderReranker(model=model, top_n=3)\n",
    "\n",
    "# CrossEncoderRerankerë¥¼ ì‚¬ìš©í•œ retriever ì´ˆê¸°í™”\n",
    "cross_encoder_reranker_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=re_ranker, \n",
    "    base_retriever=chroma_k_retriever,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) ë¬¸ì„œ ê²€ìƒ‰`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "- **Cybertruck:** 2019ë…„ 11ì›”ì— ì²˜ìŒ ë°œí‘œëœ í’€ì‚¬ì´ì¦ˆ í”½ì—… íŠ¸ëŸ­. í›„ë¥œ êµ¬ë™, ë“€ì–¼ ëª¨í„° ì „ë¥œ êµ¬ë™, íŠ¸ë¦¬ ëª¨í„° ì „ë¥œ êµ¬ë™ì˜ ì„¸ ê°€ì§€ ëª¨ë¸ì´ ì œê³µë©ë‹ˆë‹¤. [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "- **Model Y:** ì‹±ê¸€ ëª¨í„°, í›„ë¥œ êµ¬ë™ ë˜ëŠ” ë“€ì–¼ ëª¨í„°, ì „ë¥œ êµ¬ë™ ë ˆì´ì•„ì›ƒì„ ê°–ì¶˜ 5ì¸ìŠ¹ ë° 7ì¸ìŠ¹ êµ¬ì„±ìœ¼ë¡œ ì œê³µë˜ëŠ” ì¤‘í˜• í¬ë¡œìŠ¤ì˜¤ë²„ SUV. ì´ ì°¨ëŸ‰ì€ ê³ ê¸‰ Model X SUVë³´ë‹¤ ì €ë ´í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. Model Y í”„ë¡œí† íƒ€ì…ì€ 2019ë…„ 3ì›”ì— ì²˜ìŒ ê³µê°œë˜ì—ˆìœ¼ë©° ë°°ì†¡ì€ 2020ë…„ 3ì›”ì— ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "- **Tesla Semi:** Tesla SemiëŠ” Tesla, Inc.ì˜ í´ë˜ìŠ¤ 8 ì„¸ë¯¸ íŠ¸ëŸ­ìœ¼ë¡œ, íŠ¸ë¦¬ ëª¨í„°, í›„ë¥œ êµ¬ë™ ë ˆì´ì•„ì›ƒì„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤. TeslaëŠ” Semiê°€ ì¼ë°˜ì ì¸ ë””ì ¤ ì„¸ë¯¸ íŠ¸ëŸ­ë³´ë‹¤ ì•½ 3ë°° ë” ê°•ë ¥í•˜ê³  ì£¼í–‰ ê±°ë¦¬ê°€ 500ë§ˆì¼(800km)ì´ë¼ê³  ì£¼ì¥í•©ë‹ˆë‹¤. ì´ˆê¸° ë°°ì†¡ì€ 2022ë…„ 12ì›” 1ì¼ì— PepsiCoì— ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤. [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "| Tesla ëª¨ë¸ |          |       |                  |\n",
      "| :--------- | :------- | :---- | :--------------- |\n",
      "| ì´ë¦„       | ì œì¡°ë…„ë„ | ì¢Œì„  | ì°¸ê³              |\n",
      "| Roadster   | 2008     | 2     | 2012ë…„ì— ë‹¨ì¢…    |\n",
      "| Model S    | 2012     | 5/7   |                  |\n",
      "| Model X    | 2015     | 5/6/7 |                  |\n",
      "| Model 3    | 2017     | 5     |                  |\n",
      "| Model Y    | 2020     | 5/7   |                  |\n",
      "| Semi       | 2022     | 2     |                  |\n",
      "| Cybertruck | 2023     | 5     |                  |\n",
      "| Roadster 2 |          | 2/4   | 2025ë…„ ì¶œì‹œ ì˜ˆì • |\n",
      "| Cybercab   |          | 2     | 2026ë…„ ì¶œì‹œ ì˜ˆì • |\n",
      "| Robovan    |          | 20    | ëª…ì‹œëœ ê¸°ê°„ ì—†ìŒ |\n",
      "\n",
      "### ì‚¬ìš© ê°€ëŠ¥í•œ ì œí’ˆ [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "========================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# CrossEncoderRerankerë¥¼ ì‚¬ìš©í•œ retrieverë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰\n",
    "query = \"í…ŒìŠ¬ë¼ íŠ¸ëŸ­ ëª¨ë¸ì´ ìˆë‚˜ìš”?\"\n",
    "retrieved_docs = cross_encoder_reranker_retriever.invoke(query, config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [ì¶œì²˜: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) **LLM** Reranker\n",
    "\n",
    "- **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸**ì„ í™œìš©í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ì˜ ì¬ìˆœìœ„í™”ë¥¼ ìˆ˜í–‰í•¨\n",
    "- ì¿¼ë¦¬ì™€ ë¬¸ì„œ ê°„ì˜ **ê´€ë ¨ì„± ë¶„ì„**ì„ í†µí•´ ìµœì ì˜ ìˆœì„œë¥¼ ë„ì¶œí•¨\n",
    "- **LLMListwiseRerank**ì™€ ê°™ì€ ì „ë¬¸í™”ëœ ì¬ìˆœìœ„í™” ëª¨ë¸ì„ ì ìš©í•¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) ëª¨ë¸ ì´ˆê¸°í™”`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMListwiseRerank\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# LLMListwiseRerank ëª¨ë¸ ì´ˆê¸°í™” (top_n: 3)\n",
    "re_ranker = LLMListwiseRerank.from_llm(llm, top_n=3)\n",
    "\n",
    "# LLMListwiseRerank ëª¨ë¸ì„ ì‚¬ìš©í•œ re-ranker ì´ˆê¸°í™”\n",
    "llm_reranker_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=re_ranker, \n",
    "    base_retriever=chroma_k_retriever,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) ë¬¸ì„œ ê²€ìƒ‰`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "- **Cybertruck:** 2019ë…„ 11ì›”ì— ì²˜ìŒ ë°œí‘œëœ í’€ì‚¬ì´ì¦ˆ í”½ì—… íŠ¸ëŸ­. í›„ë¥œ êµ¬ë™, ë“€ì–¼ ëª¨í„° ì „ë¥œ êµ¬ë™, íŠ¸ë¦¬ ëª¨í„° ì „ë¥œ êµ¬ë™ì˜ ì„¸ ê°€ì§€ ëª¨ë¸ì´ ì œê³µë©ë‹ˆë‹¤. [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "- **Model Y:** ì‹±ê¸€ ëª¨í„°, í›„ë¥œ êµ¬ë™ ë˜ëŠ” ë“€ì–¼ ëª¨í„°, ì „ë¥œ êµ¬ë™ ë ˆì´ì•„ì›ƒì„ ê°–ì¶˜ 5ì¸ìŠ¹ ë° 7ì¸ìŠ¹ êµ¬ì„±ìœ¼ë¡œ ì œê³µë˜ëŠ” ì¤‘í˜• í¬ë¡œìŠ¤ì˜¤ë²„ SUV. ì´ ì°¨ëŸ‰ì€ ê³ ê¸‰ Model X SUVë³´ë‹¤ ì €ë ´í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. Model Y í”„ë¡œí† íƒ€ì…ì€ 2019ë…„ 3ì›”ì— ì²˜ìŒ ê³µê°œë˜ì—ˆìœ¼ë©° ë°°ì†¡ì€ 2020ë…„ 3ì›”ì— ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "- **Tesla Semi:** Tesla SemiëŠ” Tesla, Inc.ì˜ í´ë˜ìŠ¤ 8 ì„¸ë¯¸ íŠ¸ëŸ­ìœ¼ë¡œ, íŠ¸ë¦¬ ëª¨í„°, í›„ë¥œ êµ¬ë™ ë ˆì´ì•„ì›ƒì„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤. TeslaëŠ” Semiê°€ ì¼ë°˜ì ì¸ ë””ì ¤ ì„¸ë¯¸ íŠ¸ëŸ­ë³´ë‹¤ ì•½ 3ë°° ë” ê°•ë ¥í•˜ê³  ì£¼í–‰ ê±°ë¦¬ê°€ 500ë§ˆì¼(800km)ì´ë¼ê³  ì£¼ì¥í•©ë‹ˆë‹¤. ì´ˆê¸° ë°°ì†¡ì€ 2022ë…„ 12ì›” 1ì¼ì— PepsiCoì— ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤. [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "| Tesla ëª¨ë¸ |          |       |                  |\n",
      "| :--------- | :------- | :---- | :--------------- |\n",
      "| ì´ë¦„       | ì œì¡°ë…„ë„ | ì¢Œì„  | ì°¸ê³              |\n",
      "| Roadster   | 2008     | 2     | 2012ë…„ì— ë‹¨ì¢…    |\n",
      "| Model S    | 2012     | 5/7   |                  |\n",
      "| Model X    | 2015     | 5/6/7 |                  |\n",
      "| Model 3    | 2017     | 5     |                  |\n",
      "| Model Y    | 2020     | 5/7   |                  |\n",
      "| Semi       | 2022     | 2     |                  |\n",
      "| Cybertruck | 2023     | 5     |                  |\n",
      "| Roadster 2 |          | 2/4   | 2025ë…„ ì¶œì‹œ ì˜ˆì • |\n",
      "| Cybercab   |          | 2     | 2026ë…„ ì¶œì‹œ ì˜ˆì • |\n",
      "| Robovan    |          | 20    | ëª…ì‹œëœ ê¸°ê°„ ì—†ìŒ |\n",
      "\n",
      "### ì‚¬ìš© ê°€ëŠ¥í•œ ì œí’ˆ [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "========================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# LLMListwiseRerank ëª¨ë¸ì„ ì‚¬ìš©í•œ retrieverë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰\n",
    "\n",
    "query = \"í…ŒìŠ¬ë¼ íŠ¸ëŸ­ ëª¨ë¸ì´ ìˆë‚˜ìš”?\"\n",
    "retrieved_docs = llm_reranker_retriever.invoke(query, config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [ì¶œì²˜: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Contextual Compression** (ë§¥ë½ì  ì••ì¶•)\n",
    "\n",
    "- **ë§¥ë½ì  ì••ì¶• ê¸°ìˆ **ì€ ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ëŠ” ëŒ€ì‹ , ì¿¼ë¦¬ ê´€ë ¨ ì •ë³´ë§Œì„ ì„ ë³„ì ìœ¼ë¡œ ì¶”ì¶œí•¨\n",
    "\n",
    "- **ì´ì¤‘ êµ¬ì¡° ì‹œìŠ¤í…œ**ìœ¼ë¡œ ê¸°ë³¸ ê²€ìƒ‰ê³¼ ë¬¸ì„œ ì••ì¶• ê³¼ì •ì„ ìˆ˜í–‰í•¨\n",
    "    1. ê¸°ë³¸ ê²€ìƒ‰ê¸°(base retriever) \n",
    "    2. ë¬¸ì„œ ì••ì¶•ê¸°(Document Compressor)\n",
    "\n",
    "- **íš¨ìœ¨ì ì¸ ì²˜ë¦¬**ë¥¼ í†µí•´ LLM ë¹„ìš© ì ˆê°ê³¼ ì‘ë‹µ í’ˆì§ˆ í–¥ìƒì„ ë‹¬ì„±í•¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) **LLMChainFilter**\n",
    "\n",
    "- **LLM ê¸°ë°˜ í•„í„°ë§**ìœ¼ë¡œ ê²€ìƒ‰ëœ ë¬¸ì„œì˜ í¬í•¨ ì—¬ë¶€ë¥¼ ê²°ì •í•¨\n",
    "- **ì›ë³¸ ìœ ì§€ ë°©ì‹**ìœ¼ë¡œ ë¬¸ì„œ ë‚´ìš©ì˜ ë³€ê²½ ì—†ì´ ì„ ë³„ ì‘ì—…ì„ ìˆ˜í–‰í•¨\n",
    "- **ì„ íƒì  í•„í„°ë§**ì„ í†µí•´ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë§Œì„ ìµœì¢… ë°˜í™˜í•¨\n",
    "- ë¬¸ì„œ ì›ë³¸ì„ ë³´ì¡´í•˜ë©´ì„œ ê´€ë ¨ì„± ê¸°ë°˜ì˜ ìŠ¤ë§ˆíŠ¸í•œ ì„ ë³„ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ì‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) ëª¨ë¸ ì´ˆê¸°í™”`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainFilter\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# LLMChainFilter ëª¨ë¸ ì´ˆê¸°í™”\n",
    "context_filter = LLMChainFilter.from_llm(llm)\n",
    "\n",
    "# LLMChainFilter ëª¨ë¸ì„ ì‚¬ìš©í•œ retriever ì´ˆê¸°í™”\n",
    "llm_filter_compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=context_filter,                   # LLM ê¸°ë°˜ ì••ì¶•ê¸°\n",
    "    base_retriever=chroma_k_retriever,               # ê¸°ë³¸ ê²€ìƒ‰ê¸° \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) ë¬¸ì„œ ê²€ìƒ‰`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "- **Cybertruck:** 2019ë…„ 11ì›”ì— ì²˜ìŒ ë°œí‘œëœ í’€ì‚¬ì´ì¦ˆ í”½ì—… íŠ¸ëŸ­. í›„ë¥œ êµ¬ë™, ë“€ì–¼ ëª¨í„° ì „ë¥œ êµ¬ë™, íŠ¸ë¦¬ ëª¨í„° ì „ë¥œ êµ¬ë™ì˜ ì„¸ ê°€ì§€ ëª¨ë¸ì´ ì œê³µë©ë‹ˆë‹¤. [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "| Tesla ëª¨ë¸ |          |       |                  |\n",
      "| :--------- | :------- | :---- | :--------------- |\n",
      "| ì´ë¦„       | ì œì¡°ë…„ë„ | ì¢Œì„  | ì°¸ê³              |\n",
      "| Roadster   | 2008     | 2     | 2012ë…„ì— ë‹¨ì¢…    |\n",
      "| Model S    | 2012     | 5/7   |                  |\n",
      "| Model X    | 2015     | 5/6/7 |                  |\n",
      "| Model 3    | 2017     | 5     |                  |\n",
      "| Model Y    | 2020     | 5/7   |                  |\n",
      "| Semi       | 2022     | 2     |                  |\n",
      "| Cybertruck | 2023     | 5     |                  |\n",
      "| Roadster 2 |          | 2/4   | 2025ë…„ ì¶œì‹œ ì˜ˆì • |\n",
      "| Cybercab   |          | 2     | 2026ë…„ ì¶œì‹œ ì˜ˆì • |\n",
      "| Robovan    |          | 20    | ëª…ì‹œëœ ê¸°ê°„ ì—†ìŒ |\n",
      "\n",
      "### ì‚¬ìš© ê°€ëŠ¥í•œ ì œí’ˆ [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "- **Model Y:** ì‹±ê¸€ ëª¨í„°, í›„ë¥œ êµ¬ë™ ë˜ëŠ” ë“€ì–¼ ëª¨í„°, ì „ë¥œ êµ¬ë™ ë ˆì´ì•„ì›ƒì„ ê°–ì¶˜ 5ì¸ìŠ¹ ë° 7ì¸ìŠ¹ êµ¬ì„±ìœ¼ë¡œ ì œê³µë˜ëŠ” ì¤‘í˜• í¬ë¡œìŠ¤ì˜¤ë²„ SUV. ì´ ì°¨ëŸ‰ì€ ê³ ê¸‰ Model X SUVë³´ë‹¤ ì €ë ´í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. Model Y í”„ë¡œí† íƒ€ì…ì€ 2019ë…„ 3ì›”ì— ì²˜ìŒ ê³µê°œë˜ì—ˆìœ¼ë©° ë°°ì†¡ì€ 2020ë…„ 3ì›”ì— ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "- **Tesla Semi:** Tesla SemiëŠ” Tesla, Inc.ì˜ í´ë˜ìŠ¤ 8 ì„¸ë¯¸ íŠ¸ëŸ­ìœ¼ë¡œ, íŠ¸ë¦¬ ëª¨í„°, í›„ë¥œ êµ¬ë™ ë ˆì´ì•„ì›ƒì„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤. TeslaëŠ” Semiê°€ ì¼ë°˜ì ì¸ ë””ì ¤ ì„¸ë¯¸ íŠ¸ëŸ­ë³´ë‹¤ ì•½ 3ë°° ë” ê°•ë ¥í•˜ê³  ì£¼í–‰ ê±°ë¦¬ê°€ 500ë§ˆì¼(800km)ì´ë¼ê³  ì£¼ì¥í•©ë‹ˆë‹¤. ì´ˆê¸° ë°°ì†¡ì€ 2022ë…„ 12ì›” 1ì¼ì— PepsiCoì— ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤. [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "========================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# LLMListwiseRerank ëª¨ë¸ì„ ì‚¬ìš©í•œ retrieverë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰\n",
    "\n",
    "query = \"í…ŒìŠ¬ë¼ íŠ¸ëŸ­ ëª¨ë¸ì´ ìˆë‚˜ìš”?\"\n",
    "compressed_docs = llm_filter_compression_retriever.invoke(query, config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "\n",
    "for doc in compressed_docs:\n",
    "    print(f\"{doc.page_content} [ì¶œì²˜: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) **LLMChainExtractor**\n",
    "\n",
    "- **LLM ê¸°ë°˜ ì¶”ì¶œ**ë¡œ ë¬¸ì„œì—ì„œ ì¿¼ë¦¬ ê´€ë ¨ í•µì‹¬ ë‚´ìš©ë§Œì„ ì„ ë³„í•¨\n",
    "- **ìˆœì°¨ì  ì²˜ë¦¬ ë°©ì‹**ìœ¼ë¡œ ê° ë¬¸ì„œë¥¼ ê²€í† í•˜ì—¬ ê´€ë ¨ ì •ë³´ë¥¼ ì¶”ì¶œí•¨\n",
    "- **ë§ì¶¤í˜• ìš”ì•½**ì„ í†µí•´ ì¿¼ë¦¬ì— ìµœì í™”ëœ ì••ì¶• ê²°ê³¼ë¥¼ ìƒì„±í•¨\n",
    "- ì¿¼ë¦¬ ë§¥ë½ì— ë”°ë¥¸ ì„ ë³„ì  ì •ë³´ ì¶”ì¶œë¡œ íš¨ìœ¨ì ì¸ ë¬¸ì„œ ì••ì¶•ì„ ì‹¤í˜„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) ëª¨ë¸ ì´ˆê¸°í™”`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# LLMChainExtractor ëª¨ë¸ ì´ˆê¸°í™”\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "# LLMChainExtractor ëª¨ë¸ì„ ì‚¬ìš©í•œ retriever ì´ˆê¸°í™”\n",
    "llm_extractor_compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,                                    # LLM ê¸°ë°˜ ì••ì¶•ê¸°\n",
    "    base_retriever=cross_encoder_reranker_retriever,               # ê¸°ë³¸ ê²€ìƒ‰ê¸° (Re-rank)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) ë¬¸ì„œ ê²€ìƒ‰`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Cybertruck:** 2019ë…„ 11ì›”ì— ì²˜ìŒ ë°œí‘œëœ í’€ì‚¬ì´ì¦ˆ í”½ì—… íŠ¸ëŸ­. í›„ë¥œ êµ¬ë™, ë“€ì–¼ ëª¨í„° ì „ë¥œ êµ¬ë™, íŠ¸ë¦¬ ëª¨í„° ì „ë¥œ êµ¬ë™ì˜ ì„¸ ê°€ì§€ ëª¨ë¸ì´ ì œê³µë©ë‹ˆë‹¤. [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "- **Tesla Semi:** Tesla SemiëŠ” Tesla, Inc.ì˜ í´ë˜ìŠ¤ 8 ì„¸ë¯¸ íŠ¸ëŸ­ìœ¼ë¡œ, íŠ¸ë¦¬ ëª¨í„°, í›„ë¥œ êµ¬ë™ ë ˆì´ì•„ì›ƒì„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤. TeslaëŠ” Semiê°€ ì¼ë°˜ì ì¸ ë””ì ¤ ì„¸ë¯¸ íŠ¸ëŸ­ë³´ë‹¤ ì•½ 3ë°° ë” ê°•ë ¥í•˜ê³  ì£¼í–‰ ê±°ë¦¬ê°€ 500ë§ˆì¼(800km)ì´ë¼ê³  ì£¼ì¥í•©ë‹ˆë‹¤. ì´ˆê¸° ë°°ì†¡ì€ 2022ë…„ 12ì›” 1ì¼ì— PepsiCoì— ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤. [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "| Tesla ëª¨ë¸ |          |       |                  |\n",
      "| :--------- | :------- | :---- | :--------------- |\n",
      "| Semi       | 2022     | 2     |                  |\n",
      "| Cybertruck | 2023     | 5     |                  |\n",
      "| Cybercab   |          | 2     | 2026ë…„ ì¶œì‹œ ì˜ˆì • | [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "========================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# LLMChainExtractor ëª¨ë¸ì„ ì‚¬ìš©í•œ retrieverë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰\n",
    "\n",
    "query = \"í…ŒìŠ¬ë¼ íŠ¸ëŸ­ ëª¨ë¸ì´ ìˆë‚˜ìš”?\"\n",
    "compressed_docs = llm_extractor_compression_retriever.invoke(query, config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "\n",
    "for doc in compressed_docs:\n",
    "    print(f\"{doc.page_content} [ì¶œì²˜: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) **EmbeddingsFilter**\n",
    "\n",
    "- **ì„ë² ë”© ê¸°ë°˜ í•„í„°ë§**ìœ¼ë¡œ ë¬¸ì„œì™€ ì¿¼ë¦¬ ê°„ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•¨\n",
    "- **LLM ë¯¸ì‚¬ìš© ë°©ì‹**ìœ¼ë¡œ ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„ì™€ ë¹„ìš© íš¨ìœ¨ì„±ì„ í™•ë³´í•¨ (LLM í˜¸ì¶œë³´ë‹¤ ì €ë ´í•˜ê³  ë¹ ë¥¸ ì˜µì…˜)\n",
    "- **ìœ ì‚¬ë„ ê¸°ì¤€ ì„ ë³„**ì„ í†µí•´ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë§Œì„ íš¨ê³¼ì ìœ¼ë¡œ ì¶”ì¶œí•¨\n",
    "- ê²½ì œì ì´ê³  ì‹ ì†í•œ ì„ë² ë”© ê¸°ë°˜ì˜ ë¬¸ì„œ í•„í„°ë§ ê¸°ë²• "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) ëª¨ë¸ ì´ˆê¸°í™”`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "\n",
    "# ì„ë² ë”© ê¸°ë°˜ ì••ì¶•ê¸° ì´ˆê¸°í™”\n",
    "embeddings_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.4)\n",
    "\n",
    "# ì„ë² ë”© ê¸°ë°˜ ì••ì¶•ê¸°ë¥¼ ì‚¬ìš©í•œ retriever ì´ˆê¸°í™”\n",
    "embed_filter_compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=embeddings_filter,                             # ì„ë² ë”© ê¸°ë°˜ ì••ì¶•ê¸°\n",
    "    base_retriever=cross_encoder_reranker_retriever,               # ê¸°ë³¸ ê²€ìƒ‰ê¸° (Re-rank)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) ë¬¸ì„œ ê²€ìƒ‰`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "- **Cybertruck:** 2019ë…„ 11ì›”ì— ì²˜ìŒ ë°œí‘œëœ í’€ì‚¬ì´ì¦ˆ í”½ì—… íŠ¸ëŸ­. í›„ë¥œ êµ¬ë™, ë“€ì–¼ ëª¨í„° ì „ë¥œ êµ¬ë™, íŠ¸ë¦¬ ëª¨í„° ì „ë¥œ êµ¬ë™ì˜ ì„¸ ê°€ì§€ ëª¨ë¸ì´ ì œê³µë©ë‹ˆë‹¤. [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "| Tesla ëª¨ë¸ |          |       |                  |\n",
      "| :--------- | :------- | :---- | :--------------- |\n",
      "| ì´ë¦„       | ì œì¡°ë…„ë„ | ì¢Œì„  | ì°¸ê³              |\n",
      "| Roadster   | 2008     | 2     | 2012ë…„ì— ë‹¨ì¢…    |\n",
      "| Model S    | 2012     | 5/7   |                  |\n",
      "| Model X    | 2015     | 5/6/7 |                  |\n",
      "| Model 3    | 2017     | 5     |                  |\n",
      "| Model Y    | 2020     | 5/7   |                  |\n",
      "| Semi       | 2022     | 2     |                  |\n",
      "| Cybertruck | 2023     | 5     |                  |\n",
      "| Roadster 2 |          | 2/4   | 2025ë…„ ì¶œì‹œ ì˜ˆì • |\n",
      "| Cybercab   |          | 2     | 2026ë…„ ì¶œì‹œ ì˜ˆì • |\n",
      "| Robovan    |          | 20    | ëª…ì‹œëœ ê¸°ê°„ ì—†ìŒ |\n",
      "\n",
      "### ì‚¬ìš© ê°€ëŠ¥í•œ ì œí’ˆ [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "- **Model Y:** ì‹±ê¸€ ëª¨í„°, í›„ë¥œ êµ¬ë™ ë˜ëŠ” ë“€ì–¼ ëª¨í„°, ì „ë¥œ êµ¬ë™ ë ˆì´ì•„ì›ƒì„ ê°–ì¶˜ 5ì¸ìŠ¹ ë° 7ì¸ìŠ¹ êµ¬ì„±ìœ¼ë¡œ ì œê³µë˜ëŠ” ì¤‘í˜• í¬ë¡œìŠ¤ì˜¤ë²„ SUV. ì´ ì°¨ëŸ‰ì€ ê³ ê¸‰ Model X SUVë³´ë‹¤ ì €ë ´í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. Model Y í”„ë¡œí† íƒ€ì…ì€ 2019ë…„ 3ì›”ì— ì²˜ìŒ ê³µê°œë˜ì—ˆìœ¼ë©° ë°°ì†¡ì€ 2020ë…„ 3ì›”ì— ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "- **Tesla Semi:** Tesla SemiëŠ” Tesla, Inc.ì˜ í´ë˜ìŠ¤ 8 ì„¸ë¯¸ íŠ¸ëŸ­ìœ¼ë¡œ, íŠ¸ë¦¬ ëª¨í„°, í›„ë¥œ êµ¬ë™ ë ˆì´ì•„ì›ƒì„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤. TeslaëŠ” Semiê°€ ì¼ë°˜ì ì¸ ë””ì ¤ ì„¸ë¯¸ íŠ¸ëŸ­ë³´ë‹¤ ì•½ 3ë°° ë” ê°•ë ¥í•˜ê³  ì£¼í–‰ ê±°ë¦¬ê°€ 500ë§ˆì¼(800km)ì´ë¼ê³  ì£¼ì¥í•©ë‹ˆë‹¤. ì´ˆê¸° ë°°ì†¡ì€ 2022ë…„ 12ì›” 1ì¼ì— PepsiCoì— ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤. [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "========================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "query = \"í…ŒìŠ¬ë¼ íŠ¸ëŸ­ ëª¨ë¸ì´ ìˆë‚˜ìš”?\"\n",
    "compressed_docs = embed_filter_compression_retriever.invoke(query, config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "for doc in compressed_docs:\n",
    "    print(f\"{doc.page_content} [ì¶œì²˜: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) **DocumentCompressorPipeline**\n",
    "\n",
    "- **íŒŒì´í”„ë¼ì¸ êµ¬ì¡°**ë¡œ ì—¬ëŸ¬ ì••ì¶•ê¸°ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ì²˜ë¦¬í•¨\n",
    "- **ë³µí•© ë³€í™˜ ê¸°ëŠ¥**ìœ¼ë¡œ ë¬¸ì„œ ë¶„í•  ë° ì¤‘ë³µ ì œê±° ë“± ë‹¤ì–‘í•œ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•¨\n",
    "- **ìœ ì—°í•œ í™•ì¥ì„±**ì„ í†µí•´ BaseDocumentTransformers ì¶”ê°€ë¡œ ê¸°ëŠ¥ì„ í™•ì¥í•¨\n",
    "- ë‹¤ì¤‘ ì••ì¶•ê¸°ë¥¼ ì—°ê³„í•˜ì—¬ í¬ê´„ì ì´ê³  íš¨ê³¼ì ì¸ ë¬¸ì„œ ì²˜ë¦¬ë¥¼ êµ¬í˜„í•˜ëŠ” ë°©ì‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) ëª¨ë¸ ì´ˆê¸°í™”`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "\n",
    "\n",
    "# ì„ë² ë”© ê¸°ë°˜ í•„í„° ì´ˆê¸°í™” - ì¤‘ë³µ ì œê±°\n",
    "redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)\n",
    "\n",
    "# ì„ë² ë”© ê¸°ë°˜ í•„í„° ì´ˆê¸°í™” - ìœ ì‚¬ë„ ê¸°ë°˜ í•„í„° (ì„ë² ë”© ìœ ì‚¬ë„ 0.4 ì´ìƒ)\n",
    "relevant_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.4)\n",
    "\n",
    "# Re-ranking ëª¨ë¸ ì´ˆê¸°í™”\n",
    "re_ranker = LLMListwiseRerank.from_llm(llm, top_n=2)\n",
    "\n",
    "# DocumentCompressorPipeline ì´ˆê¸°í™” (ìˆœì°¨ì ìœ¼ë¡œ redundant_filter -> relevant_filter -> re_ranker ì ìš©)\n",
    "pipeline_compressor = DocumentCompressorPipeline(\n",
    "    transformers=[redundant_filter, relevant_filter, re_ranker]\n",
    ")\n",
    "\n",
    "# DocumentCompressorPipelineì„ ì‚¬ìš©í•œ retriever ì´ˆê¸°í™”\n",
    "pipeline_compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=pipeline_compressor,           # DocumentCompressorPipeline ê¸°ë°˜ ì••ì¶•ê¸°\n",
    "    base_retriever=chroma_k_retriever,             # ê¸°ë³¸ ê²€ìƒ‰ê¸°\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) ë¬¸ì„œ ê²€ìƒ‰`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "- **Cybertruck:** 2019ë…„ 11ì›”ì— ì²˜ìŒ ë°œí‘œëœ í’€ì‚¬ì´ì¦ˆ í”½ì—… íŠ¸ëŸ­. í›„ë¥œ êµ¬ë™, ë“€ì–¼ ëª¨í„° ì „ë¥œ êµ¬ë™, íŠ¸ë¦¬ ëª¨í„° ì „ë¥œ êµ¬ë™ì˜ ì„¸ ê°€ì§€ ëª¨ë¸ì´ ì œê³µë©ë‹ˆë‹¤. [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "- **Model Y:** ì‹±ê¸€ ëª¨í„°, í›„ë¥œ êµ¬ë™ ë˜ëŠ” ë“€ì–¼ ëª¨í„°, ì „ë¥œ êµ¬ë™ ë ˆì´ì•„ì›ƒì„ ê°–ì¶˜ 5ì¸ìŠ¹ ë° 7ì¸ìŠ¹ êµ¬ì„±ìœ¼ë¡œ ì œê³µë˜ëŠ” ì¤‘í˜• í¬ë¡œìŠ¤ì˜¤ë²„ SUV. ì´ ì°¨ëŸ‰ì€ ê³ ê¸‰ Model X SUVë³´ë‹¤ ì €ë ´í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. Model Y í”„ë¡œí† íƒ€ì…ì€ 2019ë…„ 3ì›”ì— ì²˜ìŒ ê³µê°œë˜ì—ˆìœ¼ë©° ë°°ì†¡ì€ 2020ë…„ 3ì›”ì— ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "- **Tesla Semi:** Tesla SemiëŠ” Tesla, Inc.ì˜ í´ë˜ìŠ¤ 8 ì„¸ë¯¸ íŠ¸ëŸ­ìœ¼ë¡œ, íŠ¸ë¦¬ ëª¨í„°, í›„ë¥œ êµ¬ë™ ë ˆì´ì•„ì›ƒì„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤. TeslaëŠ” Semiê°€ ì¼ë°˜ì ì¸ ë””ì ¤ ì„¸ë¯¸ íŠ¸ëŸ­ë³´ë‹¤ ì•½ 3ë°° ë” ê°•ë ¥í•˜ê³  ì£¼í–‰ ê±°ë¦¬ê°€ 500ë§ˆì¼(800km)ì´ë¼ê³  ì£¼ì¥í•©ë‹ˆë‹¤. ì´ˆê¸° ë°°ì†¡ì€ 2022ë…„ 12ì›” 1ì¼ì— PepsiCoì— ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤. [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "========================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "query = \"í…ŒìŠ¬ë¼ íŠ¸ëŸ­ ëª¨ë¸ì´ ìˆë‚˜ìš”?\"\n",
    "compressed_docs = pipeline_compression_retriever.invoke(query, config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "for doc in compressed_docs:\n",
    "    print(f\"{doc.page_content} [ì¶œì²˜: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# **[ì‹¤ìŠµ]**\n",
    "\n",
    "- ì§€ê¸ˆê¹Œì§€ í•™ìŠµí•œ ì—¬ëŸ¬ ê¸°ë²•ë“¤ì„ ì„ íƒí•˜ì—¬, RAG ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì²´ì¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) ê¸°ë³¸ ê²€ìƒ‰ê¸° ì„¤ì •`\n",
    "\n",
    "- Semantic Search, Keyword Search, Hybrid Search ê²€ìƒ‰ê¸°ë¥¼ ì§ì ‘ ì •ì˜í•©ë‹ˆë‹¤. \n",
    "- ì¿¼ë¦¬ í™•ì¥ ë„êµ¬ ì ìš©ì„ ê²€í† í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ 16ì½”ì–´ 128GB ìµœì í™” RAG ê²€ìƒ‰ê¸° ì´ˆê¸°í™” ì‹œì‘!\n",
      "ğŸ’» ì‹œìŠ¤í…œ ì •ë³´: CPU 16ì½”ì–´, ë©”ëª¨ë¦¬ 127GB\n",
      "ğŸ”¥ Jupyter ìµœì í™” ë³‘ë ¬ë„: {'file_loading': 32, 'text_splitting': 24, 'embedding': 64, 'bm25_indexing': 24, 'search_test': 8}\n",
      "\n",
      "====================================================================================================\n",
      "ğŸš€ 16ì½”ì–´ 128GB ì‹œìŠ¤í…œ ìµœì í™” ì´ˆê³ ì„±ëŠ¥ ê²€ìƒ‰ê¸° ì‹¤í–‰ (Jupyter í˜¸í™˜)\n",
      "====================================================================================================\n",
      "\n",
      "â° [12:51:37.591] ğŸš€ ì „ì²´_ê²€ìƒ‰ê¸°_ì´ˆê³ ì†_ì„¤ì • ì‹œì‘\n",
      "   ğŸ’» ì‹œì‘ ì‹œ ì‹œìŠ¤í…œ ìƒíƒœ: {'cpu_avg': '2.1%', 'cpu_cores': ['C0:0.0%', 'C1:0.0%', 'C2:16.7%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:0.0%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.4%)', 'memory_available': '92GB', 'active_threads': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“„ ê³ ì„±ëŠ¥ ë¬¸ì„œ ë¡œë”©...:   0%|          | 0/6 [00:00<?]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â° [12:51:37.701] ğŸš€ ê³ ì„±ëŠ¥_ë¬¸ì„œ_ë¡œë”© ì‹œì‘\n",
      "   ğŸ’» ì‹œì‘ ì‹œ ì‹œìŠ¤í…œ ìƒíƒœ: {'cpu_avg': '10.4%', 'cpu_cores': ['C0:50.0%', 'C1:0.0%', 'C2:33.3%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:16.7%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.4%)', 'memory_available': '92GB', 'active_threads': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“„ ë¡œë”©: Tesla_EN.md (12KB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 799.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° [12:51:37.821] âœ… ê³ ì„±ëŠ¥_ë¬¸ì„œ_ë¡œë”© ì™„ë£Œ\n",
      "   â±ï¸  ì†Œìš”ì‹œê°„: 0.120ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "âœ‚ï¸ ê³ ì„±ëŠ¥ í…ìŠ¤íŠ¸ ë¶„í• ...:  17%|â–ˆâ–‹        | 1/6 [00:00<00:01]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ğŸ’» ì¢…ë£Œ ì‹œ ì‹œìŠ¤í…œ ìƒíƒœ: {'cpu_avg': '0.0%', 'cpu_cores': ['C0:0.0%', 'C1:0.0%', 'C2:0.0%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:0.0%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.4%)', 'memory_available': '92GB', 'active_threads': 16}\n",
      "   ğŸ“Š ì„±ëŠ¥ ìš”ì•½: âš¡ ì´ˆê³ ì† (120ms)\n",
      "   ğŸ“ˆ ì²˜ë¦¬ëŸ‰: 0.04MB, 0.32MB/s\n",
      "\n",
      "â° [12:51:37.931] ğŸš€ ê³ ì„±ëŠ¥_í…ìŠ¤íŠ¸_ë¶„í•  ì‹œì‘\n",
      "   ğŸ’» ì‹œì‘ ì‹œ ì‹œìŠ¤í…œ ìƒíƒœ: {'cpu_avg': '13.2%', 'cpu_cores': ['C0:28.6%', 'C1:0.0%', 'C2:16.7%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:50.0%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.5%)', 'memory_available': '92GB', 'active_threads': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "âœ‚ï¸ ì²­í¬4 -> 37ê°œ ë¶„í• : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 571.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° [12:51:38.052] âœ… ê³ ì„±ëŠ¥_í…ìŠ¤íŠ¸_ë¶„í•  ì™„ë£Œ\n",
      "   â±ï¸  ì†Œìš”ì‹œê°„: 0.121ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§  ì´ˆê³ ì„±ëŠ¥ ì„ë² ë”© ì„¤ì •...:  33%|â–ˆâ–ˆâ–ˆâ–      | 2/6 [00:00<00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ğŸ’» ì¢…ë£Œ ì‹œ ì‹œìŠ¤í…œ ìƒíƒœ: {'cpu_avg': '1.0%', 'cpu_cores': ['C0:0.0%', 'C1:0.0%', 'C2:0.0%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:0.0%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.5%)', 'memory_available': '92GB', 'active_threads': 16}\n",
      "   ğŸ“Š ì„±ëŠ¥ ìš”ì•½: âš¡ ì´ˆê³ ì† (121ms)\n",
      "   ğŸ“ˆ ë¶„í•  ì„±ëŠ¥: 89ê°œ ì²­í¬, 733.1ì²­í¬/ì´ˆ\n",
      "\n",
      "â° [12:51:38.162] ğŸš€ ì´ˆê³ ì„±ëŠ¥_ì„ë² ë”©_ì„¤ì • ì‹œì‘\n",
      "   ğŸ’» ì‹œì‘ ì‹œ ì‹œìŠ¤í…œ ìƒíƒœ: {'cpu_avg': '8.5%', 'cpu_cores': ['C0:28.6%', 'C1:0.0%', 'C2:16.7%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:0.0%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.5%)', 'memory_available': '92GB', 'active_threads': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” ì´ˆê³ ì† BM25 ì¸ë±ì‹±...:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:01<00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° [12:51:38.772] âœ… ì´ˆê³ ì„±ëŠ¥_ì„ë² ë”©_ì„¤ì • ì™„ë£Œ\n",
      "   â±ï¸  ì†Œìš”ì‹œê°„: 0.611ì´ˆ\n",
      "   ğŸ’» ì¢…ë£Œ ì‹œ ì‹œìŠ¤í…œ ìƒíƒœ: {'cpu_avg': '10.3%', 'cpu_cores': ['C0:0.0%', 'C1:0.0%', 'C2:0.0%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:33.3%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.5%)', 'memory_available': '92GB', 'active_threads': 16}\n",
      "   ğŸ“Š ì„±ëŠ¥ ìš”ì•½: âš¡ ì´ˆê³ ì† (611ms)\n",
      "   âš¡ ì„ë² ë”© ë³‘ë ¬ë„: 64ê°œ ë™ì‹œ ìš”ì²­\n",
      "\n",
      "â° [12:51:38.883] ğŸš€ ì´ˆê³ ì†_BM25_ì¸ë±ì‹± ì‹œì‘\n",
      "   ğŸ’» ì‹œì‘ ì‹œ ì‹œìŠ¤í…œ ìƒíƒœ: {'cpu_avg': '11.5%', 'cpu_cores': ['C0:0.0%', 'C1:0.0%', 'C2:16.7%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:50.0%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.5%)', 'memory_available': '92GB', 'active_threads': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” ì´ˆê³ ì† BM25 ì¸ë±ì‹±: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:00<00:00, 12717.37it/s]\n",
      "ğŸ”„ ê³ ê¸‰ ê²€ìƒ‰ê¸° ìµœì í™”...:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5/6 [00:01<00:00]0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° [12:51:39.003] âœ… ì´ˆê³ ì†_BM25_ì¸ë±ì‹± ì™„ë£Œ\n",
      "   â±ï¸  ì†Œìš”ì‹œê°„: 0.120ì´ˆ\n",
      "   ğŸ’» ì¢…ë£Œ ì‹œ ì‹œìŠ¤í…œ ìƒíƒœ: {'cpu_avg': '13.8%', 'cpu_cores': ['C0:16.7%', 'C1:0.0%', 'C2:16.7%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:42.9%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.5%)', 'memory_available': '92GB', 'active_threads': 16}\n",
      "   ğŸ“Š ì„±ëŠ¥ ìš”ì•½: âš¡ ì´ˆê³ ì† (120ms)\n",
      "   ğŸ“ˆ ì¸ë±ì‹± ì„±ëŠ¥: 8898.3ë¬¸ì„œ/ì´ˆ\n",
      "   ğŸ’¾ ìºì‹œ ì €ì¥: 0.002ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”„ ê³ ê¸‰ ê²€ìƒ‰ê¸° ìµœì í™”...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° [12:51:39.618] âœ… ì „ì²´_ê²€ìƒ‰ê¸°_ì´ˆê³ ì†_ì„¤ì • ì™„ë£Œ\n",
      "   â±ï¸  ì†Œìš”ì‹œê°„: 2.027ì´ˆ\n",
      "   ğŸ’» ì¢…ë£Œ ì‹œ ì‹œìŠ¤í…œ ìƒíƒœ: {'cpu_avg': '3.1%', 'cpu_cores': ['C0:0.0%', 'C1:0.0%', 'C2:0.0%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:0.0%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.4%)', 'memory_available': '92GB', 'active_threads': 16}\n",
      "   ğŸ“Š ì„±ëŠ¥ ìš”ì•½: ğŸš€ ë¹ ë¦„ (2.03s)\n",
      "   ğŸ¯ ìƒì„±ëœ ê²€ìƒ‰ê¸°: 4ê°œ\n",
      "   ğŸ“Š ì²˜ë¦¬ëœ ë¬¸ì„œ: 4ê°œ -> 89ê°œ ì²­í¬\n",
      "\n",
      "ğŸ“‹ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: 'í…ŒìŠ¬ë¼ íŠ¸ëŸ­ ëª¨ë¸ì´ ìˆë‚˜ìš”?'\n",
      "\n",
      "â° [12:51:39.725] ğŸš€ ì´ˆê³ ì†_ë³‘ë ¬_ê²€ìƒ‰_í…ŒìŠ¤íŠ¸ ì‹œì‘\n",
      "   ğŸ’» ì‹œì‘ ì‹œ ì‹œìŠ¤í…œ ìƒíƒœ: {'cpu_avg': '7.3%', 'cpu_cores': ['C0:16.7%', 'C1:0.0%', 'C2:33.3%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:16.7%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.4%)', 'memory_available': '92GB', 'active_threads': 16}\n",
      "   ğŸ–¥ï¸ ê²€ìƒ‰ ì‹œì‘ ì‹œì  ì‹œìŠ¤í…œ ìƒíƒœ: {'cpu_avg': '5.4%', 'cpu_cores': ['C0:0.0%', 'C1:0.0%', 'C2:14.3%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:28.6%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.4%)', 'memory_available': '92GB', 'active_threads': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "âœ… multi_query ì™„ë£Œ (0.000ì´ˆ, CPU:3.4%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° [12:51:42.955] âœ… ì´ˆê³ ì†_ë³‘ë ¬_ê²€ìƒ‰_í…ŒìŠ¤íŠ¸ ì™„ë£Œ\n",
      "   â±ï¸  ì†Œìš”ì‹œê°„: 3.230ì´ˆ\n",
      "   ğŸ’» ì¢…ë£Œ ì‹œ ì‹œìŠ¤í…œ ìƒíƒœ: {'cpu_avg': '14.4%', 'cpu_cores': ['C0:44.4%', 'C1:0.0%', 'C2:28.6%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:28.6%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.5%)', 'memory_available': '92GB', 'active_threads': 16}\n",
      "   ğŸ“Š ì„±ëŠ¥ ìš”ì•½: ğŸš€ ë¹ ë¦„ (3.23s)\n",
      "   âš¡ ê²€ìƒ‰ ì„±ëŠ¥: 1.2ê²€ìƒ‰ê¸°/ì´ˆ\n",
      "\n",
      "====================================================================================================\n",
      "ğŸ“Š ì „ì²´ ì„±ëŠ¥ ë¶„ì„ ë³´ê³ ì„œ\n",
      "====================================================================================================\n",
      "ğŸ• ì´ ì‹¤í–‰ ì‹œê°„: 5.475ì´ˆ\n",
      "\n",
      "ğŸ“‹ ë‹¨ê³„ë³„ ìƒì„¸ ì‹œê°„ ë¶„ì„:\n",
      "ë‹¨ê³„ëª…                       ì‹œì‘ì‹œê°„         ì¢…ë£Œì‹œê°„         ì†Œìš”ì‹œê°„       ì„±ëŠ¥í‰ê°€           \n",
      "------------------------------------------------------------------------------------------\n",
      "ì „ì²´_ê²€ìƒ‰ê¸°_ì´ˆê³ ì†_ì„¤ì •             12:51:37.591 12:51:39.618 2.027    s ğŸš€ ë¹ ë¦„ (2.03s)   \n",
      "ê³ ì„±ëŠ¥_ë¬¸ì„œ_ë¡œë”©                 12:51:37.701 12:51:37.821 0.120    s âš¡ ì´ˆê³ ì† (120ms)  \n",
      "ê³ ì„±ëŠ¥_í…ìŠ¤íŠ¸_ë¶„í•                 12:51:37.931 12:51:38.052 0.121    s âš¡ ì´ˆê³ ì† (121ms)  \n",
      "ì´ˆê³ ì„±ëŠ¥_ì„ë² ë”©_ì„¤ì •               12:51:38.162 12:51:38.772 0.611    s âš¡ ì´ˆê³ ì† (611ms)  \n",
      "ì´ˆê³ ì†_BM25_ì¸ë±ì‹±              12:51:38.883 12:51:39.003 0.120    s âš¡ ì´ˆê³ ì† (120ms)  \n",
      "ì´ˆê³ ì†_ë³‘ë ¬_ê²€ìƒ‰_í…ŒìŠ¤íŠ¸             12:51:39.725 12:51:42.955 3.230    s ğŸš€ ë¹ ë¦„ (3.23s)   \n",
      "\n",
      "ğŸ¯ ë³‘ëª©ì  ë¶„ì„:\n",
      "   1. ì´ˆê³ ì†_ë³‘ë ¬_ê²€ìƒ‰_í…ŒìŠ¤íŠ¸: 3.230ì´ˆ (59.0%)\n",
      "   2. ì „ì²´_ê²€ìƒ‰ê¸°_ì´ˆê³ ì†_ì„¤ì •: 2.027ì´ˆ (37.0%)\n",
      "   3. ì´ˆê³ ì„±ëŠ¥_ì„ë² ë”©_ì„¤ì •: 0.611ì´ˆ (11.2%)\n",
      "\n",
      "ğŸ’¡ ìµœì í™” ì œì•ˆ:\n",
      "   ğŸ” ì´ˆê³ ì†_ë³‘ë ¬_ê²€ìƒ‰_í…ŒìŠ¤íŠ¸: 3.23ì´ˆë¡œ ê°œì„  ì—¬ì§€ ìˆìŒ\n",
      "   ğŸ” ì „ì²´_ê²€ìƒ‰ê¸°_ì´ˆê³ ì†_ì„¤ì •: 2.03ì´ˆë¡œ ê°œì„  ì—¬ì§€ ìˆìŒ\n",
      "\n",
      "====================================================================================================\n",
      "ğŸ¯ ì´ˆê³ ì„±ëŠ¥ ë³‘ë ¬ ê²€ìƒ‰ ê²°ê³¼\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ” === í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ===\n",
      "1. **ê°œìš”**\n",
      "\n",
      "Rivianì€ \"ìŠ¤ì¼€ì´íŠ¸ë³´ë“œ\" í”Œë«í¼(R1T ë° R1S ëª¨ë¸)ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì „ê¸° ìŠ¤í¬ì¸  ìœ í‹¸ë¦¬í‹° ì°¨ëŸ‰(SUV), í”½ì—… íŠ¸ëŸ­ ë° ... [ì¶œì²˜: data\\ë¦¬ë¹„ì•ˆ_KR.md]\n",
      "2. - **Model Y:** ì‹±ê¸€ ëª¨í„°, í›„ë¥œ êµ¬ë™ ë˜ëŠ” ë“€ì–¼ ëª¨í„°, ì „ë¥œ êµ¬ë™ ë ˆì´ì•„ì›ƒì„ ê°–ì¶˜ 5ì¸ìŠ¹ ë° 7ì¸ìŠ¹ êµ¬ì„±ìœ¼ë¡œ ì œê³µë˜ëŠ” ì¤‘í˜• í¬ë¡œìŠ¤ì˜¤... [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "3. **ìƒì‚° ì¤€ë¹„ (2016â€“20):**\n",
      "\n",
      "- 2017ë…„ ì¼ë¦¬ë…¸ì´ ì£¼ ë…¸ë©€ì— ìˆëŠ” ì´ì „ Mitsubishi Motors ì œì¡° ê³µì¥ì„ 1,600ë§Œ ë‹¬... [ì¶œì²˜: data\\ë¦¬ë¹„ì•ˆ_KR.md]\n",
      "\n",
      "ğŸ”„ === í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼ ===\n",
      "1. [ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "- **Cybertruck:** 2... [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "2. [ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "| Tesla ëª¨ë¸ |       ... [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "3. [ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "- **Model 3:** íŒ¨ìŠ¤íŠ¸ë°±... [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "\n",
      "ğŸ§  === ì˜ë¯¸ ê²€ìƒ‰ ê²°ê³¼ ===\n",
      "1. [ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "- **Cybertruck:** 2... [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "2. [ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "| Tesla ëª¨ë¸ |       ... [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "3. [ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "- **Model 3:** íŒ¨ìŠ¤íŠ¸ë°±... [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "\n",
      "ğŸ¯ === ë©€í‹°ì¿¼ë¦¬ ê²€ìƒ‰ ê²°ê³¼ ===\n",
      "1. [ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "- **Cybertruck:** 2... [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "2. [ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "| Tesla ëª¨ë¸ |       ... [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "3. [ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "- **Model S:** ë¦¬í”„íŠ¸ë°±... [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "\n",
      "====================================================================================================\n",
      "ğŸ‰ 16ì½”ì–´ 128GB ìµœì í™” ì‹¤ìŠµ 1 ì™„ë£Œ! (Jupyter í˜¸í™˜)\n",
      "ğŸ“Š ìµœëŒ€ ì„±ëŠ¥ í™œìš©:\n",
      "   ğŸ”¥ íŒŒì¼ ë¡œë”©: 32ê°œ ìŠ¤ë ˆë“œ\n",
      "   âš¡ í…ìŠ¤íŠ¸ ë¶„í• : 24ê°œ ìŠ¤ë ˆë“œ (Jupyter ì•ˆì „ ëª¨ë“œ)\n",
      "   ğŸš€ ì„ë² ë”© ìš”ì²­: 64ê°œ ë™ì‹œ\n",
      "   ğŸ’¾ BM25 ì¸ë±ì‹±: 24ê°œ ìŠ¤ë ˆë“œ\n",
      "   ğŸ¯ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸: 8ê°œ ë™ì‹œ\n",
      "   â° ëª¨ë“  ë‹¨ê³„ë³„ ìƒì„¸ ì‹œê°„ ì¸¡ì •\n",
      "   ğŸ“ˆ ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§\n",
      "   ğŸ” ë³‘ëª©ì  ìë™ ë¶„ì„\n",
      "   âœ… Jupyter í™˜ê²½ í˜¸í™˜ì„± í™•ë³´\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤ìŠµ 1: 16ì½”ì–´ 128GB ìµœì í™” + ìƒì„¸ ì‹œê°„ ì¸¡ì • ê²€ìƒ‰ê¸° ì„¤ì • (Jupyter í˜¸í™˜)\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import psutil\n",
    "import threading\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from functools import lru_cache\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "print(\"ğŸš€ 16ì½”ì–´ 128GB ìµœì í™” RAG ê²€ìƒ‰ê¸° ì´ˆê¸°í™” ì‹œì‘!\")\n",
    "print(f\"ğŸ’» ì‹œìŠ¤í…œ ì •ë³´: CPU {os.cpu_count()}ì½”ì–´, ë©”ëª¨ë¦¬ {psutil.virtual_memory().total // (1024**3)}GB\")\n",
    "\n",
    "# 16ì½”ì–´ 128GB ì‹œìŠ¤í…œ ìµœì í™” ë³‘ë ¬ë„ ê³„ì‚° (Jupyter í˜¸í™˜)\n",
    "def get_jupyter_optimized_parallelism():\n",
    "    \"\"\"16ì½”ì–´ 128GB ì‹œìŠ¤í…œ ìµœì í™” ë³‘ë ¬ë„ (Jupyter í™˜ê²½)\"\"\"\n",
    "    cpu_cores = os.cpu_count()  # 16\n",
    "    total_memory_gb = psutil.virtual_memory().total // (1024**3)  # 128\n",
    "    \n",
    "    # Jupyter í™˜ê²½ì— ìµœì í™”ëœ ë³‘ë ¬ë„ (ThreadPoolExecutor ì¤‘ì‹¬)\n",
    "    parallelism = {\n",
    "        \"file_loading\": min(cpu_cores * 4, 32),      # I/O ì§‘ì•½ì : 32ê°œ ìŠ¤ë ˆë“œ\n",
    "        \"text_splitting\": min(cpu_cores * 2, 24),   # CPU ì§‘ì•½ì : 24ê°œ ìŠ¤ë ˆë“œ (Process ëŒ€ì‹  Thread)\n",
    "        \"embedding\": cpu_cores * 4,                  # API í˜¸ì¶œ: 64ê°œ ë™ì‹œ ìš”ì²­\n",
    "        \"bm25_indexing\": min(cpu_cores * 2, 24),    # ë©”ëª¨ë¦¬ ì§‘ì•½ì : 24ê°œ ìŠ¤ë ˆë“œ\n",
    "        \"search_test\": 8                             # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸: 8ê°œ ë™ì‹œ\n",
    "    }\n",
    "    \n",
    "    print(f\"ğŸ”¥ Jupyter ìµœì í™” ë³‘ë ¬ë„: {parallelism}\")\n",
    "    return parallelism\n",
    "\n",
    "PARALLELISM = get_jupyter_optimized_parallelism()\n",
    "\n",
    "# ìºì‹± ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "CACHE_DIR = \"./cache\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "# ìƒì„¸ ì‹œê°„ ì¸¡ì • ë° ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤\n",
    "class DetailedPerformanceMonitor:\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "        self.stage_times = {}\n",
    "        self.stage_details = {}\n",
    "        \n",
    "    def log_stage_start(self, stage_name):\n",
    "        \"\"\"ë‹¨ê³„ ì‹œì‘ ì‹œê°„ ê¸°ë¡\"\"\"\n",
    "        start_time = time.time()\n",
    "        start_datetime = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n",
    "        \n",
    "        self.stage_times[stage_name] = {\"start\": start_time, \"start_datetime\": start_datetime}\n",
    "        \n",
    "        print(f\"\\nâ° [{start_datetime}] ğŸš€ {stage_name} ì‹œì‘\")\n",
    "        print(f\"   ğŸ’» ì‹œì‘ ì‹œ ì‹œìŠ¤í…œ ìƒíƒœ: {self.get_detailed_system_stats()}\")\n",
    "        \n",
    "        return start_time\n",
    "    \n",
    "    def log_stage_end(self, stage_name):\n",
    "        \"\"\"ë‹¨ê³„ ì¢…ë£Œ ì‹œê°„ ê¸°ë¡\"\"\"\n",
    "        end_time = time.time()\n",
    "        end_datetime = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n",
    "        \n",
    "        if stage_name in self.stage_times:\n",
    "            start_time = self.stage_times[stage_name][\"start\"]\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            self.stage_times[stage_name].update({\n",
    "                \"end\": end_time,\n",
    "                \"end_datetime\": end_datetime,\n",
    "                \"duration\": duration\n",
    "            })\n",
    "            \n",
    "            print(f\"â° [{end_datetime}] âœ… {stage_name} ì™„ë£Œ\")\n",
    "            print(f\"   â±ï¸  ì†Œìš”ì‹œê°„: {duration:.3f}ì´ˆ\")\n",
    "            print(f\"   ğŸ’» ì¢…ë£Œ ì‹œ ì‹œìŠ¤í…œ ìƒíƒœ: {self.get_detailed_system_stats()}\")\n",
    "            print(f\"   ğŸ“Š ì„±ëŠ¥ ìš”ì•½: {self.get_performance_summary(stage_name)}\")\n",
    "            \n",
    "            return duration\n",
    "        return 0\n",
    "    \n",
    "    def get_detailed_system_stats(self):\n",
    "        \"\"\"ìƒì„¸ ì‹œìŠ¤í…œ ìƒíƒœ ë°˜í™˜\"\"\"\n",
    "        try:\n",
    "            cpu_percent = psutil.cpu_percent(interval=0.1, percpu=True)\n",
    "            memory = psutil.virtual_memory()\n",
    "            \n",
    "            return {\n",
    "                \"cpu_avg\": f\"{sum(cpu_percent)/len(cpu_percent):.1f}%\",\n",
    "                \"cpu_cores\": [f\"C{i}:{cpu:.1f}%\" for i, cpu in enumerate(cpu_percent[:8])],  # ì²˜ìŒ 8ì½”ì–´ë§Œ í‘œì‹œ\n",
    "                \"memory_used\": f\"{memory.used // (1024**3)}GB/{memory.total // (1024**3)}GB ({memory.percent:.1f}%)\",\n",
    "                \"memory_available\": f\"{memory.available // (1024**3)}GB\",\n",
    "                \"active_threads\": threading.active_count()\n",
    "            }\n",
    "        except:\n",
    "            return {\"status\": \"ëª¨ë‹ˆí„°ë§ ì¼ì‹œ ì¤‘ë‹¨\"}\n",
    "    \n",
    "    def get_performance_summary(self, stage_name):\n",
    "        \"\"\"ë‹¨ê³„ë³„ ì„±ëŠ¥ ìš”ì•½\"\"\"\n",
    "        if stage_name not in self.stage_times:\n",
    "            return \"ì¸¡ì • ë°ì´í„° ì—†ìŒ\"\n",
    "        \n",
    "        duration = self.stage_times[stage_name][\"duration\"]\n",
    "        \n",
    "        if duration < 1:\n",
    "            return f\"âš¡ ì´ˆê³ ì† ({duration*1000:.0f}ms)\"\n",
    "        elif duration < 5:\n",
    "            return f\"ğŸš€ ë¹ ë¦„ ({duration:.2f}s)\"\n",
    "        elif duration < 15:\n",
    "            return f\"â±ï¸ ë³´í†µ ({duration:.2f}s)\"\n",
    "        else:\n",
    "            return f\"ğŸŒ ëŠë¦¼ ({duration:.2f}s) - ìµœì í™” í•„ìš”\"\n",
    "    \n",
    "    def print_total_summary(self):\n",
    "        \"\"\"ì „ì²´ ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥\"\"\"\n",
    "        total_time = time.time() - self.start_time\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*100)\n",
    "        print(f\"ğŸ“Š ì „ì²´ ì„±ëŠ¥ ë¶„ì„ ë³´ê³ ì„œ\")\n",
    "        print(f\"=\"*100)\n",
    "        print(f\"ğŸ• ì´ ì‹¤í–‰ ì‹œê°„: {total_time:.3f}ì´ˆ\")\n",
    "        \n",
    "        print(f\"\\nğŸ“‹ ë‹¨ê³„ë³„ ìƒì„¸ ì‹œê°„ ë¶„ì„:\")\n",
    "        print(f\"{'ë‹¨ê³„ëª…':<25} {'ì‹œì‘ì‹œê°„':<12} {'ì¢…ë£Œì‹œê°„':<12} {'ì†Œìš”ì‹œê°„':<10} {'ì„±ëŠ¥í‰ê°€':<15}\")\n",
    "        print(\"-\" * 90)\n",
    "        \n",
    "        for stage_name, times in self.stage_times.items():\n",
    "            start_time = times.get(\"start_datetime\", \"N/A\")\n",
    "            end_time = times.get(\"end_datetime\", \"N/A\")\n",
    "            duration = times.get(\"duration\", 0)\n",
    "            performance = self.get_performance_summary(stage_name)\n",
    "            \n",
    "            print(f\"{stage_name:<25} {start_time:<12} {end_time:<12} {duration:<9.3f}s {performance:<15}\")\n",
    "        \n",
    "        print(f\"\\nğŸ¯ ë³‘ëª©ì  ë¶„ì„:\")\n",
    "        sorted_stages = sorted(self.stage_times.items(), \n",
    "                              key=lambda x: x[1].get(\"duration\", 0), reverse=True)\n",
    "        \n",
    "        for i, (stage_name, times) in enumerate(sorted_stages[:3], 1):\n",
    "            duration = times.get(\"duration\", 0)\n",
    "            percentage = (duration / total_time) * 100\n",
    "            print(f\"   {i}. {stage_name}: {duration:.3f}ì´ˆ ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nğŸ’¡ ìµœì í™” ì œì•ˆ:\")\n",
    "        for stage_name, times in sorted_stages:\n",
    "            duration = times.get(\"duration\", 0)\n",
    "            if duration > 5:\n",
    "                print(f\"   âš ï¸ {stage_name}: {duration:.2f}ì´ˆë¡œ ìµœì í™” í•„ìš”\")\n",
    "            elif duration > 1:\n",
    "                print(f\"   ğŸ” {stage_name}: {duration:.2f}ì´ˆë¡œ ê°œì„  ì—¬ì§€ ìˆìŒ\")\n",
    "        \n",
    "        return total_time\n",
    "\n",
    "monitor = DetailedPerformanceMonitor()\n",
    "\n",
    "# 1ë‹¨ê³„: ê³ ì„±ëŠ¥ ë³‘ë ¬ ë¬¸ì„œ ë¡œë”©\n",
    "def load_single_file(file_path):\n",
    "    \"\"\"ë‹¨ì¼ íŒŒì¼ ë¡œë”© í•¨ìˆ˜ (ìµœì í™”)\"\"\"\n",
    "    try:\n",
    "        # íŒŒì¼ í¬ê¸° í™•ì¸ í›„ ì ì ˆí•œ ë²„í¼ í¬ê¸° ì„¤ì •\n",
    "        file_size = os.path.getsize(file_path)\n",
    "        buffer_size = min(8192 * 16, file_size)  # 128KB ë²„í¼ ë˜ëŠ” íŒŒì¼ í¬ê¸°\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8', buffering=buffer_size) as f:\n",
    "            content = f.read()\n",
    "        return {\n",
    "            \"page_content\": content,\n",
    "            \"metadata\": {\"source\": str(file_path), \"size\": file_size}\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {file_path} - {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def high_performance_document_loading():\n",
    "    \"\"\"16ì½”ì–´ ìµœì í™” ë³‘ë ¬ ë¬¸ì„œ ë¡œë”©\"\"\"\n",
    "    stage_name = \"ê³ ì„±ëŠ¥_ë¬¸ì„œ_ë¡œë”©\"\n",
    "    monitor.log_stage_start(stage_name)\n",
    "    \n",
    "    data_dir = Path(\"./data\")\n",
    "    md_files = list(data_dir.glob(\"*.md\"))\n",
    "    \n",
    "    if not md_files:\n",
    "        print(f\"   âš ï¸ ./data í´ë”ì— .md íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "        duration = monitor.log_stage_end(stage_name)\n",
    "        return []\n",
    "    \n",
    "    docs = []\n",
    "    \n",
    "    # 16ì½”ì–´ ì‹œìŠ¤í…œ ìµœì í™”: 32ê°œ ì›Œì»¤\n",
    "    with ThreadPoolExecutor(max_workers=PARALLELISM[\"file_loading\"]) as executor:\n",
    "        future_to_file = {executor.submit(load_single_file, file_path): file_path \n",
    "                         for file_path in md_files}\n",
    "        \n",
    "        with tqdm(total=len(md_files), desc=\"ğŸ“„ ê³ ì„±ëŠ¥ íŒŒì¼ ë¡œë”©\", \n",
    "                 bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\") as pbar:\n",
    "            \n",
    "            for future in as_completed(future_to_file):\n",
    "                file_path = future_to_file[future]\n",
    "                try:\n",
    "                    doc = future.result()\n",
    "                    if doc:\n",
    "                        docs.append(doc)\n",
    "                        file_size = doc[\"metadata\"][\"size\"]\n",
    "                        pbar.set_description(f\"ğŸ“„ ë¡œë”©: {file_path.name} ({file_size//1024}KB)\")\n",
    "                    pbar.update(1)\n",
    "                except Exception as e:\n",
    "                    pbar.set_description(f\"âŒ ì‹¤íŒ¨: {file_path.name}\")\n",
    "                    pbar.update(1)\n",
    "    \n",
    "    duration = monitor.log_stage_end(stage_name)\n",
    "    \n",
    "    if docs:\n",
    "        total_size = sum(doc[\"metadata\"][\"size\"] for doc in docs) / (1024*1024)\n",
    "        throughput = total_size / duration if duration > 0 else 0\n",
    "        print(f\"   ğŸ“ˆ ì²˜ë¦¬ëŸ‰: {total_size:.2f}MB, {throughput:.2f}MB/s\")\n",
    "    \n",
    "    return docs\n",
    "\n",
    "# 2ë‹¨ê³„: ê³ ì„±ëŠ¥ ìŠ¤ë ˆë“œ ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„í•  (Jupyter í˜¸í™˜)\n",
    "def split_documents_threaded(docs):\n",
    "    \"\"\"ìŠ¤ë ˆë“œ ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„í•  (Jupyter í™˜ê²½ í˜¸í™˜)\"\"\"\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    \n",
    "    # 16ì½”ì–´ ì‹œìŠ¤í…œ ìµœì í™”: ë” í° ì²­í¬ í¬ê¸°\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,      # 300 -> 500ìœ¼ë¡œ ì¦ê°€\n",
    "        chunk_overlap=100,   # 50 -> 100ìœ¼ë¡œ ì¦ê°€\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    all_split_docs = []\n",
    "    \n",
    "    for doc_data in docs:\n",
    "        try:\n",
    "            # ë¬¸ì„œ ê°ì²´ ì¬êµ¬ì„±\n",
    "            class Document:\n",
    "                def __init__(self, page_content, metadata):\n",
    "                    self.page_content = page_content\n",
    "                    self.metadata = metadata\n",
    "            \n",
    "            doc = Document(doc_data[\"page_content\"], doc_data[\"metadata\"])\n",
    "            chunks = text_splitter.split_documents([doc])\n",
    "            all_split_docs.extend(chunks)\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ ë¬¸ì„œ ë¶„í•  ì‹¤íŒ¨: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return all_split_docs\n",
    "\n",
    "def high_performance_text_splitting(docs):\n",
    "    \"\"\"16ì½”ì–´ ìµœì í™” ìŠ¤ë ˆë“œ ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„í• \"\"\"\n",
    "    stage_name = \"ê³ ì„±ëŠ¥_í…ìŠ¤íŠ¸_ë¶„í• \"\n",
    "    monitor.log_stage_start(stage_name)\n",
    "    \n",
    "    if not docs:\n",
    "        print(f\"   âš ï¸ ë¶„í• í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "        duration = monitor.log_stage_end(stage_name)\n",
    "        return []\n",
    "    \n",
    "    split_docs = []\n",
    "    \n",
    "    # ThreadPoolExecutorë¡œ ì•ˆì „í•œ ë³‘ë ¬ ì²˜ë¦¬ (Jupyter í˜¸í™˜)\n",
    "    with ThreadPoolExecutor(max_workers=PARALLELISM[\"text_splitting\"]) as executor:\n",
    "        # ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ë³‘ë ¬ ì²˜ë¦¬\n",
    "        chunk_size = max(1, len(docs) // PARALLELISM[\"text_splitting\"])\n",
    "        doc_chunks = [docs[i:i + chunk_size] for i in range(0, len(docs), chunk_size)]\n",
    "        \n",
    "        future_to_chunk = {executor.submit(split_documents_threaded, chunk): i \n",
    "                          for i, chunk in enumerate(doc_chunks)}\n",
    "        \n",
    "        with tqdm(total=len(doc_chunks), desc=\"âœ‚ï¸ ê³ ì„±ëŠ¥ í…ìŠ¤íŠ¸ ë¶„í• \",\n",
    "                 bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\") as pbar:\n",
    "            \n",
    "            for future in as_completed(future_to_chunk):\n",
    "                chunk_idx = future_to_chunk[future]\n",
    "                try:\n",
    "                    chunks = future.result()\n",
    "                    split_docs.extend(chunks)\n",
    "                    pbar.set_description(f\"âœ‚ï¸ ì²­í¬{chunk_idx+1} -> {len(chunks)}ê°œ ë¶„í• \")\n",
    "                    pbar.update(1)\n",
    "                except Exception as e:\n",
    "                    pbar.set_description(f\"âŒ ì²­í¬{chunk_idx+1} ë¶„í•  ì‹¤íŒ¨\")\n",
    "                    pbar.update(1)\n",
    "    \n",
    "    duration = monitor.log_stage_end(stage_name)\n",
    "    \n",
    "    chunk_rate = len(split_docs) / duration if duration > 0 else 0\n",
    "    print(f\"   ğŸ“ˆ ë¶„í•  ì„±ëŠ¥: {len(split_docs)}ê°œ ì²­í¬, {chunk_rate:.1f}ì²­í¬/ì´ˆ\")\n",
    "    \n",
    "    return split_docs\n",
    "\n",
    "# 3ë‹¨ê³„: 64ê°œ ë™ì‹œ ìš”ì²­ ì„ë² ë”© ìµœì í™”\n",
    "def setup_ultra_optimized_embeddings():\n",
    "    \"\"\"64ê°œ ë™ì‹œ ìš”ì²­ ì„ë² ë”© ì„¤ì •\"\"\"\n",
    "    stage_name = \"ì´ˆê³ ì„±ëŠ¥_ì„ë² ë”©_ì„¤ì •\"\n",
    "    monitor.log_stage_start(stage_name)\n",
    "    \n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    \n",
    "    # 16ì½”ì–´ ì‹œìŠ¤í…œ: 64ê°œ ë™ì‹œ ìš”ì²­\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=\"text-embedding-3-small\",\n",
    "        max_retries=5,\n",
    "        request_timeout=120,\n",
    "        chunk_size=min(2000, PARALLELISM[\"embedding\"]),  # 2000ê°œ ë˜ëŠ” 64ê°œ\n",
    "    )\n",
    "    \n",
    "    duration = monitor.log_stage_end(stage_name)\n",
    "    print(f\"   âš¡ ì„ë² ë”© ë³‘ë ¬ë„: {PARALLELISM['embedding']}ê°œ ë™ì‹œ ìš”ì²­\")\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# 4ë‹¨ê³„: ì´ˆê³ ì† BM25 ì¸ë±ì‹±\n",
    "def ultra_fast_bm25_setup(split_docs):\n",
    "    \"\"\"128GB ë©”ëª¨ë¦¬ í™œìš© ì´ˆê³ ì† BM25 ì¸ë±ì‹±\"\"\"\n",
    "    stage_name = \"ì´ˆê³ ì†_BM25_ì¸ë±ì‹±\"\n",
    "    monitor.log_stage_start(stage_name)\n",
    "    \n",
    "    if not split_docs:\n",
    "        print(f\"   âš ï¸ ì¸ë±ì‹±í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "        duration = monitor.log_stage_end(stage_name)\n",
    "        return None\n",
    "    \n",
    "    bm25_cache_path = os.path.join(CACHE_DIR, \"bm25_retriever_jupyter_v4.pkl\")\n",
    "    \n",
    "    # ìºì‹œ í™•ì¸\n",
    "    if os.path.exists(bm25_cache_path):\n",
    "        cache_start = time.time()\n",
    "        with tqdm(total=1, desc=\"ğŸ“‹ BM25 ìºì‹œ ë¡œë”©\") as pbar:\n",
    "            with open(bm25_cache_path, 'rb') as f:\n",
    "                bm25_retriever = pickle.load(f)\n",
    "            pbar.update(1)\n",
    "        \n",
    "        cache_time = time.time() - cache_start\n",
    "        duration = monitor.log_stage_end(stage_name)\n",
    "        print(f\"   âš¡ ìºì‹œ ë¡œë”© ì†ë„: {cache_time:.3f}ì´ˆ\")\n",
    "        return bm25_retriever\n",
    "    \n",
    "    # ìƒˆë¡œ ìƒì„± - 128GB ë©”ëª¨ë¦¬ í™œìš©\n",
    "    from langchain_community.retrievers import BM25Retriever\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ í’ë¶€í•œ ì‹œìŠ¤í…œ: í•œ ë²ˆì— ëª¨ë“  ë¬¸ì„œ ì²˜ë¦¬\n",
    "    index_start = time.time()\n",
    "    \n",
    "    with tqdm(total=len(split_docs), desc=\"ğŸ” ì´ˆê³ ì† BM25 ì¸ë±ì‹±\",\n",
    "             bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\") as pbar:\n",
    "        \n",
    "        try:\n",
    "            # 128GB ë©”ëª¨ë¦¬: ëª¨ë“  ë¬¸ì„œë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œí•˜ì—¬ ì²˜ë¦¬\n",
    "            bm25_retriever = BM25Retriever.from_documents(split_docs)\n",
    "            bm25_retriever.k = 5\n",
    "            \n",
    "            pbar.update(len(split_docs))\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ BM25 ì¸ë±ì‹± ì‹¤íŒ¨: {e}\")\n",
    "            duration = monitor.log_stage_end(stage_name)\n",
    "            return None\n",
    "    \n",
    "    index_time = time.time() - index_start\n",
    "    \n",
    "    # ìºì‹œ ì €ì¥\n",
    "    cache_save_start = time.time()\n",
    "    with open(bm25_cache_path, 'wb') as f:\n",
    "        pickle.dump(bm25_retriever, f)\n",
    "    cache_save_time = time.time() - cache_save_start\n",
    "    \n",
    "    duration = monitor.log_stage_end(stage_name)\n",
    "    \n",
    "    indexing_rate = len(split_docs) / index_time if index_time > 0 else 0\n",
    "    print(f\"   ğŸ“ˆ ì¸ë±ì‹± ì„±ëŠ¥: {indexing_rate:.1f}ë¬¸ì„œ/ì´ˆ\")\n",
    "    print(f\"   ğŸ’¾ ìºì‹œ ì €ì¥: {cache_save_time:.3f}ì´ˆ\")\n",
    "    \n",
    "    return bm25_retriever\n",
    "\n",
    "# 5ë‹¨ê³„: ì „ì²´ ê²€ìƒ‰ê¸° ì´ˆê³ ì† ì„¤ì •\n",
    "def setup_ultra_high_performance_retrievers():\n",
    "    \"\"\"16ì½”ì–´ 128GB ì‹œìŠ¤í…œ ìµœì í™” ê²€ìƒ‰ê¸° ì„¤ì •\"\"\"\n",
    "    stage_name = \"ì „ì²´_ê²€ìƒ‰ê¸°_ì´ˆê³ ì†_ì„¤ì •\"\n",
    "    monitor.log_stage_start(stage_name)\n",
    "    \n",
    "    # ì „ì²´ ì§„í–‰ë¥  í‘œì‹œ\n",
    "    main_progress = tqdm(total=6, desc=\"ğŸ—ï¸ ì´ˆê³ ì„±ëŠ¥ ê²€ìƒ‰ê¸° ì‹œìŠ¤í…œ êµ¬ì¶•\", position=0,\n",
    "                        bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]\")\n",
    "    \n",
    "    # 1. ê³ ì„±ëŠ¥ ë¬¸ì„œ ë¡œë”©\n",
    "    main_progress.set_description(\"ğŸ“„ ê³ ì„±ëŠ¥ ë¬¸ì„œ ë¡œë”©...\")\n",
    "    docs = high_performance_document_loading()\n",
    "    main_progress.update(1)\n",
    "    \n",
    "    # 2. ê³ ì„±ëŠ¥ í…ìŠ¤íŠ¸ ë¶„í• \n",
    "    main_progress.set_description(\"âœ‚ï¸ ê³ ì„±ëŠ¥ í…ìŠ¤íŠ¸ ë¶„í• ...\")\n",
    "    split_docs = high_performance_text_splitting(docs)\n",
    "    main_progress.update(1)\n",
    "    \n",
    "    # 3. ì´ˆê³ ì„±ëŠ¥ ì„ë² ë”© ì„¤ì •\n",
    "    main_progress.set_description(\"ğŸ§  ì´ˆê³ ì„±ëŠ¥ ì„ë² ë”© ì„¤ì •...\")\n",
    "    embeddings = setup_ultra_optimized_embeddings()\n",
    "    main_progress.update(1)\n",
    "    \n",
    "    # 4. ì˜ë¯¸ ê²€ìƒ‰ê¸° ì„¤ì •\n",
    "    main_progress.set_description(\"ğŸ§  ì˜ë¯¸ ê²€ìƒ‰ê¸° ìµœì í™”...\")\n",
    "    try:\n",
    "        semantic_retriever = chroma_db.as_retriever(\n",
    "            search_type=\"similarity\",\n",
    "            search_kwargs={\"k\": 5}\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ChromaDB ê²€ìƒ‰ê¸° ì„¤ì • ì‹¤íŒ¨: {e}\")\n",
    "        semantic_retriever = None\n",
    "    main_progress.update(1)\n",
    "    \n",
    "    # 5. ì´ˆê³ ì† BM25 ê²€ìƒ‰ê¸°\n",
    "    main_progress.set_description(\"ğŸ” ì´ˆê³ ì† BM25 ì¸ë±ì‹±...\")\n",
    "    bm25_retriever = ultra_fast_bm25_setup(split_docs)\n",
    "    main_progress.update(1)\n",
    "    \n",
    "    # 6. ê³ ê¸‰ ê²€ìƒ‰ê¸° êµ¬ì„±\n",
    "    main_progress.set_description(\"ğŸ”„ ê³ ê¸‰ ê²€ìƒ‰ê¸° ìµœì í™”...\")\n",
    "    \n",
    "    retrievers = {}\n",
    "    \n",
    "    if semantic_retriever:\n",
    "        retrievers[\"semantic\"] = semantic_retriever\n",
    "    \n",
    "    if bm25_retriever:\n",
    "        retrievers[\"bm25\"] = bm25_retriever\n",
    "        \n",
    "        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° (ì˜ë¯¸ ê²€ìƒ‰ê¸°ê°€ ìˆì„ ë•Œë§Œ)\n",
    "        if semantic_retriever:\n",
    "            from langchain.retrievers import EnsembleRetriever\n",
    "            hybrid_retriever = EnsembleRetriever(\n",
    "                retrievers=[semantic_retriever, bm25_retriever],\n",
    "                weights=[0.7, 0.3]  # ì˜ë¯¸ ê²€ìƒ‰ ë¹„ì¤‘ ì¦ê°€\n",
    "            )\n",
    "            retrievers[\"hybrid\"] = hybrid_retriever\n",
    "            \n",
    "            # ë©€í‹°ì¿¼ë¦¬ ê²€ìƒ‰ê¸°\n",
    "            try:\n",
    "                from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "                from langchain_openai import ChatOpenAI\n",
    "                \n",
    "                llm = ChatOpenAI(\n",
    "                    model=\"gpt-4o-mini\", \n",
    "                    temperature=0,\n",
    "                    request_timeout=60,\n",
    "                    max_retries=3\n",
    "                )\n",
    "                \n",
    "                multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "                    retriever=hybrid_retriever,\n",
    "                    llm=llm\n",
    "                )\n",
    "                retrievers[\"multi_query\"] = multi_query_retriever\n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ ë©€í‹°ì¿¼ë¦¬ ê²€ìƒ‰ê¸° ì„¤ì • ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    main_progress.update(1)\n",
    "    main_progress.close()\n",
    "    \n",
    "    duration = monitor.log_stage_end(stage_name)\n",
    "    \n",
    "    print(f\"   ğŸ¯ ìƒì„±ëœ ê²€ìƒ‰ê¸°: {len(retrievers)}ê°œ\")\n",
    "    print(f\"   ğŸ“Š ì²˜ë¦¬ëœ ë¬¸ì„œ: {len(docs)}ê°œ -> {len(split_docs)}ê°œ ì²­í¬\")\n",
    "    \n",
    "    return retrievers\n",
    "\n",
    "# 6ë‹¨ê³„: 8ê°œ ë™ì‹œ ì´ˆê³ ì† ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "def ultra_high_speed_search_test(query, retrievers_dict):\n",
    "    \"\"\"8ê°œ ë™ì‹œ ì´ˆê³ ì† ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    stage_name = \"ì´ˆê³ ì†_ë³‘ë ¬_ê²€ìƒ‰_í…ŒìŠ¤íŠ¸\"\n",
    "    monitor.log_stage_start(stage_name)\n",
    "    \n",
    "    if not retrievers_dict:\n",
    "        print(f\"   âš ï¸ ê²€ìƒ‰í•  ê²€ìƒ‰ê¸°ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "        duration = monitor.log_stage_end(stage_name)\n",
    "        return {}, duration\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # ì‹œìŠ¤í…œ ìƒíƒœ ì¶œë ¥\n",
    "    initial_stats = monitor.get_detailed_system_stats()\n",
    "    print(f\"   ğŸ–¥ï¸ ê²€ìƒ‰ ì‹œì‘ ì‹œì  ì‹œìŠ¤í…œ ìƒíƒœ: {initial_stats}\")\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=PARALLELISM[\"search_test\"]) as executor:\n",
    "        future_to_name = {}\n",
    "        \n",
    "        # ëª¨ë“  ê²€ìƒ‰ê¸°ì— ëŒ€í•´ Future ìƒì„±\n",
    "        for name, retriever in retrievers_dict.items():\n",
    "            future = executor.submit(retriever.invoke, query)\n",
    "            future_to_name[future] = name\n",
    "        \n",
    "        # ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§\n",
    "        with tqdm(total=len(future_to_name), desc=\"ğŸš€ ì´ˆê³ ì† ë³‘ë ¬ ê²€ìƒ‰\",\n",
    "                 bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\") as pbar:\n",
    "            \n",
    "            for future in as_completed(future_to_name):\n",
    "                name = future_to_name[future]\n",
    "                search_start = time.time()\n",
    "                \n",
    "                try:\n",
    "                    docs = future.result(timeout=60)\n",
    "                    search_time = time.time() - search_start\n",
    "                    results[name] = docs[:3]\n",
    "                    \n",
    "                    # ê°œë³„ ê²€ìƒ‰ê¸° ì„±ëŠ¥ ì¸¡ì •\n",
    "                    current_stats = monitor.get_detailed_system_stats()\n",
    "                    cpu_info = current_stats.get('cpu_avg', 'N/A')\n",
    "                    pbar.set_description(f\"âœ… {name} ì™„ë£Œ ({search_time:.3f}ì´ˆ, CPU:{cpu_info})\")\n",
    "                    pbar.update(1)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    search_time = time.time() - search_start\n",
    "                    results[name] = []\n",
    "                    pbar.set_description(f\"âŒ {name} ì‹¤íŒ¨ ({search_time:.3f}ì´ˆ)\")\n",
    "                    pbar.update(1)\n",
    "    \n",
    "    duration = monitor.log_stage_end(stage_name)\n",
    "    \n",
    "    search_rate = len(retrievers_dict) / duration if duration > 0 else 0\n",
    "    print(f\"   âš¡ ê²€ìƒ‰ ì„±ëŠ¥: {search_rate:.1f}ê²€ìƒ‰ê¸°/ì´ˆ\")\n",
    "    \n",
    "    return results, duration\n",
    "\n",
    "# ë©”ì¸ ì‹¤í–‰\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ğŸš€ 16ì½”ì–´ 128GB ì‹œìŠ¤í…œ ìµœì í™” ì´ˆê³ ì„±ëŠ¥ ê²€ìƒ‰ê¸° ì‹¤í–‰ (Jupyter í˜¸í™˜)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "total_start = time.time()\n",
    "\n",
    "# ëª¨ë“  ê²€ìƒ‰ê¸° ì„¤ì •\n",
    "retrievers = setup_ultra_high_performance_retrievers()\n",
    "\n",
    "if not retrievers:\n",
    "    print(\"âŒ ê²€ìƒ‰ê¸° ì„¤ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë°ì´í„° í´ë”ì™€ ChromaDBë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "else:\n",
    "    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬\n",
    "    test_query = \"í…ŒìŠ¬ë¼ íŠ¸ëŸ­ ëª¨ë¸ì´ ìˆë‚˜ìš”?\"\n",
    "    print(f\"\\nğŸ“‹ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: '{test_query}'\")\n",
    "\n",
    "    # ì´ˆê³ ì† ë³‘ë ¬ ê²€ìƒ‰ ì‹¤í–‰\n",
    "    search_results, search_time = ultra_high_speed_search_test(test_query, retrievers)\n",
    "\n",
    "    # ì „ì²´ ì„±ëŠ¥ ë¶„ì„ ì¶œë ¥\n",
    "    total_time = monitor.print_total_summary()\n",
    "\n",
    "    # ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥\n",
    "    print(f\"\\n\" + \"=\"*100)\n",
    "    print(f\"ğŸ¯ ì´ˆê³ ì„±ëŠ¥ ë³‘ë ¬ ê²€ìƒ‰ ê²°ê³¼\")\n",
    "    print(\"=\"*100)\n",
    "\n",
    "    result_icons = {\"semantic\": \"ğŸ§ \", \"bm25\": \"ğŸ”\", \"hybrid\": \"ğŸ”„\", \"multi_query\": \"ğŸ¯\"}\n",
    "    result_names = {\"semantic\": \"ì˜ë¯¸ ê²€ìƒ‰\", \"bm25\": \"í‚¤ì›Œë“œ ê²€ìƒ‰\", \n",
    "                   \"hybrid\": \"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰\", \"multi_query\": \"ë©€í‹°ì¿¼ë¦¬ ê²€ìƒ‰\"}\n",
    "\n",
    "    for name, docs in search_results.items():\n",
    "        print(f\"\\n{result_icons.get(name, 'ğŸ”§')} === {result_names.get(name, name)} ê²°ê³¼ ===\")\n",
    "        if docs:\n",
    "            for i, doc in enumerate(docs, 1):\n",
    "                source = doc.metadata.get('source', 'Unknown')\n",
    "                print(f\"{i}. {doc.page_content[:80]}... [ì¶œì²˜: {source}]\")\n",
    "        else:\n",
    "            print(\"âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ ë˜ëŠ” ì˜¤ë¥˜ ë°œìƒ\")\n",
    "\n",
    "    print(f\"\\n\" + \"=\"*100)\n",
    "    print(\"ğŸ‰ 16ì½”ì–´ 128GB ìµœì í™” ì‹¤ìŠµ 1 ì™„ë£Œ! (Jupyter í˜¸í™˜)\")\n",
    "    print(\"ğŸ“Š ìµœëŒ€ ì„±ëŠ¥ í™œìš©:\")\n",
    "    print(f\"   ğŸ”¥ íŒŒì¼ ë¡œë”©: {PARALLELISM['file_loading']}ê°œ ìŠ¤ë ˆë“œ\")\n",
    "    print(f\"   âš¡ í…ìŠ¤íŠ¸ ë¶„í• : {PARALLELISM['text_splitting']}ê°œ ìŠ¤ë ˆë“œ (Jupyter ì•ˆì „ ëª¨ë“œ)\")\n",
    "    print(f\"   ğŸš€ ì„ë² ë”© ìš”ì²­: {PARALLELISM['embedding']}ê°œ ë™ì‹œ\")\n",
    "    print(f\"   ğŸ’¾ BM25 ì¸ë±ì‹±: {PARALLELISM['bm25_indexing']}ê°œ ìŠ¤ë ˆë“œ\")\n",
    "    print(f\"   ğŸ¯ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸: {PARALLELISM['search_test']}ê°œ ë™ì‹œ\")\n",
    "    print(\"   â° ëª¨ë“  ë‹¨ê³„ë³„ ìƒì„¸ ì‹œê°„ ì¸¡ì •\")\n",
    "    print(\"   ğŸ“ˆ ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§\")\n",
    "    print(\"   ğŸ” ë³‘ëª©ì  ìë™ ë¶„ì„\")\n",
    "    print(\"   âœ… Jupyter í™˜ê²½ í˜¸í™˜ì„± í™•ë³´\")\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) ê²€ìƒ‰ê¸°ë²• ê³ ë„í™”`\n",
    "\n",
    "- Rerank, Comporession ê¸°ë²•ì„ ì ìš©í•©ë‹ˆë‹¤. \n",
    "- Pipeline Compressorë¡œ ì—°ê²°í•˜ì—¬ êµ¬ì„±í•©ë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ ì‹¤ìŠµ 2: ê²€ìƒ‰ê¸°ë²• ê³ ë„í™” ì‹œì‘\n",
      "âŒ semantic_retriever ì—†ìŒ\n",
      "âŒ bm25_retriever ì—†ìŒ\n",
      "âŒ hybrid_retriever ì—†ìŒ\n",
      "âœ… retrievers ë°œê²¬ë¨\n",
      "\n",
      "âš ï¸ ì‹¤ìŠµ 1ì˜ ì¼ë¶€ ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤: ['semantic_retriever', 'bm25_retriever', 'hybrid_retriever']\n",
      "ğŸ”„ í•„ìš”í•œ ê²€ìƒ‰ê¸°ë“¤ì„ ì¬ìƒì„±í•©ë‹ˆë‹¤...\n",
      "\n",
      "ğŸ“‹ ê²€ìƒ‰ê¸° ì¬ìƒì„± ì¤‘...\n",
      "âœ… semantic_retriever ìƒì„± ì™„ë£Œ\n",
      "ğŸ“‹ BM25 ìºì‹œì—ì„œ ë¡œë“œ ì¤‘...\n",
      "âœ… bm25_retriever ìºì‹œ ë¡œë“œ ì™„ë£Œ\n",
      "âœ… hybrid_retriever ìƒì„± ì™„ë£Œ\n",
      "âœ… ì‹¤ìŠµ 2 ì¤€ë¹„ ì™„ë£Œ! ì‚¬ìš© ê²€ìƒ‰ê¸°: EnsembleRetriever\n",
      "\n",
      "ğŸ”§ ê³ ë„í™” ê¸°ë²• êµ¬ì„± ì‹œì‘...\n",
      "1ï¸âƒ£ LLM Reranker ì„¤ì •...\n",
      "2ï¸âƒ£ LLM Chain Extractor ì„¤ì •...\n",
      "3ï¸âƒ£ Embeddings Filter ì„¤ì •...\n",
      "4ï¸âƒ£ Redundant Filter ì„¤ì •...\n",
      "5ï¸âƒ£ Pipeline Compressor êµ¬ì„±...\n",
      "6ï¸âƒ£ ê³ ë„í™”ëœ ê²€ìƒ‰ê¸° êµ¬ì„±...\n",
      "\n",
      "ğŸ¯ ê³ ë„í™” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹œì‘ (ì´ 3ê°œ ì¿¼ë¦¬)\n",
      "\n",
      "================================================================================\n",
      "ğŸ” ì¿¼ë¦¬ 1: í…ŒìŠ¬ë¼ íŠ¸ëŸ­ ëª¨ë¸ì´ ìˆë‚˜ìš”?\n",
      "================================================================================\n",
      "\n",
      "--- ê¸°ë³¸ ê²€ìƒ‰ ê²°ê³¼ ---\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 10\n",
      "1. [ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "- **Cybertruck:** 2019ë…„ 11ì›”ì— ì²˜ìŒ ë°œí‘œëœ í’€ì‚¬ì´ì¦ˆ í”½ì—… íŠ¸ëŸ­. í›„ë¥œ êµ¬ë™, ë“€ì–¼ ëª¨í„° ì „ë¥œ êµ¬ë™, íŠ¸ë¦¬ ëª¨í„° ì „ë¥œ êµ¬ë™ì˜ ì„¸ ê°€ì§€ ëª¨ë¸ì´...\n",
      "2. [ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "| Tesla ëª¨ë¸ |          |       |                  |\n",
      "| :--------- | :------- | :---- | :---...\n",
      "\n",
      "--- ê³ ë„í™”ëœ ê²€ìƒ‰ ê²°ê³¼ (Pipeline) ---\n",
      "ìµœì¢… ë¬¸ì„œ ìˆ˜: 2\n",
      "1. - **Cybertruck:** 2019ë…„ 11ì›”ì— ì²˜ìŒ ë°œí‘œëœ í’€ì‚¬ì´ì¦ˆ í”½ì—… íŠ¸ëŸ­. í›„ë¥œ êµ¬ë™, ë“€ì–¼ ëª¨í„° ì „ë¥œ êµ¬ë™, íŠ¸ë¦¬ ëª¨í„° ì „ë¥œ êµ¬ë™ì˜ ì„¸ ê°€ì§€ ëª¨ë¸ì´ ì œê³µë©ë‹ˆë‹¤.\n",
      "   [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "\n",
      "2. | Semi       | 2022     | 2     |                  |\n",
      "| Cybertruck | 2023     | 5     |                  |\n",
      "   [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ğŸ” ì¿¼ë¦¬ 2: ë¦¬ë¹„ì•ˆì˜ ì „ê¸° íŠ¸ëŸ­ íŠ¹ì§•ì€?\n",
      "================================================================================\n",
      "\n",
      "--- ê¸°ë³¸ ê²€ìƒ‰ ê²°ê³¼ ---\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 10\n",
      "1. [ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "## ì—ë„ˆì§€ ì œí’ˆ\n",
      "\n",
      "Tesla EnergyëŠ” íƒœì–‘ ì—ë„ˆì§€ ìƒì„± ì‹œìŠ¤í…œê³¼ ë°°í„°ë¦¬ ì—ë„ˆì§€ ì €ì¥ ì œí’ˆì„ ê°œë°œ, êµ¬ì¶•, íŒë§¤ ë° ì„¤ì¹˜í•©ë‹ˆë‹¤. ì œí’ˆì—ëŠ” íƒœì–‘ ì „ì§€íŒ, S...\n",
      "2. [ì¶œì²˜] ì´ ë¬¸ì„œëŠ” ë¦¬ë¹„ì•ˆì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "Rivian Automotive, Inc.ëŠ” 2009ë…„ì— ì„¤ë¦½ëœ ë¯¸êµ­ì˜ ì „ê¸° ìë™ì°¨ ì œì¡°ì—…ì²´, ìë™ì°¨ ê¸°ìˆ  ë° ì•¼ì™¸ ë ˆí¬ë¦¬ì—ì´ì…˜ íšŒì‚¬ì…ë‹ˆë‹¤.\n",
      "\n",
      "**ì£¼ìš” ì •ë³´:*...\n",
      "\n",
      "--- ê³ ë„í™”ëœ ê²€ìƒ‰ ê²°ê³¼ (Pipeline) ---\n",
      "ìµœì¢… ë¬¸ì„œ ìˆ˜: 0\n",
      "\n",
      "================================================================================\n",
      "ğŸ” ì¿¼ë¦¬ 3: í…ŒìŠ¬ë¼ì™€ ë¦¬ë¹„ì•ˆì˜ ì°¨ì´ì ì€?\n",
      "================================================================================\n",
      "\n",
      "--- ê¸°ë³¸ ê²€ìƒ‰ ê²°ê³¼ ---\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 10\n",
      "1. [ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "### ë°œí‘œëœ ì œí’ˆ\n",
      "\n",
      "- **Roadster (2ì„¸ëŒ€):** 2017ë…„ì— ê³µê°œë˜ì—ˆìœ¼ë©° 620ë§ˆì¼(1,000km)ì˜ ì£¼í–‰ ê±°ë¦¬ì™€ ê³ ì„±ëŠ¥ ì‚¬ì–‘ì„ ê°–ì¶˜ ê²ƒìœ¼ë¡œ ì•Œë ¤ì ¸...\n",
      "2. [ì¶œì²˜] ì´ ë¬¸ì„œëŠ” í…ŒìŠ¬ë¼ì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\n",
      "----------------------------------\n",
      "### ì¶©ì „ ì„œë¹„ìŠ¤\n",
      "\n",
      "- **Supercharger ë„¤íŠ¸ì›Œí¬:** Teslaì˜ ê³ ì „ì•• DC ê¸‰ì† ì¶©ì „ ë„¤íŠ¸ì›Œí¬ë¡œ, 2012ë…„ì— ë„ì…ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "- **Desti...\n",
      "\n",
      "--- ê³ ë„í™”ëœ ê²€ìƒ‰ ê²°ê³¼ (Pipeline) ---\n",
      "ìµœì¢… ë¬¸ì„œ ìˆ˜: 0\n",
      "\n",
      "ğŸ¯ Pipeline êµ¬ì„±:\n",
      "1. ì¤‘ë³µ ì œê±° (EmbeddingsRedundantFilter)\n",
      "2. ìœ ì‚¬ë„ í•„í„°ë§ (EmbeddingsFilter, threshold=0.5)\n",
      "3. ë§¥ë½ ì••ì¶• (LLMChainExtractor)\n",
      "4. ì¬ìˆœìœ„í™” (LLMListwiseRerank, top_n=3)\n",
      "\n",
      "âœ… ì‹¤ìŠµ 2 ì™„ë£Œ!\n",
      "ğŸ“Š ì‚¬ìš©ëœ ê²€ìƒ‰ê¸°: EnsembleRetriever\n",
      "ğŸ”§ ì ìš©ëœ ê¸°ë²•: 4ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì••ì¶• + ì¬ìˆœìœ„í™”\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤ìŠµ 2: ê²€ìƒ‰ê¸°ë²• ê³ ë„í™” (Rerank + Compression)\n",
    "\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import (\n",
    "    LLMListwiseRerank, \n",
    "    LLMChainExtractor,\n",
    "    EmbeddingsFilter,\n",
    "    DocumentCompressorPipeline\n",
    ")\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "print(\"ğŸ”§ ì‹¤ìŠµ 2: ê²€ìƒ‰ê¸°ë²• ê³ ë„í™” ì‹œì‘\")\n",
    "\n",
    "# ì‹¤ìŠµ 1ì—ì„œ ìƒì„±ëœ ê²€ìƒ‰ê¸°ë“¤ í™•ì¸ ë° ì¬ìƒì„± (í•„ìš”ì‹œ)\n",
    "try:\n",
    "    # ì‹¤ìŠµ 1ì˜ ë³€ìˆ˜ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸\n",
    "    test_vars = [\n",
    "        ('semantic_retriever', 'semantic_retriever'),\n",
    "        ('bm25_retriever', 'bm25_retriever'), \n",
    "        ('hybrid_retriever', 'hybrid_retriever'),\n",
    "        ('retrievers', 'retrievers')\n",
    "    ]\n",
    "    \n",
    "    missing_vars = []\n",
    "    for var_name, display_name in test_vars:\n",
    "        try:\n",
    "            eval(var_name)\n",
    "            print(f\"âœ… {display_name} ë°œê²¬ë¨\")\n",
    "        except NameError:\n",
    "            missing_vars.append(var_name)\n",
    "            print(f\"âŒ {display_name} ì—†ìŒ\")\n",
    "    \n",
    "    if missing_vars:\n",
    "        print(f\"\\nâš ï¸ ì‹¤ìŠµ 1ì˜ ì¼ë¶€ ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤: {missing_vars}\")\n",
    "        print(\"ğŸ”„ í•„ìš”í•œ ê²€ìƒ‰ê¸°ë“¤ì„ ì¬ìƒì„±í•©ë‹ˆë‹¤...\")\n",
    "        \n",
    "        # ê¸°ë³¸ ê²€ìƒ‰ê¸°ë“¤ ì¬ìƒì„±\n",
    "        print(\"\\nğŸ“‹ ê²€ìƒ‰ê¸° ì¬ìƒì„± ì¤‘...\")\n",
    "        \n",
    "        # 1. Semantic retriever (ChromaDB ê¸°ë°˜)\n",
    "        try:\n",
    "            semantic_retriever = chroma_db.as_retriever(\n",
    "                search_type=\"similarity\",\n",
    "                search_kwargs={\"k\": 5}\n",
    "            )\n",
    "            print(\"âœ… semantic_retriever ìƒì„± ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ semantic_retriever ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "            semantic_retriever = None\n",
    "        \n",
    "        # 2. BM25 retriever ìºì‹œì—ì„œ ë¡œë“œ ë˜ëŠ” ì¬ìƒì„±\n",
    "        try:\n",
    "            import os\n",
    "            import pickle\n",
    "            from pathlib import Path\n",
    "            \n",
    "            bm25_cache_path = \"./cache/bm25_retriever_jupyter_v4.pkl\"\n",
    "            \n",
    "            if os.path.exists(bm25_cache_path):\n",
    "                print(\"ğŸ“‹ BM25 ìºì‹œì—ì„œ ë¡œë“œ ì¤‘...\")\n",
    "                with open(bm25_cache_path, 'rb') as f:\n",
    "                    bm25_retriever = pickle.load(f)\n",
    "                print(\"âœ… bm25_retriever ìºì‹œ ë¡œë“œ ì™„ë£Œ\")\n",
    "            else:\n",
    "                print(\"ğŸ”„ BM25 retriever ìƒˆë¡œ ìƒì„± ì¤‘...\")\n",
    "                \n",
    "                # ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• \n",
    "                from langchain_community.document_loaders import DirectoryLoader\n",
    "                from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "                from langchain_community.retrievers import BM25Retriever\n",
    "                \n",
    "                data_dir = Path(\"./data\")\n",
    "                md_files = list(data_dir.glob(\"*.md\"))\n",
    "                \n",
    "                if md_files:\n",
    "                    # ë¬¸ì„œ ë¡œë“œ\n",
    "                    docs = []\n",
    "                    for file_path in md_files:\n",
    "                        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                            content = f.read()\n",
    "                        docs.append({\n",
    "                            \"page_content\": content,\n",
    "                            \"metadata\": {\"source\": str(file_path)}\n",
    "                        })\n",
    "                    \n",
    "                    # í…ìŠ¤íŠ¸ ë¶„í• \n",
    "                    text_splitter = RecursiveCharacterTextSplitter(\n",
    "                        chunk_size=500,\n",
    "                        chunk_overlap=100,\n",
    "                        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "                    )\n",
    "                    \n",
    "                    class Document:\n",
    "                        def __init__(self, page_content, metadata):\n",
    "                            self.page_content = page_content\n",
    "                            self.metadata = metadata\n",
    "                    \n",
    "                    split_docs = []\n",
    "                    for doc_data in docs:\n",
    "                        doc = Document(doc_data[\"page_content\"], doc_data[\"metadata\"])\n",
    "                        chunks = text_splitter.split_documents([doc])\n",
    "                        split_docs.extend(chunks)\n",
    "                    \n",
    "                    # BM25 ìƒì„±\n",
    "                    bm25_retriever = BM25Retriever.from_documents(split_docs)\n",
    "                    bm25_retriever.k = 5\n",
    "                    \n",
    "                    # ìºì‹œ ì €ì¥\n",
    "                    os.makedirs(\"./cache\", exist_ok=True)\n",
    "                    with open(bm25_cache_path, 'wb') as f:\n",
    "                        pickle.dump(bm25_retriever, f)\n",
    "                    \n",
    "                    print(\"âœ… bm25_retriever ìƒì„± ë° ìºì‹œ ì €ì¥ ì™„ë£Œ\")\n",
    "                else:\n",
    "                    print(\"âŒ ./data í´ë”ì— .md íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "                    bm25_retriever = None\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ bm25_retriever ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "            bm25_retriever = None\n",
    "        \n",
    "        # 3. Hybrid retriever ìƒì„±\n",
    "        if semantic_retriever and bm25_retriever:\n",
    "            try:\n",
    "                from langchain.retrievers import EnsembleRetriever\n",
    "                \n",
    "                hybrid_retriever = EnsembleRetriever(\n",
    "                    retrievers=[semantic_retriever, bm25_retriever],\n",
    "                    weights=[0.7, 0.3]  # semantic: 70%, keyword: 30%\n",
    "                )\n",
    "                print(\"âœ… hybrid_retriever ìƒì„± ì™„ë£Œ\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ hybrid_retriever ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "                hybrid_retriever = semantic_retriever  # fallback\n",
    "        elif semantic_retriever:\n",
    "            hybrid_retriever = semantic_retriever\n",
    "            print(\"âš ï¸ semantic_retrieverë¥¼ hybrid_retrieverë¡œ ì‚¬ìš©\")\n",
    "        elif bm25_retriever:\n",
    "            hybrid_retriever = bm25_retriever\n",
    "            print(\"âš ï¸ bm25_retrieverë¥¼ hybrid_retrieverë¡œ ì‚¬ìš©\")\n",
    "        else:\n",
    "            print(\"âŒ ê²€ìƒ‰ê¸° ìƒì„±ì— ì™„ì „íˆ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤!\")\n",
    "            hybrid_retriever = None\n",
    "    \n",
    "    else:\n",
    "        print(\"âœ… ëª¨ë“  í•„ìˆ˜ ê²€ìƒ‰ê¸°ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "        \n",
    "        # ì‹¤ìŠµ 1ì˜ retrievers ë”•ì…”ë„ˆë¦¬ì—ì„œ ê°€ì ¸ì˜¤ê¸°\n",
    "        if 'retrievers' in locals() or 'retrievers' in globals():\n",
    "            retrievers_dict = eval('retrievers')\n",
    "            if 'hybrid' in retrievers_dict:\n",
    "                hybrid_retriever = retrievers_dict['hybrid']\n",
    "                print(\"âœ… ì‹¤ìŠµ 1ì˜ hybrid_retriever ì‚¬ìš©\")\n",
    "            elif 'semantic' in retrievers_dict:\n",
    "                hybrid_retriever = retrievers_dict['semantic']\n",
    "                print(\"âš ï¸ ì‹¤ìŠµ 1ì˜ semantic_retrieverë¥¼ hybrid_retrieverë¡œ ì‚¬ìš©\")\n",
    "        else:\n",
    "            # ë³€ìˆ˜ê°€ ì§ì ‘ ì •ì˜ë˜ì–´ ìˆëŠ” ê²½ìš°\n",
    "            if 'hybrid_retriever' not in locals() and 'hybrid_retriever' not in globals():\n",
    "                hybrid_retriever = semantic_retriever\n",
    "                print(\"âš ï¸ semantic_retrieverë¥¼ hybrid_retrieverë¡œ ì‚¬ìš©\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ê²€ìƒ‰ê¸° í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    # ìµœì†Œí•œì˜ ê²€ìƒ‰ê¸°ë¼ë„ ì„¤ì •\n",
    "    try:\n",
    "        hybrid_retriever = chroma_db.as_retriever(search_kwargs={\"k\": 5})\n",
    "        print(\"âœ… ChromaDBë¥¼ ê¸°ë³¸ ê²€ìƒ‰ê¸°ë¡œ ì‚¬ìš©\")\n",
    "    except:\n",
    "        print(\"âŒ ëª¨ë“  ê²€ìƒ‰ê¸° ì„¤ì • ì‹¤íŒ¨\")\n",
    "        hybrid_retriever = None\n",
    "\n",
    "# ê²€ìƒ‰ê¸°ê°€ ì¤€ë¹„ë˜ì—ˆëŠ”ì§€ ìµœì¢… í™•ì¸\n",
    "if hybrid_retriever is None:\n",
    "    print(\"âŒ ì‹¤ìŠµ 2ë¥¼ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²€ìƒ‰ê¸°ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "    print(\"ğŸ’¡ ì‹¤ìŠµ 1ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
    "else:\n",
    "    print(f\"âœ… ì‹¤ìŠµ 2 ì¤€ë¹„ ì™„ë£Œ! ì‚¬ìš© ê²€ìƒ‰ê¸°: {type(hybrid_retriever).__name__}\")\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "print(\"\\nğŸ”§ ê³ ë„í™” ê¸°ë²• êµ¬ì„± ì‹œì‘...\")\n",
    "\n",
    "# 1) LLM Reranker ì„¤ì •\n",
    "print(\"1ï¸âƒ£ LLM Reranker ì„¤ì •...\")\n",
    "llm_reranker = LLMListwiseRerank.from_llm(llm, top_n=3)\n",
    "\n",
    "# 2) LLM Chain Extractor ì„¤ì • (ë§¥ë½ ì••ì¶•)\n",
    "print(\"2ï¸âƒ£ LLM Chain Extractor ì„¤ì •...\")\n",
    "llm_extractor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "# 3) Embeddings Filter ì„¤ì • (ìœ ì‚¬ë„ ê¸°ë°˜ í•„í„°ë§)\n",
    "print(\"3ï¸âƒ£ Embeddings Filter ì„¤ì •...\")\n",
    "embeddings_filter = EmbeddingsFilter(\n",
    "    embeddings=embeddings, \n",
    "    similarity_threshold=0.5\n",
    ")\n",
    "\n",
    "# 4) Redundant Filter ì„¤ì • (ì¤‘ë³µ ì œê±°)\n",
    "print(\"4ï¸âƒ£ Redundant Filter ì„¤ì •...\")\n",
    "redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)\n",
    "\n",
    "# 5) Pipeline Compressor êµ¬ì„±\n",
    "print(\"5ï¸âƒ£ Pipeline Compressor êµ¬ì„±...\")\n",
    "# ìˆœì„œ: ì¤‘ë³µì œê±° -> ìœ ì‚¬ë„ í•„í„°ë§ -> ë§¥ë½ ì••ì¶• -> ì¬ìˆœìœ„í™”\n",
    "pipeline_compressor = DocumentCompressorPipeline(\n",
    "    transformers=[\n",
    "        redundant_filter,      # 1ë‹¨ê³„: ì¤‘ë³µ ë¬¸ì„œ ì œê±°\n",
    "        embeddings_filter,     # 2ë‹¨ê³„: ìœ ì‚¬ë„ ê¸°ë°˜ í•„í„°ë§\n",
    "        llm_extractor,         # 3ë‹¨ê³„: ê´€ë ¨ ë‚´ìš©ë§Œ ì¶”ì¶œ\n",
    "        llm_reranker          # 4ë‹¨ê³„: ìµœì¢… ì¬ìˆœìœ„í™”\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 6) ìµœì¢… ê³ ë„í™”ëœ ê²€ìƒ‰ê¸° êµ¬ì„±\n",
    "if hybrid_retriever is not None:\n",
    "    print(\"6ï¸âƒ£ ê³ ë„í™”ëœ ê²€ìƒ‰ê¸° êµ¬ì„±...\")\n",
    "    advanced_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=pipeline_compressor,\n",
    "        base_retriever=hybrid_retriever  # ì¤€ë¹„ëœ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ì‚¬ìš©\n",
    "    )\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ë° ê²°ê³¼ ë¹„êµ\n",
    "    test_queries = [\n",
    "        \"í…ŒìŠ¬ë¼ íŠ¸ëŸ­ ëª¨ë¸ì´ ìˆë‚˜ìš”?\",\n",
    "        \"ë¦¬ë¹„ì•ˆì˜ ì „ê¸° íŠ¸ëŸ­ íŠ¹ì§•ì€?\",\n",
    "        \"í…ŒìŠ¬ë¼ì™€ ë¦¬ë¹„ì•ˆì˜ ì°¨ì´ì ì€?\"\n",
    "    ]\n",
    "\n",
    "    print(f\"\\nğŸ¯ ê³ ë„í™” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹œì‘ (ì´ {len(test_queries)}ê°œ ì¿¼ë¦¬)\")\n",
    "\n",
    "    for i, query in enumerate(test_queries, 1):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ğŸ” ì¿¼ë¦¬ {i}: {query}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        try:\n",
    "            # ê¸°ë³¸ ê²€ìƒ‰ ê²°ê³¼\n",
    "            print(\"\\n--- ê¸°ë³¸ ê²€ìƒ‰ ê²°ê³¼ ---\")\n",
    "            basic_docs = hybrid_retriever.invoke(query)\n",
    "            print(f\"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(basic_docs)}\")\n",
    "            for j, doc in enumerate(basic_docs[:2], 1):\n",
    "                print(f\"{j}. {doc.page_content[:150]}...\")\n",
    "            \n",
    "            # ê³ ë„í™”ëœ ê²€ìƒ‰ ê²°ê³¼\n",
    "            print(\"\\n--- ê³ ë„í™”ëœ ê²€ìƒ‰ ê²°ê³¼ (Pipeline) ---\")\n",
    "            advanced_docs = advanced_retriever.invoke(query, config={\"callbacks\": [langfuse_handler]})\n",
    "            print(f\"ìµœì¢… ë¬¸ì„œ ìˆ˜: {len(advanced_docs)}\")\n",
    "            for j, doc in enumerate(advanced_docs, 1):\n",
    "                print(f\"{j}. {doc.page_content}\")\n",
    "                print(f\"   [ì¶œì²˜: {doc.metadata['source']}]\")\n",
    "                print()\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì¿¼ë¦¬ '{query}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"\\nğŸ¯ Pipeline êµ¬ì„±:\")\n",
    "    print(\"1. ì¤‘ë³µ ì œê±° (EmbeddingsRedundantFilter)\")\n",
    "    print(\"2. ìœ ì‚¬ë„ í•„í„°ë§ (EmbeddingsFilter, threshold=0.5)\")  \n",
    "    print(\"3. ë§¥ë½ ì••ì¶• (LLMChainExtractor)\")\n",
    "    print(\"4. ì¬ìˆœìœ„í™” (LLMListwiseRerank, top_n=3)\")\n",
    "    \n",
    "    print(f\"\\nâœ… ì‹¤ìŠµ 2 ì™„ë£Œ!\")\n",
    "    print(f\"ğŸ“Š ì‚¬ìš©ëœ ê²€ìƒ‰ê¸°: {type(hybrid_retriever).__name__}\")\n",
    "    print(f\"ğŸ”§ ì ìš©ëœ ê¸°ë²•: 4ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì••ì¶• + ì¬ìˆœìœ„í™”\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ ì‹¤ìŠµ 2ë¥¼ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ê²€ìƒ‰ê¸°ê°€ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ’¡ ì‹¤ìŠµ 1ì„ ë¨¼ì € ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) RAG ì²´ì¸ ì—°ê²°`\n",
    "\n",
    "- ê²€ìƒ‰ê¸°, í”„ë¡¬í”„íŠ¸, LLMì„ LCELë¡œ ì—°ê²°í•˜ì—¬ RAG Chainì„ êµ¬ì„±í•©ë‹ˆë‹¤. \n",
    "- ë‹¤ì–‘í•œ ì¿¼ë¦¬ë¥¼ ì…ë ¥í•˜ê³ , ìƒì„±ëœ ë‹µë³€ì˜ í’ˆì§ˆì„ í‰ê°€í•©ë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš— RAG ì²´ì¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n",
      "================================================================================\n",
      "\n",
      "ì§ˆë¬¸ 1: í…ŒìŠ¬ë¼ Cybertruckì˜ íŠ¹ì§•ê³¼ ì¶œì‹œë…„ë„ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”\n",
      "------------------------------------------------------------\n",
      "ë‹µë³€: í…ŒìŠ¬ë¼ Cybertruckì€ 2019ë…„ 11ì›”ì— ì²˜ìŒ ë°œí‘œëœ í’€ì‚¬ì´ì¦ˆ í”½ì—… íŠ¸ëŸ­ì…ë‹ˆë‹¤. ì´ ì°¨ëŸ‰ì€ í›„ë¥œ êµ¬ë™, ë“€ì–¼ ëª¨í„° ì „ë¥œ êµ¬ë™, íŠ¸ë¦¬ ëª¨í„° ì „ë¥œ êµ¬ë™ì˜ ì„¸ ê°€ì§€ ëª¨ë¸ë¡œ ì œê³µë©ë‹ˆë‹¤. Cybertruckì˜ ë°°ì†¡ì€ 2023ë…„ 11ì›”ì— ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. (ì¶œì²˜: ë¬¸ì„œ 1, ë¬¸ì„œ 2, ë¬¸ì„œ 3)\n",
      "ğŸ“Š ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 3\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ì§ˆë¬¸ 2: ë¦¬ë¹„ì•ˆ R1Tì™€ í…ŒìŠ¬ë¼ Cybertruckì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "------------------------------------------------------------\n",
      "ë‹µë³€: ì œê³µëœ ë¬¸ì„œì—ì„œëŠ” ë¦¬ë¹„ì•ˆ R1Tì— ëŒ€í•œ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ, ë¦¬ë¹„ì•ˆ R1Tì™€ í…ŒìŠ¬ë¼ Cybertruckì˜ ì°¨ì´ì ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ë¹„êµë¥¼ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ í…ŒìŠ¬ë¼ Cybertruckì— ëŒ€í•œ ì •ë³´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "- **ëª¨ë¸ëª…:** Cybertruck\n",
      "- **ë°œí‘œ ì—°ë„:** 2019ë…„ 11ì›”\n",
      "- **ëª¨ë¸ ì‚¬ì–‘:** í›„ë¥œ êµ¬ë™, ë“€ì–¼ ëª¨í„° ì „ë¥œ êµ¬ë™, íŠ¸ë¦¬ ëª¨í„° ì „ë¥œ êµ¬ë™ì˜ ì„¸ ê°€ì§€ ëª¨ë¸ì´ ì œê³µë©ë‹ˆë‹¤.\n",
      "- **ë°°ì†¡ ì‹œì‘:** 2023ë…„ 11ì›”ì— Cybertruck ë°°ì†¡ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì œê³µëœ ë¬¸ì„œì—ì„œëŠ” ë¦¬ë¹„ì•ˆ R1Tì— ëŒ€í•œ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ, í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md)\n",
      "ğŸ“Š ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 2\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ì§ˆë¬¸ 3: í…ŒìŠ¬ë¼ì—ì„œ ìƒì‚°í•˜ëŠ” íŠ¸ëŸ­ ëª¨ë¸ë“¤ì„ ëª¨ë‘ ë‚˜ì—´í•´ì£¼ì„¸ìš”\n",
      "------------------------------------------------------------\n",
      "ë‹µë³€: í…ŒìŠ¬ë¼ì—ì„œ ìƒì‚°í•˜ëŠ” íŠ¸ëŸ­ ëª¨ë¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **Cybertruck**\n",
      "   - ë°œí‘œ ì—°ë„: 2019ë…„\n",
      "   - ëª¨ë¸ ì‚¬ì–‘: í›„ë¥œ êµ¬ë™, ë“€ì–¼ ëª¨í„° ì „ë¥œ êµ¬ë™, íŠ¸ë¦¬ ëª¨í„° ì „ë¥œ êµ¬ë™ì˜ ì„¸ ê°€ì§€ ëª¨ë¸ ì œê³µ\n",
      "\n",
      "2. **Semi**\n",
      "   - ìƒì‚° ì—°ë„: 2022ë…„\n",
      "\n",
      "3. **Cybertruck**\n",
      "   - ìƒì‚° ì—°ë„: 2023ë…„\n",
      "\n",
      "ì¶œì²˜: ë¬¸ì„œ 1 [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md], ë¬¸ì„œ 2 [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "ğŸ“Š ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 2\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ì§ˆë¬¸ 4: ì „ê¸° í”½ì—…íŠ¸ëŸ­ ì¤‘ì—ì„œ ì–´ë–¤ ëª¨ë¸ì„ ì¶”ì²œí•˜ì‹œë‚˜ìš”?\n",
      "------------------------------------------------------------\n",
      "ë‹µë³€: ì œê³µëœ ë¬¸ì„œì—ì„œëŠ” ì „ê¸° í”½ì—…íŠ¸ëŸ­ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ëª¨ë¸ëª…ì´ë‚˜ ì‚¬ì–‘ì— ëŒ€í•œ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì¶”ì²œí•  ìˆ˜ ìˆëŠ” ì „ê¸° í”½ì—…íŠ¸ëŸ­ ëª¨ë¸ì— ëŒ€í•œ ì •ë³´ëŠ” ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n",
      "ğŸ“Š ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 0\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ì§ˆë¬¸ 5: í…ŒìŠ¬ë¼ Model Sì˜ ì œì¡°ë…„ë„ì™€ ì¢Œì„ ìˆ˜ëŠ”?\n",
      "------------------------------------------------------------\n",
      "ë‹µë³€: í…ŒìŠ¬ë¼ Model Sì˜ ì œì¡°ë…„ë„ëŠ” 2012ë…„ì´ë©°, ì¢Œì„ ìˆ˜ëŠ” 5/7ì…ë‹ˆë‹¤. (ì¶œì²˜: ë¬¸ì„œ 1, ë¬¸ì„œ 2, ë¬¸ì„œ 3)\n",
      "ğŸ“Š ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 3\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ì§ˆë¬¸ 6: 2025ë…„ì— ì¶œì‹œ ì˜ˆì •ì¸ í…ŒìŠ¬ë¼ ëª¨ë¸ì´ ìˆë‚˜ìš”?\n",
      "------------------------------------------------------------\n",
      "ë‹µë³€: 2025ë…„ì— ì¶œì‹œ ì˜ˆì •ì¸ í…ŒìŠ¬ë¼ ëª¨ë¸ì€ **Roadster (2ì„¸ëŒ€)**ì…ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ 620ë§ˆì¼(1,000km)ì˜ ì£¼í–‰ ê±°ë¦¬ì™€ ê³ ì„±ëŠ¥ ì‚¬ì–‘ì„ ê°–ì¶”ê³  ìˆìœ¼ë©°, 2017ë…„ì— ê³µê°œë˜ì—ˆìŠµë‹ˆë‹¤. ì¶œì²˜: ë¬¸ì„œ 1 [ì¶œì²˜: data\\í…ŒìŠ¬ë¼_KR.md]\n",
      "ğŸ“Š ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 2\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ˆ RAG ì‹œìŠ¤í…œ êµ¬ì„± ìš”ì•½:\n",
      "â”œâ”€â”€ ê²€ìƒ‰ê¸°: Hybrid (Semantic + BM25) + MultiQuery\n",
      "â”œâ”€â”€ ê³ ë„í™”: Pipeline (ì¤‘ë³µì œê±° â†’ ìœ ì‚¬ë„í•„í„° â†’ ì••ì¶• â†’ ì¬ìˆœìœ„)\n",
      "â”œâ”€â”€ í”„ë¡¬í”„íŠ¸: ì „ê¸°ì°¨ ì „ë¬¸ê°€ ì—­í•  + ëª…í™•í•œ ê°€ì´ë“œë¼ì¸\n",
      "â”œâ”€â”€ LLM: GPT-4o-mini (temperature=0.1)\n",
      "â””â”€â”€ ì¶”ì : Langfuse ì½œë°±ìœ¼ë¡œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§\n",
      "\n",
      "ğŸ” ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸:\n",
      "\n",
      "ì§ˆë¬¸: í…ŒìŠ¬ë¼ íŠ¸ëŸ­ ëª¨ë¸ì´ ìˆë‚˜ìš”?\n",
      "\n",
      "--- ê¸°ë³¸ RAG ê²°ê³¼ ---\n",
      "í…ŒìŠ¬ë¼ì˜ íŠ¸ëŸ­ ëª¨ë¸ì€ **Cybertruck**ì…ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ 2019ë…„ 11ì›”ì— ì²˜ìŒ ë°œí‘œëœ í’€ì‚¬ì´ì¦ˆ í”½ì—… íŠ¸ëŸ­ìœ¼ë¡œ, í›„ë¥œ êµ¬ë™, ë“€ì–¼ ëª¨í„° ì „ë¥œ êµ¬ë™, íŠ¸ë¦¬ ëª¨í„° ì „ë¥œ êµ¬ë™ì˜ ì„¸ ê°€ì§€ ëª¨ë¸ì´ ì œê³µë©ë‹ˆë‹¤. Cybertruckì˜ ì¶œì‹œ ì—°ë„ëŠ” 2023ë…„ì…ë‹ˆë‹¤. \n",
      "\n",
      "ì¶œì²˜: ë¬¸ì„œ 1, ë¬¸ì„œ 2.\n",
      "\n",
      "--- ê³ ë„í™”ëœ RAG ê²°ê³¼ ---\n",
      "í…ŒìŠ¬ë¼ì˜ íŠ¸ëŸ­ ëª¨ë¸ë¡œëŠ” **Cybertruck**ê°€ ìˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì€ 2019ë…„ 11ì›”ì— ì²˜ìŒ ë°œí‘œë˜ì—ˆìœ¼ë©°, í›„ë¥œ êµ¬ë™, ë“€ì–¼ ëª¨í„° ì „ë¥œ êµ¬ë™, íŠ¸ë¦¬ ëª¨í„° ì „ë¥œ êµ¬ë™ì˜ ì„¸ ê°€ì§€ ëª¨ë¸ì´ ì œê³µë©ë‹ˆë‹¤. Cybertruckì˜ ì¶œì‹œ ì—°ë„ëŠ” 2023ë…„ìœ¼ë¡œ ì˜ˆì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. (ì¶œì²˜: ë¬¸ì„œ 1, ë¬¸ì„œ 2)\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤ìŠµ 3: RAG ì²´ì¸ ì—°ê²° (LCEL ì‚¬ìš©)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1) í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "rag_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "ë‹¹ì‹ ì€ ì „ê¸°ì°¨ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ê²€ìƒ‰ëœ ë¬¸ì„œ:\n",
    "{context}\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "\n",
    "ë‹µë³€ ê°€ì´ë“œë¼ì¸:\n",
    "1. ë¬¸ì„œì— ìˆëŠ” ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”\n",
    "2. ì •í™•í•œ ëª¨ë¸ëª…, ì—°ë„, ì‚¬ì–‘ ë“±ì„ í¬í•¨í•˜ì„¸ìš”  \n",
    "3. ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš”\n",
    "4. ë¬¸ì„œì— ì •ë³´ê°€ ì—†ë‹¤ë©´ \"ì œê³µëœ ë¬¸ì„œì—ì„œëŠ” í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”\n",
    "\n",
    "ë‹µë³€:\n",
    "\"\"\")\n",
    "\n",
    "# 2) LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "# 3) ë¬¸ì„œ í¬ë§·íŒ… í•¨ìˆ˜\n",
    "def format_docs(docs):\n",
    "    formatted_docs = []\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        source = doc.metadata.get('source', 'Unknown')\n",
    "        content = doc.page_content.strip()\n",
    "        formatted_docs.append(f\"ë¬¸ì„œ {i} [ì¶œì²˜: {source}]:\\n{content}\")\n",
    "    return \"\\n\\n\" + \"\\n\\n\".join(formatted_docs)\n",
    "\n",
    "# 4) RAG ì²´ì¸ êµ¬ì„± (LCEL)\n",
    "rag_chain = (\n",
    "    RunnableParallel({\n",
    "        \"context\": advanced_retriever | format_docs,  # ì‹¤ìŠµ2ì˜ ê³ ë„í™”ëœ ê²€ìƒ‰ê¸° ì‚¬ìš©\n",
    "        \"question\": RunnablePassthrough()\n",
    "    })\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 5) ë‹¤ì–‘í•œ ì¿¼ë¦¬ë¡œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n",
    "test_questions = [\n",
    "    \"í…ŒìŠ¬ë¼ Cybertruckì˜ íŠ¹ì§•ê³¼ ì¶œì‹œë…„ë„ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
    "    \"ë¦¬ë¹„ì•ˆ R1Tì™€ í…ŒìŠ¬ë¼ Cybertruckì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"í…ŒìŠ¬ë¼ì—ì„œ ìƒì‚°í•˜ëŠ” íŠ¸ëŸ­ ëª¨ë¸ë“¤ì„ ëª¨ë‘ ë‚˜ì—´í•´ì£¼ì„¸ìš”\",\n",
    "    \"ì „ê¸° í”½ì—…íŠ¸ëŸ­ ì¤‘ì—ì„œ ì–´ë–¤ ëª¨ë¸ì„ ì¶”ì²œí•˜ì‹œë‚˜ìš”?\",\n",
    "    \"í…ŒìŠ¬ë¼ Model Sì˜ ì œì¡°ë…„ë„ì™€ ì¢Œì„ ìˆ˜ëŠ”?\",\n",
    "    \"2025ë…„ì— ì¶œì‹œ ì˜ˆì •ì¸ í…ŒìŠ¬ë¼ ëª¨ë¸ì´ ìˆë‚˜ìš”?\"\n",
    "]\n",
    "\n",
    "print(\"ğŸš— RAG ì²´ì¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\nì§ˆë¬¸ {i}: {question}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # RAG ì²´ì¸ ì‹¤í–‰\n",
    "        answer = rag_chain.invoke(question, config={\"callbacks\": [langfuse_handler]})\n",
    "        print(f\"ë‹µë³€: {answer}\")\n",
    "        \n",
    "        # ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜ í™•ì¸\n",
    "        retrieved_docs = advanced_retriever.invoke(question)\n",
    "        print(f\"ğŸ“Š ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(retrieved_docs)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# 6) ì„±ëŠ¥ í‰ê°€ ë©”íŠ¸ë¦­\n",
    "print(\"\\nğŸ“ˆ RAG ì‹œìŠ¤í…œ êµ¬ì„± ìš”ì•½:\")\n",
    "print(\"â”œâ”€â”€ ê²€ìƒ‰ê¸°: Hybrid (Semantic + BM25) + MultiQuery\")\n",
    "print(\"â”œâ”€â”€ ê³ ë„í™”: Pipeline (ì¤‘ë³µì œê±° â†’ ìœ ì‚¬ë„í•„í„° â†’ ì••ì¶• â†’ ì¬ìˆœìœ„)\")\n",
    "print(\"â”œâ”€â”€ í”„ë¡¬í”„íŠ¸: ì „ê¸°ì°¨ ì „ë¬¸ê°€ ì—­í•  + ëª…í™•í•œ ê°€ì´ë“œë¼ì¸\")\n",
    "print(\"â”œâ”€â”€ LLM: GPT-4o-mini (temperature=0.1)\")\n",
    "print(\"â””â”€â”€ ì¶”ì : Langfuse ì½œë°±ìœ¼ë¡œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§\")\n",
    "\n",
    "# 7) ê°„ë‹¨í•œ ì„±ëŠ¥ ë¹„êµ (ê¸°ë³¸ vs ê³ ë„í™”)\n",
    "print(\"\\nğŸ” ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸:\")\n",
    "comparison_query = \"í…ŒìŠ¬ë¼ íŠ¸ëŸ­ ëª¨ë¸ì´ ìˆë‚˜ìš”?\"\n",
    "\n",
    "# ê¸°ë³¸ ê²€ìƒ‰ê¸°ë¡œ RAG\n",
    "basic_rag_chain = (\n",
    "    RunnableParallel({\n",
    "        \"context\": semantic_retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    })\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(f\"\\nì§ˆë¬¸: {comparison_query}\")\n",
    "print(\"\\n--- ê¸°ë³¸ RAG ê²°ê³¼ ---\")\n",
    "basic_answer = basic_rag_chain.invoke(comparison_query)\n",
    "print(basic_answer)\n",
    "\n",
    "print(\"\\n--- ê³ ë„í™”ëœ RAG ê²°ê³¼ ---\")\n",
    "advanced_answer = rag_chain.invoke(comparison_query)\n",
    "print(advanced_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
