{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  검색 성능 향상을 위한 기법 \n",
    "\n",
    "- 재순위화 (Re-rank)\n",
    "- 맥락 압축  (Contextural Compression)\n",
    "\n",
    "### **학습 목표:** 재순위화(Re-rank) 기법, 맥락 압축(Contextual Compression) 기법을 활용하여 최종 검색 시스템을 구축한다\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정 및 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) langfuase handler 설정`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# LangChain 콜백 핸들러 생성\n",
    "langfuse_handler = CallbackHandler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) 벡터스토어 로드`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 저장소 로드 \n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "chroma_db = Chroma(\n",
    "    collection_name=\"db_korean_cosine_metadata\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(5) 백터 검색기 생성`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "- **Cybertruck:** 2019년 11월에 처음 발표된 풀사이즈 픽업 트럭. 후륜 구동, 듀얼 모터 전륜 구동, 트리 모터 전륜 구동의 세 가지 모델이 제공됩니다. [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "| Tesla 모델 |          |       |                  |\n",
      "| :--------- | :------- | :---- | :--------------- |\n",
      "| 이름       | 제조년도 | 좌석  | 참고             |\n",
      "| Roadster   | 2008     | 2     | 2012년에 단종    |\n",
      "| Model S    | 2012     | 5/7   |                  |\n",
      "| Model X    | 2015     | 5/6/7 |                  |\n",
      "| Model 3    | 2017     | 5     |                  |\n",
      "| Model Y    | 2020     | 5/7   |                  |\n",
      "| Semi       | 2022     | 2     |                  |\n",
      "| Cybertruck | 2023     | 5     |                  |\n",
      "| Roadster 2 |          | 2/4   | 2025년 출시 예정 |\n",
      "| Cybercab   |          | 2     | 2026년 출시 예정 |\n",
      "| Robovan    |          | 20    | 명시된 기간 없음 |\n",
      "\n",
      "### 사용 가능한 제품 [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "- **Model 3:** 패스트백 차체 스타일과 듀얼 모터, 전륜 구동 레이아웃 또는 후륜 모터, 후륜 구동 레이아웃을 갖춘 중형차. 이 차량은 고급 Model S 세단보다 저렴하도록 설계되었습니다. Model 3 프로토타입은 2016년에 처음 공개되었으며 일주일 만에 325,000건 이상의 유료 예약이 접수되었습니다. [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "- **Model S:** 리프트백 차체 스타일과 듀얼 모터, 전륜 구동 레이아웃을 갖춘 풀사이즈 고급차. Model S 개발은 2007년 이전에 시작되었으며 배송은 2012년 6월에 시작되었습니다.\n",
      "- **Model X:** 듀얼 모터 또는 트리 모터, 전륜 구동 레이아웃을 갖춘 5인승, 6인승 및 7인승 구성으로 제공되는 중형 고급 크로스오버 SUV. 뒷좌석 승객 문은 관절형 \"팔콘 윙\" 디자인으로 수직으로 열립니다. Model X 프로토타입은 2012년 2월에 처음 공개되었으며 배송은 2015년 9월에 시작되었습니다. [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "- **Model Y:** 싱글 모터, 후륜 구동 또는 듀얼 모터, 전륜 구동 레이아웃을 갖춘 5인승 및 7인승 구성으로 제공되는 중형 크로스오버 SUV. 이 차량은 고급 Model X SUV보다 저렴하도록 설계되었습니다. Model Y 프로토타입은 2019년 3월에 처음 공개되었으며 배송은 2020년 3월에 시작되었습니다.\n",
      "- **Tesla Semi:** Tesla Semi는 Tesla, Inc.의 클래스 8 세미 트럭으로, 트리 모터, 후륜 구동 레이아웃을 갖추고 있습니다. Tesla는 Semi가 일반적인 디젤 세미 트럭보다 약 3배 더 강력하고 주행 거리가 500마일(800km)이라고 주장합니다. 초기 배송은 2022년 12월 1일에 PepsiCo에 이루어졌습니다. [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 기본 retriever 초기화\n",
    "chroma_k_retriever = chroma_db.as_retriever(\n",
    "    search_kwargs={\"k\": 5}\n",
    ")\n",
    "\n",
    "query = \"테슬라 트럭 모델이 있나요?\"\n",
    "retrieved_docs = chroma_k_retriever.invoke(query, config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Re-rank** (재순위화)\n",
    "\n",
    "- **재순위화**는 검색 결과를 재분석하여 최적의 순서로 정렬하는 고도화된 기술임\n",
    "\n",
    "- **이중 단계 프로세스**로 기본 검색 후 정교한 기준으로 재평가를 진행함\n",
    "    1. 먼저 기본 검색 알고리즘으로 관련 문서들을 찾은 후, \n",
    "    2. 더 정교한 기준으로 이들을 재평가하여 최종 순위를 결정\n",
    "\n",
    "- 사용자의 검색 의도에 맞는 **정확도 향상**을 통해 검색 품질을 개선함\n",
    "\n",
    "- 검색 결과의 품질을 높이기 위한 체계적인 최적화 방법론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### 1) **Cross Encoder** Reranker\n",
    "\n",
    "- **Cross-Encoder** 모델을 활용하여 검색 결과의 정밀한 재정렬을 수행함\n",
    "- 데이터를 **쌍(pair) 단위**로 처리하여 문서와 쿼리 간의 관계를 분석함 (예: 두 개의 문장 또는 문서)\n",
    "- **통합 인코딩 방식**으로 검색 쿼리와 검색된 문서 간 유사도를 더 정확하게 계산함\n",
    "\n",
    "- 참고: https://www.sbert.net/examples/applications/cross-encoder/README.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 모델 초기화`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "# CrossEncoderReranker 모델 초기화 \n",
    "model = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-v2-m3\")\n",
    "\n",
    "# CrossEncoderReranker 모델을 사용한 re-ranker 초기화 (top_n: 3)\n",
    "re_ranker = CrossEncoderReranker(model=model, top_n=3)\n",
    "\n",
    "# CrossEncoderReranker를 사용한 retriever 초기화\n",
    "cross_encoder_reranker_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=re_ranker, \n",
    "    base_retriever=chroma_k_retriever,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 문서 검색`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "- **Cybertruck:** 2019년 11월에 처음 발표된 풀사이즈 픽업 트럭. 후륜 구동, 듀얼 모터 전륜 구동, 트리 모터 전륜 구동의 세 가지 모델이 제공됩니다. [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "- **Model Y:** 싱글 모터, 후륜 구동 또는 듀얼 모터, 전륜 구동 레이아웃을 갖춘 5인승 및 7인승 구성으로 제공되는 중형 크로스오버 SUV. 이 차량은 고급 Model X SUV보다 저렴하도록 설계되었습니다. Model Y 프로토타입은 2019년 3월에 처음 공개되었으며 배송은 2020년 3월에 시작되었습니다.\n",
      "- **Tesla Semi:** Tesla Semi는 Tesla, Inc.의 클래스 8 세미 트럭으로, 트리 모터, 후륜 구동 레이아웃을 갖추고 있습니다. Tesla는 Semi가 일반적인 디젤 세미 트럭보다 약 3배 더 강력하고 주행 거리가 500마일(800km)이라고 주장합니다. 초기 배송은 2022년 12월 1일에 PepsiCo에 이루어졌습니다. [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "| Tesla 모델 |          |       |                  |\n",
      "| :--------- | :------- | :---- | :--------------- |\n",
      "| 이름       | 제조년도 | 좌석  | 참고             |\n",
      "| Roadster   | 2008     | 2     | 2012년에 단종    |\n",
      "| Model S    | 2012     | 5/7   |                  |\n",
      "| Model X    | 2015     | 5/6/7 |                  |\n",
      "| Model 3    | 2017     | 5     |                  |\n",
      "| Model Y    | 2020     | 5/7   |                  |\n",
      "| Semi       | 2022     | 2     |                  |\n",
      "| Cybertruck | 2023     | 5     |                  |\n",
      "| Roadster 2 |          | 2/4   | 2025년 출시 예정 |\n",
      "| Cybercab   |          | 2     | 2026년 출시 예정 |\n",
      "| Robovan    |          | 20    | 명시된 기간 없음 |\n",
      "\n",
      "### 사용 가능한 제품 [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# CrossEncoderReranker를 사용한 retriever를 사용하여 검색\n",
    "query = \"테슬라 트럭 모델이 있나요?\"\n",
    "retrieved_docs = cross_encoder_reranker_retriever.invoke(query, config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) **LLM** Reranker\n",
    "\n",
    "- **대규모 언어 모델**을 활용하여 검색 결과의 재순위화를 수행함\n",
    "- 쿼리와 문서 간의 **관련성 분석**을 통해 최적의 순서를 도출함\n",
    "- **LLMListwiseRerank**와 같은 전문화된 재순위화 모델을 적용함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 모델 초기화`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMListwiseRerank\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI 모델 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# LLMListwiseRerank 모델 초기화 (top_n: 3)\n",
    "re_ranker = LLMListwiseRerank.from_llm(llm, top_n=3)\n",
    "\n",
    "# LLMListwiseRerank 모델을 사용한 re-ranker 초기화\n",
    "llm_reranker_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=re_ranker, \n",
    "    base_retriever=chroma_k_retriever,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 문서 검색`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "- **Cybertruck:** 2019년 11월에 처음 발표된 풀사이즈 픽업 트럭. 후륜 구동, 듀얼 모터 전륜 구동, 트리 모터 전륜 구동의 세 가지 모델이 제공됩니다. [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "- **Model Y:** 싱글 모터, 후륜 구동 또는 듀얼 모터, 전륜 구동 레이아웃을 갖춘 5인승 및 7인승 구성으로 제공되는 중형 크로스오버 SUV. 이 차량은 고급 Model X SUV보다 저렴하도록 설계되었습니다. Model Y 프로토타입은 2019년 3월에 처음 공개되었으며 배송은 2020년 3월에 시작되었습니다.\n",
      "- **Tesla Semi:** Tesla Semi는 Tesla, Inc.의 클래스 8 세미 트럭으로, 트리 모터, 후륜 구동 레이아웃을 갖추고 있습니다. Tesla는 Semi가 일반적인 디젤 세미 트럭보다 약 3배 더 강력하고 주행 거리가 500마일(800km)이라고 주장합니다. 초기 배송은 2022년 12월 1일에 PepsiCo에 이루어졌습니다. [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "| Tesla 모델 |          |       |                  |\n",
      "| :--------- | :------- | :---- | :--------------- |\n",
      "| 이름       | 제조년도 | 좌석  | 참고             |\n",
      "| Roadster   | 2008     | 2     | 2012년에 단종    |\n",
      "| Model S    | 2012     | 5/7   |                  |\n",
      "| Model X    | 2015     | 5/6/7 |                  |\n",
      "| Model 3    | 2017     | 5     |                  |\n",
      "| Model Y    | 2020     | 5/7   |                  |\n",
      "| Semi       | 2022     | 2     |                  |\n",
      "| Cybertruck | 2023     | 5     |                  |\n",
      "| Roadster 2 |          | 2/4   | 2025년 출시 예정 |\n",
      "| Cybercab   |          | 2     | 2026년 출시 예정 |\n",
      "| Robovan    |          | 20    | 명시된 기간 없음 |\n",
      "\n",
      "### 사용 가능한 제품 [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# LLMListwiseRerank 모델을 사용한 retriever를 사용하여 검색\n",
    "\n",
    "query = \"테슬라 트럭 모델이 있나요?\"\n",
    "retrieved_docs = llm_reranker_retriever.invoke(query, config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Contextual Compression** (맥락적 압축)\n",
    "\n",
    "- **맥락적 압축 기술**은 검색된 문서를 그대로 반환하는 대신, 쿼리 관련 정보만을 선별적으로 추출함\n",
    "\n",
    "- **이중 구조 시스템**으로 기본 검색과 문서 압축 과정을 수행함\n",
    "    1. 기본 검색기(base retriever) \n",
    "    2. 문서 압축기(Document Compressor)\n",
    "\n",
    "- **효율적인 처리**를 통해 LLM 비용 절감과 응답 품질 향상을 달성함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) **LLMChainFilter**\n",
    "\n",
    "- **LLM 기반 필터링**으로 검색된 문서의 포함 여부를 결정함\n",
    "- **원본 유지 방식**으로 문서 내용의 변경 없이 선별 작업을 수행함\n",
    "- **선택적 필터링**을 통해 관련성 높은 문서만을 최종 반환함\n",
    "- 문서 원본을 보존하면서 관련성 기반의 스마트한 선별을 수행하는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 모델 초기화`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainFilter\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI 모델 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# LLMChainFilter 모델 초기화\n",
    "context_filter = LLMChainFilter.from_llm(llm)\n",
    "\n",
    "# LLMChainFilter 모델을 사용한 retriever 초기화\n",
    "llm_filter_compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=context_filter,                   # LLM 기반 압축기\n",
    "    base_retriever=chroma_k_retriever,               # 기본 검색기 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 문서 검색`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "- **Cybertruck:** 2019년 11월에 처음 발표된 풀사이즈 픽업 트럭. 후륜 구동, 듀얼 모터 전륜 구동, 트리 모터 전륜 구동의 세 가지 모델이 제공됩니다. [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "| Tesla 모델 |          |       |                  |\n",
      "| :--------- | :------- | :---- | :--------------- |\n",
      "| 이름       | 제조년도 | 좌석  | 참고             |\n",
      "| Roadster   | 2008     | 2     | 2012년에 단종    |\n",
      "| Model S    | 2012     | 5/7   |                  |\n",
      "| Model X    | 2015     | 5/6/7 |                  |\n",
      "| Model 3    | 2017     | 5     |                  |\n",
      "| Model Y    | 2020     | 5/7   |                  |\n",
      "| Semi       | 2022     | 2     |                  |\n",
      "| Cybertruck | 2023     | 5     |                  |\n",
      "| Roadster 2 |          | 2/4   | 2025년 출시 예정 |\n",
      "| Cybercab   |          | 2     | 2026년 출시 예정 |\n",
      "| Robovan    |          | 20    | 명시된 기간 없음 |\n",
      "\n",
      "### 사용 가능한 제품 [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "- **Model Y:** 싱글 모터, 후륜 구동 또는 듀얼 모터, 전륜 구동 레이아웃을 갖춘 5인승 및 7인승 구성으로 제공되는 중형 크로스오버 SUV. 이 차량은 고급 Model X SUV보다 저렴하도록 설계되었습니다. Model Y 프로토타입은 2019년 3월에 처음 공개되었으며 배송은 2020년 3월에 시작되었습니다.\n",
      "- **Tesla Semi:** Tesla Semi는 Tesla, Inc.의 클래스 8 세미 트럭으로, 트리 모터, 후륜 구동 레이아웃을 갖추고 있습니다. Tesla는 Semi가 일반적인 디젤 세미 트럭보다 약 3배 더 강력하고 주행 거리가 500마일(800km)이라고 주장합니다. 초기 배송은 2022년 12월 1일에 PepsiCo에 이루어졌습니다. [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# LLMListwiseRerank 모델을 사용한 retriever를 사용하여 검색\n",
    "\n",
    "query = \"테슬라 트럭 모델이 있나요?\"\n",
    "compressed_docs = llm_filter_compression_retriever.invoke(query, config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "\n",
    "for doc in compressed_docs:\n",
    "    print(f\"{doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) **LLMChainExtractor**\n",
    "\n",
    "- **LLM 기반 추출**로 문서에서 쿼리 관련 핵심 내용만을 선별함\n",
    "- **순차적 처리 방식**으로 각 문서를 검토하여 관련 정보를 추출함\n",
    "- **맞춤형 요약**을 통해 쿼리에 최적화된 압축 결과를 생성함\n",
    "- 쿼리 맥락에 따른 선별적 정보 추출로 효율적인 문서 압축을 실현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 모델 초기화`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI 모델 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# LLMChainExtractor 모델 초기화\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "# LLMChainExtractor 모델을 사용한 retriever 초기화\n",
    "llm_extractor_compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,                                    # LLM 기반 압축기\n",
    "    base_retriever=cross_encoder_reranker_retriever,               # 기본 검색기 (Re-rank)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 문서 검색`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Cybertruck:** 2019년 11월에 처음 발표된 풀사이즈 픽업 트럭. 후륜 구동, 듀얼 모터 전륜 구동, 트리 모터 전륜 구동의 세 가지 모델이 제공됩니다. [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "- **Tesla Semi:** Tesla Semi는 Tesla, Inc.의 클래스 8 세미 트럭으로, 트리 모터, 후륜 구동 레이아웃을 갖추고 있습니다. Tesla는 Semi가 일반적인 디젤 세미 트럭보다 약 3배 더 강력하고 주행 거리가 500마일(800km)이라고 주장합니다. 초기 배송은 2022년 12월 1일에 PepsiCo에 이루어졌습니다. [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "| Tesla 모델 |          |       |                  |\n",
      "| :--------- | :------- | :---- | :--------------- |\n",
      "| Semi       | 2022     | 2     |                  |\n",
      "| Cybertruck | 2023     | 5     |                  |\n",
      "| Cybercab   |          | 2     | 2026년 출시 예정 | [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# LLMChainExtractor 모델을 사용한 retriever를 사용하여 검색\n",
    "\n",
    "query = \"테슬라 트럭 모델이 있나요?\"\n",
    "compressed_docs = llm_extractor_compression_retriever.invoke(query, config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "\n",
    "for doc in compressed_docs:\n",
    "    print(f\"{doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) **EmbeddingsFilter**\n",
    "\n",
    "- **임베딩 기반 필터링**으로 문서와 쿼리 간 유사도를 계산함\n",
    "- **LLM 미사용 방식**으로 빠른 처리 속도와 비용 효율성을 확보함 (LLM 호출보다 저렴하고 빠른 옵션)\n",
    "- **유사도 기준 선별**을 통해 관련성 높은 문서만을 효과적으로 추출함\n",
    "- 경제적이고 신속한 임베딩 기반의 문서 필터링 기법 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 모델 초기화`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "\n",
    "# 임베딩 기반 압축기 초기화\n",
    "embeddings_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.4)\n",
    "\n",
    "# 임베딩 기반 압축기를 사용한 retriever 초기화\n",
    "embed_filter_compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=embeddings_filter,                             # 임베딩 기반 압축기\n",
    "    base_retriever=cross_encoder_reranker_retriever,               # 기본 검색기 (Re-rank)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 문서 검색`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "- **Cybertruck:** 2019년 11월에 처음 발표된 풀사이즈 픽업 트럭. 후륜 구동, 듀얼 모터 전륜 구동, 트리 모터 전륜 구동의 세 가지 모델이 제공됩니다. [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "| Tesla 모델 |          |       |                  |\n",
      "| :--------- | :------- | :---- | :--------------- |\n",
      "| 이름       | 제조년도 | 좌석  | 참고             |\n",
      "| Roadster   | 2008     | 2     | 2012년에 단종    |\n",
      "| Model S    | 2012     | 5/7   |                  |\n",
      "| Model X    | 2015     | 5/6/7 |                  |\n",
      "| Model 3    | 2017     | 5     |                  |\n",
      "| Model Y    | 2020     | 5/7   |                  |\n",
      "| Semi       | 2022     | 2     |                  |\n",
      "| Cybertruck | 2023     | 5     |                  |\n",
      "| Roadster 2 |          | 2/4   | 2025년 출시 예정 |\n",
      "| Cybercab   |          | 2     | 2026년 출시 예정 |\n",
      "| Robovan    |          | 20    | 명시된 기간 없음 |\n",
      "\n",
      "### 사용 가능한 제품 [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "- **Model Y:** 싱글 모터, 후륜 구동 또는 듀얼 모터, 전륜 구동 레이아웃을 갖춘 5인승 및 7인승 구성으로 제공되는 중형 크로스오버 SUV. 이 차량은 고급 Model X SUV보다 저렴하도록 설계되었습니다. Model Y 프로토타입은 2019년 3월에 처음 공개되었으며 배송은 2020년 3월에 시작되었습니다.\n",
      "- **Tesla Semi:** Tesla Semi는 Tesla, Inc.의 클래스 8 세미 트럭으로, 트리 모터, 후륜 구동 레이아웃을 갖추고 있습니다. Tesla는 Semi가 일반적인 디젤 세미 트럭보다 약 3배 더 강력하고 주행 거리가 500마일(800km)이라고 주장합니다. 초기 배송은 2022년 12월 1일에 PepsiCo에 이루어졌습니다. [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "query = \"테슬라 트럭 모델이 있나요?\"\n",
    "compressed_docs = embed_filter_compression_retriever.invoke(query, config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "for doc in compressed_docs:\n",
    "    print(f\"{doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) **DocumentCompressorPipeline**\n",
    "\n",
    "- **파이프라인 구조**로 여러 압축기를 순차적으로 연결하여 처리함\n",
    "- **복합 변환 기능**으로 문서 분할 및 중복 제거 등 다양한 처리가 가능함\n",
    "- **유연한 확장성**을 통해 BaseDocumentTransformers 추가로 기능을 확장함\n",
    "- 다중 압축기를 연계하여 포괄적이고 효과적인 문서 처리를 구현하는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 모델 초기화`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "\n",
    "\n",
    "# 임베딩 기반 필터 초기화 - 중복 제거\n",
    "redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)\n",
    "\n",
    "# 임베딩 기반 필터 초기화 - 유사도 기반 필터 (임베딩 유사도 0.4 이상)\n",
    "relevant_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.4)\n",
    "\n",
    "# Re-ranking 모델 초기화\n",
    "re_ranker = LLMListwiseRerank.from_llm(llm, top_n=2)\n",
    "\n",
    "# DocumentCompressorPipeline 초기화 (순차적으로 redundant_filter -> relevant_filter -> re_ranker 적용)\n",
    "pipeline_compressor = DocumentCompressorPipeline(\n",
    "    transformers=[redundant_filter, relevant_filter, re_ranker]\n",
    ")\n",
    "\n",
    "# DocumentCompressorPipeline을 사용한 retriever 초기화\n",
    "pipeline_compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=pipeline_compressor,           # DocumentCompressorPipeline 기반 압축기\n",
    "    base_retriever=chroma_k_retriever,             # 기본 검색기\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 문서 검색`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "- **Cybertruck:** 2019년 11월에 처음 발표된 풀사이즈 픽업 트럭. 후륜 구동, 듀얼 모터 전륜 구동, 트리 모터 전륜 구동의 세 가지 모델이 제공됩니다. [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "[출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "- **Model Y:** 싱글 모터, 후륜 구동 또는 듀얼 모터, 전륜 구동 레이아웃을 갖춘 5인승 및 7인승 구성으로 제공되는 중형 크로스오버 SUV. 이 차량은 고급 Model X SUV보다 저렴하도록 설계되었습니다. Model Y 프로토타입은 2019년 3월에 처음 공개되었으며 배송은 2020년 3월에 시작되었습니다.\n",
      "- **Tesla Semi:** Tesla Semi는 Tesla, Inc.의 클래스 8 세미 트럭으로, 트리 모터, 후륜 구동 레이아웃을 갖추고 있습니다. Tesla는 Semi가 일반적인 디젤 세미 트럭보다 약 3배 더 강력하고 주행 거리가 500마일(800km)이라고 주장합니다. 초기 배송은 2022년 12월 1일에 PepsiCo에 이루어졌습니다. [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "query = \"테슬라 트럭 모델이 있나요?\"\n",
    "compressed_docs = pipeline_compression_retriever.invoke(query, config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "for doc in compressed_docs:\n",
    "    print(f\"{doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# **[실습]**\n",
    "\n",
    "- 지금까지 학습한 여러 기법들을 선택하여, RAG 답변을 생성하는 체인을 구성합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 기본 검색기 설정`\n",
    "\n",
    "- Semantic Search, Keyword Search, Hybrid Search 검색기를 직접 정의합니다. \n",
    "- 쿼리 확장 도구 적용을 검토합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 16코어 128GB 최적화 RAG 검색기 초기화 시작!\n",
      "💻 시스템 정보: CPU 16코어, 메모리 127GB\n",
      "🔥 Jupyter 최적화 병렬도: {'file_loading': 32, 'text_splitting': 24, 'embedding': 64, 'bm25_indexing': 24, 'search_test': 8}\n",
      "\n",
      "====================================================================================================\n",
      "🚀 16코어 128GB 시스템 최적화 초고성능 검색기 실행 (Jupyter 호환)\n",
      "====================================================================================================\n",
      "\n",
      "⏰ [12:51:37.591] 🚀 전체_검색기_초고속_설정 시작\n",
      "   💻 시작 시 시스템 상태: {'cpu_avg': '2.1%', 'cpu_cores': ['C0:0.0%', 'C1:0.0%', 'C2:16.7%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:0.0%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.4%)', 'memory_available': '92GB', 'active_threads': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 고성능 문서 로딩...:   0%|          | 0/6 [00:00<?]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏰ [12:51:37.701] 🚀 고성능_문서_로딩 시작\n",
      "   💻 시작 시 시스템 상태: {'cpu_avg': '10.4%', 'cpu_cores': ['C0:50.0%', 'C1:0.0%', 'C2:33.3%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:16.7%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.4%)', 'memory_available': '92GB', 'active_threads': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 로딩: Tesla_EN.md (12KB): 100%|██████████| 4/4 [00:00<00:00, 799.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏰ [12:51:37.821] ✅ 고성능_문서_로딩 완료\n",
      "   ⏱️  소요시간: 0.120초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "✂️ 고성능 텍스트 분할...:  17%|█▋        | 1/6 [00:00<00:01]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   💻 종료 시 시스템 상태: {'cpu_avg': '0.0%', 'cpu_cores': ['C0:0.0%', 'C1:0.0%', 'C2:0.0%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:0.0%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.4%)', 'memory_available': '92GB', 'active_threads': 16}\n",
      "   📊 성능 요약: ⚡ 초고속 (120ms)\n",
      "   📈 처리량: 0.04MB, 0.32MB/s\n",
      "\n",
      "⏰ [12:51:37.931] 🚀 고성능_텍스트_분할 시작\n",
      "   💻 시작 시 시스템 상태: {'cpu_avg': '13.2%', 'cpu_cores': ['C0:28.6%', 'C1:0.0%', 'C2:16.7%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:50.0%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.5%)', 'memory_available': '92GB', 'active_threads': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "✂️ 청크4 -> 37개 분할: 100%|██████████| 4/4 [00:00<00:00, 571.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏰ [12:51:38.052] ✅ 고성능_텍스트_분할 완료\n",
      "   ⏱️  소요시간: 0.121초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 초고성능 임베딩 설정...:  33%|███▎      | 2/6 [00:00<00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   💻 종료 시 시스템 상태: {'cpu_avg': '1.0%', 'cpu_cores': ['C0:0.0%', 'C1:0.0%', 'C2:0.0%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:0.0%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.5%)', 'memory_available': '92GB', 'active_threads': 16}\n",
      "   📊 성능 요약: ⚡ 초고속 (121ms)\n",
      "   📈 분할 성능: 89개 청크, 733.1청크/초\n",
      "\n",
      "⏰ [12:51:38.162] 🚀 초고성능_임베딩_설정 시작\n",
      "   💻 시작 시 시스템 상태: {'cpu_avg': '8.5%', 'cpu_cores': ['C0:28.6%', 'C1:0.0%', 'C2:16.7%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:0.0%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.5%)', 'memory_available': '92GB', 'active_threads': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 초고속 BM25 인덱싱...:  67%|██████▋   | 4/6 [00:01<00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏰ [12:51:38.772] ✅ 초고성능_임베딩_설정 완료\n",
      "   ⏱️  소요시간: 0.611초\n",
      "   💻 종료 시 시스템 상태: {'cpu_avg': '10.3%', 'cpu_cores': ['C0:0.0%', 'C1:0.0%', 'C2:0.0%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:33.3%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.5%)', 'memory_available': '92GB', 'active_threads': 16}\n",
      "   📊 성능 요약: ⚡ 초고속 (611ms)\n",
      "   ⚡ 임베딩 병렬도: 64개 동시 요청\n",
      "\n",
      "⏰ [12:51:38.883] 🚀 초고속_BM25_인덱싱 시작\n",
      "   💻 시작 시 시스템 상태: {'cpu_avg': '11.5%', 'cpu_cores': ['C0:0.0%', 'C1:0.0%', 'C2:16.7%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:50.0%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.5%)', 'memory_available': '92GB', 'active_threads': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 초고속 BM25 인덱싱: 100%|██████████| 89/89 [00:00<00:00, 12717.37it/s]\n",
      "🔄 고급 검색기 최적화...:  83%|████████▎ | 5/6 [00:01<00:00]0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏰ [12:51:39.003] ✅ 초고속_BM25_인덱싱 완료\n",
      "   ⏱️  소요시간: 0.120초\n",
      "   💻 종료 시 시스템 상태: {'cpu_avg': '13.8%', 'cpu_cores': ['C0:16.7%', 'C1:0.0%', 'C2:16.7%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:42.9%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.5%)', 'memory_available': '92GB', 'active_threads': 16}\n",
      "   📊 성능 요약: ⚡ 초고속 (120ms)\n",
      "   📈 인덱싱 성능: 8898.3문서/초\n",
      "   💾 캐시 저장: 0.002초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 고급 검색기 최적화...: 100%|██████████| 6/6 [00:01<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏰ [12:51:39.618] ✅ 전체_검색기_초고속_설정 완료\n",
      "   ⏱️  소요시간: 2.027초\n",
      "   💻 종료 시 시스템 상태: {'cpu_avg': '3.1%', 'cpu_cores': ['C0:0.0%', 'C1:0.0%', 'C2:0.0%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:0.0%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.4%)', 'memory_available': '92GB', 'active_threads': 16}\n",
      "   📊 성능 요약: 🚀 빠름 (2.03s)\n",
      "   🎯 생성된 검색기: 4개\n",
      "   📊 처리된 문서: 4개 -> 89개 청크\n",
      "\n",
      "📋 테스트 쿼리: '테슬라 트럭 모델이 있나요?'\n",
      "\n",
      "⏰ [12:51:39.725] 🚀 초고속_병렬_검색_테스트 시작\n",
      "   💻 시작 시 시스템 상태: {'cpu_avg': '7.3%', 'cpu_cores': ['C0:16.7%', 'C1:0.0%', 'C2:33.3%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:16.7%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.4%)', 'memory_available': '92GB', 'active_threads': 16}\n",
      "   🖥️ 검색 시작 시점 시스템 상태: {'cpu_avg': '5.4%', 'cpu_cores': ['C0:0.0%', 'C1:0.0%', 'C2:14.3%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:28.6%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.4%)', 'memory_available': '92GB', 'active_threads': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "✅ multi_query 완료 (0.000초, CPU:3.4%): 100%|██████████| 4/4 [00:03<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏰ [12:51:42.955] ✅ 초고속_병렬_검색_테스트 완료\n",
      "   ⏱️  소요시간: 3.230초\n",
      "   💻 종료 시 시스템 상태: {'cpu_avg': '14.4%', 'cpu_cores': ['C0:44.4%', 'C1:0.0%', 'C2:28.6%', 'C3:0.0%', 'C4:0.0%', 'C5:0.0%', 'C6:28.6%', 'C7:0.0%'], 'memory_used': '35GB/127GB (27.5%)', 'memory_available': '92GB', 'active_threads': 16}\n",
      "   📊 성능 요약: 🚀 빠름 (3.23s)\n",
      "   ⚡ 검색 성능: 1.2검색기/초\n",
      "\n",
      "====================================================================================================\n",
      "📊 전체 성능 분석 보고서\n",
      "====================================================================================================\n",
      "🕐 총 실행 시간: 5.475초\n",
      "\n",
      "📋 단계별 상세 시간 분석:\n",
      "단계명                       시작시간         종료시간         소요시간       성능평가           \n",
      "------------------------------------------------------------------------------------------\n",
      "전체_검색기_초고속_설정             12:51:37.591 12:51:39.618 2.027    s 🚀 빠름 (2.03s)   \n",
      "고성능_문서_로딩                 12:51:37.701 12:51:37.821 0.120    s ⚡ 초고속 (120ms)  \n",
      "고성능_텍스트_분할                12:51:37.931 12:51:38.052 0.121    s ⚡ 초고속 (121ms)  \n",
      "초고성능_임베딩_설정               12:51:38.162 12:51:38.772 0.611    s ⚡ 초고속 (611ms)  \n",
      "초고속_BM25_인덱싱              12:51:38.883 12:51:39.003 0.120    s ⚡ 초고속 (120ms)  \n",
      "초고속_병렬_검색_테스트             12:51:39.725 12:51:42.955 3.230    s 🚀 빠름 (3.23s)   \n",
      "\n",
      "🎯 병목점 분석:\n",
      "   1. 초고속_병렬_검색_테스트: 3.230초 (59.0%)\n",
      "   2. 전체_검색기_초고속_설정: 2.027초 (37.0%)\n",
      "   3. 초고성능_임베딩_설정: 0.611초 (11.2%)\n",
      "\n",
      "💡 최적화 제안:\n",
      "   🔍 초고속_병렬_검색_테스트: 3.23초로 개선 여지 있음\n",
      "   🔍 전체_검색기_초고속_설정: 2.03초로 개선 여지 있음\n",
      "\n",
      "====================================================================================================\n",
      "🎯 초고성능 병렬 검색 결과\n",
      "====================================================================================================\n",
      "\n",
      "🔍 === 키워드 검색 결과 ===\n",
      "1. **개요**\n",
      "\n",
      "Rivian은 \"스케이트보드\" 플랫폼(R1T 및 R1S 모델)을 기반으로 한 전기 스포츠 유틸리티 차량(SUV), 픽업 트럭 및 ... [출처: data\\리비안_KR.md]\n",
      "2. - **Model Y:** 싱글 모터, 후륜 구동 또는 듀얼 모터, 전륜 구동 레이아웃을 갖춘 5인승 및 7인승 구성으로 제공되는 중형 크로스오... [출처: data\\테슬라_KR.md]\n",
      "3. **생산 준비 (2016–20):**\n",
      "\n",
      "- 2017년 일리노이 주 노멀에 있는 이전 Mitsubishi Motors 제조 공장을 1,600만 달... [출처: data\\리비안_KR.md]\n",
      "\n",
      "🔄 === 하이브리드 검색 결과 ===\n",
      "1. [출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "- **Cybertruck:** 2... [출처: data\\테슬라_KR.md]\n",
      "2. [출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "| Tesla 모델 |       ... [출처: data\\테슬라_KR.md]\n",
      "3. [출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "- **Model 3:** 패스트백... [출처: data\\테슬라_KR.md]\n",
      "\n",
      "🧠 === 의미 검색 결과 ===\n",
      "1. [출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "- **Cybertruck:** 2... [출처: data\\테슬라_KR.md]\n",
      "2. [출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "| Tesla 모델 |       ... [출처: data\\테슬라_KR.md]\n",
      "3. [출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "- **Model 3:** 패스트백... [출처: data\\테슬라_KR.md]\n",
      "\n",
      "🎯 === 멀티쿼리 검색 결과 ===\n",
      "1. [출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "- **Cybertruck:** 2... [출처: data\\테슬라_KR.md]\n",
      "2. [출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "| Tesla 모델 |       ... [출처: data\\테슬라_KR.md]\n",
      "3. [출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "- **Model S:** 리프트백... [출처: data\\테슬라_KR.md]\n",
      "\n",
      "====================================================================================================\n",
      "🎉 16코어 128GB 최적화 실습 1 완료! (Jupyter 호환)\n",
      "📊 최대 성능 활용:\n",
      "   🔥 파일 로딩: 32개 스레드\n",
      "   ⚡ 텍스트 분할: 24개 스레드 (Jupyter 안전 모드)\n",
      "   🚀 임베딩 요청: 64개 동시\n",
      "   💾 BM25 인덱싱: 24개 스레드\n",
      "   🎯 검색 테스트: 8개 동시\n",
      "   ⏰ 모든 단계별 상세 시간 측정\n",
      "   📈 실시간 성능 모니터링\n",
      "   🔍 병목점 자동 분석\n",
      "   ✅ Jupyter 환경 호환성 확보\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 실습 1: 16코어 128GB 최적화 + 상세 시간 측정 검색기 설정 (Jupyter 호환)\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import psutil\n",
    "import threading\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from functools import lru_cache\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "print(\"🚀 16코어 128GB 최적화 RAG 검색기 초기화 시작!\")\n",
    "print(f\"💻 시스템 정보: CPU {os.cpu_count()}코어, 메모리 {psutil.virtual_memory().total // (1024**3)}GB\")\n",
    "\n",
    "# 16코어 128GB 시스템 최적화 병렬도 계산 (Jupyter 호환)\n",
    "def get_jupyter_optimized_parallelism():\n",
    "    \"\"\"16코어 128GB 시스템 최적화 병렬도 (Jupyter 환경)\"\"\"\n",
    "    cpu_cores = os.cpu_count()  # 16\n",
    "    total_memory_gb = psutil.virtual_memory().total // (1024**3)  # 128\n",
    "    \n",
    "    # Jupyter 환경에 최적화된 병렬도 (ThreadPoolExecutor 중심)\n",
    "    parallelism = {\n",
    "        \"file_loading\": min(cpu_cores * 4, 32),      # I/O 집약적: 32개 스레드\n",
    "        \"text_splitting\": min(cpu_cores * 2, 24),   # CPU 집약적: 24개 스레드 (Process 대신 Thread)\n",
    "        \"embedding\": cpu_cores * 4,                  # API 호출: 64개 동시 요청\n",
    "        \"bm25_indexing\": min(cpu_cores * 2, 24),    # 메모리 집약적: 24개 스레드\n",
    "        \"search_test\": 8                             # 검색 테스트: 8개 동시\n",
    "    }\n",
    "    \n",
    "    print(f\"🔥 Jupyter 최적화 병렬도: {parallelism}\")\n",
    "    return parallelism\n",
    "\n",
    "PARALLELISM = get_jupyter_optimized_parallelism()\n",
    "\n",
    "# 캐싱 디렉토리 설정\n",
    "CACHE_DIR = \"./cache\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "# 상세 시간 측정 및 성능 모니터링 클래스\n",
    "class DetailedPerformanceMonitor:\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "        self.stage_times = {}\n",
    "        self.stage_details = {}\n",
    "        \n",
    "    def log_stage_start(self, stage_name):\n",
    "        \"\"\"단계 시작 시간 기록\"\"\"\n",
    "        start_time = time.time()\n",
    "        start_datetime = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n",
    "        \n",
    "        self.stage_times[stage_name] = {\"start\": start_time, \"start_datetime\": start_datetime}\n",
    "        \n",
    "        print(f\"\\n⏰ [{start_datetime}] 🚀 {stage_name} 시작\")\n",
    "        print(f\"   💻 시작 시 시스템 상태: {self.get_detailed_system_stats()}\")\n",
    "        \n",
    "        return start_time\n",
    "    \n",
    "    def log_stage_end(self, stage_name):\n",
    "        \"\"\"단계 종료 시간 기록\"\"\"\n",
    "        end_time = time.time()\n",
    "        end_datetime = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n",
    "        \n",
    "        if stage_name in self.stage_times:\n",
    "            start_time = self.stage_times[stage_name][\"start\"]\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            self.stage_times[stage_name].update({\n",
    "                \"end\": end_time,\n",
    "                \"end_datetime\": end_datetime,\n",
    "                \"duration\": duration\n",
    "            })\n",
    "            \n",
    "            print(f\"⏰ [{end_datetime}] ✅ {stage_name} 완료\")\n",
    "            print(f\"   ⏱️  소요시간: {duration:.3f}초\")\n",
    "            print(f\"   💻 종료 시 시스템 상태: {self.get_detailed_system_stats()}\")\n",
    "            print(f\"   📊 성능 요약: {self.get_performance_summary(stage_name)}\")\n",
    "            \n",
    "            return duration\n",
    "        return 0\n",
    "    \n",
    "    def get_detailed_system_stats(self):\n",
    "        \"\"\"상세 시스템 상태 반환\"\"\"\n",
    "        try:\n",
    "            cpu_percent = psutil.cpu_percent(interval=0.1, percpu=True)\n",
    "            memory = psutil.virtual_memory()\n",
    "            \n",
    "            return {\n",
    "                \"cpu_avg\": f\"{sum(cpu_percent)/len(cpu_percent):.1f}%\",\n",
    "                \"cpu_cores\": [f\"C{i}:{cpu:.1f}%\" for i, cpu in enumerate(cpu_percent[:8])],  # 처음 8코어만 표시\n",
    "                \"memory_used\": f\"{memory.used // (1024**3)}GB/{memory.total // (1024**3)}GB ({memory.percent:.1f}%)\",\n",
    "                \"memory_available\": f\"{memory.available // (1024**3)}GB\",\n",
    "                \"active_threads\": threading.active_count()\n",
    "            }\n",
    "        except:\n",
    "            return {\"status\": \"모니터링 일시 중단\"}\n",
    "    \n",
    "    def get_performance_summary(self, stage_name):\n",
    "        \"\"\"단계별 성능 요약\"\"\"\n",
    "        if stage_name not in self.stage_times:\n",
    "            return \"측정 데이터 없음\"\n",
    "        \n",
    "        duration = self.stage_times[stage_name][\"duration\"]\n",
    "        \n",
    "        if duration < 1:\n",
    "            return f\"⚡ 초고속 ({duration*1000:.0f}ms)\"\n",
    "        elif duration < 5:\n",
    "            return f\"🚀 빠름 ({duration:.2f}s)\"\n",
    "        elif duration < 15:\n",
    "            return f\"⏱️ 보통 ({duration:.2f}s)\"\n",
    "        else:\n",
    "            return f\"🐌 느림 ({duration:.2f}s) - 최적화 필요\"\n",
    "    \n",
    "    def print_total_summary(self):\n",
    "        \"\"\"전체 성능 요약 출력\"\"\"\n",
    "        total_time = time.time() - self.start_time\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*100)\n",
    "        print(f\"📊 전체 성능 분석 보고서\")\n",
    "        print(f\"=\"*100)\n",
    "        print(f\"🕐 총 실행 시간: {total_time:.3f}초\")\n",
    "        \n",
    "        print(f\"\\n📋 단계별 상세 시간 분석:\")\n",
    "        print(f\"{'단계명':<25} {'시작시간':<12} {'종료시간':<12} {'소요시간':<10} {'성능평가':<15}\")\n",
    "        print(\"-\" * 90)\n",
    "        \n",
    "        for stage_name, times in self.stage_times.items():\n",
    "            start_time = times.get(\"start_datetime\", \"N/A\")\n",
    "            end_time = times.get(\"end_datetime\", \"N/A\")\n",
    "            duration = times.get(\"duration\", 0)\n",
    "            performance = self.get_performance_summary(stage_name)\n",
    "            \n",
    "            print(f\"{stage_name:<25} {start_time:<12} {end_time:<12} {duration:<9.3f}s {performance:<15}\")\n",
    "        \n",
    "        print(f\"\\n🎯 병목점 분석:\")\n",
    "        sorted_stages = sorted(self.stage_times.items(), \n",
    "                              key=lambda x: x[1].get(\"duration\", 0), reverse=True)\n",
    "        \n",
    "        for i, (stage_name, times) in enumerate(sorted_stages[:3], 1):\n",
    "            duration = times.get(\"duration\", 0)\n",
    "            percentage = (duration / total_time) * 100\n",
    "            print(f\"   {i}. {stage_name}: {duration:.3f}초 ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(f\"\\n💡 최적화 제안:\")\n",
    "        for stage_name, times in sorted_stages:\n",
    "            duration = times.get(\"duration\", 0)\n",
    "            if duration > 5:\n",
    "                print(f\"   ⚠️ {stage_name}: {duration:.2f}초로 최적화 필요\")\n",
    "            elif duration > 1:\n",
    "                print(f\"   🔍 {stage_name}: {duration:.2f}초로 개선 여지 있음\")\n",
    "        \n",
    "        return total_time\n",
    "\n",
    "monitor = DetailedPerformanceMonitor()\n",
    "\n",
    "# 1단계: 고성능 병렬 문서 로딩\n",
    "def load_single_file(file_path):\n",
    "    \"\"\"단일 파일 로딩 함수 (최적화)\"\"\"\n",
    "    try:\n",
    "        # 파일 크기 확인 후 적절한 버퍼 크기 설정\n",
    "        file_size = os.path.getsize(file_path)\n",
    "        buffer_size = min(8192 * 16, file_size)  # 128KB 버퍼 또는 파일 크기\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8', buffering=buffer_size) as f:\n",
    "            content = f.read()\n",
    "        return {\n",
    "            \"page_content\": content,\n",
    "            \"metadata\": {\"source\": str(file_path), \"size\": file_size}\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ 파일 로딩 실패: {file_path} - {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def high_performance_document_loading():\n",
    "    \"\"\"16코어 최적화 병렬 문서 로딩\"\"\"\n",
    "    stage_name = \"고성능_문서_로딩\"\n",
    "    monitor.log_stage_start(stage_name)\n",
    "    \n",
    "    data_dir = Path(\"./data\")\n",
    "    md_files = list(data_dir.glob(\"*.md\"))\n",
    "    \n",
    "    if not md_files:\n",
    "        print(f\"   ⚠️ ./data 폴더에 .md 파일이 없습니다!\")\n",
    "        duration = monitor.log_stage_end(stage_name)\n",
    "        return []\n",
    "    \n",
    "    docs = []\n",
    "    \n",
    "    # 16코어 시스템 최적화: 32개 워커\n",
    "    with ThreadPoolExecutor(max_workers=PARALLELISM[\"file_loading\"]) as executor:\n",
    "        future_to_file = {executor.submit(load_single_file, file_path): file_path \n",
    "                         for file_path in md_files}\n",
    "        \n",
    "        with tqdm(total=len(md_files), desc=\"📄 고성능 파일 로딩\", \n",
    "                 bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\") as pbar:\n",
    "            \n",
    "            for future in as_completed(future_to_file):\n",
    "                file_path = future_to_file[future]\n",
    "                try:\n",
    "                    doc = future.result()\n",
    "                    if doc:\n",
    "                        docs.append(doc)\n",
    "                        file_size = doc[\"metadata\"][\"size\"]\n",
    "                        pbar.set_description(f\"📄 로딩: {file_path.name} ({file_size//1024}KB)\")\n",
    "                    pbar.update(1)\n",
    "                except Exception as e:\n",
    "                    pbar.set_description(f\"❌ 실패: {file_path.name}\")\n",
    "                    pbar.update(1)\n",
    "    \n",
    "    duration = monitor.log_stage_end(stage_name)\n",
    "    \n",
    "    if docs:\n",
    "        total_size = sum(doc[\"metadata\"][\"size\"] for doc in docs) / (1024*1024)\n",
    "        throughput = total_size / duration if duration > 0 else 0\n",
    "        print(f\"   📈 처리량: {total_size:.2f}MB, {throughput:.2f}MB/s\")\n",
    "    \n",
    "    return docs\n",
    "\n",
    "# 2단계: 고성능 스레드 기반 텍스트 분할 (Jupyter 호환)\n",
    "def split_documents_threaded(docs):\n",
    "    \"\"\"스레드 기반 텍스트 분할 (Jupyter 환경 호환)\"\"\"\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    \n",
    "    # 16코어 시스템 최적화: 더 큰 청크 크기\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,      # 300 -> 500으로 증가\n",
    "        chunk_overlap=100,   # 50 -> 100으로 증가\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    all_split_docs = []\n",
    "    \n",
    "    for doc_data in docs:\n",
    "        try:\n",
    "            # 문서 객체 재구성\n",
    "            class Document:\n",
    "                def __init__(self, page_content, metadata):\n",
    "                    self.page_content = page_content\n",
    "                    self.metadata = metadata\n",
    "            \n",
    "            doc = Document(doc_data[\"page_content\"], doc_data[\"metadata\"])\n",
    "            chunks = text_splitter.split_documents([doc])\n",
    "            all_split_docs.extend(chunks)\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ 문서 분할 실패: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return all_split_docs\n",
    "\n",
    "def high_performance_text_splitting(docs):\n",
    "    \"\"\"16코어 최적화 스레드 기반 텍스트 분할\"\"\"\n",
    "    stage_name = \"고성능_텍스트_분할\"\n",
    "    monitor.log_stage_start(stage_name)\n",
    "    \n",
    "    if not docs:\n",
    "        print(f\"   ⚠️ 분할할 문서가 없습니다!\")\n",
    "        duration = monitor.log_stage_end(stage_name)\n",
    "        return []\n",
    "    \n",
    "    split_docs = []\n",
    "    \n",
    "    # ThreadPoolExecutor로 안전한 병렬 처리 (Jupyter 호환)\n",
    "    with ThreadPoolExecutor(max_workers=PARALLELISM[\"text_splitting\"]) as executor:\n",
    "        # 문서를 청크로 나누어 병렬 처리\n",
    "        chunk_size = max(1, len(docs) // PARALLELISM[\"text_splitting\"])\n",
    "        doc_chunks = [docs[i:i + chunk_size] for i in range(0, len(docs), chunk_size)]\n",
    "        \n",
    "        future_to_chunk = {executor.submit(split_documents_threaded, chunk): i \n",
    "                          for i, chunk in enumerate(doc_chunks)}\n",
    "        \n",
    "        with tqdm(total=len(doc_chunks), desc=\"✂️ 고성능 텍스트 분할\",\n",
    "                 bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\") as pbar:\n",
    "            \n",
    "            for future in as_completed(future_to_chunk):\n",
    "                chunk_idx = future_to_chunk[future]\n",
    "                try:\n",
    "                    chunks = future.result()\n",
    "                    split_docs.extend(chunks)\n",
    "                    pbar.set_description(f\"✂️ 청크{chunk_idx+1} -> {len(chunks)}개 분할\")\n",
    "                    pbar.update(1)\n",
    "                except Exception as e:\n",
    "                    pbar.set_description(f\"❌ 청크{chunk_idx+1} 분할 실패\")\n",
    "                    pbar.update(1)\n",
    "    \n",
    "    duration = monitor.log_stage_end(stage_name)\n",
    "    \n",
    "    chunk_rate = len(split_docs) / duration if duration > 0 else 0\n",
    "    print(f\"   📈 분할 성능: {len(split_docs)}개 청크, {chunk_rate:.1f}청크/초\")\n",
    "    \n",
    "    return split_docs\n",
    "\n",
    "# 3단계: 64개 동시 요청 임베딩 최적화\n",
    "def setup_ultra_optimized_embeddings():\n",
    "    \"\"\"64개 동시 요청 임베딩 설정\"\"\"\n",
    "    stage_name = \"초고성능_임베딩_설정\"\n",
    "    monitor.log_stage_start(stage_name)\n",
    "    \n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    \n",
    "    # 16코어 시스템: 64개 동시 요청\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=\"text-embedding-3-small\",\n",
    "        max_retries=5,\n",
    "        request_timeout=120,\n",
    "        chunk_size=min(2000, PARALLELISM[\"embedding\"]),  # 2000개 또는 64개\n",
    "    )\n",
    "    \n",
    "    duration = monitor.log_stage_end(stage_name)\n",
    "    print(f\"   ⚡ 임베딩 병렬도: {PARALLELISM['embedding']}개 동시 요청\")\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# 4단계: 초고속 BM25 인덱싱\n",
    "def ultra_fast_bm25_setup(split_docs):\n",
    "    \"\"\"128GB 메모리 활용 초고속 BM25 인덱싱\"\"\"\n",
    "    stage_name = \"초고속_BM25_인덱싱\"\n",
    "    monitor.log_stage_start(stage_name)\n",
    "    \n",
    "    if not split_docs:\n",
    "        print(f\"   ⚠️ 인덱싱할 문서가 없습니다!\")\n",
    "        duration = monitor.log_stage_end(stage_name)\n",
    "        return None\n",
    "    \n",
    "    bm25_cache_path = os.path.join(CACHE_DIR, \"bm25_retriever_jupyter_v4.pkl\")\n",
    "    \n",
    "    # 캐시 확인\n",
    "    if os.path.exists(bm25_cache_path):\n",
    "        cache_start = time.time()\n",
    "        with tqdm(total=1, desc=\"📋 BM25 캐시 로딩\") as pbar:\n",
    "            with open(bm25_cache_path, 'rb') as f:\n",
    "                bm25_retriever = pickle.load(f)\n",
    "            pbar.update(1)\n",
    "        \n",
    "        cache_time = time.time() - cache_start\n",
    "        duration = monitor.log_stage_end(stage_name)\n",
    "        print(f\"   ⚡ 캐시 로딩 속도: {cache_time:.3f}초\")\n",
    "        return bm25_retriever\n",
    "    \n",
    "    # 새로 생성 - 128GB 메모리 활용\n",
    "    from langchain_community.retrievers import BM25Retriever\n",
    "    \n",
    "    # 메모리 풍부한 시스템: 한 번에 모든 문서 처리\n",
    "    index_start = time.time()\n",
    "    \n",
    "    with tqdm(total=len(split_docs), desc=\"🔍 초고속 BM25 인덱싱\",\n",
    "             bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\") as pbar:\n",
    "        \n",
    "        try:\n",
    "            # 128GB 메모리: 모든 문서를 메모리에 로드하여 처리\n",
    "            bm25_retriever = BM25Retriever.from_documents(split_docs)\n",
    "            bm25_retriever.k = 5\n",
    "            \n",
    "            pbar.update(len(split_docs))\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ BM25 인덱싱 실패: {e}\")\n",
    "            duration = monitor.log_stage_end(stage_name)\n",
    "            return None\n",
    "    \n",
    "    index_time = time.time() - index_start\n",
    "    \n",
    "    # 캐시 저장\n",
    "    cache_save_start = time.time()\n",
    "    with open(bm25_cache_path, 'wb') as f:\n",
    "        pickle.dump(bm25_retriever, f)\n",
    "    cache_save_time = time.time() - cache_save_start\n",
    "    \n",
    "    duration = monitor.log_stage_end(stage_name)\n",
    "    \n",
    "    indexing_rate = len(split_docs) / index_time if index_time > 0 else 0\n",
    "    print(f\"   📈 인덱싱 성능: {indexing_rate:.1f}문서/초\")\n",
    "    print(f\"   💾 캐시 저장: {cache_save_time:.3f}초\")\n",
    "    \n",
    "    return bm25_retriever\n",
    "\n",
    "# 5단계: 전체 검색기 초고속 설정\n",
    "def setup_ultra_high_performance_retrievers():\n",
    "    \"\"\"16코어 128GB 시스템 최적화 검색기 설정\"\"\"\n",
    "    stage_name = \"전체_검색기_초고속_설정\"\n",
    "    monitor.log_stage_start(stage_name)\n",
    "    \n",
    "    # 전체 진행률 표시\n",
    "    main_progress = tqdm(total=6, desc=\"🏗️ 초고성능 검색기 시스템 구축\", position=0,\n",
    "                        bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]\")\n",
    "    \n",
    "    # 1. 고성능 문서 로딩\n",
    "    main_progress.set_description(\"📄 고성능 문서 로딩...\")\n",
    "    docs = high_performance_document_loading()\n",
    "    main_progress.update(1)\n",
    "    \n",
    "    # 2. 고성능 텍스트 분할\n",
    "    main_progress.set_description(\"✂️ 고성능 텍스트 분할...\")\n",
    "    split_docs = high_performance_text_splitting(docs)\n",
    "    main_progress.update(1)\n",
    "    \n",
    "    # 3. 초고성능 임베딩 설정\n",
    "    main_progress.set_description(\"🧠 초고성능 임베딩 설정...\")\n",
    "    embeddings = setup_ultra_optimized_embeddings()\n",
    "    main_progress.update(1)\n",
    "    \n",
    "    # 4. 의미 검색기 설정\n",
    "    main_progress.set_description(\"🧠 의미 검색기 최적화...\")\n",
    "    try:\n",
    "        semantic_retriever = chroma_db.as_retriever(\n",
    "            search_type=\"similarity\",\n",
    "            search_kwargs={\"k\": 5}\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ ChromaDB 검색기 설정 실패: {e}\")\n",
    "        semantic_retriever = None\n",
    "    main_progress.update(1)\n",
    "    \n",
    "    # 5. 초고속 BM25 검색기\n",
    "    main_progress.set_description(\"🔍 초고속 BM25 인덱싱...\")\n",
    "    bm25_retriever = ultra_fast_bm25_setup(split_docs)\n",
    "    main_progress.update(1)\n",
    "    \n",
    "    # 6. 고급 검색기 구성\n",
    "    main_progress.set_description(\"🔄 고급 검색기 최적화...\")\n",
    "    \n",
    "    retrievers = {}\n",
    "    \n",
    "    if semantic_retriever:\n",
    "        retrievers[\"semantic\"] = semantic_retriever\n",
    "    \n",
    "    if bm25_retriever:\n",
    "        retrievers[\"bm25\"] = bm25_retriever\n",
    "        \n",
    "        # 하이브리드 검색기 (의미 검색기가 있을 때만)\n",
    "        if semantic_retriever:\n",
    "            from langchain.retrievers import EnsembleRetriever\n",
    "            hybrid_retriever = EnsembleRetriever(\n",
    "                retrievers=[semantic_retriever, bm25_retriever],\n",
    "                weights=[0.7, 0.3]  # 의미 검색 비중 증가\n",
    "            )\n",
    "            retrievers[\"hybrid\"] = hybrid_retriever\n",
    "            \n",
    "            # 멀티쿼리 검색기\n",
    "            try:\n",
    "                from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "                from langchain_openai import ChatOpenAI\n",
    "                \n",
    "                llm = ChatOpenAI(\n",
    "                    model=\"gpt-4o-mini\", \n",
    "                    temperature=0,\n",
    "                    request_timeout=60,\n",
    "                    max_retries=3\n",
    "                )\n",
    "                \n",
    "                multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "                    retriever=hybrid_retriever,\n",
    "                    llm=llm\n",
    "                )\n",
    "                retrievers[\"multi_query\"] = multi_query_retriever\n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ 멀티쿼리 검색기 설정 실패: {e}\")\n",
    "    \n",
    "    main_progress.update(1)\n",
    "    main_progress.close()\n",
    "    \n",
    "    duration = monitor.log_stage_end(stage_name)\n",
    "    \n",
    "    print(f\"   🎯 생성된 검색기: {len(retrievers)}개\")\n",
    "    print(f\"   📊 처리된 문서: {len(docs)}개 -> {len(split_docs)}개 청크\")\n",
    "    \n",
    "    return retrievers\n",
    "\n",
    "# 6단계: 8개 동시 초고속 검색 테스트\n",
    "def ultra_high_speed_search_test(query, retrievers_dict):\n",
    "    \"\"\"8개 동시 초고속 검색 테스트\"\"\"\n",
    "    stage_name = \"초고속_병렬_검색_테스트\"\n",
    "    monitor.log_stage_start(stage_name)\n",
    "    \n",
    "    if not retrievers_dict:\n",
    "        print(f\"   ⚠️ 검색할 검색기가 없습니다!\")\n",
    "        duration = monitor.log_stage_end(stage_name)\n",
    "        return {}, duration\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # 시스템 상태 출력\n",
    "    initial_stats = monitor.get_detailed_system_stats()\n",
    "    print(f\"   🖥️ 검색 시작 시점 시스템 상태: {initial_stats}\")\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=PARALLELISM[\"search_test\"]) as executor:\n",
    "        future_to_name = {}\n",
    "        \n",
    "        # 모든 검색기에 대해 Future 생성\n",
    "        for name, retriever in retrievers_dict.items():\n",
    "            future = executor.submit(retriever.invoke, query)\n",
    "            future_to_name[future] = name\n",
    "        \n",
    "        # 실시간 성능 모니터링\n",
    "        with tqdm(total=len(future_to_name), desc=\"🚀 초고속 병렬 검색\",\n",
    "                 bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\") as pbar:\n",
    "            \n",
    "            for future in as_completed(future_to_name):\n",
    "                name = future_to_name[future]\n",
    "                search_start = time.time()\n",
    "                \n",
    "                try:\n",
    "                    docs = future.result(timeout=60)\n",
    "                    search_time = time.time() - search_start\n",
    "                    results[name] = docs[:3]\n",
    "                    \n",
    "                    # 개별 검색기 성능 측정\n",
    "                    current_stats = monitor.get_detailed_system_stats()\n",
    "                    cpu_info = current_stats.get('cpu_avg', 'N/A')\n",
    "                    pbar.set_description(f\"✅ {name} 완료 ({search_time:.3f}초, CPU:{cpu_info})\")\n",
    "                    pbar.update(1)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    search_time = time.time() - search_start\n",
    "                    results[name] = []\n",
    "                    pbar.set_description(f\"❌ {name} 실패 ({search_time:.3f}초)\")\n",
    "                    pbar.update(1)\n",
    "    \n",
    "    duration = monitor.log_stage_end(stage_name)\n",
    "    \n",
    "    search_rate = len(retrievers_dict) / duration if duration > 0 else 0\n",
    "    print(f\"   ⚡ 검색 성능: {search_rate:.1f}검색기/초\")\n",
    "    \n",
    "    return results, duration\n",
    "\n",
    "# 메인 실행\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"🚀 16코어 128GB 시스템 최적화 초고성능 검색기 실행 (Jupyter 호환)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "total_start = time.time()\n",
    "\n",
    "# 모든 검색기 설정\n",
    "retrievers = setup_ultra_high_performance_retrievers()\n",
    "\n",
    "if not retrievers:\n",
    "    print(\"❌ 검색기 설정에 실패했습니다. 데이터 폴더와 ChromaDB를 확인해주세요.\")\n",
    "else:\n",
    "    # 테스트 쿼리\n",
    "    test_query = \"테슬라 트럭 모델이 있나요?\"\n",
    "    print(f\"\\n📋 테스트 쿼리: '{test_query}'\")\n",
    "\n",
    "    # 초고속 병렬 검색 실행\n",
    "    search_results, search_time = ultra_high_speed_search_test(test_query, retrievers)\n",
    "\n",
    "    # 전체 성능 분석 출력\n",
    "    total_time = monitor.print_total_summary()\n",
    "\n",
    "    # 검색 결과 출력\n",
    "    print(f\"\\n\" + \"=\"*100)\n",
    "    print(f\"🎯 초고성능 병렬 검색 결과\")\n",
    "    print(\"=\"*100)\n",
    "\n",
    "    result_icons = {\"semantic\": \"🧠\", \"bm25\": \"🔍\", \"hybrid\": \"🔄\", \"multi_query\": \"🎯\"}\n",
    "    result_names = {\"semantic\": \"의미 검색\", \"bm25\": \"키워드 검색\", \n",
    "                   \"hybrid\": \"하이브리드 검색\", \"multi_query\": \"멀티쿼리 검색\"}\n",
    "\n",
    "    for name, docs in search_results.items():\n",
    "        print(f\"\\n{result_icons.get(name, '🔧')} === {result_names.get(name, name)} 결과 ===\")\n",
    "        if docs:\n",
    "            for i, doc in enumerate(docs, 1):\n",
    "                source = doc.metadata.get('source', 'Unknown')\n",
    "                print(f\"{i}. {doc.page_content[:80]}... [출처: {source}]\")\n",
    "        else:\n",
    "            print(\"❌ 검색 결과 없음 또는 오류 발생\")\n",
    "\n",
    "    print(f\"\\n\" + \"=\"*100)\n",
    "    print(\"🎉 16코어 128GB 최적화 실습 1 완료! (Jupyter 호환)\")\n",
    "    print(\"📊 최대 성능 활용:\")\n",
    "    print(f\"   🔥 파일 로딩: {PARALLELISM['file_loading']}개 스레드\")\n",
    "    print(f\"   ⚡ 텍스트 분할: {PARALLELISM['text_splitting']}개 스레드 (Jupyter 안전 모드)\")\n",
    "    print(f\"   🚀 임베딩 요청: {PARALLELISM['embedding']}개 동시\")\n",
    "    print(f\"   💾 BM25 인덱싱: {PARALLELISM['bm25_indexing']}개 스레드\")\n",
    "    print(f\"   🎯 검색 테스트: {PARALLELISM['search_test']}개 동시\")\n",
    "    print(\"   ⏰ 모든 단계별 상세 시간 측정\")\n",
    "    print(\"   📈 실시간 성능 모니터링\")\n",
    "    print(\"   🔍 병목점 자동 분석\")\n",
    "    print(\"   ✅ Jupyter 환경 호환성 확보\")\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 검색기법 고도화`\n",
    "\n",
    "- Rerank, Comporession 기법을 적용합니다. \n",
    "- Pipeline Compressor로 연결하여 구성합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 실습 2: 검색기법 고도화 시작\n",
      "❌ semantic_retriever 없음\n",
      "❌ bm25_retriever 없음\n",
      "❌ hybrid_retriever 없음\n",
      "✅ retrievers 발견됨\n",
      "\n",
      "⚠️ 실습 1의 일부 변수가 없습니다: ['semantic_retriever', 'bm25_retriever', 'hybrid_retriever']\n",
      "🔄 필요한 검색기들을 재생성합니다...\n",
      "\n",
      "📋 검색기 재생성 중...\n",
      "✅ semantic_retriever 생성 완료\n",
      "📋 BM25 캐시에서 로드 중...\n",
      "✅ bm25_retriever 캐시 로드 완료\n",
      "✅ hybrid_retriever 생성 완료\n",
      "✅ 실습 2 준비 완료! 사용 검색기: EnsembleRetriever\n",
      "\n",
      "🔧 고도화 기법 구성 시작...\n",
      "1️⃣ LLM Reranker 설정...\n",
      "2️⃣ LLM Chain Extractor 설정...\n",
      "3️⃣ Embeddings Filter 설정...\n",
      "4️⃣ Redundant Filter 설정...\n",
      "5️⃣ Pipeline Compressor 구성...\n",
      "6️⃣ 고도화된 검색기 구성...\n",
      "\n",
      "🎯 고도화 검색 테스트 시작 (총 3개 쿼리)\n",
      "\n",
      "================================================================================\n",
      "🔍 쿼리 1: 테슬라 트럭 모델이 있나요?\n",
      "================================================================================\n",
      "\n",
      "--- 기본 검색 결과 ---\n",
      "검색된 문서 수: 10\n",
      "1. [출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "- **Cybertruck:** 2019년 11월에 처음 발표된 풀사이즈 픽업 트럭. 후륜 구동, 듀얼 모터 전륜 구동, 트리 모터 전륜 구동의 세 가지 모델이...\n",
      "2. [출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "| Tesla 모델 |          |       |                  |\n",
      "| :--------- | :------- | :---- | :---...\n",
      "\n",
      "--- 고도화된 검색 결과 (Pipeline) ---\n",
      "최종 문서 수: 2\n",
      "1. - **Cybertruck:** 2019년 11월에 처음 발표된 풀사이즈 픽업 트럭. 후륜 구동, 듀얼 모터 전륜 구동, 트리 모터 전륜 구동의 세 가지 모델이 제공됩니다.\n",
      "   [출처: data\\테슬라_KR.md]\n",
      "\n",
      "2. | Semi       | 2022     | 2     |                  |\n",
      "| Cybertruck | 2023     | 5     |                  |\n",
      "   [출처: data\\테슬라_KR.md]\n",
      "\n",
      "\n",
      "================================================================================\n",
      "🔍 쿼리 2: 리비안의 전기 트럭 특징은?\n",
      "================================================================================\n",
      "\n",
      "--- 기본 검색 결과 ---\n",
      "검색된 문서 수: 10\n",
      "1. [출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "## 에너지 제품\n",
      "\n",
      "Tesla Energy는 태양 에너지 생성 시스템과 배터리 에너지 저장 제품을 개발, 구축, 판매 및 설치합니다. 제품에는 태양 전지판, S...\n",
      "2. [출처] 이 문서는 리비안에 대한 문서입니다.\n",
      "----------------------------------\n",
      "Rivian Automotive, Inc.는 2009년에 설립된 미국의 전기 자동차 제조업체, 자동차 기술 및 야외 레크리에이션 회사입니다.\n",
      "\n",
      "**주요 정보:*...\n",
      "\n",
      "--- 고도화된 검색 결과 (Pipeline) ---\n",
      "최종 문서 수: 0\n",
      "\n",
      "================================================================================\n",
      "🔍 쿼리 3: 테슬라와 리비안의 차이점은?\n",
      "================================================================================\n",
      "\n",
      "--- 기본 검색 결과 ---\n",
      "검색된 문서 수: 10\n",
      "1. [출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "### 발표된 제품\n",
      "\n",
      "- **Roadster (2세대):** 2017년에 공개되었으며 620마일(1,000km)의 주행 거리와 고성능 사양을 갖춘 것으로 알려져...\n",
      "2. [출처] 이 문서는 테슬라에 대한 문서입니다.\n",
      "----------------------------------\n",
      "### 충전 서비스\n",
      "\n",
      "- **Supercharger 네트워크:** Tesla의 고전압 DC 급속 충전 네트워크로, 2012년에 도입되었습니다.\n",
      "- **Desti...\n",
      "\n",
      "--- 고도화된 검색 결과 (Pipeline) ---\n",
      "최종 문서 수: 0\n",
      "\n",
      "🎯 Pipeline 구성:\n",
      "1. 중복 제거 (EmbeddingsRedundantFilter)\n",
      "2. 유사도 필터링 (EmbeddingsFilter, threshold=0.5)\n",
      "3. 맥락 압축 (LLMChainExtractor)\n",
      "4. 재순위화 (LLMListwiseRerank, top_n=3)\n",
      "\n",
      "✅ 실습 2 완료!\n",
      "📊 사용된 검색기: EnsembleRetriever\n",
      "🔧 적용된 기법: 4단계 파이프라인 압축 + 재순위화\n"
     ]
    }
   ],
   "source": [
    "# 실습 2: 검색기법 고도화 (Rerank + Compression)\n",
    "\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import (\n",
    "    LLMListwiseRerank, \n",
    "    LLMChainExtractor,\n",
    "    EmbeddingsFilter,\n",
    "    DocumentCompressorPipeline\n",
    ")\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "print(\"🔧 실습 2: 검색기법 고도화 시작\")\n",
    "\n",
    "# 실습 1에서 생성된 검색기들 확인 및 재생성 (필요시)\n",
    "try:\n",
    "    # 실습 1의 변수들이 있는지 확인\n",
    "    test_vars = [\n",
    "        ('semantic_retriever', 'semantic_retriever'),\n",
    "        ('bm25_retriever', 'bm25_retriever'), \n",
    "        ('hybrid_retriever', 'hybrid_retriever'),\n",
    "        ('retrievers', 'retrievers')\n",
    "    ]\n",
    "    \n",
    "    missing_vars = []\n",
    "    for var_name, display_name in test_vars:\n",
    "        try:\n",
    "            eval(var_name)\n",
    "            print(f\"✅ {display_name} 발견됨\")\n",
    "        except NameError:\n",
    "            missing_vars.append(var_name)\n",
    "            print(f\"❌ {display_name} 없음\")\n",
    "    \n",
    "    if missing_vars:\n",
    "        print(f\"\\n⚠️ 실습 1의 일부 변수가 없습니다: {missing_vars}\")\n",
    "        print(\"🔄 필요한 검색기들을 재생성합니다...\")\n",
    "        \n",
    "        # 기본 검색기들 재생성\n",
    "        print(\"\\n📋 검색기 재생성 중...\")\n",
    "        \n",
    "        # 1. Semantic retriever (ChromaDB 기반)\n",
    "        try:\n",
    "            semantic_retriever = chroma_db.as_retriever(\n",
    "                search_type=\"similarity\",\n",
    "                search_kwargs={\"k\": 5}\n",
    "            )\n",
    "            print(\"✅ semantic_retriever 생성 완료\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ semantic_retriever 생성 실패: {e}\")\n",
    "            semantic_retriever = None\n",
    "        \n",
    "        # 2. BM25 retriever 캐시에서 로드 또는 재생성\n",
    "        try:\n",
    "            import os\n",
    "            import pickle\n",
    "            from pathlib import Path\n",
    "            \n",
    "            bm25_cache_path = \"./cache/bm25_retriever_jupyter_v4.pkl\"\n",
    "            \n",
    "            if os.path.exists(bm25_cache_path):\n",
    "                print(\"📋 BM25 캐시에서 로드 중...\")\n",
    "                with open(bm25_cache_path, 'rb') as f:\n",
    "                    bm25_retriever = pickle.load(f)\n",
    "                print(\"✅ bm25_retriever 캐시 로드 완료\")\n",
    "            else:\n",
    "                print(\"🔄 BM25 retriever 새로 생성 중...\")\n",
    "                \n",
    "                # 문서 로드 및 분할\n",
    "                from langchain_community.document_loaders import DirectoryLoader\n",
    "                from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "                from langchain_community.retrievers import BM25Retriever\n",
    "                \n",
    "                data_dir = Path(\"./data\")\n",
    "                md_files = list(data_dir.glob(\"*.md\"))\n",
    "                \n",
    "                if md_files:\n",
    "                    # 문서 로드\n",
    "                    docs = []\n",
    "                    for file_path in md_files:\n",
    "                        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                            content = f.read()\n",
    "                        docs.append({\n",
    "                            \"page_content\": content,\n",
    "                            \"metadata\": {\"source\": str(file_path)}\n",
    "                        })\n",
    "                    \n",
    "                    # 텍스트 분할\n",
    "                    text_splitter = RecursiveCharacterTextSplitter(\n",
    "                        chunk_size=500,\n",
    "                        chunk_overlap=100,\n",
    "                        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "                    )\n",
    "                    \n",
    "                    class Document:\n",
    "                        def __init__(self, page_content, metadata):\n",
    "                            self.page_content = page_content\n",
    "                            self.metadata = metadata\n",
    "                    \n",
    "                    split_docs = []\n",
    "                    for doc_data in docs:\n",
    "                        doc = Document(doc_data[\"page_content\"], doc_data[\"metadata\"])\n",
    "                        chunks = text_splitter.split_documents([doc])\n",
    "                        split_docs.extend(chunks)\n",
    "                    \n",
    "                    # BM25 생성\n",
    "                    bm25_retriever = BM25Retriever.from_documents(split_docs)\n",
    "                    bm25_retriever.k = 5\n",
    "                    \n",
    "                    # 캐시 저장\n",
    "                    os.makedirs(\"./cache\", exist_ok=True)\n",
    "                    with open(bm25_cache_path, 'wb') as f:\n",
    "                        pickle.dump(bm25_retriever, f)\n",
    "                    \n",
    "                    print(\"✅ bm25_retriever 생성 및 캐시 저장 완료\")\n",
    "                else:\n",
    "                    print(\"❌ ./data 폴더에 .md 파일이 없습니다!\")\n",
    "                    bm25_retriever = None\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"❌ bm25_retriever 생성 실패: {e}\")\n",
    "            bm25_retriever = None\n",
    "        \n",
    "        # 3. Hybrid retriever 생성\n",
    "        if semantic_retriever and bm25_retriever:\n",
    "            try:\n",
    "                from langchain.retrievers import EnsembleRetriever\n",
    "                \n",
    "                hybrid_retriever = EnsembleRetriever(\n",
    "                    retrievers=[semantic_retriever, bm25_retriever],\n",
    "                    weights=[0.7, 0.3]  # semantic: 70%, keyword: 30%\n",
    "                )\n",
    "                print(\"✅ hybrid_retriever 생성 완료\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ hybrid_retriever 생성 실패: {e}\")\n",
    "                hybrid_retriever = semantic_retriever  # fallback\n",
    "        elif semantic_retriever:\n",
    "            hybrid_retriever = semantic_retriever\n",
    "            print(\"⚠️ semantic_retriever를 hybrid_retriever로 사용\")\n",
    "        elif bm25_retriever:\n",
    "            hybrid_retriever = bm25_retriever\n",
    "            print(\"⚠️ bm25_retriever를 hybrid_retriever로 사용\")\n",
    "        else:\n",
    "            print(\"❌ 검색기 생성에 완전히 실패했습니다!\")\n",
    "            hybrid_retriever = None\n",
    "    \n",
    "    else:\n",
    "        print(\"✅ 모든 필수 검색기가 준비되었습니다!\")\n",
    "        \n",
    "        # 실습 1의 retrievers 딕셔너리에서 가져오기\n",
    "        if 'retrievers' in locals() or 'retrievers' in globals():\n",
    "            retrievers_dict = eval('retrievers')\n",
    "            if 'hybrid' in retrievers_dict:\n",
    "                hybrid_retriever = retrievers_dict['hybrid']\n",
    "                print(\"✅ 실습 1의 hybrid_retriever 사용\")\n",
    "            elif 'semantic' in retrievers_dict:\n",
    "                hybrid_retriever = retrievers_dict['semantic']\n",
    "                print(\"⚠️ 실습 1의 semantic_retriever를 hybrid_retriever로 사용\")\n",
    "        else:\n",
    "            # 변수가 직접 정의되어 있는 경우\n",
    "            if 'hybrid_retriever' not in locals() and 'hybrid_retriever' not in globals():\n",
    "                hybrid_retriever = semantic_retriever\n",
    "                print(\"⚠️ semantic_retriever를 hybrid_retriever로 사용\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 검색기 확인 중 오류: {e}\")\n",
    "    # 최소한의 검색기라도 설정\n",
    "    try:\n",
    "        hybrid_retriever = chroma_db.as_retriever(search_kwargs={\"k\": 5})\n",
    "        print(\"✅ ChromaDB를 기본 검색기로 사용\")\n",
    "    except:\n",
    "        print(\"❌ 모든 검색기 설정 실패\")\n",
    "        hybrid_retriever = None\n",
    "\n",
    "# 검색기가 준비되었는지 최종 확인\n",
    "if hybrid_retriever is None:\n",
    "    print(\"❌ 실습 2를 진행할 수 없습니다. 검색기가 없습니다!\")\n",
    "    print(\"💡 실습 1을 먼저 실행해주세요.\")\n",
    "else:\n",
    "    print(f\"✅ 실습 2 준비 완료! 사용 검색기: {type(hybrid_retriever).__name__}\")\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "print(\"\\n🔧 고도화 기법 구성 시작...\")\n",
    "\n",
    "# 1) LLM Reranker 설정\n",
    "print(\"1️⃣ LLM Reranker 설정...\")\n",
    "llm_reranker = LLMListwiseRerank.from_llm(llm, top_n=3)\n",
    "\n",
    "# 2) LLM Chain Extractor 설정 (맥락 압축)\n",
    "print(\"2️⃣ LLM Chain Extractor 설정...\")\n",
    "llm_extractor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "# 3) Embeddings Filter 설정 (유사도 기반 필터링)\n",
    "print(\"3️⃣ Embeddings Filter 설정...\")\n",
    "embeddings_filter = EmbeddingsFilter(\n",
    "    embeddings=embeddings, \n",
    "    similarity_threshold=0.5\n",
    ")\n",
    "\n",
    "# 4) Redundant Filter 설정 (중복 제거)\n",
    "print(\"4️⃣ Redundant Filter 설정...\")\n",
    "redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)\n",
    "\n",
    "# 5) Pipeline Compressor 구성\n",
    "print(\"5️⃣ Pipeline Compressor 구성...\")\n",
    "# 순서: 중복제거 -> 유사도 필터링 -> 맥락 압축 -> 재순위화\n",
    "pipeline_compressor = DocumentCompressorPipeline(\n",
    "    transformers=[\n",
    "        redundant_filter,      # 1단계: 중복 문서 제거\n",
    "        embeddings_filter,     # 2단계: 유사도 기반 필터링\n",
    "        llm_extractor,         # 3단계: 관련 내용만 추출\n",
    "        llm_reranker          # 4단계: 최종 재순위화\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 6) 최종 고도화된 검색기 구성\n",
    "if hybrid_retriever is not None:\n",
    "    print(\"6️⃣ 고도화된 검색기 구성...\")\n",
    "    advanced_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=pipeline_compressor,\n",
    "        base_retriever=hybrid_retriever  # 준비된 하이브리드 검색기 사용\n",
    "    )\n",
    "    \n",
    "    # 테스트 및 결과 비교\n",
    "    test_queries = [\n",
    "        \"테슬라 트럭 모델이 있나요?\",\n",
    "        \"리비안의 전기 트럭 특징은?\",\n",
    "        \"테슬라와 리비안의 차이점은?\"\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n🎯 고도화 검색 테스트 시작 (총 {len(test_queries)}개 쿼리)\")\n",
    "\n",
    "    for i, query in enumerate(test_queries, 1):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"🔍 쿼리 {i}: {query}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        try:\n",
    "            # 기본 검색 결과\n",
    "            print(\"\\n--- 기본 검색 결과 ---\")\n",
    "            basic_docs = hybrid_retriever.invoke(query)\n",
    "            print(f\"검색된 문서 수: {len(basic_docs)}\")\n",
    "            for j, doc in enumerate(basic_docs[:2], 1):\n",
    "                print(f\"{j}. {doc.page_content[:150]}...\")\n",
    "            \n",
    "            # 고도화된 검색 결과\n",
    "            print(\"\\n--- 고도화된 검색 결과 (Pipeline) ---\")\n",
    "            advanced_docs = advanced_retriever.invoke(query, config={\"callbacks\": [langfuse_handler]})\n",
    "            print(f\"최종 문서 수: {len(advanced_docs)}\")\n",
    "            for j, doc in enumerate(advanced_docs, 1):\n",
    "                print(f\"{j}. {doc.page_content}\")\n",
    "                print(f\"   [출처: {doc.metadata['source']}]\")\n",
    "                print()\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 쿼리 '{query}' 처리 중 오류: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"\\n🎯 Pipeline 구성:\")\n",
    "    print(\"1. 중복 제거 (EmbeddingsRedundantFilter)\")\n",
    "    print(\"2. 유사도 필터링 (EmbeddingsFilter, threshold=0.5)\")  \n",
    "    print(\"3. 맥락 압축 (LLMChainExtractor)\")\n",
    "    print(\"4. 재순위화 (LLMListwiseRerank, top_n=3)\")\n",
    "    \n",
    "    print(f\"\\n✅ 실습 2 완료!\")\n",
    "    print(f\"📊 사용된 검색기: {type(hybrid_retriever).__name__}\")\n",
    "    print(f\"🔧 적용된 기법: 4단계 파이프라인 압축 + 재순위화\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ 실습 2를 완료할 수 없습니다. 기본 검색기가 필요합니다.\")\n",
    "    print(\"💡 실습 1을 먼저 성공적으로 실행해주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) RAG 체인 연결`\n",
    "\n",
    "- 검색기, 프롬프트, LLM을 LCEL로 연결하여 RAG Chain을 구성합니다. \n",
    "- 다양한 쿼리를 입력하고, 생성된 답변의 품질을 평가합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚗 RAG 체인 성능 테스트\n",
      "================================================================================\n",
      "\n",
      "질문 1: 테슬라 Cybertruck의 특징과 출시년도를 알려주세요\n",
      "------------------------------------------------------------\n",
      "답변: 테슬라 Cybertruck은 2019년 11월에 처음 발표된 풀사이즈 픽업 트럭입니다. 이 차량은 후륜 구동, 듀얼 모터 전륜 구동, 트리 모터 전륜 구동의 세 가지 모델로 제공됩니다. Cybertruck의 배송은 2023년 11월에 시작되었습니다. (출처: 문서 1, 문서 2, 문서 3)\n",
      "📊 검색된 문서 수: 3\n",
      "\n",
      "================================================================================\n",
      "\n",
      "질문 2: 리비안 R1T와 테슬라 Cybertruck의 차이점은 무엇인가요?\n",
      "------------------------------------------------------------\n",
      "답변: 제공된 문서에서는 리비안 R1T에 대한 정보가 없으므로, 리비안 R1T와 테슬라 Cybertruck의 차이점에 대한 구체적인 비교를 제공할 수 없습니다. 그러나 테슬라 Cybertruck에 대한 정보는 다음과 같습니다:\n",
      "\n",
      "- **모델명:** Cybertruck\n",
      "- **발표 연도:** 2019년 11월\n",
      "- **모델 사양:** 후륜 구동, 듀얼 모터 전륜 구동, 트리 모터 전륜 구동의 세 가지 모델이 제공됩니다.\n",
      "- **배송 시작:** 2023년 11월에 Cybertruck 배송이 시작되었습니다.\n",
      "\n",
      "제공된 문서에서는 리비안 R1T에 대한 정보가 없으므로, 해당 정보를 찾을 수 없습니다. (출처: data\\테슬라_KR.md)\n",
      "📊 검색된 문서 수: 2\n",
      "\n",
      "================================================================================\n",
      "\n",
      "질문 3: 테슬라에서 생산하는 트럭 모델들을 모두 나열해주세요\n",
      "------------------------------------------------------------\n",
      "답변: 테슬라에서 생산하는 트럭 모델은 다음과 같습니다:\n",
      "\n",
      "1. **Cybertruck**\n",
      "   - 발표 연도: 2019년\n",
      "   - 모델 사양: 후륜 구동, 듀얼 모터 전륜 구동, 트리 모터 전륜 구동의 세 가지 모델 제공\n",
      "\n",
      "2. **Semi**\n",
      "   - 생산 연도: 2022년\n",
      "\n",
      "3. **Cybertruck**\n",
      "   - 생산 연도: 2023년\n",
      "\n",
      "출처: 문서 1 [출처: data\\테슬라_KR.md], 문서 2 [출처: data\\테슬라_KR.md]\n",
      "📊 검색된 문서 수: 2\n",
      "\n",
      "================================================================================\n",
      "\n",
      "질문 4: 전기 픽업트럭 중에서 어떤 모델을 추천하시나요?\n",
      "------------------------------------------------------------\n",
      "답변: 제공된 문서에서는 전기 픽업트럭에 대한 구체적인 모델명이나 사양에 대한 정보가 포함되어 있지 않습니다. 따라서 추천할 수 있는 전기 픽업트럭 모델에 대한 정보는 찾을 수 없습니다.\n",
      "📊 검색된 문서 수: 0\n",
      "\n",
      "================================================================================\n",
      "\n",
      "질문 5: 테슬라 Model S의 제조년도와 좌석 수는?\n",
      "------------------------------------------------------------\n",
      "답변: 테슬라 Model S의 제조년도는 2012년이며, 좌석 수는 5/7입니다. (출처: 문서 1, 문서 2, 문서 3)\n",
      "📊 검색된 문서 수: 3\n",
      "\n",
      "================================================================================\n",
      "\n",
      "질문 6: 2025년에 출시 예정인 테슬라 모델이 있나요?\n",
      "------------------------------------------------------------\n",
      "답변: 2025년에 출시 예정인 테슬라 모델은 **Roadster (2세대)**입니다. 이 모델은 620마일(1,000km)의 주행 거리와 고성능 사양을 갖추고 있으며, 2017년에 공개되었습니다. 출처: 문서 1 [출처: data\\테슬라_KR.md]\n",
      "📊 검색된 문서 수: 2\n",
      "\n",
      "================================================================================\n",
      "\n",
      "📈 RAG 시스템 구성 요약:\n",
      "├── 검색기: Hybrid (Semantic + BM25) + MultiQuery\n",
      "├── 고도화: Pipeline (중복제거 → 유사도필터 → 압축 → 재순위)\n",
      "├── 프롬프트: 전기차 전문가 역할 + 명확한 가이드라인\n",
      "├── LLM: GPT-4o-mini (temperature=0.1)\n",
      "└── 추적: Langfuse 콜백으로 성능 모니터링\n",
      "\n",
      "🔍 성능 비교 테스트:\n",
      "\n",
      "질문: 테슬라 트럭 모델이 있나요?\n",
      "\n",
      "--- 기본 RAG 결과 ---\n",
      "테슬라의 트럭 모델은 **Cybertruck**입니다. 이 모델은 2019년 11월에 처음 발표된 풀사이즈 픽업 트럭으로, 후륜 구동, 듀얼 모터 전륜 구동, 트리 모터 전륜 구동의 세 가지 모델이 제공됩니다. Cybertruck의 출시 연도는 2023년입니다. \n",
      "\n",
      "출처: 문서 1, 문서 2.\n",
      "\n",
      "--- 고도화된 RAG 결과 ---\n",
      "테슬라의 트럭 모델로는 **Cybertruck**가 있습니다. 이 모델은 2019년 11월에 처음 발표되었으며, 후륜 구동, 듀얼 모터 전륜 구동, 트리 모터 전륜 구동의 세 가지 모델이 제공됩니다. Cybertruck의 출시 연도는 2023년으로 예정되어 있습니다. (출처: 문서 1, 문서 2)\n"
     ]
    }
   ],
   "source": [
    "# 실습 3: RAG 체인 연결 (LCEL 사용)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1) 프롬프트 템플릿 정의\n",
    "rag_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "당신은 전기차 전문가입니다. 주어진 문서를 바탕으로 정확하고 도움이 되는 답변을 제공해주세요.\n",
    "\n",
    "검색된 문서:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변 가이드라인:\n",
    "1. 문서에 있는 정보만을 사용하여 답변하세요\n",
    "2. 정확한 모델명, 연도, 사양 등을 포함하세요  \n",
    "3. 출처를 명시하세요\n",
    "4. 문서에 정보가 없다면 \"제공된 문서에서는 해당 정보를 찾을 수 없습니다\"라고 답변하세요\n",
    "\n",
    "답변:\n",
    "\"\"\")\n",
    "\n",
    "# 2) LLM 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "# 3) 문서 포맷팅 함수\n",
    "def format_docs(docs):\n",
    "    formatted_docs = []\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        source = doc.metadata.get('source', 'Unknown')\n",
    "        content = doc.page_content.strip()\n",
    "        formatted_docs.append(f\"문서 {i} [출처: {source}]:\\n{content}\")\n",
    "    return \"\\n\\n\" + \"\\n\\n\".join(formatted_docs)\n",
    "\n",
    "# 4) RAG 체인 구성 (LCEL)\n",
    "rag_chain = (\n",
    "    RunnableParallel({\n",
    "        \"context\": advanced_retriever | format_docs,  # 실습2의 고도화된 검색기 사용\n",
    "        \"question\": RunnablePassthrough()\n",
    "    })\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 5) 다양한 쿼리로 성능 테스트\n",
    "test_questions = [\n",
    "    \"테슬라 Cybertruck의 특징과 출시년도를 알려주세요\",\n",
    "    \"리비안 R1T와 테슬라 Cybertruck의 차이점은 무엇인가요?\",\n",
    "    \"테슬라에서 생산하는 트럭 모델들을 모두 나열해주세요\",\n",
    "    \"전기 픽업트럭 중에서 어떤 모델을 추천하시나요?\",\n",
    "    \"테슬라 Model S의 제조년도와 좌석 수는?\",\n",
    "    \"2025년에 출시 예정인 테슬라 모델이 있나요?\"\n",
    "]\n",
    "\n",
    "print(\"🚗 RAG 체인 성능 테스트\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n질문 {i}: {question}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # RAG 체인 실행\n",
    "        answer = rag_chain.invoke(question, config={\"callbacks\": [langfuse_handler]})\n",
    "        print(f\"답변: {answer}\")\n",
    "        \n",
    "        # 검색된 문서 수 확인\n",
    "        retrieved_docs = advanced_retriever.invoke(question)\n",
    "        print(f\"📊 검색된 문서 수: {len(retrieved_docs)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류 발생: {str(e)}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# 6) 성능 평가 메트릭\n",
    "print(\"\\n📈 RAG 시스템 구성 요약:\")\n",
    "print(\"├── 검색기: Hybrid (Semantic + BM25) + MultiQuery\")\n",
    "print(\"├── 고도화: Pipeline (중복제거 → 유사도필터 → 압축 → 재순위)\")\n",
    "print(\"├── 프롬프트: 전기차 전문가 역할 + 명확한 가이드라인\")\n",
    "print(\"├── LLM: GPT-4o-mini (temperature=0.1)\")\n",
    "print(\"└── 추적: Langfuse 콜백으로 성능 모니터링\")\n",
    "\n",
    "# 7) 간단한 성능 비교 (기본 vs 고도화)\n",
    "print(\"\\n🔍 성능 비교 테스트:\")\n",
    "comparison_query = \"테슬라 트럭 모델이 있나요?\"\n",
    "\n",
    "# 기본 검색기로 RAG\n",
    "basic_rag_chain = (\n",
    "    RunnableParallel({\n",
    "        \"context\": semantic_retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    })\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(f\"\\n질문: {comparison_query}\")\n",
    "print(\"\\n--- 기본 RAG 결과 ---\")\n",
    "basic_answer = basic_rag_chain.invoke(comparison_query)\n",
    "print(basic_answer)\n",
    "\n",
    "print(\"\\n--- 고도화된 RAG 결과 ---\")\n",
    "advanced_answer = rag_chain.invoke(comparison_query)\n",
    "print(advanced_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
