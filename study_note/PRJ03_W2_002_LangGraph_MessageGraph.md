# LangGraph MessageGraph - Reducerì™€ ë³‘ë ¬ ì²˜ë¦¬ íŒ¨í„´

## ğŸ“š í•™ìŠµ ëª©í‘œ

- **Reducerì˜ ê°œë…ê³¼ ì¢…ë¥˜**ë¥¼ ì´í•´í•˜ê³  ìƒíƒœ ê´€ë¦¬ ì „ëµì„ ì„ íƒí•  ìˆ˜ ìˆë‹¤
- **operator.add, add_messages, Custom Reducer**ë¥¼ ìƒí™©ì— ë§ê²Œ í™œìš©í•  ìˆ˜ ìˆë‹¤
- **MessagesState**ë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ê¸°ë°˜ ì‹œìŠ¤í…œì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤
- **ë³‘ë ¬ ì²˜ë¦¬ íŒ¨í„´** (Fan-out/Fan-in, ì¡°ê±´ë¶€ ë¶„ê¸°, ë‹¤ë‹¨ê³„ ë¶„ê¸°)ì„ ì„¤ê³„í•  ìˆ˜ ìˆë‹¤
- **Send API**ë¥¼ í™œìš©í•œ ë™ì  Map-Reduce íŒ¨í„´ì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤

## ğŸ”‘ í•µì‹¬ ê°œë…

### Reducerë€?

**Reducer(ë¦¬ë“€ì„œ)**ëŠ” LangGraphì˜ ìƒíƒœ ê´€ë¦¬ í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ, ê° ë…¸ë“œì˜ ì¶œë ¥ì„ ì „ì²´ ê·¸ë˜í”„ ìƒíƒœì— ì–´ë–»ê²Œ í†µí•©í• ì§€ ì •ì˜í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

#### Reducerê°€ í•„ìš”í•œ ì´ìœ 

```python
# âŒ ë¬¸ì œ ìƒí™©: Reducer ì—†ì´ ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
class State(TypedDict):
    documents: List[str]  # Reducer ì§€ì • ì•ˆ í•¨

# ì´ˆê¸° ìƒíƒœ
state = {"documents": ["doc1.pdf"]}

# node_2ê°€ ì‹¤í–‰
def node_2(state):
    return {"documents": ["doc2.pdf", "doc3.pdf"]}

# ê²°ê³¼: ì´ì „ ê°’ì´ ì‚¬ë¼ì§!
# state = {"documents": ["doc2.pdf", "doc3.pdf"]}  # doc1.pdf ì—†ì–´ì§!
```

```python
# âœ… í•´ê²°: operator.add Reducer ì‚¬ìš©
from typing import Annotated
from operator import add

class State(TypedDict):
    documents: Annotated[List[str], add]  # Reducer ì§€ì •!

# ê°™ì€ ìƒí™©ì—ì„œ
# ê²°ê³¼: ëˆ„ì ë¨!
# state = {"documents": ["doc1.pdf", "doc2.pdf", "doc3.pdf"]}  # ëª¨ë‘ ìœ ì§€!
```

### Reducerì˜ ì„¸ ê°€ì§€ ìœ í˜•

#### 1. ê¸°ë³¸ Reducer (ë®ì–´ì“°ê¸°)

Reducerë¥¼ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ **ì™„ì „íˆ ë®ì–´ì“°ê¸°**ê°€ ë°œìƒí•©ë‹ˆë‹¤.

**ì‚¬ìš© ì‹œê¸°:**
- ë‹¨ìˆœ ê°’ (ë¬¸ìì—´, ìˆ«ì, ë¶ˆë¦°)
- ìµœì‹  ê°’ë§Œ í•„ìš”í•œ ê²½ìš°
- ì˜ˆ: í˜„ì¬ ì¿¼ë¦¬, ìµœì¢… ê²°ê³¼, ì‹ ë¢°ë„ ì ìˆ˜

**ë™ì‘ ë°©ì‹:**
```python
ìƒˆë¡œìš´_ìƒíƒœ[í‚¤] = ë…¸ë“œ_ë°˜í™˜ê°’[í‚¤]  # ì´ì „ ê°’ ë¬´ì‹œ
```

#### 2. operator.add (ë¦¬ìŠ¤íŠ¸ ëˆ„ì )

Pythonì˜ `+` ì—°ì‚°ìë¥¼ ì‚¬ìš©í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ì—°ê²°í•©ë‹ˆë‹¤.

**ì‚¬ìš© ì‹œê¸°:**
- ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ë°ì´í„° ëˆ„ì 
- ìˆœì„œê°€ ì¤‘ìš”í•œ ê²½ìš°
- ì˜ˆ: ê²€ìƒ‰ ê²°ê³¼, ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬

**ë™ì‘ ë°©ì‹:**
```python
[1, 2, 3] + [4, 5] = [1, 2, 3, 4, 5]
```

#### 3. Custom Reducer (ì‚¬ìš©ì ì •ì˜)

ë³µì¡í•œ ë³‘í•© ë¡œì§ì´ í•„ìš”í•  ë•Œ ì§ì ‘ êµ¬í˜„í•©ë‹ˆë‹¤.

**ì‚¬ìš© ì‹œê¸°:**
- ì¤‘ë³µ ì œê±°
- ì •ë ¬, í•„í„°ë§
- ì¡°ê±´ë¶€ ë³‘í•©
- ìµœëŒ€/ìµœì†Œê°’ ìœ ì§€

**êµ¬í˜„ ì˜ˆì‹œ:**
```python
def reduce_unique(left: list | None, right: list | None) -> list:
    """ì¤‘ë³µ ì œê±° Reducer"""
    if not left:
        left = []
    if not right:
        right = []

    seen = set()
    result = []

    for item in left + right:
        if item not in seen:
            seen.add(item)
            result.append(item)

    return result
```

### MessagesState

**MessagesState**ëŠ” ëŒ€í™” ê¸°ë°˜ ì‹œìŠ¤í…œì„ ìœ„í•œ ë¯¸ë¦¬ ì •ì˜ëœ ìƒíƒœ íƒ€ì…ìœ¼ë¡œ, `add_messages` Reducerê°€ ìë™ìœ¼ë¡œ ì ìš©ë©ë‹ˆë‹¤.

#### operator.add vs add_messages

| íŠ¹ì„± | operator.add | add_messages |
|------|-------------|--------------|
| **ê¸°ë³¸ ë™ì‘** | ë¦¬ìŠ¤íŠ¸ ì—°ê²° (`+`) | ë©”ì‹œì§€ ID ê¸°ë°˜ ê´€ë¦¬ |
| **ì¤‘ë³µ ì²˜ë¦¬** | ì¤‘ë³µ í—ˆìš© | IDë¡œ ì¤‘ë³µ ê°ì§€ |
| **ë©”ì‹œì§€ ìˆ˜ì •** | ë¶ˆê°€ëŠ¥ | ê°™ì€ ID ë©”ì‹œì§€ ì—…ë°ì´íŠ¸ ê°€ëŠ¥ |
| **ë©”ì‹œì§€ í¬ë§·** | ëª…ì‹œì  ê°ì²´ë§Œ | ë‹¤ì–‘í•œ í¬ë§· ìë™ ë³€í™˜ |
| **ì‚¬ìš© ì‚¬ë¡€** | ë‹¨ìˆœ ë¦¬ìŠ¤íŠ¸ ëˆ„ì  | ì±„íŒ… ëŒ€í™” ê´€ë¦¬ |

#### MessagesState ì‚¬ìš©ë²•

```python
from langgraph.graph import MessagesState

# ë°©ë²• 1: ê¸°ë³¸ ì‚¬ìš©
class State(MessagesState):
    pass  # messages í•„ë“œ ìë™ í¬í•¨

# ë°©ë²• 2: ì»¤ìŠ¤í…€ í•„ë“œ ì¶”ê°€
class CustomState(MessagesState):
    user_id: str
    emotion: Optional[str]
    session_info: dict
```

### ë³‘ë ¬ ì²˜ë¦¬ íŒ¨í„´

LangGraphëŠ” ë‹¤ì–‘í•œ ë³‘ë ¬ ì²˜ë¦¬ íŒ¨í„´ì„ ì§€ì›í•˜ì—¬ ë…ë¦½ì ì¸ ì‘ì—…ë“¤ì„ ë™ì‹œì— ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### 1. Fan-out/Fan-in (ê¸°ë³¸ ë³‘ë ¬)

í•˜ë‚˜ì˜ ë…¸ë“œì—ì„œ ì—¬ëŸ¬ ë³‘ë ¬ ë…¸ë“œë¡œ ë¶„ì‚° í›„ ë‹¤ì‹œ í•˜ë‚˜ë¡œ ìˆ˜ë ´í•©ë‹ˆë‹¤.

```
START â†’ node_a â†’ [node_b1, node_b2, node_b3] â†’ node_c â†’ END
               â†˜    (ë™ì‹œ ì‹¤í–‰)         â†™
```

#### 2. ì¡°ê±´ë¶€ ë¶„ê¸°

ì¡°ê±´ì— ë”°ë¼ ì„ íƒì ìœ¼ë¡œ ë³‘ë ¬ ì‹¤í–‰í•©ë‹ˆë‹¤.

```python
def router(state) -> list[str]:
    if "weather" in state["intent"]:
        return ["weather_service", "news_service"]
    else:
        return ["news_service"]
```

#### 3. ë‹¤ë‹¨ê³„ ë¶„ê¸°

ê° ë³‘ë ¬ ê²½ë¡œê°€ ì—¬ëŸ¬ ë‹¨ê³„ë¥¼ ê°€ì§‘ë‹ˆë‹¤.

```
       â”Œâ”€ fetch_a â†’ process_a â”€â”
START â”€â”¤                        â”œâ”€ combine â†’ END
       â””â”€ fetch_b â†’ process_b â”€â”˜
```

#### 4. Map-Reduce íŒ¨í„´ (Send API)

**Send API**ë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì ìœ¼ë¡œ ë³‘ë ¬ ì‘ì—…ì„ ìƒì„±í•©ë‹ˆë‹¤.

```python
from langgraph.types import Send

def mapper(state):
    # ê° ì•„ì´í…œì— ëŒ€í•´ Send ê°ì²´ ìƒì„±
    return [
        Send("process_item", {"item": item})
        for item in state["items"]
    ]
```

**í•µì‹¬ íŠ¹ì§•:**
- **ë™ì  ì—£ì§€**: ì‹¤í–‰ ì‹œì ì— ë³‘ë ¬ ì‘ì—… ìˆ˜ ê²°ì •
- **ê°œë³„ ìƒíƒœ**: ê° ë³‘ë ¬ ì‘ì—…ì´ ë…ë¦½ì ì¸ ìƒíƒœ ì‚¬ìš©
- **ìë™ ìˆ˜ì§‘**: ëª¨ë“  ë³‘ë ¬ ì‘ì—… ì™„ë£Œ í›„ ìë™ í†µí•©

## ğŸ›  í™˜ê²½ ì„¤ì •

### 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

```bash
# LangGraph ë° ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
pip install langgraph langchain-openai langchain-community langchain-core

# ê²€ìƒ‰ ë„êµ¬
pip install tavily-python

# í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬
pip install python-dotenv

# ë°ì´í„° ê²€ì¦
pip install pydantic
```

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

`.env` íŒŒì¼ì— API í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤:

```bash
OPENAI_API_KEY=your_openai_api_key_here
TAVILY_API_KEY=your_tavily_api_key_here
```

### 3. ê¸°ë³¸ ì„¤ì • ì½”ë“œ

```python
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os
import operator
from glob import glob
from pprint import pprint
from typing import TypedDict, Annotated, List, Optional, Literal

# LangChain ë° LangGraph
from langchain_openai import ChatOpenAI
from langchain_core.messages import AnyMessage, HumanMessage, AIMessage
from langchain_community.tools.tavily_search import TavilySearchResults

from langgraph.graph import StateGraph, START, END, MessagesState
from langgraph.graph.message import add_messages
from langgraph.types import Send

# ë°ì´í„° ê²€ì¦
from pydantic import BaseModel, Field

# ì‹œê°í™”
from IPython.display import Image, display
```

## ğŸ’» ë‹¨ê³„ë³„ êµ¬í˜„

### 1ë‹¨ê³„: Reducer ê¸°ë³¸ ì‚¬ìš©

#### ê¸°ë³¸ Reducer (ë®ì–´ì“°ê¸°)

```python
from typing import TypedDict, List
from langgraph.graph import StateGraph, START, END

# Reducer ì—†ëŠ” ìƒíƒœ ì •ì˜
class DocumentState(TypedDict):
    query: str
    documents: List[str]  # Reducer ì§€ì • ì•ˆ í•¨ = ë®ì–´ì“°ê¸°

# ë…¸ë“œ ì •ì˜
def node_1(state: DocumentState):
    print("---Node 1---")
    return {"query": state["query"]}

def node_2(state: DocumentState):
    print("---Node 2: ìƒˆ ë¬¸ì„œ ì¶”ê°€---")
    return {"documents": ["doc1.pdf", "doc2.pdf"]}

def node_3(state: DocumentState):
    print("---Node 3: ë˜ ë‹¤ë¥¸ ë¬¸ì„œ ì¶”ê°€---")
    return {"documents": ["doc3.pdf"]}  # ì´ì „ ë¬¸ì„œ ì‚¬ë¼ì§!

# ê·¸ë˜í”„ êµ¬ì„±
workflow = StateGraph(DocumentState)
workflow.add_node("node_1", node_1)
workflow.add_node("node_2", node_2)
workflow.add_node("node_3", node_3)

workflow.add_edge(START, "node_1")
workflow.add_edge("node_1", "node_2")
workflow.add_edge("node_2", "node_3")
workflow.add_edge("node_3", END)

graph = workflow.compile()

# ì‹¤í–‰
result = graph.invoke({
    "query": "ì±„ì‹ì£¼ì˜ìë¥¼ ìœ„í•œ ë¹„ê±´ ìŒì‹ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”."
})

print("ìµœì¢… ë¬¸ì„œ:", result['documents'])
# ì¶œë ¥: ['doc3.pdf']  # node_2ì˜ ë¬¸ì„œë“¤ì´ ì‚¬ë¼ì§!
```

#### operator.add Reducer (ëˆ„ì )

```python
from operator import add
from typing import Annotated

# operator.add Reducer ì‚¬ìš©
class ReducerState(TypedDict):
    query: str
    documents: Annotated[List[str], add]  # ë¦¬ìŠ¤íŠ¸ ëˆ„ì !

# ë…¸ë“œëŠ” ë™ì¼
def node_2(state: ReducerState):
    return {"documents": ["doc1.pdf", "doc2.pdf"]}

def node_3(state: ReducerState):
    return {"documents": ["doc3.pdf"]}

# ê·¸ë˜í”„ êµ¬ì„± (ë™ì¼)
workflow = StateGraph(ReducerState)
# ... (ë…¸ë“œ ì¶”ê°€ ë° ì—£ì§€ ì„¤ì •)

graph = workflow.compile()

# ì‹¤í–‰
result = graph.invoke({
    "query": "ì±„ì‹ì£¼ì˜ìë¥¼ ìœ„í•œ ë¹„ê±´ ìŒì‹ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”."
})

print("ìµœì¢… ë¬¸ì„œ:", result['documents'])
# ì¶œë ¥: ['doc1.pdf', 'doc2.pdf', 'doc3.pdf']  # ëª¨ë‘ ìœ ì§€!
```

### 2ë‹¨ê³„: Custom Reducer êµ¬í˜„

ì¤‘ë³µ ì œê±° ë° ì •ë ¬ ê¸°ëŠ¥ì´ í¬í•¨ëœ Custom Reducerë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

```python
from typing import Annotated, List

def reduce_unique_sorted(left: list | None, right: list | None) -> list:
    """
    ì¤‘ë³µ ì œê±° ë° ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ Reducer

    Args:
        left: ê¸°ì¡´ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        right: ìƒˆë¡œ ì¶”ê°€í•  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸

    Returns:
        ì¤‘ë³µì´ ì œê±°ë˜ê³  ì •ë ¬ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
    """
    if not left:
        left = []
    if not right:
        right = []

    # ì¤‘ë³µ ì œê±°
    unique_docs = list(set(left + right))

    # ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    return sorted(unique_docs, reverse=True)

# ìƒíƒœ ì •ì˜
class CustomState(TypedDict):
    query: str
    documents: Annotated[List[str], reduce_unique_sorted]

# ë…¸ë“œ ì •ì˜
def node_2(state: CustomState):
    return {"documents": ["doc1.pdf", "doc2.pdf", "doc3.pdf"]}

def node_3(state: CustomState):
    return {"documents": ["doc2.pdf", "doc4.pdf"]}  # doc2.pdf ì¤‘ë³µ

# ê·¸ë˜í”„ êµ¬ì„± ë° ì‹¤í–‰
workflow = StateGraph(CustomState)
workflow.add_node("node_1", lambda s: {"query": s["query"]})
workflow.add_node("node_2", node_2)
workflow.add_node("node_3", node_3)

workflow.add_edge(START, "node_1")
workflow.add_edge("node_1", "node_2")
workflow.add_edge("node_2", "node_3")
workflow.add_edge("node_3", END)

graph = workflow.compile()

result = graph.invoke({
    "query": "ì±„ì‹ì£¼ì˜ìë¥¼ ìœ„í•œ ë¹„ê±´ ìŒì‹ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”."
})

print("ìµœì¢… ë¬¸ì„œ:", result['documents'])
# ì¶œë ¥: ['doc4.pdf', 'doc3.pdf', 'doc2.pdf', 'doc1.pdf']
# ì¤‘ë³µ ì œê±° + ì •ë ¬ë¨!
```

### 3ë‹¨ê³„: MessagesState í™œìš©

ëŒ€í™” ê¸°ë°˜ ì±—ë´‡ì„ MessagesStateë¡œ êµ¬í˜„í•©ë‹ˆë‹¤.

#### ê¸°ë³¸ ì‚¬ìš©

```python
from langgraph.graph import MessagesState
from langchain_openai import ChatOpenAI

# MessagesState ìƒì†
class ChatState(MessagesState):
    pass  # messages í•„ë“œ ìë™ í¬í•¨

# LLM ì¸ìŠ¤í„´ìŠ¤
llm = ChatOpenAI(model="gpt-4.1-mini")

# ì±—ë´‡ ë…¸ë“œ
def chatbot(state: ChatState):
    # LLMì— messages ì „ë‹¬í•˜ì—¬ ì‘ë‹µ ìƒì„±
    return {"messages": [llm.invoke(state["messages"])]}

# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(ChatState)
builder.add_node("chatbot", chatbot)
builder.add_edge(START, "chatbot")
builder.add_edge("chatbot", END)

graph = builder.compile()

# ì‹¤í–‰
for event in graph.stream(
    {"messages": [("user", "ì•ˆë…•í•˜ì„¸ìš”!")]},
    stream_mode="values"
):
    pprint(event['messages'])
```

#### ì»¤ìŠ¤í…€ í•„ë“œ ì¶”ê°€

```python
from typing import Optional

# ê°ì • ë¶„ì„ ê¸°ëŠ¥ ì¶”ê°€
class EmotionChatState(MessagesState):
    emotion: Optional[str]  # ê°ì • ìƒíƒœ ì¶”ì 

llm = ChatOpenAI(model="gpt-4.1-mini")

# ê°ì • ë¶„ì„ ë…¸ë“œ
def analyze_emotion(state: EmotionChatState):
    """ì‚¬ìš©ì ë©”ì‹œì§€ì˜ ê°ì • ë¶„ì„"""
    user_message = state["messages"][-1].content

    prompt = f"""
    ì‚¬ìš©ì ë©”ì‹œì§€ì˜ ê°ì • ìƒíƒœë¥¼ íŒŒì•…í•˜ì„¸ìš”.
    ê°€ëŠ¥í•œ ê°ì •: í–‰ë³µ, ìŠ¬í””, í™”ë‚¨, ì¤‘ë¦½

    ë©”ì‹œì§€: {user_message}

    ê°ì •ë§Œ í•œ ë‹¨ì–´ë¡œ:
    """

    emotion = llm.invoke(prompt).content.strip()
    return {"emotion": emotion}

# ê°ì • ê¸°ë°˜ ì‘ë‹µ ë…¸ë“œ
def respond_with_emotion(state: EmotionChatState):
    """ê°ì •ì— ë§ì¶° ì‘ë‹µ ìƒì„±"""
    emotion = state.get("emotion", "ì¤‘ë¦½")

    prompt = f"""
    ì‚¬ìš©ìì˜ ê°ì •({emotion})ì„ ê³ ë ¤í•˜ì—¬ ê³µê°í•˜ë©° ì‘ë‹µí•˜ì„¸ìš”.

    ëŒ€í™” íˆìŠ¤í† ë¦¬:
    {state["messages"]}

    ì‘ë‹µ:
    """

    response = llm.invoke(prompt)
    return {"messages": [response]}

# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(EmotionChatState)
builder.add_node("analyze_emotion", analyze_emotion)
builder.add_node("respond", respond_with_emotion)

builder.add_edge(START, "analyze_emotion")
builder.add_edge("analyze_emotion", "respond")
builder.add_edge("respond", END)

graph = builder.compile()

# ì‹¤í–‰
result = graph.invoke({
    "messages": [("user", "ì˜¤ëŠ˜ ì •ë§ í˜ë“  í•˜ë£¨ì˜€ì–´ìš”...")]
})

print(f"ê°ì •: {result['emotion']}")
print(f"ì‘ë‹µ: {result['messages'][-1].content}")
```

### 4ë‹¨ê³„: ë³‘ë ¬ ì²˜ë¦¬ - Fan-out/Fan-in

ì—¬ëŸ¬ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ë™ì‹œì— ê²€ìƒ‰í•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.

```python
import operator
from typing import Annotated

class SearchState(TypedDict):
    query: str
    results: Annotated[list[str], operator.add]

# ë³‘ë ¬ ê²€ìƒ‰ ë…¸ë“œë“¤
def search_db(state: SearchState):
    """ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰"""
    print(f"ğŸ“Š DB ê²€ìƒ‰: {state['query']}")
    return {"results": ["DB: ë°ì´í„° 1", "DB: ë°ì´í„° 2"]}

def search_web(state: SearchState):
    """ì›¹ ê²€ìƒ‰"""
    print(f"ğŸŒ ì›¹ ê²€ìƒ‰: {state['query']}")
    return {"results": ["ì›¹: ì •ë³´ 1", "ì›¹: ì •ë³´ 2"]}

def search_api(state: SearchState):
    """API ê²€ìƒ‰"""
    print(f"ğŸ”Œ API ê²€ìƒ‰: {state['query']}")
    return {"results": ["API: ê²°ê³¼ 1", "API: ê²°ê³¼ 2"]}

def aggregate(state: SearchState):
    """ê²°ê³¼ í†µí•©"""
    print(f"ğŸ“‹ ì´ {len(state['results'])}ê°œ ê²°ê³¼ ìˆ˜ì§‘ ì™„ë£Œ")
    return {}

# ê·¸ë˜í”„ êµ¬ì„±
workflow = StateGraph(SearchState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("search_db", search_db)
workflow.add_node("search_web", search_web)
workflow.add_node("search_api", search_api)
workflow.add_node("aggregate", aggregate)

# Fan-out: START â†’ 3ê°œ ë³‘ë ¬ ë…¸ë“œ
workflow.add_edge(START, "search_db")
workflow.add_edge(START, "search_web")
workflow.add_edge(START, "search_api")

# Fan-in: 3ê°œ ë…¸ë“œ â†’ aggregate
workflow.add_edge("search_db", "aggregate")
workflow.add_edge("search_web", "aggregate")
workflow.add_edge("search_api", "aggregate")

workflow.add_edge("aggregate", END)

graph = workflow.compile()

# ì‹¤í–‰
result = graph.invoke({"query": "LangGraph íŠœí† ë¦¬ì–¼"})
for r in result["results"]:
    print(f"  - {r}")
```

### 5ë‹¨ê³„: ì¡°ê±´ë¶€ ë³‘ë ¬ ë¶„ê¸°

ì‚¬ìš©ì ì˜ë„ì— ë”°ë¼ ì„ íƒì ìœ¼ë¡œ ì„œë¹„ìŠ¤ë¥¼ ë³‘ë ¬ ì‹¤í–‰í•©ë‹ˆë‹¤.

```python
from typing import Literal

class IntentState(TypedDict):
    messages: Annotated[list, operator.add]
    user_intent: str

# ì„œë¹„ìŠ¤ ë…¸ë“œë“¤
def greet_service(state: IntentState):
    return {"messages": ["ì•ˆë…•í•˜ì„¸ìš”!"]}

def weather_service(state: IntentState):
    return {"messages": ["ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ë§‘ìŠµë‹ˆë‹¤."]}

def news_service(state: IntentState):
    return {"messages": ["ìµœì‹  ë‰´ìŠ¤ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤."]}

def end_service(state: IntentState):
    return {"messages": ["ì„œë¹„ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤."]}

# ë¼ìš°íŒ… í•¨ìˆ˜
def route_services(state: IntentState) -> list[Literal["weather_service", "news_service"]]:
    """ì˜ë„ì— ë”°ë¼ ì‹¤í–‰í•  ì„œë¹„ìŠ¤ ì„ íƒ"""
    intent = state["user_intent"]

    if "weather" in intent and "news" in intent:
        return ["weather_service", "news_service"]
    elif "weather" in intent:
        return ["weather_service"]
    elif "news" in intent:
        return ["news_service"]
    else:
        return []

# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(IntentState)

builder.add_node("greet_service", greet_service)
builder.add_node("weather_service", weather_service)
builder.add_node("news_service", news_service)
builder.add_node("end_service", end_service)

builder.add_edge(START, "greet_service")

# ì¡°ê±´ë¶€ ì—£ì§€: greet â†’ ì„ íƒì  ì„œë¹„ìŠ¤ë“¤
builder.add_conditional_edges(
    "greet_service",
    route_services,
    ["weather_service", "news_service"]
)

builder.add_edge("weather_service", "end_service")
builder.add_edge("news_service", "end_service")
builder.add_edge("end_service", END)

graph = builder.compile()

# í…ŒìŠ¤íŠ¸ 1: ë‚ ì”¨ + ë‰´ìŠ¤
print("=== weather_news ===")
result = graph.invoke({"user_intent": "weather_news"})
print(result["messages"])

# í…ŒìŠ¤íŠ¸ 2: ë‰´ìŠ¤ë§Œ
print("\n=== news ===")
result = graph.invoke({"user_intent": "news"})
print(result["messages"])
```

### 6ë‹¨ê³„: Send APIë¡œ ë™ì  Map-Reduce êµ¬í˜„

URL ê°œìˆ˜ì— ê´€ê³„ì—†ì´ ë™ì ìœ¼ë¡œ ë³‘ë ¬ ìŠ¤í¬ë˜í•‘ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

```python
from langgraph.types import Send
import time

# ì „ì²´ ìƒíƒœ
class ScrapingState(TypedDict):
    urls: List[str]
    scraped_data: Annotated[List[dict], operator.add]

# ê°œë³„ URL ìƒíƒœ
class URLState(TypedDict):
    url: str

# 1. URL ëª©ë¡ ì¤€ë¹„ (Map ì‹œì‘ì )
def prepare_urls(state: ScrapingState):
    """ìŠ¤í¬ë˜í•‘í•  URL ëª©ë¡ í™•ì¸"""
    print(f"ğŸ“‹ ì´ {len(state['urls'])}ê°œ URL ì¤€ë¹„")
    return {}

# 2. Sendë¥¼ ì‚¬ìš©í•œ ë™ì  ë¶„ë°°
def distribute_urls(state: ScrapingState):
    """ê° URLì„ ë³„ë„ ë…¸ë“œë¡œ ë¶„ë°°"""
    print(f"ğŸ”€ {len(state['urls'])}ê°œ URLì„ ë³‘ë ¬ë¡œ ë¶„ë°°...")

    # ê° URLì— ëŒ€í•´ Send ê°ì²´ ìƒì„±
    return [
        Send("scrape_url", {"url": url})
        for url in state["urls"]
    ]

# 3. ê°œë³„ ìŠ¤í¬ë˜í•‘ ë…¸ë“œ (ë³‘ë ¬ ì‹¤í–‰)
def scrape_url(state: URLState) -> ScrapingState:
    """ë‹¨ì¼ URL ìŠ¤í¬ë˜í•‘"""
    url = state["url"]
    print(f"ğŸŒ ìŠ¤í¬ë˜í•‘: {url}")

    # ì‹¤ì œë¡œëŠ” ì›¹ ìŠ¤í¬ë˜í•‘ ìˆ˜í–‰
    time.sleep(0.5)  # ì‹œë®¬ë ˆì´ì…˜

    # ê²°ê³¼ ë°˜í™˜ (ì „ì²´ ìƒíƒœì— ì¶”ê°€ë¨)
    return {
        "scraped_data": [{
            "url": url,
            "title": f"Title from {url}",
            "content": f"Content from {url}"
        }]
    }

# 4. ê²°ê³¼ í†µí•©
def aggregate_results(state: ScrapingState):
    """ìŠ¤í¬ë˜í•‘ ê²°ê³¼ í†µí•©"""
    print(f"âœ… {len(state['scraped_data'])}ê°œ ê²°ê³¼ ìˆ˜ì§‘ ì™„ë£Œ")
    return {}

# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(ScrapingState)

builder.add_node("prepare_urls", prepare_urls)
builder.add_node("scrape_url", scrape_url)
builder.add_node("aggregate_results", aggregate_results)

builder.add_edge(START, "prepare_urls")

# ì¡°ê±´ë¶€ ì—£ì§€ì—ì„œ Send ì‚¬ìš©
builder.add_conditional_edges(
    "prepare_urls",
    distribute_urls,  # Send ê°ì²´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    ["scrape_url"]
)

builder.add_edge("scrape_url", "aggregate_results")
builder.add_edge("aggregate_results", END)

graph = builder.compile()

# ì‹¤í–‰ - URL ê°œìˆ˜ëŠ” ë™ì !
result = graph.invoke({
    "urls": [
        "https://example.com",
        "https://example.org",
        "https://example.net",
        "https://example.io"
    ]
})

print("\n=== ìŠ¤í¬ë˜í•‘ ê²°ê³¼ ===")
for data in result["scraped_data"]:
    print(f"âœ… {data['url']}: {data['title']}")
```

## ğŸ¯ ì‹¤ìŠµ ë¬¸ì œ

### ë¬¸ì œ 1: Custom Reducer - ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ë¬¸ì„œ ê´€ë¦¬ (ë‚œì´ë„: â­â­)

**ìš”êµ¬ì‚¬í•­:**
ë¬¸ì„œì— ìš°ì„ ìˆœìœ„ë¥¼ ë¶€ì—¬í•˜ê³ , ë†’ì€ ìš°ì„ ìˆœìœ„ ë¬¸ì„œë¥¼ ì•ìª½ì— ìœ ì§€í•˜ëŠ” Custom Reducerë¥¼ êµ¬í˜„í•˜ì„¸ìš”.

1. ë¬¸ì„œ êµ¬ì¡°: `{"name": str, "priority": int}`
2. Reducer ë™ì‘:
   - ê¸°ì¡´ ë¬¸ì„œì™€ ìƒˆ ë¬¸ì„œë¥¼ ë³‘í•©
   - ìš°ì„ ìˆœìœ„ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
   - ê°™ì€ ì´ë¦„ì˜ ë¬¸ì„œëŠ” ë” ë†’ì€ ìš°ì„ ìˆœìœ„ë¡œ ì—…ë°ì´íŠ¸

**íŒíŠ¸:**
```python
def reduce_priority_docs(left: list | None, right: list | None) -> list:
    # ë¬¸ì„œ ë³‘í•© ë¡œì§
    # ì¤‘ë³µ ì œê±° (ê°™ì€ ì´ë¦„)
    # ìš°ì„ ìˆœìœ„ ì •ë ¬
    pass
```

---

### ë¬¸ì œ 2: MessagesState - ë‹¤êµ­ì–´ ì±„íŒ…ë´‡ (ë‚œì´ë„: â­â­â­)

**ìš”êµ¬ì‚¬í•­:**
ì‚¬ìš©ìì˜ ì–¸ì–´ë¥¼ ìë™ ê°ì§€í•˜ê³  í•´ë‹¹ ì–¸ì–´ë¡œ ì‘ë‹µí•˜ëŠ” ì±„íŒ…ë´‡ì„ êµ¬í˜„í•˜ì„¸ìš”.

1. State êµ¬ì„±:
   - `MessagesState` ìƒì†
   - `detected_language` í•„ë“œ ì¶”ê°€
   - `translation_enabled` í•„ë“œ ì¶”ê°€

2. ë…¸ë“œ êµ¬ì„±:
   - `detect_language`: ì–¸ì–´ ê°ì§€
   - `translate_if_needed`: í•„ìš”ì‹œ ë²ˆì—­
   - `generate_response`: ì‘ë‹µ ìƒì„±

3. ì§€ì› ì–¸ì–´: í•œêµ­ì–´, ì˜ì–´, ì¼ë³¸ì–´

---

### ë¬¸ì œ 3: ë³‘ë ¬ ì²˜ë¦¬ - ë©€í‹° ì†ŒìŠ¤ RAG ì‹œìŠ¤í…œ (ë‚œì´ë„: â­â­â­)

**ìš”êµ¬ì‚¬í•­:**
ì—¬ëŸ¬ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ë³‘ë ¬ë¡œ ê²€ìƒ‰í•˜ê³  ê²°ê³¼ë¥¼ í†µí•©í•˜ëŠ” RAG ì‹œìŠ¤í…œì„ êµ¬í˜„í•˜ì„¸ìš”.

1. ë°ì´í„° ì†ŒìŠ¤:
   - ë¡œì»¬ ë²¡í„° DB (Chroma)
   - ì›¹ ê²€ìƒ‰ (Tavily)
   - ë‚´ë¶€ API (Mock)

2. ë³‘ë ¬ ì²˜ë¦¬:
   - 3ê°œ ì†ŒìŠ¤ ë™ì‹œ ê²€ìƒ‰
   - ê° ì†ŒìŠ¤ë³„ ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
   - ì‹ ë¢°ë„ ê¸°ë°˜ ê²°ê³¼ ê°€ì¤‘ í†µí•©

3. ìµœì¢… ì‘ë‹µ:
   - í†µí•©ëœ ì»¨í…ìŠ¤íŠ¸ë¡œ ë‹µë³€ ìƒì„±
   - ì¶œì²˜ ì •ë³´ í¬í•¨

---

### ë¬¸ì œ 4: Send API - ë™ì  ë°ì´í„° íŒŒì´í”„ë¼ì¸ (ë‚œì´ë„: â­â­â­â­)

**ìš”êµ¬ì‚¬í•­:**
ë‹¤ì–‘í•œ í˜•ì‹ì˜ íŒŒì¼ë“¤ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ëŠ” ë°ì´í„° íŒŒì´í”„ë¼ì¸ì„ Send APIë¡œ êµ¬í˜„í•˜ì„¸ìš”.

1. ì§€ì› íŒŒì¼ í˜•ì‹: PDF, DOCX, TXT, CSV

2. ì²˜ë¦¬ íë¦„:
   - íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
   - íŒŒì¼ í˜•ì‹ë³„ë¡œ ë‹¤ë¥¸ ì²˜ë¦¬ ë…¸ë“œë¡œ ë¼ìš°íŒ…
   - ê° íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì¶”ì¶œ)
   - ì¶”ì¶œëœ í…ìŠ¤íŠ¸ í†µí•© ë° ìš”ì•½

3. Send API í™œìš©:
   - íŒŒì¼ í˜•ì‹ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ë…¸ë“œ ì„ íƒ
   - ê° íŒŒì¼ì— ê°œë³„ ìƒíƒœ ì „ë‹¬
   - ë³‘ë ¬ ì²˜ë¦¬ í›„ ìë™ í†µí•©

**íŒíŠ¸:**
```python
def route_by_file_type(state: PipelineState):
    return [
        Send(
            f"process_{get_file_type(file)}",
            {"file_path": file}
        )
        for file in state["files"]
    ]
```

## âœ… ì†”ë£¨ì…˜ ì˜ˆì‹œ

### ë¬¸ì œ 1 ì†”ë£¨ì…˜: ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ë¬¸ì„œ ê´€ë¦¬

```python
from typing import TypedDict, Annotated, List
from langgraph.graph import StateGraph, START, END

def reduce_priority_docs(left: list | None, right: list | None) -> list:
    """
    ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ë¬¸ì„œ ë³‘í•© Reducer

    - ì¤‘ë³µ ë¬¸ì„œëŠ” ë” ë†’ì€ ìš°ì„ ìˆœìœ„ë¡œ ì—…ë°ì´íŠ¸
    - ìš°ì„ ìˆœìœ„ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    """
    if not left:
        left = []
    if not right:
        right = []

    # ë¬¸ì„œ ë³‘í•© (ì´ë¦„ ê¸°ì¤€ ìµœê³  ìš°ì„ ìˆœìœ„ ìœ ì§€)
    doc_dict = {}

    for doc in left + right:
        name = doc["name"]
        if name not in doc_dict or doc["priority"] > doc_dict[name]["priority"]:
            doc_dict[name] = doc

    # ìš°ì„ ìˆœìœ„ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    result = sorted(doc_dict.values(), key=lambda x: x["priority"], reverse=True)

    return result

# ìƒíƒœ ì •ì˜
class DocumentState(TypedDict):
    query: str
    documents: Annotated[List[dict], reduce_priority_docs]

# ë…¸ë“œ ì •ì˜
def search_primary(state: DocumentState):
    """ì£¼ìš” ë¬¸ì„œ ê²€ìƒ‰"""
    return {
        "documents": [
            {"name": "doc1.pdf", "priority": 5},
            {"name": "doc2.pdf", "priority": 3},
            {"name": "doc3.pdf", "priority": 4}
        ]
    }

def search_secondary(state: DocumentState):
    """ì¶”ê°€ ë¬¸ì„œ ê²€ìƒ‰"""
    return {
        "documents": [
            {"name": "doc2.pdf", "priority": 8},  # ìš°ì„ ìˆœìœ„ ì—…ë°ì´íŠ¸!
            {"name": "doc4.pdf", "priority": 7},
            {"name": "doc5.pdf", "priority": 2}
        ]
    }

def display_results(state: DocumentState):
    """ê²°ê³¼ ì¶œë ¥"""
    print("\n=== ìµœì¢… ë¬¸ì„œ ëª©ë¡ (ìš°ì„ ìˆœìœ„ ìˆœ) ===")
    for i, doc in enumerate(state["documents"], 1):
        print(f"{i}. {doc['name']} (ìš°ì„ ìˆœìœ„: {doc['priority']})")
    return {}

# ê·¸ë˜í”„ êµ¬ì„±
workflow = StateGraph(DocumentState)

workflow.add_node("search_primary", search_primary)
workflow.add_node("search_secondary", search_secondary)
workflow.add_node("display_results", display_results)

workflow.add_edge(START, "search_primary")
workflow.add_edge("search_primary", "search_secondary")
workflow.add_edge("search_secondary", "display_results")
workflow.add_edge("display_results", END)

graph = workflow.compile()

# ì‹¤í–‰
result = graph.invoke({"query": "test"})

# ì˜ˆìƒ ì¶œë ¥:
# 1. doc2.pdf (ìš°ì„ ìˆœìœ„: 8)  # ì—…ë°ì´íŠ¸ë¨!
# 2. doc4.pdf (ìš°ì„ ìˆœìœ„: 7)
# 3. doc1.pdf (ìš°ì„ ìˆœìœ„: 5)
# 4. doc3.pdf (ìš°ì„ ìˆœìœ„: 4)
# 5. doc5.pdf (ìš°ì„ ìˆœìœ„: 2)
```

### ë¬¸ì œ 2 ì†”ë£¨ì…˜: ë‹¤êµ­ì–´ ì±„íŒ…ë´‡

```python
from typing import Optional
from langgraph.graph import MessagesState, StateGraph, START, END
from langchain_openai import ChatOpenAI

# ìƒíƒœ ì •ì˜
class MultilingualChatState(MessagesState):
    detected_language: Optional[str]
    translation_enabled: bool = False

llm = ChatOpenAI(model="gpt-4.1-mini")

# ì–¸ì–´ ê°ì§€ ë…¸ë“œ
def detect_language(state: MultilingualChatState):
    """ì‚¬ìš©ì ë©”ì‹œì§€ì˜ ì–¸ì–´ ê°ì§€"""
    user_message = state["messages"][-1].content

    prompt = f"""
    ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ê°ì§€í•˜ì„¸ìš”.
    ê°€ëŠ¥í•œ ì–¸ì–´: korean, english, japanese

    í…ìŠ¤íŠ¸: {user_message}

    ì–¸ì–´ë§Œ ì†Œë¬¸ìë¡œ ì‘ë‹µ:
    """

    language = llm.invoke(prompt).content.strip().lower()
    print(f"ğŸŒ ê°ì§€ëœ ì–¸ì–´: {language}")

    return {"detected_language": language}

# ë²ˆì—­ ë…¸ë“œ (í•„ìš”ì‹œ)
def translate_if_needed(state: MultilingualChatState):
    """ì˜ì–´ê°€ ì•„ë‹ˆë©´ ì˜ì–´ë¡œ ë²ˆì—­"""
    language = state.get("detected_language", "english")

    if language == "english":
        print("âœ… ë²ˆì—­ ë¶ˆí•„ìš”")
        return {}

    user_message = state["messages"][-1].content

    prompt = f"""
    ë‹¤ìŒ {language} í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”:

    {user_message}

    ë²ˆì—­ë§Œ ì¶œë ¥:
    """

    translated = llm.invoke(prompt).content
    print(f"ğŸ”„ ë²ˆì—­ ì™„ë£Œ: {translated[:50]}...")

    # ë²ˆì—­ëœ ë©”ì‹œì§€ë¥¼ ì¶”ê°€
    return {
        "messages": [("system", f"[Translated from {language}] {translated}")],
        "translation_enabled": True
    }

# ì‘ë‹µ ìƒì„± ë…¸ë“œ
def generate_response(state: MultilingualChatState):
    """ì‘ë‹µ ìƒì„± (ì›ë˜ ì–¸ì–´ë¡œ)"""
    language = state.get("detected_language", "english")
    translation_enabled = state.get("translation_enabled", False)

    # LLMì— ë©”ì‹œì§€ ì „ë‹¬
    ai_response = llm.invoke(state["messages"])

    # ì›ë˜ ì–¸ì–´ë¡œ ë²ˆì—­ (í•„ìš”ì‹œ)
    if translation_enabled and language != "english":
        prompt = f"""
        ë‹¤ìŒ ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ {language}ë¡œ ë²ˆì—­í•˜ì„¸ìš”:

        {ai_response.content}

        ë²ˆì—­ë§Œ ì¶œë ¥:
        """

        final_response = llm.invoke(prompt).content
        print(f"ğŸ”„ ì‘ë‹µì„ {language}ë¡œ ë²ˆì—­")
    else:
        final_response = ai_response.content

    return {"messages": [("assistant", final_response)]}

# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(MultilingualChatState)

builder.add_node("detect_language", detect_language)
builder.add_node("translate_if_needed", translate_if_needed)
builder.add_node("generate_response", generate_response)

builder.add_edge(START, "detect_language")
builder.add_edge("detect_language", "translate_if_needed")
builder.add_edge("translate_if_needed", "generate_response")
builder.add_edge("generate_response", END)

graph = builder.compile()

# í…ŒìŠ¤íŠ¸
test_messages = [
    "ì•ˆë…•í•˜ì„¸ìš”! LangGraphì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.",
    "Hello! Tell me about LangGraph.",
    "ã“ã‚“ã«ã¡ã¯ï¼LangGraphã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚"
]

for msg in test_messages:
    print(f"\n{'='*60}")
    print(f"ì…ë ¥: {msg}")
    result = graph.invoke({"messages": [("user", msg)]})
    print(f"ì‘ë‹µ: {result['messages'][-1].content}")
```

### ë¬¸ì œ 3 ì†”ë£¨ì…˜: ë©€í‹° ì†ŒìŠ¤ RAG ì‹œìŠ¤í…œ

```python
import operator
from typing import Annotated, List, Optional
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_community.tools.tavily_search import TavilySearchResults

class MultiSourceRAGState(TypedDict):
    query: str
    vector_results: Annotated[List[dict], operator.add]
    web_results: Annotated[List[dict], operator.add]
    api_results: Annotated[List[dict], operator.add]
    final_context: Optional[str]
    answer: Optional[str]

llm = ChatOpenAI(model="gpt-4.1-mini")

# ë³‘ë ¬ ê²€ìƒ‰ ë…¸ë“œë“¤
def search_vector_db(state: MultiSourceRAGState):
    """ë²¡í„° DB ê²€ìƒ‰"""
    print("ğŸ“Š ë²¡í„° DB ê²€ìƒ‰ ì¤‘...")

    # ì‹¤ì œë¡œëŠ” Chroma DB ì‚¬ìš©
    # db = Chroma(embedding_function=OpenAIEmbeddings())
    # results = db.similarity_search(state["query"], k=3)

    # Mock ê²°ê³¼
    results = [
        {"content": "ë²¡í„° DB ê²°ê³¼ 1", "confidence": 0.9},
        {"content": "ë²¡í„° DB ê²°ê³¼ 2", "confidence": 0.85}
    ]

    return {"vector_results": results}

def search_web(state: MultiSourceRAGState):
    """ì›¹ ê²€ìƒ‰"""
    print("ğŸŒ ì›¹ ê²€ìƒ‰ ì¤‘...")

    search_tool = TavilySearchResults(max_results=2)
    results = search_tool.invoke(state["query"])

    # ì‹ ë¢°ë„ ì¶”ê°€
    web_results = [
        {"content": r["content"], "confidence": 0.75}
        for r in results
    ]

    return {"web_results": web_results}

def search_api(state: MultiSourceRAGState):
    """ë‚´ë¶€ API ê²€ìƒ‰"""
    print("ğŸ”Œ API ê²€ìƒ‰ ì¤‘...")

    # Mock API ê²°ê³¼
    results = [
        {"content": "API ê²°ê³¼ 1", "confidence": 0.8}
    ]

    return {"api_results": results}

# ê²°ê³¼ í†µí•© ë…¸ë“œ
def integrate_results(state: MultiSourceRAGState):
    """ê²€ìƒ‰ ê²°ê³¼ í†µí•© ë° ê°€ì¤‘ í‰ê· """
    all_results = (
        state.get("vector_results", []) +
        state.get("web_results", []) +
        state.get("api_results", [])
    )

    # ì‹ ë¢°ë„ ê¸°ì¤€ ì •ë ¬
    sorted_results = sorted(all_results, key=lambda x: x["confidence"], reverse=True)

    # ìƒìœ„ 5ê°œ ì„ íƒ
    top_results = sorted_results[:5]

    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context_parts = []
    for i, r in enumerate(top_results, 1):
        context_parts.append(
            f"{i}. (ì‹ ë¢°ë„: {r['confidence']:.2f}) {r['content']}"
        )

    final_context = "\n".join(context_parts)

    print(f"âœ… {len(top_results)}ê°œ ê²°ê³¼ í†µí•© ì™„ë£Œ")

    return {"final_context": final_context}

# ë‹µë³€ ìƒì„± ë…¸ë“œ
def generate_answer(state: MultiSourceRAGState):
    """í†µí•©ëœ ì»¨í…ìŠ¤íŠ¸ë¡œ ë‹µë³€ ìƒì„±"""
    prompt = f"""
    ë‹¤ìŒ ì •ë³´ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

    ì§ˆë¬¸: {state['query']}

    ì°¸ê³  ìë£Œ:
    {state['final_context']}

    ë‹µë³€ (ì¶œì²˜ í¬í•¨):
    """

    answer = llm.invoke(prompt).content
    return {"answer": answer}

# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(MultiSourceRAGState)

builder.add_node("search_vector_db", search_vector_db)
builder.add_node("search_web", search_web)
builder.add_node("search_api", search_api)
builder.add_node("integrate_results", integrate_results)
builder.add_node("generate_answer", generate_answer)

# Fan-out: ë³‘ë ¬ ê²€ìƒ‰
builder.add_edge(START, "search_vector_db")
builder.add_edge(START, "search_web")
builder.add_edge(START, "search_api")

# Fan-in: í†µí•©
builder.add_edge("search_vector_db", "integrate_results")
builder.add_edge("search_web", "integrate_results")
builder.add_edge("search_api", "integrate_results")

builder.add_edge("integrate_results", "generate_answer")
builder.add_edge("generate_answer", END)

graph = builder.compile()

# ì‹¤í–‰
result = graph.invoke({"query": "LangGraphì˜ ì£¼ìš” ê¸°ëŠ¥ì€?"})

print("\n=== ìµœì¢… ë‹µë³€ ===")
print(result["answer"])
```

### ë¬¸ì œ 4 ì†”ë£¨ì…˜: ë™ì  ë°ì´í„° íŒŒì´í”„ë¼ì¸

```python
from langgraph.types import Send
from pathlib import Path
from typing import Dict

# ì „ì²´ ìƒíƒœ
class PipelineState(TypedDict):
    files: List[str]
    extracted_texts: Annotated[List[Dict[str, str]], operator.add]
    final_summary: Optional[str]

# ê°œë³„ íŒŒì¼ ìƒíƒœ
class FileState(TypedDict):
    file_path: str

def get_file_type(file_path: str) -> str:
    """íŒŒì¼ í™•ì¥ì ì¶”ì¶œ"""
    return Path(file_path).suffix[1:].lower()

# 1. íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
def collect_files(state: PipelineState):
    """ì²˜ë¦¬í•  íŒŒì¼ ëª©ë¡ í™•ì¸"""
    print(f"ğŸ“ ì´ {len(state['files'])}ê°œ íŒŒì¼ ë°œê²¬")
    return {}

# 2. ë™ì  ë¼ìš°íŒ… (Send ì‚¬ìš©)
def route_by_file_type(state: PipelineState):
    """íŒŒì¼ í˜•ì‹ë³„ë¡œ ì ì ˆí•œ ë…¸ë“œë¡œ ë¼ìš°íŒ…"""
    print("ğŸ”€ íŒŒì¼ í˜•ì‹ë³„ ë¼ìš°íŒ…...")

    sends = []
    for file_path in state["files"]:
        file_type = get_file_type(file_path)
        node_name = f"process_{file_type}"

        sends.append(
            Send(node_name, {"file_path": file_path})
        )
        print(f"  â†’ {file_path} â†’ {node_name}")

    return sends

# 3. íŒŒì¼ í˜•ì‹ë³„ ì²˜ë¦¬ ë…¸ë“œë“¤
def process_pdf(state: FileState) -> PipelineState:
    """PDF íŒŒì¼ ì²˜ë¦¬"""
    file_path = state["file_path"]
    print(f"ğŸ“„ PDF ì²˜ë¦¬: {file_path}")

    # ì‹¤ì œë¡œëŠ” PyPDF2, pdfplumber ë“± ì‚¬ìš©
    text = f"[PDF í…ìŠ¤íŠ¸ from {file_path}]"

    return {
        "extracted_texts": [{
            "file": file_path,
            "type": "pdf",
            "text": text
        }]
    }

def process_docx(state: FileState) -> PipelineState:
    """DOCX íŒŒì¼ ì²˜ë¦¬"""
    file_path = state["file_path"]
    print(f"ğŸ“ DOCX ì²˜ë¦¬: {file_path}")

    # ì‹¤ì œë¡œëŠ” python-docx ì‚¬ìš©
    text = f"[DOCX í…ìŠ¤íŠ¸ from {file_path}]"

    return {
        "extracted_texts": [{
            "file": file_path,
            "type": "docx",
            "text": text
        }]
    }

def process_txt(state: FileState) -> PipelineState:
    """TXT íŒŒì¼ ì²˜ë¦¬"""
    file_path = state["file_path"]
    print(f"ğŸ“ƒ TXT ì²˜ë¦¬: {file_path}")

    # ì‹¤ì œë¡œëŠ” íŒŒì¼ ì½ê¸°
    text = f"[TXT í…ìŠ¤íŠ¸ from {file_path}]"

    return {
        "extracted_texts": [{
            "file": file_path,
            "type": "txt",
            "text": text
        }]
    }

def process_csv(state: FileState) -> PipelineState:
    """CSV íŒŒì¼ ì²˜ë¦¬"""
    file_path = state["file_path"]
    print(f"ğŸ“Š CSV ì²˜ë¦¬: {file_path}")

    # ì‹¤ì œë¡œëŠ” pandas ì‚¬ìš©
    text = f"[CSV ë°ì´í„° from {file_path}]"

    return {
        "extracted_texts": [{
            "file": file_path,
            "type": "csv",
            "text": text
        }]
    }

# 4. í†µí•© ë° ìš”ì•½
def summarize_all(state: PipelineState):
    """ì¶”ì¶œëœ í…ìŠ¤íŠ¸ í†µí•© ë° ìš”ì•½"""
    print(f"\nâœ… {len(state['extracted_texts'])}ê°œ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")

    # ëª¨ë“  í…ìŠ¤íŠ¸ í†µí•©
    all_texts = "\n\n".join([
        f"[{item['type'].upper()}] {item['file']}\n{item['text']}"
        for item in state["extracted_texts"]
    ])

    # LLMìœ¼ë¡œ ìš”ì•½
    prompt = f"""
    ë‹¤ìŒ ë¬¸ì„œë“¤ì˜ ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ ìš”ì•½í•˜ì„¸ìš”:

    {all_texts}

    ì¢…í•© ìš”ì•½:
    """

    summary = llm.invoke(prompt).content

    return {"final_summary": summary}

# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(PipelineState)

builder.add_node("collect_files", collect_files)
builder.add_node("process_pdf", process_pdf)
builder.add_node("process_docx", process_docx)
builder.add_node("process_txt", process_txt)
builder.add_node("process_csv", process_csv)
builder.add_node("summarize_all", summarize_all)

builder.add_edge(START, "collect_files")

# ì¡°ê±´ë¶€ ì—£ì§€ì—ì„œ Send ì‚¬ìš©
builder.add_conditional_edges(
    "collect_files",
    route_by_file_type,
    ["process_pdf", "process_docx", "process_txt", "process_csv"]
)

# ëª¨ë“  ì²˜ë¦¬ ë…¸ë“œ â†’ ìš”ì•½
builder.add_edge("process_pdf", "summarize_all")
builder.add_edge("process_docx", "summarize_all")
builder.add_edge("process_txt", "summarize_all")
builder.add_edge("process_csv", "summarize_all")

builder.add_edge("summarize_all", END)

graph = builder.compile()

# ì‹¤í–‰
result = graph.invoke({
    "files": [
        "report.pdf",
        "notes.docx",
        "readme.txt",
        "data.csv",
        "summary.pdf",
        "analysis.txt"
    ]
})

print("\n=== ìµœì¢… ìš”ì•½ ===")
print(result["final_summary"])
```

## ğŸš€ ì‹¤ë¬´ í™œìš© ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ê³ ê¸‰ ë¬¸ì„œ íŒ©íŠ¸ì²´í¬ ì‹œìŠ¤í…œ

ì‹¤ë¬´ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì¢…í•©ì ì¸ íŒ©íŠ¸ì²´í¬ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

```python
from typing import Annotated, List, Optional
from pydantic import BaseModel, Field
from langgraph.types import Send
import operator

# íŒ©íŠ¸ì²´í¬ ê²°ê³¼ ëª¨ë¸
class FactCheckResult(BaseModel):
    sentence: str
    score: float
    reasoning: str
    sources: List[str]

# ì „ì²´ ìƒíƒœ
class FactCheckState(TypedDict):
    query: str
    search_results: Optional[str]
    summary: Optional[str]
    fact_checks: Annotated[List[FactCheckResult], operator.add]
    overall_reliability: Optional[float]

# ê°œë³„ ë¬¸ì¥ ìƒíƒœ
class SentenceState(TypedDict):
    sentence: str
    search_results: str  # ì°¸ê³  ìë£Œ

llm = ChatOpenAI(model="gpt-4.1-mini")

# 1. ê²€ìƒ‰ ë…¸ë“œ
def search_information(state: FactCheckState):
    """ì£¼ì œì— ëŒ€í•œ ì •ë³´ ê²€ìƒ‰"""
    search_tool = TavilySearchResults(max_results=5)
    query = state["query"]

    print(f"ğŸ” ê²€ìƒ‰: {query}")

    results = search_tool.invoke(query)

    # ê²€ìƒ‰ ê²°ê³¼ í…ìŠ¤íŠ¸ í†µí•©
    search_text = "\n\n".join([
        f"[ì¶œì²˜ {i+1}] {r['content']}"
        for i, r in enumerate(results)
    ])

    return {"search_results": search_text}

# 2. ìš”ì•½ ë…¸ë“œ
def generate_summary(state: FactCheckState):
    """ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½"""
    prompt = f"""
    ë‹¤ìŒ ì •ë³´ë¥¼ 3-4ê°œì˜ í•µì‹¬ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.
    ê° ë¬¸ì¥ì€ í•œ ì¤„ì”© ë¶„ë¦¬í•˜ì„¸ìš”.

    ì •ë³´:
    {state['search_results']}

    ìš”ì•½:
    """

    summary = llm.invoke(prompt).content
    print("ğŸ“ ìš”ì•½ ì™„ë£Œ")

    return {"summary": summary}

# 3. ë¬¸ì¥ ë¶„ë°° ë…¸ë“œ (Send ì‚¬ìš©)
def distribute_sentences(state: FactCheckState):
    """ê° ë¬¸ì¥ì„ ë³‘ë ¬ íŒ©íŠ¸ì²´í¬"""
    if not state["summary"]:
        return []

    sentences = [s.strip() for s in state["summary"].split("\n") if s.strip()]

    print(f"ğŸ”€ {len(sentences)}ê°œ ë¬¸ì¥ ë³‘ë ¬ íŒ©íŠ¸ì²´í¬")

    return [
        Send(
            "fact_check_sentence",
            {
                "sentence": sentence,
                "search_results": state["search_results"]
            }
        )
        for sentence in sentences
    ]

# 4. ê°œë³„ íŒ©íŠ¸ì²´í¬ ë…¸ë“œ
def fact_check_sentence(state: SentenceState) -> FactCheckState:
    """ë‹¨ì¼ ë¬¸ì¥ íŒ©íŠ¸ì²´í¬"""
    sentence = state["sentence"]
    search_results = state["search_results"]

    print(f"âœ… íŒ©íŠ¸ì²´í¬: {sentence[:50]}...")

    prompt = f"""
    ë‹¤ìŒ ë¬¸ì¥ì˜ ì‚¬ì‹¤ ì—¬ë¶€ë¥¼ ê²€ì¦í•˜ì„¸ìš”.

    ë¬¸ì¥: {sentence}

    ì°¸ê³  ìë£Œ:
    {search_results}

    ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”:
    {{
        "score": 0.0-1.0 ì‚¬ì´ì˜ ì‹ ë¢°ë„ ì ìˆ˜,
        "reasoning": "í‰ê°€ ê·¼ê±° (2-3ë¬¸ì¥)",
        "sources": ["ê´€ë ¨ ì¶œì²˜ ë²ˆí˜¸ë“¤"]
    }}
    """

    fact_check_llm = llm.with_structured_output(FactCheckResult)

    try:
        result = fact_check_llm.invoke(prompt)
        result.sentence = sentence
    except:
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
        result = FactCheckResult(
            sentence=sentence,
            score=0.5,
            reasoning="í‰ê°€ ì‹¤íŒ¨",
            sources=[]
        )

    return {"fact_checks": [result]}

# 5. ì¢…í•© í‰ê°€ ë…¸ë“œ
def calculate_overall_reliability(state: FactCheckState):
    """ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚°"""
    fact_checks = state.get("fact_checks", [])

    if not fact_checks:
        return {"overall_reliability": 0.0}

    # í‰ê·  ì‹ ë¢°ë„
    avg_score = sum(fc.score for fc in fact_checks) / len(fact_checks)

    print(f"\nğŸ“Š ì „ì²´ ì‹ ë¢°ë„: {avg_score:.2f}")

    # ìƒì„¸ ê²°ê³¼ ì¶œë ¥
    print("\n=== ë¬¸ì¥ë³„ íŒ©íŠ¸ì²´í¬ ê²°ê³¼ ===")
    for i, fc in enumerate(fact_checks, 1):
        print(f"\n{i}. {fc.sentence}")
        print(f"   ì‹ ë¢°ë„: {fc.score:.2f}")
        print(f"   ê·¼ê±°: {fc.reasoning}")
        print(f"   ì¶œì²˜: {', '.join(fc.sources)}")

    return {"overall_reliability": avg_score}

# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(FactCheckState)

builder.add_node("search_information", search_information)
builder.add_node("generate_summary", generate_summary)
builder.add_node("fact_check_sentence", fact_check_sentence)
builder.add_node("calculate_overall_reliability", calculate_overall_reliability)

builder.add_edge(START, "search_information")
builder.add_edge("search_information", "generate_summary")

# ì¡°ê±´ë¶€ ì—£ì§€ì—ì„œ Send ì‚¬ìš©
builder.add_conditional_edges(
    "generate_summary",
    distribute_sentences,
    ["fact_check_sentence"]
)

builder.add_edge("fact_check_sentence", "calculate_overall_reliability")
builder.add_edge("calculate_overall_reliability", END)

graph = builder.compile()

# ì‹¤í–‰
result = graph.invoke({
    "query": "ì¸ê³µì§€ëŠ¥ì˜ í™˜ê²½ ì˜í–¥ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”"
})

print(f"\n{'='*60}")
print(f"ìš”ì•½:\n{result['summary']}")
print(f"\nì „ì²´ ì‹ ë¢°ë„: {result['overall_reliability']:.2%}")
```

### ì˜ˆì‹œ 2: ì‹¤ì‹œê°„ ë©€í‹° ì—ì´ì „íŠ¸ ë‰´ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ

ì—¬ëŸ¬ ì—ì´ì „íŠ¸ê°€ ë³‘ë ¬ë¡œ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

```python
from typing import Annotated, List
from enum import Enum

class NewsTopic(str, Enum):
    TECHNOLOGY = "technology"
    BUSINESS = "business"
    POLITICS = "politics"
    SCIENCE = "science"

# ì „ì²´ ìƒíƒœ
class NewsAnalysisState(TypedDict):
    topics: List[NewsTopic]
    topic_analyses: Annotated[List[dict], operator.add]
    summary_report: Optional[str]
    trending_keywords: Optional[List[str]]

# ê°œë³„ í† í”½ ìƒíƒœ
class TopicState(TypedDict):
    topic: NewsTopic

llm = ChatOpenAI(model="gpt-4.1-mini")

# 1. í† í”½ ì„ íƒ ë…¸ë“œ
def select_topics(state: NewsAnalysisState):
    """ë¶„ì„í•  í† í”½ í™•ì¸"""
    topics = state.get("topics", [NewsTopic.TECHNOLOGY])
    print(f"ğŸ“° {len(topics)}ê°œ í† í”½ ë¶„ì„ ì‹œì‘")
    return {}

# 2. í† í”½ë³„ ë¶„ë°° (Send ì‚¬ìš©)
def distribute_topics(state: NewsAnalysisState):
    """ê° í† í”½ì„ ë³‘ë ¬ ë¶„ì„"""
    return [
        Send("analyze_topic", {"topic": topic})
        for topic in state["topics"]
    ]

# 3. ê°œë³„ í† í”½ ë¶„ì„ ë…¸ë“œ
def analyze_topic(state: TopicState) -> NewsAnalysisState:
    """ë‹¨ì¼ í† í”½ ë‰´ìŠ¤ ë¶„ì„"""
    topic = state["topic"]
    print(f"ğŸ” {topic.value} ë‰´ìŠ¤ ë¶„ì„ ì¤‘...")

    # ì‹¤ì œë¡œëŠ” ë‰´ìŠ¤ API í˜¸ì¶œ
    search_tool = TavilySearchResults(max_results=5)
    query = f"latest {topic.value} news"

    results = search_tool.invoke(query)

    # LLMìœ¼ë¡œ ìš”ì•½ ë° ë¶„ì„
    prompt = f"""
    ë‹¤ìŒ {topic.value} ë‰´ìŠ¤ë“¤ì„ ë¶„ì„í•˜ì„¸ìš”:

    {chr(10).join([r['content'] for r in results[:3]])}

    ë‹¤ìŒ í•­ëª©ì„ JSONìœ¼ë¡œ ì œê³µ:
    {{
        "summary": "í•µì‹¬ ìš”ì•½ (3ë¬¸ì¥)",
        "sentiment": "positive/neutral/negative",
        "key_events": ["ì£¼ìš” ì´ë²¤íŠ¸ 3ê°œ"],
        "keywords": ["í‚¤ì›Œë“œ 5ê°œ"]
    }}
    """

    analysis = llm.invoke(prompt).content

    # ê°„ë‹¨í•œ íŒŒì‹± (ì‹¤ì œë¡œëŠ” structured output ì‚¬ìš©)
    return {
        "topic_analyses": [{
            "topic": topic.value,
            "analysis": analysis,
            "timestamp": "2025-10-31"
        }]
    }

# 4. íŠ¸ë Œë“œ í‚¤ì›Œë“œ ì¶”ì¶œ ë…¸ë“œ
def extract_trending_keywords(state: NewsAnalysisState):
    """ëª¨ë“  í† í”½ì—ì„œ ê³µí†µ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    analyses = state.get("topic_analyses", [])

    # ëª¨ë“  ë¶„ì„ í†µí•©
    all_analyses = "\n\n".join([
        f"[{a['topic']}]\n{a['analysis']}"
        for a in analyses
    ])

    prompt = f"""
    ë‹¤ìŒ ë‰´ìŠ¤ ë¶„ì„ë“¤ì—ì„œ ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ íŠ¸ë Œë“œ í‚¤ì›Œë“œ 10ê°œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”:

    {all_analyses}

    í‚¤ì›Œë“œë§Œ ì‰¼í‘œë¡œ êµ¬ë¶„:
    """

    keywords_text = llm.invoke(prompt).content
    keywords = [k.strip() for k in keywords_text.split(",")][:10]

    print(f"ğŸ”¥ íŠ¸ë Œë”© í‚¤ì›Œë“œ: {', '.join(keywords[:5])}...")

    return {"trending_keywords": keywords}

# 5. ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ë…¸ë“œ
def generate_summary_report(state: NewsAnalysisState):
    """ìµœì¢… ì¢…í•© ë¦¬í¬íŠ¸"""
    analyses = state.get("topic_analyses", [])
    keywords = state.get("trending_keywords", [])

    prompt = f"""
    ë‹¤ìŒ í† í”½ë³„ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ì¢…í•© ë‰´ìŠ¤ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”:

    í† í”½ë³„ ë¶„ì„:
    {chr(10).join([f"- {a['topic']}: {a['analysis'][:200]}..." for a in analyses])}

    íŠ¸ë Œë”© í‚¤ì›Œë“œ: {', '.join(keywords)}

    ì¢…í•© ë¦¬í¬íŠ¸ (5ë¬¸ì¥):
    """

    report = llm.invoke(prompt).content

    return {"summary_report": report}

# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(NewsAnalysisState)

builder.add_node("select_topics", select_topics)
builder.add_node("analyze_topic", analyze_topic)
builder.add_node("extract_trending_keywords", extract_trending_keywords)
builder.add_node("generate_summary_report", generate_summary_report)

builder.add_edge(START, "select_topics")

builder.add_conditional_edges(
    "select_topics",
    distribute_topics,
    ["analyze_topic"]
)

builder.add_edge("analyze_topic", "extract_trending_keywords")
builder.add_edge("extract_trending_keywords", "generate_summary_report")
builder.add_edge("generate_summary_report", END)

graph = builder.compile()

# ì‹¤í–‰
result = graph.invoke({
    "topics": [
        NewsTopic.TECHNOLOGY,
        NewsTopic.BUSINESS,
        NewsTopic.SCIENCE
    ]
})

print("\n" + "="*60)
print("ğŸ“Š ì¢…í•© ë‰´ìŠ¤ ë¦¬í¬íŠ¸")
print("="*60)
print(f"\n{result['summary_report']}")
print(f"\nğŸ”¥ íŠ¸ë Œë”© í‚¤ì›Œë“œ:")
print(", ".join(result['trending_keywords']))
```

## ğŸ“– ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [LangGraph Reducer ê°€ì´ë“œ](https://langchain-ai.github.io/langgraph/how-tos/state-reducers/)
- [MessagesState API ë ˆí¼ëŸ°ìŠ¤](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.MessagesState)
- [Send API ë¬¸ì„œ](https://langchain-ai.github.io/langgraph/how-tos/map-reduce/)
- [ë³‘ë ¬ ì²˜ë¦¬ íŒ¨í„´](https://langchain-ai.github.io/langgraph/how-tos/branching/)

### ì¶”ê°€ í•™ìŠµ ìë£Œ
- [Map-Reduce íŒ¨í„´ ì‹¤ì „ ì˜ˆì œ](https://github.com/langchain-ai/langgraph/tree/main/examples/map-reduce)
- [Custom Reducer ê³ ê¸‰ í™œìš©](https://langchain-ai.github.io/langgraph/tutorials/custom-reducers/)
- [ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™” ê°€ì´ë“œ](https://python.langchain.com/docs/langgraph/performance)

### ê´€ë ¨ ê¸°ìˆ  ìŠ¤íƒ
- **Pydantic**: ë°ì´í„° ê²€ì¦ - [Pydantic ë¬¸ì„œ](https://docs.pydantic.dev/)
- **Tavily Search**: ì›¹ ê²€ìƒ‰ API - [Tavily ë¬¸ì„œ](https://tavily.com/docs)
- **Operator ëª¨ë“ˆ**: Python ë‚´ì¥ ì—°ì‚°ì - [Python ê³µì‹ ë¬¸ì„œ](https://docs.python.org/3/library/operator.html)

### ë³‘ë ¬ ì²˜ë¦¬ íŒ¨í„´ ì°¸ê³ 
- **Fan-out/Fan-in íŒ¨í„´**: [Martin Fowler's Enterprise Patterns](https://www.enterpriseintegrationpatterns.com/patterns/messaging/BroadcastAggregate.html)
- **Map-Reduce**: [Googleì˜ MapReduce ë…¼ë¬¸](https://research.google/pubs/pub62/)

---

**ë‹¤ìŒ ë‹¨ê³„:**
- ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ì—ì„œ Reducerì™€ Send API ì¡°í•©í•˜ê¸°
- ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§ êµ¬í˜„
- ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”
- Human-in-the-Loop íŒ¨í„´ê³¼ í†µí•©í•˜ê¸°
