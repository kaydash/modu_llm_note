# W1_003_LangChain_Components.md - LangChain ê¸°ë³¸ êµ¬ì¡°ì™€ ì»´í¬ë„ŒíŠ¸

## ğŸ¯ í•™ìŠµ ëª©í‘œ
- LangChainì˜ ê¸°ë³¸ ê°œë…ê³¼ ì•„í‚¤í…ì²˜ ì´í•´
- LangChain í•µì‹¬ ì»´í¬ë„ŒíŠ¸ í™œìš©ë²• í•™ìŠµ
- ëª¨ë¸, ë©”ì‹œì§€, í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿, ì¶œë ¥ íŒŒì„œ ì‹¤ì „ ì‚¬ìš©ë²• ìŠµë“
- ì²´ì¸ êµ¬ì„±ì„ í†µí•œ íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ëŠ¥ë ¥ ê°œë°œ

## ğŸ“š í•µì‹¬ ê°œë…

### LangChain ê°œë…
- **LangChain**: LLM ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬
- **Chain**: ì‘ì—…ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” íŒŒì´í”„ë¼ì¸ êµ¬ì¡°
- **Agent**: ììœ¨ì  ì˜ì‚¬ê²°ì •ì´ ê°€ëŠ¥í•œ ì‹¤í–‰ ë‹¨ìœ„
- **ëª¨ë“ˆì„±**: ë…ë¦½ì ì¸ ì»´í¬ë„ŒíŠ¸ë“¤ì„ ì¡°í•©í•´ ë³µì¡í•œ ì‹œìŠ¤í…œ êµ¬í˜„ ê°€ëŠ¥

### ì»´í¬ë„ŒíŠ¸ êµ¬ì¡°
- **ì–¸ì–´ ì²˜ë¦¬ ê¸°ëŠ¥**: LLM/ChatModelì´ ì¤‘ì‹¬, Promptì™€ Memoryë¡œ ëŒ€í™” ê´€ë¦¬
- **ë¬¸ì„œ ì²˜ë¦¬ì™€ ê²€ìƒ‰**: Document Loader, Text Splitter, Embedding, Vectorstore
- **í†µí•© ì¸í„°í˜ì´ìŠ¤**: ë‹¤ì–‘í•œ ëª¨ë¸ ì œê³µìë¥¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥

## ğŸ”§ í™˜ê²½ ì„¤ì •

### í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
```bash
# UV íŒ¨í‚¤ì§€ ë§¤ë‹ˆì € ì‚¬ìš© ì‹œ
uv add ipykernel python-dotenv langchain langchain-openai langchain-google-genai

# pip ì‚¬ìš© ì‹œ
pip install ipykernel python-dotenv langchain langchain-openai langchain-google-genai
```

### í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
```bash
# .env íŒŒì¼ ìƒì„±
OPENAI_API_KEY=your_openai_api_key_here
GOOGLE_API_KEY=your_google_api_key_here
```

### ê¸°ë³¸ í™˜ê²½ ë¡œë“œ
```python
from dotenv import load_dotenv
load_dotenv()
```

## ğŸ’» ì½”ë“œ ì˜ˆì œ

### 1. ëª¨ë¸ (Models) í™œìš©

#### ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ
```python
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI

load_dotenv()

# Gemini ëª¨ë¸ ì´ˆê¸°í™”
gemini_model = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0)

# OpenAI ëª¨ë¸ ì´ˆê¸°í™”
openai_model = ChatOpenAI(model="gpt-4.1-mini", temperature=0)

# ê° ëª¨ë¸ ì‘ë‹µ ë¹„êµ
gemini_response = gemini_model.invoke("ì•ˆë…•í•˜ì„¸ìš”!")
openai_response = openai_model.invoke("ì•ˆë…•í•˜ì„¸ìš”!")

print("Gemini ë‹µë³€:", gemini_response.content)
print("OpenAI ë‹µë³€:", openai_response.content)
```

#### ì‘ë‹µ ê°ì²´ ë©”íƒ€ë°ì´í„° ë¶„ì„
```python
# ì‘ë‹µ ê°ì²´ êµ¬ì¡° í™•ì¸
print("ì‘ë‹µ íƒ€ì…:", type(gemini_response))
print("ë©”ì‹œì§€ ë‚´ìš©:", gemini_response.content)
print("ë©”íƒ€ë°ì´í„°:", gemini_response.response_metadata)
print("ì‚¬ìš©ëŸ‰ ì •ë³´:", gemini_response.usage_metadata)
```

### 2. ë©”ì‹œì§€ (Messages) ì‹œìŠ¤í…œ

#### HumanMessage ì‚¬ìš©
```python
from langchain_core.messages import HumanMessage
from langchain_google_genai import ChatGoogleGenerativeAI

model = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)

# ì‚¬ìš©ì ë©”ì‹œì§€ ìƒì„±
human_message = HumanMessage(content="Gloryë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”.")

# ë²ˆì—­ ìš”ì²­
response = model.invoke([human_message])
print("ë²ˆì—­ ê²°ê³¼:", response.content)
```

#### SystemMessageì™€ HumanMessage ì¡°í•©
```python
from langchain_core.messages import SystemMessage, HumanMessage

# ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ ì—­í•  ì„¤ì •
system_msg = SystemMessage(content="ë‹¹ì‹ ì€ ì˜ì–´ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.")
human_msg = HumanMessage(content="Glory")

# ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬
messages = [system_msg, human_msg]
response = model.invoke(messages)

print("ë‹µë³€:", response.content)  # ì¶œë ¥: "ì˜ê´‘"
```

### 3. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (Prompt Template)

#### ê¸°ë³¸ ë¬¸ìì—´ í…œí”Œë¦¿
```python
from langchain_core.prompts import PromptTemplate

# í…œí”Œë¦¿ ìƒì„±
template = PromptTemplate.from_template("{topic}ì— ëŒ€í•œ ì´ì•¼ê¸°ë¥¼ í•´ì¤˜")

# í…œí”Œë¦¿ ì‚¬ìš©
prompt = template.invoke({"topic": "ê³ ì–‘ì´"})
print(prompt)  # StringPromptValue(text='ê³ ì–‘ì´ì— ëŒ€í•œ ì´ì•¼ê¸°ë¥¼ í•´ì¤˜')
```

#### ì±„íŒ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
```python
from langchain_core.prompts import ChatPromptTemplate

# ì±„íŒ… í…œí”Œë¦¿ ìƒì„±
template = ChatPromptTemplate.from_messages([
    ("system", "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ë¹„ì„œì…ë‹ˆë‹¤"),
    ("user", "{subject}ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”")
])

# í…œí”Œë¦¿ ì‚¬ìš©
prompt = template.invoke({"subject": "ì¸ê³µì§€ëŠ¥"})
print(prompt.messages)
```

#### MessagesPlaceholder í™œìš©
```python
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage

# ë©”ì‹œì§€ í”Œë ˆì´ìŠ¤í™€ë” í¬í•¨ í…œí”Œë¦¿
template = ChatPromptTemplate.from_messages([
    ("system", "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ë¹„ì„œì…ë‹ˆë‹¤"),
    MessagesPlaceholder("chat_history")  # ì±„íŒ… ê¸°ë¡ì„ ìœ„í•œ í”Œë ˆì´ìŠ¤í™€ë”
])

# ì±„íŒ… íˆìŠ¤í† ë¦¬ì™€ í•¨ê»˜ ì‚¬ìš©
prompt = template.invoke({
    "chat_history": [
        HumanMessage(content="ì•ˆë…•í•˜ì„¸ìš”! ì œ ì´ë¦„ì€ ìŠ¤í‹°ë¸Œì…ë‹ˆë‹¤."),
        AIMessage(content="ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"),
        HumanMessage(content="ì œ ì´ë¦„ì„ ê¸°ì–µí•˜ë‚˜ìš”?")
    ]
})

print(prompt.messages)
```

### 4. ì¶œë ¥ íŒŒì„œ (Output Parser)

#### ê¸°ë³¸ ë¬¸ìì—´ íŒŒì„œ
```python
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

# íŒŒì´í”„ë¼ì¸ êµ¬ì„±
parser = StrOutputParser()
prompt = PromptTemplate.from_template("ë„ì‹œ {city}ì˜ íŠ¹ì§•ì„ ì•Œë ¤ì£¼ì„¸ìš”")
model = ChatOpenAI(model='gpt-4.1-mini')

# ì²´ì¸ ìƒì„± ë° ì‹¤í–‰
chain = prompt | model | parser
result = chain.invoke({"city": "ì„œìš¸"})

print(result)  # ë¬¸ìì—´ í˜•íƒœì˜ ì‘ë‹µ
```

#### êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì„œ
```python
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate

# Pydantic ëª¨ë¸ë¡œ ì¶œë ¥ êµ¬ì¡° ì •ì˜
class CityInfo(BaseModel):
    name: str = Field(description="ë„ì‹œ ì´ë¦„")
    description: str = Field(description="ë„ì‹œì˜ íŠ¹ì§•")

# êµ¬ì¡°í™”ëœ ì¶œë ¥ ëª¨ë¸ ìƒì„±
prompt = PromptTemplate.from_template("ë„ì‹œ {city}ì˜ íŠ¹ì§•ì„ ì•Œë ¤ì£¼ì„¸ìš”.")
model = ChatOpenAI(model="gpt-4.1-mini", temperature=0)
structured_model = model.with_structured_output(CityInfo)

# ì²´ì¸ ì‹¤í–‰
chain = prompt | structured_model
result = chain.invoke({"city": "ì„œìš¸"})

print(f"ë„ì‹œ ì´ë¦„: {result.name}")
print(f"íŠ¹ì§•: {result.description}")
```

## ğŸš€ ì‹¤ìŠµí•´ë³´ê¸°

### ì‹¤ìŠµ 1: ë‹¤ì¤‘ ëª¨ë¸ í…ìŠ¤íŠ¸ ìƒì„±
**ëª©í‘œ**: Gemini ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„±í•˜ê³  ì‘ë‹µ ê°ì²´ í™•ì¸
```python
# ì½”ë“œë¥¼ ì‘ì„±í•´ë³´ì„¸ìš”
from langchain_google_genai import ChatGoogleGenerativeAI

# Gemini ëª¨ë¸ ì´ˆê¸°í™”
gemini = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash",
    temperature=0,
    max_tokens=None,
    timeout=None,
    max_retries=2,
)

# ë©”ì‹œì§€ ì „ì†¡ ë° ì‘ë‹µ í™•ì¸
response = gemini.invoke("ì•ˆë…•í•˜ì„¸ìš”!")

# ê²°ê³¼ ë¶„ì„
print("ë‹µë³€:", response.content)
print("ë©”íƒ€ë°ì´í„°:", response.response_metadata)
```

### ì‹¤ìŠµ 2: ì±„íŒ… ë©”ì‹œì§€ ì‹œìŠ¤í…œ í™œìš©
**ëª©í‘œ**: ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì¡°í•©í•˜ì—¬ ë²ˆì—­ ì‹œìŠ¤í…œ êµ¬í˜„
```python
# ì½”ë“œë¥¼ ì‘ì„±í•´ë³´ì„¸ìš”
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_google_genai import ChatGoogleGenerativeAI

# ëª¨ë¸ ë° ë©”ì‹œì§€ êµ¬ì„±
gemini = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)
system_msg = SystemMessage(content="ë‹¹ì‹ ì€ ì˜ì–´ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.")
human_message = HumanMessage(content="Glory")

# ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
messages = [system_msg, human_message]
response = gemini.invoke(messages)

print("ë‹µë³€:", response.content)
print("ë©”íƒ€ë°ì´í„°:", response.response_metadata)
```

### ì‹¤ìŠµ 3: í…ìŠ¤íŠ¸ ìš”ì•½ í…œí”Œë¦¿ êµ¬í˜„
**ëª©í‘œ**: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì‚¬ìš©í•œ ìš”ì•½ ì‹œìŠ¤í…œ êµ¬ì¶•
```python
# ì½”ë“œë¥¼ ì‘ì„±í•´ë³´ì„¸ìš”
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate

# ëª¨ë¸ ë° í…œí”Œë¦¿ êµ¬ì„±
gemini = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)

template = ChatPromptTemplate.from_messages([
    ("system", "ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ìš”ì•½ì„ ì˜í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."),
    ("user", "ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ 1~2 ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ ë‚´ìš©ì„ ìœ„ì£¼ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”: {text}")
])

# ìš”ì•½ ì²´ì¸ ìƒì„±
summarization_chain = template | gemini

# í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
text = """
ì¸ê³µì§€ëŠ¥ì€ ì»´í“¨í„° ì‹œìŠ¤í…œì´ ì¸ê°„ì˜ ì§€ëŠ¥ì„ ëª¨ë°©í•˜ì—¬ í•™ìŠµ, ì¶”ë¡ , ë¬¸ì œ í•´ê²° ë“±ì„ ìˆ˜í–‰í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.
ì¸ê³µì§€ëŠ¥ì€ ë¨¸ì‹ ëŸ¬ë‹, ë”¥ëŸ¬ë‹, ìì—°ì–´ ì²˜ë¦¬ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë˜ë©°, ììœ¨ì£¼í–‰ì°¨, ìŒì„± ì¸ì‹, ì´ë¯¸ì§€ ë¶„ì„ ë“± ì—¬ëŸ¬ ì‘ìš© í”„ë¡œê·¸ë¨ì— ì ìš©ë©ë‹ˆë‹¤.
ìƒì„±í˜• ì¸ê³µì§€ëŠ¥ì€ í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ìŒì•… ë“± ë‹¤ì–‘í•œ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë˜ë©°, ì°½ì˜ì ì¸ ì‘ì—…ì—ì„œë„ í° ì—­í• ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
"""

response = summarization_chain.invoke({"text": text})
print("ë‹µë³€:", response.content)
```

### ì‹¤ìŠµ 4: êµ¬ì¡°í™”ëœ ë‰´ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ
**ëª©í‘œ**: Pydantic ëª¨ë¸ì„ í™œìš©í•œ êµ¬ì¡°í™”ëœ ì¶œë ¥ ì‹œìŠ¤í…œ êµ¬í˜„
```python
# ì½”ë“œë¥¼ ì‘ì„±í•´ë³´ì„¸ìš”
from typing import Optional
from pydantic import BaseModel, Field, confloat
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate

# ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ êµ¬ì¡° ì •ì˜
class NewsAnalysis(BaseModel):
    ì–¸ë¡ ì‚¬: str = Field(description="ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì–¸ë¡ ì‚¬ ì´ë¦„")
    ê¸°ì‚¬_ì œëª©: str = Field(description="ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì œëª©", alias="ê¸°ì‚¬ ì œëª©")
    ì‘ì„±ì: str = Field(description="ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì‘ì„±ì")
    ì‘ì„±ì¼: str = Field(description="ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì‘ì„±ì¼")
    ìš”ì•½: str = Field(description="ë‰´ìŠ¤ ê¸°ì‚¬ ë‚´ìš©ì˜ ê°„ê²°í•œ ìš”ì•½ (20-30ì)")
    ë¶„ì•¼: str = Field(description="ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ë¶„ì•¼ (ê²½ì œ/ì‚¬íšŒ/ì •ì¹˜/êµ­ì œ/ë¬¸í™”/IT/ê³¼í•™ ë“±)")
    ì¤‘ìš”ë„: confloat(ge=0.0, le=1.0) = Field(description="ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì¤‘ìš”ë„ (0.00-1.00)")
    confidence: confloat(ge=0.0, le=1.0) = Field(description="ì¶”ì¶œì˜ í™•ì‹ ë„ (0.00-1.00)")

# ëª¨ë¸ ë° êµ¬ì¡°í™”ëœ ì¶œë ¥ ì„¤ì •
gemini = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)
structured_gemini = gemini.with_structured_output(NewsAnalysis)

# ë¶„ì„ í…œí”Œë¦¿
template = ChatPromptTemplate.from_messages([
    ("system", "ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ìš”ì•½ê³¼ ë¶„ì„ì„ ì˜í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."),
    ("user", """
     ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ ì–¸ë¡ ì‚¬, ê¸°ì‚¬ ì œëª©, ì‘ì„±ì, ì‘ì„±ì¼, ê¸°ì‚¬ ë‚´ìš© ìš”ì•½(20-30ì), ë¶„ì•¼ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
     ì¶”ì¶œí•œ ì •ë³´ì˜ ì¤‘ìš”ë„(0.00~1.00 ì‚¬ì´)ì™€ ì¶”ì¶œì— ëŒ€í•œ í™•ì‹ ë„(0.00~1.00 ì‚¬ì´)ë„ í•¨ê»˜ í‰ê°€í•´ ì£¼ì„¸ìš”.

     ```ê¸°ì‚¬ ë‚´ìš©
     {news_article}
     ```
     """)
])

# ë¶„ì„ ì²´ì¸ ìƒì„±
analysis_chain = template | structured_gemini

# í…ŒìŠ¤íŠ¸ (ì‹¤ì œ ë‰´ìŠ¤ ê¸°ì‚¬ í…ìŠ¤íŠ¸ë¥¼ news_article ë³€ìˆ˜ì— í• ë‹¹ í›„ ì‹¤í–‰)
# result = analysis_chain.invoke({"news_article": news_article})
# print(f"ì–¸ë¡ ì‚¬: {result.ì–¸ë¡ ì‚¬}")
# print(f"ê¸°ì‚¬ ì œëª©: {result.ê¸°ì‚¬_ì œëª©}")
```

## ğŸ“‹ í•´ë‹µ

### í•´ë‹µ 1: ë‹¤ì¤‘ ëª¨ë¸ í…ìŠ¤íŠ¸ ìƒì„±
```python
from langchain_google_genai import ChatGoogleGenerativeAI

gemini = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash",
    temperature=0,
    max_tokens=None,
    timeout=None,
    max_retries=2,
)

response = gemini.invoke("ì•ˆë…•í•˜ì„¸ìš”!")

print("ë‹µë³€:", response.content)
# ì¶œë ¥: ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š

print("ë©”íƒ€ë°ì´í„°:", response.response_metadata)
# ì¶œë ¥: {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}
```

### í•´ë‹µ 2: ì±„íŒ… ë©”ì‹œì§€ ì‹œìŠ¤í…œ í™œìš©
```python
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_google_genai import ChatGoogleGenerativeAI

gemini = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)

system_msg = SystemMessage(content="ë‹¹ì‹ ì€ ì˜ì–´ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.")
human_message = HumanMessage(content="Glory")

messages = [system_msg, human_message]
response = gemini.invoke(messages)

print("ë‹µë³€:", response.content)  # ì¶œë ¥: ì˜ê´‘
print("ë©”íƒ€ë°ì´í„°:", response.response_metadata)
```

### í•´ë‹µ 3: í…ìŠ¤íŠ¸ ìš”ì•½ í…œí”Œë¦¿ êµ¬í˜„
```python
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate

gemini = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)

template = ChatPromptTemplate.from_messages([
    ("system", "ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ìš”ì•½ì„ ì˜í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."),
    ("user", "ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ 1~2 ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ ë‚´ìš©ì„ ìœ„ì£¼ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”: {text}")
])

summarization_chain = template | gemini

text = """
ì¸ê³µì§€ëŠ¥ì€ ì»´í“¨í„° ì‹œìŠ¤í…œì´ ì¸ê°„ì˜ ì§€ëŠ¥ì„ ëª¨ë°©í•˜ì—¬ í•™ìŠµ, ì¶”ë¡ , ë¬¸ì œ í•´ê²° ë“±ì„ ìˆ˜í–‰í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.
ì¸ê³µì§€ëŠ¥ì€ ë¨¸ì‹ ëŸ¬ë‹, ë”¥ëŸ¬ë‹, ìì—°ì–´ ì²˜ë¦¬ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë˜ë©°, ììœ¨ì£¼í–‰ì°¨, ìŒì„± ì¸ì‹, ì´ë¯¸ì§€ ë¶„ì„ ë“± ì—¬ëŸ¬ ì‘ìš© í”„ë¡œê·¸ë¨ì— ì ìš©ë©ë‹ˆë‹¤.
ìƒì„±í˜• ì¸ê³µì§€ëŠ¥ì€ í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ìŒì•… ë“± ë‹¤ì–‘í•œ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë˜ë©°, ì°½ì˜ì ì¸ ì‘ì—…ì—ì„œë„ í° ì—­í• ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
"""

response = summarization_chain.invoke({"text": text})
print("ë‹µë³€:", response.content)
# ì¶œë ¥: ì¸ê³µì§€ëŠ¥ì€ ì¸ê°„ì˜ ì§€ëŠ¥ì„ ëª¨ë°©í•˜ì—¬ í•™ìŠµ, ì¶”ë¡ , ë¬¸ì œ í•´ê²° ë“±ì„ ìˆ˜í–‰í•˜ëŠ” ê¸°ìˆ ë¡œ, ë¨¸ì‹ ëŸ¬ë‹, ë”¥ëŸ¬ë‹, ìì—°ì–´ ì²˜ë¦¬ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë©ë‹ˆë‹¤. íŠ¹íˆ ìƒì„±í˜• ì¸ê³µì§€ëŠ¥ì€ í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ìŒì•… ë“± ë‹¤ì–‘í•œ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ë©° ì°½ì˜ì ì¸ ì‘ì—…ì— ê¸°ì—¬í•©ë‹ˆë‹¤.
```

### í•´ë‹µ 4: êµ¬ì¡°í™”ëœ ë‰´ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ
```python
from typing import Optional
from pydantic import BaseModel, Field, confloat
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate

class NewsAnalysis(BaseModel):
    ì–¸ë¡ ì‚¬: str = Field(description="ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì–¸ë¡ ì‚¬ ì´ë¦„")
    ê¸°ì‚¬_ì œëª©: str = Field(description="ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì œëª©", alias="ê¸°ì‚¬ ì œëª©")
    ì‘ì„±ì: str = Field(description="ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì‘ì„±ì")
    ì‘ì„±ì¼: str = Field(description="ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì‘ì„±ì¼")
    ìš”ì•½: str = Field(description="ë‰´ìŠ¤ ê¸°ì‚¬ ë‚´ìš©ì˜ ê°„ê²°í•œ ìš”ì•½ (20-30ì)")
    ë¶„ì•¼: str = Field(description="ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ë¶„ì•¼ (ê²½ì œ/ì‚¬íšŒ/ì •ì¹˜/êµ­ì œ/ë¬¸í™”/IT/ê³¼í•™ ë“±)")
    ì¤‘ìš”ë„: confloat(ge=0.0, le=1.0) = Field(description="ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì¤‘ìš”ë„ (0.00-1.00)")
    confidence: confloat(ge=0.0, le=1.0) = Field(description="ì¶”ì¶œì˜ í™•ì‹ ë„ (0.00-1.00)")

gemini = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)
structured_gemini = gemini.with_structured_output(NewsAnalysis)

template = ChatPromptTemplate.from_messages([
    ("system", "ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ìš”ì•½ê³¼ ë¶„ì„ì„ ì˜í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."),
    ("user", """
     ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ ì–¸ë¡ ì‚¬, ê¸°ì‚¬ ì œëª©, ì‘ì„±ì, ì‘ì„±ì¼, ê¸°ì‚¬ ë‚´ìš© ìš”ì•½(20-30ì), ë¶„ì•¼ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
     ì¶”ì¶œí•œ ì •ë³´ì˜ ì¤‘ìš”ë„(0.00~1.00 ì‚¬ì´)ì™€ ì¶”ì¶œì— ëŒ€í•œ í™•ì‹ ë„(0.00~1.00 ì‚¬ì´)ë„ í•¨ê»˜ í‰ê°€í•´ ì£¼ì„¸ìš”.

     ```ê¸°ì‚¬ ë‚´ìš©
     {news_article}
     ```
     """)
])

analysis_chain = template | structured_gemini

# ì‹¤ì œ ë‰´ìŠ¤ ê¸°ì‚¬ë¡œ í…ŒìŠ¤íŠ¸ ì‹œ:
# result = analysis_chain.invoke({"news_article": news_article})
# print(f"ì–¸ë¡ ì‚¬: {result.ì–¸ë¡ ì‚¬}")
# print(f"ê¸°ì‚¬ ì œëª©: {result.ê¸°ì‚¬_ì œëª©}")
# print(f"ì¤‘ìš”ë„: {result.ì¤‘ìš”ë„:.2f}")
```

## ğŸ” ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [LangChain ê³µì‹ ë¬¸ì„œ](https://python.langchain.com/docs/introduction/)
- [Google Generative AI í†µí•©](https://python.langchain.com/docs/integrations/chat/google_generative_ai/)
- [OpenAI í†µí•©](https://python.langchain.com/docs/integrations/chat/openai/)
- [í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê°€ì´ë“œ](https://python.langchain.com/docs/concepts/prompt_templates/)

### í•™ìŠµ ìë£Œ
- [LangChain Cookbook](https://github.com/langchain-ai/langchain/tree/master/cookbook)
- [Pydantic ëª¨ë¸ ë¬¸ì„œ](https://docs.pydantic.dev/latest/)
- [êµ¬ì¡°í™”ëœ ì¶œë ¥ ê°€ì´ë“œ](https://python.langchain.com/docs/how_to/structured_output/)

### ê°œë°œ ë„êµ¬
- [LangSmith](https://smith.langchain.com/) - ë””ë²„ê¹… ë° ëª¨ë‹ˆí„°ë§
- [LangServe](https://github.com/langchain-ai/langserve) - API ë°°í¬
- [Google AI Studio](https://aistudio.google.com/) - Gemini API í‚¤ ë°œê¸‰
- [OpenAI Platform](https://platform.openai.com/) - OpenAI API í‚¤ ë°œê¸‰

### ì¶”ê°€ í•™ìŠµ
- LangChain Expression Language (LCEL) í•™ìŠµ
- ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì™€ ì„ë² ë”© ëª¨ë¸ ì—°ë™
- RAG (Retrieval-Augmented Generation) ì‹œìŠ¤í…œ êµ¬ì¶•
- ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œê³¼ ë„êµ¬ í†µí•©