# PRJ02_W1_004 ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒ ê¸°ë²• ë§¤ë‰´ì–¼ - ì¿¼ë¦¬ í™•ì¥ (Query Expansion)

## ğŸ“‹ ê°œìš”

ì´ ë…¸íŠ¸ë¶ì€ RAG ì‹œìŠ¤í…œì˜ ê²€ìƒ‰ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê³ ê¸‰ ì¿¼ë¦¬ í™•ì¥ ê¸°ë²•ë“¤ì„ ì¢…í•©ì ìœ¼ë¡œ ë‹¤ë£¹ë‹ˆë‹¤. Query Reformulation, Multi Query, Decomposition, Step-Back Prompting, HyDE ë“± 5ê°€ì§€ í•µì‹¬ ê¸°ë²•ì„ í†µí•´ ì›ë³¸ ì¿¼ë¦¬ë¥¼ ê°œì„ í•˜ê³  í™•ì¥í•˜ì—¬ ë” ì •í™•í•˜ê³  í¬ê´„ì ì¸ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì–»ëŠ” ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.

### ğŸ“Š ì‹¤í—˜ í™˜ê²½ ë° ê²°ê³¼ ìš”ì•½
- **ë°ì´í„°ì…‹**: í•œêµ­ì–´ ì „ê¸°ì°¨ ê´€ë ¨ ë¬¸ì„œ (Tesla, Rivian ë“±)
- **ë²¡í„° ì €ì¥ì†Œ**: ChromaDB (text-embedding-3-small)
- **í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬**: "ë¯¸êµ­ ì „ê¸°ì°¨ ì‹œì¥ì—ì„œ Teslaì™€ ë‹¤ë¥¸ íšŒì‚¬ë“¤ì˜ ì°¨ì´ì ì€?"
- **í‰ê°€ ì§€í‘œ**: Hit Rate, MRR, MAP, NDCG (k=2,3,4)
- **ì£¼ìš” ê²°ê³¼**: ê° ê¸°ë²•ë³„ ì‹¤ì œ ê²€ìƒ‰ ì„±ëŠ¥ ë° ë¬¸ì„œ ìˆ˜ ì¸¡ì •

### ğŸ¯ í•™ìŠµ ëª©í‘œ
- ì¿¼ë¦¬ í™•ì¥(Query Expansion) ê¸°ë²•ì„ êµ¬í˜„í•˜ê³  ì„±ëŠ¥ ê°œì„ ì„ ì¸¡ì •
- 5ê°€ì§€ ì¿¼ë¦¬ í™•ì¥ ì „ëµì˜ íŠ¹ì§•ê³¼ ì ìš© ìƒí™© ì´í•´
- LLMì„ í™œìš©í•œ ì§€ëŠ¥í˜• ì¿¼ë¦¬ ë³€í™˜ ì‹œìŠ¤í…œ êµ¬ì¶•
- ì‹¤ìŠµì„ í†µí•œ ê° ê¸°ë²•ì˜ ê°œì„  ë°©ë²•ë¡  í•™ìŠµ

## ğŸ› ï¸ í™˜ê²½ ì„¤ì •

### 1. í•„ìˆ˜ íŒ¨í‚¤ì§€
```python
# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os
from glob import glob
from pprint import pprint
import json

# LangChain ê´€ë ¨
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, PromptTemplate, FewShotChatMessagePromptTemplate
from langchain_core.output_parsers import StrOutputParser, BaseOutputParser
from langchain.retrievers.multi_query import MultiQueryRetriever
from typing import List

# Langfuse íŠ¸ë ˆì´ì‹±
from langfuse.langchain import CallbackHandler
```

### 2. ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”
```python
# ì‹¤ì œ êµ¬í˜„ëœ ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ
chroma_db = Chroma(
    embedding_function=OpenAIEmbeddings(model="text-embedding-3-small"),
    collection_name="db_korean_cosine",
    persist_directory="./chroma_db"
)

# ê¸°ë³¸ ê²€ìƒ‰ê¸° ì„¤ì • (k=4)
chroma_k_retriever = chroma_db.as_retriever(search_kwargs={"k": 4})

# ì‹¤í—˜ìš© í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì •ì˜
test_queries = [
    "ë¯¸êµ­ ì „ê¸°ì°¨ ì‹œì¥ì—ì„œ Teslaì™€ ë‹¤ë¥¸ íšŒì‚¬ë“¤ì˜ ì°¨ì´ì ì€?",
    "ë¦¬ë¹„ì•ˆì˜ ì‚¬ì—… ê²½ìŸë ¥ì€ ì–´ë””ì„œ ë‚˜ì˜¤ë‚˜ìš”?",
    "í…ŒìŠ¬ë¼ì˜ ê¸°ìˆ ë ¥ì€ ì–´ë–¤ê°€ìš”?"
]

# K-RAG í‰ê°€ì ì„¤ì •
from krag.evaluators import OfflineRetrievalEvaluators

def setup_evaluator(actual_docs, predicted_docs):
    """í‰ê°€ì ì´ˆê¸°í™”"""
    return OfflineRetrievalEvaluators(
        actual_docs, predicted_docs,
        match_method="text"
    )
```

## ğŸ” ì¿¼ë¦¬ í™•ì¥ ê¸°ë²• ë¶„ë¥˜

### 1. Query Reformulation (ì¿¼ë¦¬ ì¬êµ¬ì„±)

**ê°œë…**: LLMì„ í™œìš©í•´ ì›ë³¸ ì§ˆë¬¸ì„ ê²€ìƒ‰ì— ìµœì í™”ëœ í˜•íƒœë¡œ ì¬êµ¬ì„±

**íŠ¹ì§•**:
- ğŸ¯ **ëª…í™•ì„± í–¥ìƒ**: ëª¨í˜¸í•œ ì§ˆë¬¸ì„ êµ¬ì²´ì ìœ¼ë¡œ ë³€í™˜
- ğŸ”„ **ê²€ìƒ‰ ìµœì í™”**: ê²€ìƒ‰ ì—”ì§„ì— ì¹œí™”ì ì¸ í‘œí˜„ìœ¼ë¡œ ë³€ê²½
- ğŸ“ **ë‹¨ì¼ ì¿¼ë¦¬**: í•˜ë‚˜ì˜ ê°œì„ ëœ ì¿¼ë¦¬ ìƒì„±

**ê¸°ë³¸ êµ¬í˜„**:
```python
# ì‹¤ì œ êµ¬í˜„ëœ ì¿¼ë¦¬ ë¦¬í¬ë®¬ë ˆì´ì…˜ í…œí”Œë¦¿
reformulation_template = """ë‹¤ìŒ ì§ˆë¬¸ì„ ê²€ìƒ‰ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ë‹¤ì‹œ ì‘ì„±í•´ì£¼ì„¸ìš”:

[ì§ˆë¬¸]
{question}

[ê°œì„ ëœ ì§ˆë¬¸]
"""

# ì²´ì¸ êµ¬ì„±
prompt = ChatPromptTemplate.from_template(reformulation_template)
llm = ChatOpenAI(model='gpt-4.1-mini', temperature=0)
reformulation_chain = prompt | llm | StrOutputParser()

# LCEL íŒ¨í„´ìœ¼ë¡œ ê²€ìƒ‰ê¸°ì™€ ê²°í•©
reformulation_retriever = reformulation_chain | chroma_k_retriever

# ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì˜ˆì‹œ
query = "ë¯¸êµ­ ì „ê¸°ì°¨ ì‹œì¥ì—ì„œ Teslaì™€ ë‹¤ë¥¸ íšŒì‚¬ë“¤ì˜ ì°¨ì´ì ì€?"
reformulated = reformulation_chain.invoke({"question": query})
print(f"ğŸ”¸ ê¸°ì¡´ ë¦¬í¬ë®¬ë ˆì´ì…˜ ì¿¼ë¦¬: {reformulated}")

# ê²€ìƒ‰ ì„±ëŠ¥ ë¹„êµ
original_docs = chroma_k_retriever.invoke(query)
reformulated_docs = chroma_k_retriever.invoke(reformulated)
print(f"ì›ë³¸ ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜: {len(original_docs)}")
print(f"ë¦¬í¬ë®¬ë ˆì´ì…˜ ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜: {len(reformulated_docs)}")
```

**ê°œì„ ëœ êµ¬í˜„**:
```python
# ê°œì„ ëœ ì¿¼ë¦¬ ë¦¬í¬ë®¬ë ˆì´ì…˜ í…œí”Œë¦¿
improved_reformulation_template = """ë‹¹ì‹ ì€ ì •ë³´ ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì§ˆë¬¸ì„ ê²€ìƒ‰ ì„±ëŠ¥ì„ ìµœëŒ€í™”í•˜ê¸° ìœ„í•´ ê°œì„ í•´ì£¼ì„¸ìš”.

ê°œì„  ì§€ì¹¨:
1. êµ¬ì²´ì ì´ê³  ëª…í™•í•œ í‚¤ì›Œë“œ ì‚¬ìš©
2. ê²€ìƒ‰ ì˜ë„ë¥¼ ëª…í™•íˆ í‘œí˜„
3. ê´€ë ¨ ë™ì˜ì–´ë‚˜ ìœ ì‚¬ í‘œí˜„ í¬í•¨
4. í•œêµ­ì–´ ìì—°ì–´ ìœ ì§€

[ì›ë³¸ ì§ˆë¬¸]
{question}

[ê²€ìƒ‰ ìµœì í™”ëœ ì§ˆë¬¸]
"""

# Langfuse íŠ¸ë ˆì´ì‹±ì´ í¬í•¨ëœ ì²´ì¸
improved_reformulation_chain = ChatPromptTemplate.from_template(improved_reformulation_template) | \
                              ChatOpenAI(model='gpt-4.1-mini', temperature=0.3, callbacks=[langfuse_handler]) | \
                              StrOutputParser()
```

### 2. Multi Query (ë‹¤ì¤‘ ì¿¼ë¦¬)

**ê°œë…**: ë‹¨ì¼ ì§ˆë¬¸ì„ ë‹¤ì–‘í•œ ê´€ì ì˜ ì—¬ëŸ¬ ì¿¼ë¦¬ë¡œ í™•ì¥í•˜ì—¬ í¬ê´„ì  ê²€ìƒ‰ ìˆ˜í–‰

**íŠ¹ì§•**:
- ğŸ”€ **ë‹¤ê°ë„ ì ‘ê·¼**: ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ì§ˆë¬¸ ìƒì„±
- ğŸ“ˆ **ì¬í˜„ìœ¨ í–¥ìƒ**: ë” ë§ì€ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
- ğŸ¯ **í¬ê´„ì„±**: ë†“ì¹  ìˆ˜ ìˆëŠ” ì •ë³´ê¹Œì§€ í¬ì°©

**ì¶œë ¥ íŒŒì„œ êµ¬í˜„**:
```python
class LineListOutputParser(BaseOutputParser[List[str]]):
    """LLM ì¶œë ¥ì„ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” íŒŒì„œ"""

    def parse(self, text: str) -> List[str]:
        lines = text.strip().split('\n')
        return [line.strip() for line in lines if line.strip()]

    @property
    def _type(self) -> str:
        return "line_list"
```

**ê¸°ë³¸ êµ¬í˜„**:
```python
# ì¿¼ë¦¬ ìƒì„± í”„ë¡¬í”„íŠ¸
QUERY_PROMPT = PromptTemplate(
    input_variables=["question"],
    template="""ì£¼ì–´ì§„ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì„œë¡œ ë‹¤ë¥¸ 3ê°œì˜ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
ê° ì§ˆë¬¸ì€ ì›ë³¸ ì§ˆë¬¸ì˜ ë‹¤ë¥¸ ì¸¡ë©´ì„ ë‹¤ë¤„ì•¼ í•©ë‹ˆë‹¤.
í•œ ì¤„ì— í•˜ë‚˜ì˜ ì§ˆë¬¸ë§Œ ì‘ì„±í•˜ì„¸ìš”.

ì›ë³¸ ì§ˆë¬¸: {question}

ìƒì„±ëœ ì§ˆë¬¸ë“¤:
"""
)

# ë©€í‹°ì¿¼ë¦¬ ì²´ì¸ êµ¬ì„±
multiquery_chain = QUERY_PROMPT | llm | LineListOutputParser()

# MultiQueryRetrieverì™€ ê²°í•©
multi_query_retriever = MultiQueryRetriever(
    retriever=chroma_k_retriever,
    llm_chain=multiquery_chain,
    parser_key="lines"
)
```

**ê°œì„ ëœ êµ¬í˜„**:
```python
# ê°œì„ ëœ ë©€í‹°ì¿¼ë¦¬ í”„ë¡¬í”„íŠ¸
IMPROVED_MULTIQUERY_PROMPT = PromptTemplate(
    input_variables=["question"],
    template="""ë‹¹ì‹ ì€ ì „ë¬¸ ì—°êµ¬ì›ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì§ˆë¬¸ì— ëŒ€í•´ í¬ê´„ì ì¸ ì •ë³´ ìˆ˜ì§‘ì„ ìœ„í•œ ë‹¤ì–‘í•œ ê´€ì ì˜ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

ìƒì„± ì§€ì¹¨:
1. ì„œë¡œ ë‹¤ë¥¸ ì ‘ê·¼ ë°©ì‹ì˜ ì§ˆë¬¸ (ê¸°ìˆ ì , ë¹„ì¦ˆë‹ˆìŠ¤ì , ì—­ì‚¬ì  ê´€ì  ë“±)
2. êµ¬ì²´ì ì´ê³  ê²€ìƒ‰ ê°€ëŠ¥í•œ í‘œí˜„ ì‚¬ìš©
3. ê° ì§ˆë¬¸ì€ ë…ë¦½ì ì´ë©´ì„œ ì›ë³¸ ì§ˆë¬¸ê³¼ ê´€ë ¨ì„± ìœ ì§€
4. ì •í™•íˆ 4ê°œì˜ ì§ˆë¬¸ ìƒì„±

ì›ë³¸ ì§ˆë¬¸: {question}

ë‹¤ê°ë„ ë¶„ì„ ì§ˆë¬¸ë“¤:
"""
)

# ê°œì„ ëœ ì²´ì¸ (ë‹¤ì–‘ì„±ì„ ìœ„í•´ temperature ìƒìŠ¹)
improved_multiquery_chain = IMPROVED_MULTIQUERY_PROMPT | \
                           ChatOpenAI(model="gpt-4.1-mini", temperature=0.7, callbacks=[langfuse_handler]) | \
                           LineListOutputParser()
```

### 3. Decomposition (ì¿¼ë¦¬ ë¶„í•´)

**ê°œë…**: ë³µì¡í•œ ì§ˆë¬¸ì„ ì‘ì€ ë‹¨ìœ„ì˜ í•˜ìœ„ ì§ˆë¬¸ë“¤ë¡œ ë¶„í•´í•˜ì—¬ ë‹¨ê³„ë³„ë¡œ ì²˜ë¦¬

**íŠ¹ì§•**:
- ğŸ”§ **ë³µì¡ì„± ë‹¨ìˆœí™”**: ì–´ë ¤ìš´ ë¬¸ì œë¥¼ ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„í• 
- ğŸ“‹ **ë‹¨ê³„ë³„ í•´ê²°**: ê° í•˜ìœ„ ë¬¸ì œë¥¼ ìˆœì°¨ì ìœ¼ë¡œ í•´ê²°
- ğŸ¯ **ì •í™•ì„± í–¥ìƒ**: ì„¸ë¶„í™”ëœ ê²€ìƒ‰ìœ¼ë¡œ ì •ë°€ë„ ì¦ê°€

**ê¸°ë³¸ êµ¬í˜„**:
```python
# ë¶„í•´ í”„ë¡¬í”„íŠ¸ (MultiQueryì™€ ë™ì¼í•œ ê¸°ë³¸ êµ¬ì¡° ì‚¬ìš©)
decomposition_chain = QUERY_PROMPT | llm | LineListOutputParser()

multi_query_decomposition_retriever = MultiQueryRetriever(
    retriever=chroma_k_retriever,
    llm_chain=decomposition_chain,
    parser_key="lines"
)
```

**ê°œì„ ëœ êµ¬í˜„**:
```python
# ê°œì„ ëœ ë¶„í•´ í”„ë¡¬í”„íŠ¸
IMPROVED_DECOMPOSITION_PROMPT = PromptTemplate(
    input_variables=["question"],
    template="""ë‹¹ì‹ ì€ ì²´ê³„ì  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë³µì¡í•œ ì§ˆë¬¸ì„ ë…¼ë¦¬ì  ìˆœì„œì˜ í•˜ìœ„ ì§ˆë¬¸ë“¤ë¡œ ë¶„í•´í•´ì£¼ì„¸ìš”.

ë¶„í•´ ì›ì¹™:
1. ë…¼ë¦¬ì  ìˆœì„œ: ê¸°ë³¸ ê°œë… â†’ êµ¬ì²´ì  ë‚´ìš© â†’ ì‘ìš©/ë¹„êµ
2. ë…ë¦½ì„±: ê° í•˜ìœ„ ì§ˆë¬¸ì€ ë…ë¦½ì ìœ¼ë¡œ ë‹µë³€ ê°€ëŠ¥
3. ì™„ì „ì„±: ëª¨ë“  í•˜ìœ„ ë‹µë³€ì„ í†µí•©í•˜ë©´ ì›ë³¸ ì§ˆë¬¸ì˜ ì™„ì „í•œ ë‹µë³€ êµ¬ì„±
4. ì‹¤í–‰ ê°€ëŠ¥ì„±: ì‹¤ì œ ê²€ìƒ‰ìœ¼ë¡œ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ìˆëŠ” ì§ˆë¬¸

ë³µí•© ì§ˆë¬¸: {question}

ë…¼ë¦¬ì  í•˜ìœ„ ì§ˆë¬¸ë“¤:
"""
)

# êµ¬ì¡°í™”ëœ ë¶„í•´ë¥¼ ìœ„í•´ ì¤‘ê°„ ì˜¨ë„ ì„¤ì •
improved_decomposition_chain = IMPROVED_DECOMPOSITION_PROMPT | \
                              ChatOpenAI(model="gpt-4.1-mini", temperature=0.5, callbacks=[langfuse_handler]) | \
                              LineListOutputParser()
```

### 4. Step-Back Prompting (ë‹¨ê³„ì  í›„í‡´)

**ê°œë…**: êµ¬ì²´ì  ì§ˆë¬¸ì„ ì¼ë°˜ì ì´ê³  í¬ê´„ì ì¸ ë§¥ë½ì—ì„œ ì ‘ê·¼í•˜ëŠ” ë°©ì‹

**íŠ¹ì§•**:
- ğŸ”™ **ì¶”ìƒí™”**: êµ¬ì²´ì  â†’ ì¼ë°˜ì  ê´€ì ìœ¼ë¡œ í›„í‡´
- ğŸŒ **ë§¥ë½ í™•ì¥**: ë” ë„“ì€ ë°°ê²½ ì§€ì‹ í™œìš©
- ğŸ¯ **ì›ë¦¬ ì¤‘ì‹¬**: ê·¼ë³¸ì  ì›ë¦¬ì—ì„œ ì¶œë°œ

**Few-Shot ì˜ˆì œ ì„¤ì •**:
```python
# Few-Shot ì˜ˆì œ ì •ì˜
examples = [
    {
        "input": "í…ŒìŠ¬ë¼ Model 3ì˜ 2023ë…„ íŒë§¤ëŸ‰ì€ ì–¼ë§ˆì¸ê°€ìš”?",
        "output": "ì „ê¸°ì°¨ ì‹œì¥ì—ì„œ í…ŒìŠ¬ë¼ì˜ ì „ì²´ì ì¸ íŒë§¤ ì„±ê³¼ì™€ ì‹œì¥ ì ìœ ìœ¨ì€ ì–´ë–»ê²Œ ë³€í™”í•˜ê³  ìˆë‚˜ìš”?"
    },
    {
        "input": "ë¦¬ë¹„ì•ˆ R1Tì˜ ë°°í„°ë¦¬ ìš©ëŸ‰ì€?",
        "output": "ì „ê¸° í”½ì—…íŠ¸ëŸ­ ì‹œì¥ì—ì„œ ë°°í„°ë¦¬ ê¸°ìˆ ê³¼ ì„±ëŠ¥ ê²½ìŸì€ ì–´ë–»ê²Œ ì´ë£¨ì–´ì§€ê³  ìˆë‚˜ìš”?"
    },
    {
        "input": "í¬ë“œ F-150 Lightningì˜ ì¶©ì „ ì‹œê°„ì€?",
        "output": "ì „ê¸°ì°¨ ì¶©ì „ ì¸í”„ë¼ì™€ ì¶©ì „ ê¸°ìˆ ì˜ ë°œì „ í˜„í™©ì€ ì–´ë– í•œê°€ìš”?"
    }
]

# Few-Shot í”„ë¡¬í”„íŠ¸ êµ¬ì„±
example_prompt = ChatPromptTemplate.from_messages([
    ("human", "{input}"),
    ("ai", "{output}"),
])

few_shot_prompt = FewShotChatMessagePromptTemplate(
    example_prompt=example_prompt,
    examples=examples,
)

# Step-Back í”„ë¡¬í”„íŠ¸
step_back_prompt = ChatPromptTemplate.from_messages([
    ("system", "ë‹¹ì‹ ì€ ë¶„ì„ì  ì‚¬ê³ ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ ë” ì¼ë°˜ì ì´ê³  í¬ê´„ì ì¸ ê´€ì ì˜ ì§ˆë¬¸ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”."),
    few_shot_prompt,
    ("human", "{question}"),
])
```

**ì²´ì¸ êµ¬ì„± ë° ë‹µë³€ ìƒì„±**:
```python
# Step-Back ì²´ì¸
step_back_chain = step_back_prompt | llm | StrOutputParser()

# ë‹µë³€ ìƒì„±ì„ ìœ„í•œ ì´ì¤‘ ê²€ìƒ‰ ì²´ì¸
response_prompt = ChatPromptTemplate.from_template(
    """ë‹¹ì‹ ì€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ì™€ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ í¬ê´„ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:
"""
)

def format_docs(docs):
    return "\n".join([doc.page_content for doc in docs])

# ì´ì¤‘ ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„± ì²´ì¸
answer_chain = (
    {
        "step_back_docs": step_back_chain | chroma_k_retriever,
        "normal_docs": chroma_k_retriever,
        "question": lambda x: x
    }
    | (lambda x: {
        "context": format_docs(x["step_back_docs"] + x["normal_docs"]),
        "question": x["question"]
    })
    | response_prompt
    | llm
    | StrOutputParser()
)
```

### 5. HyDE (Hypothetical Document Embedding)

**ê°œë…**: ì§ˆë¬¸ì— ëŒ€í•œ ê°€ìƒì˜ ì´ìƒì ì¸ ë‹µë³€ ë¬¸ì„œë¥¼ ìƒì„±í•˜ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ ì‚¬ ë¬¸ì„œë¥¼ ê²€ìƒ‰

**íŠ¹ì§•**:
- ğŸ­ **ê°€ìƒ ë¬¸ì„œ**: ì´ìƒì ì¸ ë‹µë³€ ë¬¸ì„œ ìƒì„±
- ğŸ” **ì˜ë¯¸ì  ë§¤ì¹­**: ê°€ìƒ ë¬¸ì„œì™€ ìœ ì‚¬í•œ ì‹¤ì œ ë¬¸ì„œ ê²€ìƒ‰
- ğŸ“ˆ **ê²€ìƒ‰ í’ˆì§ˆ**: ë¬¸ì„œ-ë¬¸ì„œ ìœ ì‚¬ì„±ì„ í†µí•œ ë†’ì€ ì •í™•ë„

**ê¸°ë³¸ êµ¬í˜„**:
```python
# HyDE ë¬¸ì„œ ìƒì„± í”„ë¡¬í”„íŠ¸
hyde_template = """ì£¼ì–´ì§„ ì§ˆë¬¸ì— ëŒ€í•œ ì´ìƒì ì¸ ë¬¸ì„œ ë‚´ìš©ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
ë¬¸ì„œëŠ” í•™ìˆ ì ì´ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

ì§ˆë¬¸: {question}

ì´ìƒì ì¸ ë¬¸ì„œ:
"""

# HyDE ì²´ì¸
hyde_prompt = ChatPromptTemplate.from_template(hyde_template)
hyde_llm = ChatOpenAI(model="gpt-4.1-mini", temperature=0)
hyde_chain = hyde_prompt | hyde_llm | StrOutputParser()

# RAG ì²´ì¸ (ê°€ìƒ ë¬¸ì„œ ê¸°ë°˜ ê²€ìƒ‰ â†’ ì‹¤ì œ ë‹µë³€)
rag_template = """ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:
"""

rag_prompt = ChatPromptTemplate.from_template(rag_template)
rag_chain = rag_prompt | hyde_llm | StrOutputParser()
```

**ë‹¤ê´€ì  HyDE êµ¬í˜„**:
```python
# ê¸°ìˆ ì  ê´€ì  HyDE
technical_hyde_template = """ê¸°ìˆ  ì „ë¬¸ê°€ ê´€ì ì—ì„œ ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ ìƒì„¸í•œ ê¸°ìˆ  ë¶„ì„ ë¬¸ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

í¬í•¨ ìš”ì†Œ:
- ê¸°ìˆ ì  ì‚¬ì–‘ê³¼ ì„±ëŠ¥ ì§€í‘œ
- ê¸°ìˆ ì  í˜ì‹ ì ê³¼ ì°¨ë³„í™” ìš”ì†Œ
- ê¸°ìˆ ì  í•œê³„ì™€ ê°œì„  ë°©í–¥
- ê²½ìŸ ê¸°ìˆ ê³¼ì˜ ë¹„êµ

ì§ˆë¬¸: {question}

ê¸°ìˆ  ë¶„ì„ ë¬¸ì„œ:
"""

# ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì  HyDE
business_hyde_template = """ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ ì „ë¬¸ê°€ ê´€ì ì—ì„œ ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ ì¢…í•©ì ì¸ ì‹œì¥ ë¶„ì„ ë¬¸ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

í¬í•¨ ìš”ì†Œ:
- ì‹œì¥ ë™í–¥ê³¼ ê²½ìŸ í™˜ê²½
- ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ê³¼ ìˆ˜ìµ êµ¬ì¡°
- íˆ¬ìì™€ ì„±ì¥ ì „ëµ
- ìœ„í—˜ ìš”ì†Œì™€ ê¸°íšŒ ë¶„ì„

ì§ˆë¬¸: {question}

ì‹œì¥ ë¶„ì„ ë¬¸ì„œ:
"""

# ë‹¤ì¤‘ ê´€ì  HyDE ì²´ì¸ë“¤
technical_hyde_chain = ChatPromptTemplate.from_template(technical_hyde_template) | \
                      ChatOpenAI(model="gpt-4.1-mini", temperature=0.7, callbacks=[langfuse_handler]) | \
                      StrOutputParser()

business_hyde_chain = ChatPromptTemplate.from_template(business_hyde_template) | \
                     ChatOpenAI(model="gpt-4.1-mini", temperature=0.7, callbacks=[langfuse_handler]) | \
                     StrOutputParser()
```

## ğŸ§ª ì‹¤ìŠµ ê³¼ì œ ë° ê°œì„  ë°©ë²•ë¡ 

### ì‹¤ìŠµ 1: Query Reformulation ê°œì„ 

**ê°œì„  ìš”ì†Œ**:
1. **êµ¬ì²´ì„± ê°•í™”**: ëª¨í˜¸í•œ í‘œí˜„ì„ êµ¬ì²´ì  í‚¤ì›Œë“œë¡œ ë³€í™˜
2. **ê²€ìƒ‰ ì¹œí™”ì **: ê²€ìƒ‰ ì—”ì§„ ìµœì í™” ê³ ë ¤
3. **ë§¥ë½ ë³´ì¡´**: ì›ë³¸ ì˜ë„ ìœ ì§€

```python
# ê°œì„  ì „í›„ ë¹„êµ í…ŒìŠ¤íŠ¸
test_queries = [
    "ë¦¬ë¹„ì•ˆì˜ ì‚¬ì—… ê²½ìŸë ¥ì€ ì–´ë””ì„œ ë‚˜ì˜¤ë‚˜ìš”?",
    "í…ŒìŠ¬ë¼ì˜ ê¸°ìˆ ë ¥ì€ ì–´ë–¤ê°€ìš”?",
    "ì „ê¸°ì°¨ ì‹œì¥ ì „ë§ì€?"
]

for query in test_queries:
    original = reformulation_chain.invoke({"question": query})
    improved = improved_reformulation_chain.invoke({"question": query})

    print(f"ì›ë³¸: {query}")
    print(f"ê¸°ë³¸ ê°œì„ : {original}")
    print(f"ê³ ê¸‰ ê°œì„ : {improved}")
    print("-" * 80)
```

### ì‹¤ìŠµ 2: MultiQuery êµ¬ì¡° ë¶„ì„ ë° ê°œì„ 

**ë¶„ì„ ìš”ì†Œ**:
1. **ì§ˆë¬¸ ë‹¤ì–‘ì„±**: ìƒì„±ëœ ì§ˆë¬¸ë“¤ì˜ ê´€ì  ì°¨ì´
2. **ê²€ìƒ‰ ì»¤ë²„ë¦¬ì§€**: ë‹¤ì–‘í•œ ë¬¸ì„œ ê²€ìƒ‰ ë²”ìœ„
3. **ì¤‘ë³µ ì œê±°**: ìœ ì‚¬í•œ ì§ˆë¬¸ í•„í„°ë§

```python
def analyze_query_diversity(queries, title):
    """ìƒì„±ëœ ì§ˆë¬¸ì˜ ë‹¤ì–‘ì„± ë¶„ì„"""
    print(f"\n{title}")

    # ì§ˆë¬¸ë³„ í‚¤ì›Œë“œ ì¶”ì¶œ
    all_words = []
    for q in queries:
        words = set(q.lower().replace('?', '').split())
        all_words.extend(words)

    unique_words = len(set(all_words))
    total_words = len(all_words)
    diversity_ratio = unique_words / total_words if total_words > 0 else 0

    print(f"ì´ ë‹¨ì–´: {total_words}, ê³ ìœ  ë‹¨ì–´: {unique_words}")
    print(f"ë‹¤ì–‘ì„± ë¹„ìœ¨: {diversity_ratio:.3f}")

    return diversity_ratio, unique_words
```

### ì‹¤ìŠµ 3: Query Decomposition ìµœì í™”

**ìµœì í™” ì „ëµ**:
1. **ë…¼ë¦¬ì  ìˆœì„œ**: ê¸°ë³¸ ê°œë… â†’ ì„¸ë¶€ ì‚¬í•­ â†’ ì‘ìš©
2. **ë…ë¦½ì„±**: ê° í•˜ìœ„ ì§ˆë¬¸ì˜ ë…ë¦½ì  ì‹¤í–‰ ê°€ëŠ¥ì„±
3. **ì™„ì „ì„±**: ì „ì²´ ë‹µë³€ êµ¬ì„±ì„ ìœ„í•œ ì¶©ë¶„ì„±

```python
def analyze_subquery_search(subqueries, retriever, title):
    """ì„œë¸Œ ì§ˆë¬¸ë³„ ê²€ìƒ‰ ì„±ëŠ¥ ë¶„ì„"""
    print(f"\n{title}")

    all_docs = []
    source_counts = {}

    for i, subq in enumerate(subqueries):
        docs = retriever.invoke(subq)
        all_docs.extend(docs)

        print(f"ì„œë¸Œì§ˆë¬¸ {i+1}: {subq}")
        print(f"ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜: {len(docs)}")

        # ì¶œì²˜ ë¶„ì„
        for doc in docs:
            source = doc.metadata.get('source', 'unknown')
            source_counts[source] = source_counts.get(source, 0) + 1

    return len(all_docs), source_counts
```

### ì‹¤ìŠµ 4: Step-Back Prompting ê³ ë„í™”

**ê³ ë„í™” ë°©í–¥**:
1. **ë„ë©”ì¸ íŠ¹í™”**: íŠ¹ì • ë¶„ì•¼ì— ë§ëŠ” ì¶”ìƒí™” íŒ¨í„´
2. **ê³„ì¸µì  ì ‘ê·¼**: ë‹¤ë‹¨ê³„ ì¶”ìƒí™” ë ˆë²¨
3. **ë§¥ë½ í†µí•©**: ì¼ë°˜ë¡ ê³¼ êµ¬ì²´ë¡ ì˜ ì¡°í™”

```python
# ê°œì„ ëœ Few-Shot ì˜ˆì œ (ë„ë©”ì¸ íŠ¹í™”)
enhanced_examples = [
    {
        "input": "ë¦¬ë¹„ì•ˆ R1Tì˜ ìµœëŒ€ ê²¬ì¸ë ¥ì€ ì–¼ë§ˆì¸ê°€ìš”?",
        "output": "ì „ê¸° í”½ì—…íŠ¸ëŸ­ ì‹œì¥ì—ì„œ ê²¬ì¸ ì„±ëŠ¥ê³¼ ì‹¤ìš©ì„± ê²½ìŸì€ ì–´ë–»ê²Œ ì´ë£¨ì–´ì§€ê³  ìˆìœ¼ë©°, ì´ê²ƒì´ ì†Œë¹„ì ì„ íƒì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    },
    {
        "input": "í…ŒìŠ¬ë¼ ìŠˆí¼ì°¨ì € V4ì˜ ì¶©ì „ ì†ë„ëŠ”?",
        "output": "ì „ê¸°ì°¨ ì¶©ì „ ì¸í”„ë¼ì˜ ê¸°ìˆ  ë°œì „ì´ ì „ê¸°ì°¨ ë³´ê¸‰ê³¼ ì‚¬ìš©ì ê²½í—˜ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€ ì–´ë– í•˜ë©°, í–¥í›„ ë°œì „ ë°©í–¥ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    }
]

# ê°œì„ ëœ Step-Back ì‹œìŠ¤í…œ
enhanced_step_back_prompt = ChatPromptTemplate.from_messages([
    ("system", """ë‹¹ì‹ ì€ ì „ëµì  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ ë” í¬ê´„ì ì´ê³  í†µì°°ë ¥ ìˆëŠ” ê´€ì ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

ë³€í™˜ ì§€ì¹¨:
1. ë‹¨ìˆœ ì‚¬ì‹¤ â†’ íŠ¸ë Œë“œì™€ ì˜í–¥ ë¶„ì„
2. ê°œë³„ ì œí’ˆ â†’ ì‹œì¥ ìƒíƒœê³„ ê´€ì 
3. ê¸°ìˆ  ìŠ¤í™ â†’ ê¸°ìˆ  ë°œì „ì˜ ì˜ë¯¸ì™€ ë°©í–¥
4. ì¦‰ì„ ë‹µë³€ë³´ë‹¤ëŠ” ê¹Šì´ ìˆëŠ” ì´í•´ ì¶”êµ¬"""),
    FewShotChatMessagePromptTemplate(
        example_prompt=ChatPromptTemplate.from_messages([
            ("human", "{input}"),
            ("ai", "{output}"),
        ]),
        examples=enhanced_examples,
    ),
    ("human", "{question}"),
])
```

### ì‹¤ìŠµ 5: HyDE ì‹œìŠ¤í…œ ì •êµí™”

**ì •êµí™” ìš”ì†Œ**:
1. **ë‹¤ì¤‘ ê´€ì **: ê¸°ìˆ ì , ë¹„ì¦ˆë‹ˆìŠ¤ì , ì‚¬ìš©ì ê´€ì 
2. **í’ˆì§ˆ ì œì–´**: ìƒì„±ëœ ë¬¸ì„œì˜ í’ˆì§ˆ ê²€ì¦
3. **ì ì‘ì  ì„ íƒ**: ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¥¸ ìµœì  ê´€ì  ì„ íƒ

```python
class AdaptiveHyDESystem:
    """ì ì‘ì  HyDE ì‹œìŠ¤í…œ"""

    def __init__(self, retriever):
        self.retriever = retriever
        self.technical_chain = technical_hyde_chain
        self.business_chain = business_hyde_chain
        self.general_chain = hyde_chain

    def _classify_query_domain(self, query):
        """ì¿¼ë¦¬ ë„ë©”ì¸ ë¶„ë¥˜"""
        technical_keywords = ['ê¸°ìˆ ', 'ì„±ëŠ¥', 'ì‚¬ì–‘', 'ì—”ì§„', 'ë°°í„°ë¦¬', 'ì¶©ì „']
        business_keywords = ['ì‹œì¥', 'ê²½ìŸ', 'ì „ëµ', 'íˆ¬ì', 'ìˆ˜ìµ', 'ì ìœ ìœ¨']

        if any(keyword in query for keyword in technical_keywords):
            return 'technical'
        elif any(keyword in query for keyword in business_keywords):
            return 'business'
        else:
            return 'general'

    def invoke(self, query):
        """ë„ë©”ì¸ë³„ ì ì‘ì  HyDE ì‹¤í–‰"""
        domain = self._classify_query_domain(query)

        if domain == 'technical':
            hypothetical_doc = self.technical_chain.invoke({"question": query})
        elif domain == 'business':
            hypothetical_doc = self.business_chain.invoke({"question": query})
        else:
            hypothetical_doc = self.general_chain.invoke({"question": query})

        # ê°€ìƒ ë¬¸ì„œë¡œ ì‹¤ì œ ë¬¸ì„œ ê²€ìƒ‰
        retrieved_docs = self.retriever.invoke(hypothetical_doc)

        return {
            'domain': domain,
            'hypothetical_doc': hypothetical_doc,
            'retrieved_docs': retrieved_docs
        }
```

## ğŸ¯ ì„±ëŠ¥ ìµœì í™” ì „ëµ

### 1. ê¸°ë²•ë³„ íŠ¹ì„± ë¹„êµ

| ê¸°ë²• | ì¥ì  | ë‹¨ì  | ìµœì  ìƒí™© |
|------|------|------|-----------|
| **Query Reformulation** | ê°„ë‹¨, ë¹ ë¦„ | ì œí•œì  í™•ì¥ | ëª…í™•í•œ ì§ˆë¬¸ ê°œì„  |
| **Multi Query** | í¬ê´„ì  ê²€ìƒ‰ | ì¤‘ë³µ ìœ„í—˜ | íƒìƒ‰ì  ê²€ìƒ‰ |
| **Decomposition** | ë…¼ë¦¬ì  êµ¬ì¡° | ë³µì¡ì„± ì¦ê°€ | ë³µí•© ì§ˆë¬¸ |
| **Step-Back** | ë§¥ë½ ì´í•´ | ì¶”ìƒí™” ê³¼ë‹¤ | ë°°ê²½ ì§€ì‹ í•„ìš” |
| **HyDE** | ë†’ì€ ì •í™•ë„ | ê³„ì‚° ë¹„ìš© | ì •ë°€ ê²€ìƒ‰ |

### 2. í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ

```python
class QueryExpansionOrchestrator:
    """ë‹¤ì¤‘ ì¿¼ë¦¬ í™•ì¥ ê¸°ë²• í†µí•© ê´€ë¦¬ì"""

    def __init__(self, retriever):
        self.retriever = retriever
        self.strategies = {
            'reformulation': improved_reformulation_chain,
            'multi_query': improved_multiquery_chain,
            'decomposition': improved_decomposition_chain,
            'step_back': enhanced_step_back_chain,
            'hyde': AdaptiveHyDESystem(retriever)
        }

    def _select_strategy(self, query, context=None):
        """ì§ˆë¬¸ íŠ¹ì„±ì— ë”°ë¥¸ ìµœì  ì „ëµ ì„ íƒ"""
        query_lower = query.lower()

        # ë³µí•© ì§ˆë¬¸ ê°ì§€
        if 'ê·¸ë¦¬ê³ ' in query or 'ë˜í•œ' in query or len(query.split('?')) > 2:
            return 'decomposition'

        # êµ¬ì²´ì  ì‚¬ì‹¤ ì§ˆë¬¸
        elif any(word in query_lower for word in ['ì–¸ì œ', 'ì–¼ë§ˆ', 'ëª‡', 'ì–´ë””']):
            return 'hyde'

        # ë¹„êµ/ë¶„ì„ ì§ˆë¬¸
        elif any(word in query_lower for word in ['ë¹„êµ', 'ì°¨ì´', 'ì¥ë‹¨ì ', 'ì–´ë–¤']):
            return 'step_back'

        # íƒìƒ‰ì  ì§ˆë¬¸
        elif any(word in query_lower for word in ['ì–´ë–»ê²Œ', 'ì™œ', 'ë°©ë²•']):
            return 'multi_query'

        # ê¸°ë³¸: reformulation
        else:
            return 'reformulation'

    def expand_query(self, query, strategy=None):
        """ì¿¼ë¦¬ í™•ì¥ ì‹¤í–‰"""
        if strategy is None:
            strategy = self._select_strategy(query)

        selected_strategy = self.strategies[strategy]

        if strategy == 'hyde':
            return selected_strategy.invoke(query)
        else:
            expanded_query = selected_strategy.invoke({"question": query})
            retrieved_docs = self.retriever.invoke(expanded_query)

            return {
                'strategy': strategy,
                'expanded_query': expanded_query,
                'retrieved_docs': retrieved_docs
            }
```

### 3. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```python
class QueryExpansionMonitor:
    """ì¿¼ë¦¬ í™•ì¥ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""

    def __init__(self):
        self.metrics_history = []
        self.strategy_performance = {}

    def evaluate_expansion(self, original_query, expanded_result, ground_truth):
        """í™•ì¥ ê²°ê³¼ í‰ê°€"""
        from sklearn.metrics import accuracy_score, precision_score, recall_score

        # ê²€ìƒ‰ í’ˆì§ˆ í‰ê°€ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
        retrieved_docs = expanded_result.get('retrieved_docs', [])
        relevance_scores = [
            self._calculate_relevance(doc, ground_truth)
            for doc in retrieved_docs
        ]

        metrics = {
            'avg_relevance': np.mean(relevance_scores) if relevance_scores else 0,
            'doc_count': len(retrieved_docs),
            'strategy': expanded_result.get('strategy', 'unknown'),
            'timestamp': datetime.now()
        }

        self.metrics_history.append(metrics)
        return metrics

    def _calculate_relevance(self, doc, ground_truth):
        """ë¬¸ì„œ-ì •ë‹µ ê´€ë ¨ì„± ê³„ì‚° (ROUGE-like)"""
        # ê°„ë‹¨í•œ ë‹¨ì–´ ê²¹ì¹¨ ê¸°ë°˜ ìœ ì‚¬ë„
        doc_words = set(doc.page_content.lower().split())
        truth_words = set(ground_truth.lower().split())

        intersection = doc_words.intersection(truth_words)
        union = doc_words.union(truth_words)

        return len(intersection) / len(union) if union else 0

    def get_strategy_rankings(self):
        """ì „ëµë³„ ì„±ëŠ¥ ìˆœìœ„"""
        strategy_scores = {}

        for metric in self.metrics_history:
            strategy = metric['strategy']
            score = metric['avg_relevance']

            if strategy not in strategy_scores:
                strategy_scores[strategy] = []
            strategy_scores[strategy].append(score)

        # í‰ê·  ì„±ëŠ¥ ê³„ì‚°
        avg_scores = {
            strategy: np.mean(scores)
            for strategy, scores in strategy_scores.items()
        }

        # ìˆœìœ„ ë°˜í™˜
        return sorted(avg_scores.items(), key=lambda x: x[1], reverse=True)
```

## ğŸ’¡ ì‹¤ë¬´ í™œìš© ê°€ì´ë“œ

### 1. ìƒí™©ë³„ ê¸°ë²• ì„ íƒ

```python
def recommend_expansion_technique(query_type, complexity, domain):
    """ìƒí™©ë³„ ìµœì  ê¸°ë²• ì¶”ì²œ"""

    recommendations = []

    # ë³µì¡ë„ ê¸°ë°˜
    if complexity == 'high':
        recommendations.append('decomposition')
    elif complexity == 'medium':
        recommendations.append('multi_query')
    else:
        recommendations.append('reformulation')

    # ë„ë©”ì¸ ê¸°ë°˜
    if domain == 'technical':
        recommendations.append('hyde')
    elif domain == 'exploratory':
        recommendations.extend(['step_back', 'multi_query'])

    # ì§ˆë¬¸ ìœ í˜• ê¸°ë°˜
    if query_type == 'factual':
        recommendations.append('hyde')
    elif query_type == 'comparative':
        recommendations.append('step_back')
    elif query_type == 'procedural':
        recommendations.append('decomposition')

    # ê°€ì¥ ë§ì´ ì¶”ì²œëœ ê¸°ë²• ì„ íƒ
    from collections import Counter
    return Counter(recommendations).most_common(1)[0][0]
```

### 2. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹

```python
class ExpansionBenchmark:
    """ì¿¼ë¦¬ í™•ì¥ ê¸°ë²• ë²¤ì¹˜ë§ˆí‚¹"""

    def __init__(self, test_queries, ground_truths):
        self.test_queries = test_queries
        self.ground_truths = ground_truths
        self.results = {}

    def run_benchmark(self, techniques):
        """ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        for technique_name, technique_func in techniques.items():
            print(f"ë²¤ì¹˜ë§ˆí‚¹: {technique_name}")

            technique_results = []

            for query, truth in zip(self.test_queries, self.ground_truths):
                try:
                    start_time = time.time()
                    result = technique_func(query)
                    end_time = time.time()

                    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°
                    metrics = self._calculate_metrics(result, truth)
                    metrics['latency'] = end_time - start_time

                    technique_results.append(metrics)

                except Exception as e:
                    print(f"ì˜¤ë¥˜ ë°œìƒ - {technique_name}: {e}")
                    technique_results.append(None)

            self.results[technique_name] = technique_results

    def generate_report(self):
        """ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = "## ì¿¼ë¦¬ í™•ì¥ ê¸°ë²• ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼\n\n"

        for technique, results in self.results.items():
            valid_results = [r for r in results if r is not None]

            if valid_results:
                avg_relevance = np.mean([r['relevance'] for r in valid_results])
                avg_latency = np.mean([r['latency'] for r in valid_results])
                success_rate = len(valid_results) / len(results)

                report += f"### {technique}\n"
                report += f"- í‰ê·  ê´€ë ¨ì„±: {avg_relevance:.3f}\n"
                report += f"- í‰ê·  ì§€ì—°ì‹œê°„: {avg_latency:.3f}ì´ˆ\n"
                report += f"- ì„±ê³µë¥ : {success_rate:.1%}\n\n"

        return report
```

## ğŸ”§ ë¬¸ì œ í•´ê²° ë° ìµœì í™”

### 1. ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

```python
# 1. LLM ì‘ë‹µ ë¶ˆì•ˆì •ì„± í•´ê²°
def robust_llm_invoke(chain, input_data, max_retries=3):
    """ê²¬ê³ í•œ LLM í˜¸ì¶œ"""
    for attempt in range(max_retries):
        try:
            return chain.invoke(input_data)
        except Exception as e:
            if attempt == max_retries - 1:
                raise e
            time.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„

# 2. í† í° ì œí•œ ê´€ë¦¬
def manage_token_limits(text, max_tokens=4000):
    """í† í° ì œí•œ ê´€ë¦¬"""
    # ê°„ë‹¨í•œ í† í° ì¶”ì • (ì‹¤ì œë¡œëŠ” tiktoken ì‚¬ìš© ê¶Œì¥)
    estimated_tokens = len(text.split()) * 1.3

    if estimated_tokens > max_tokens:
        # í…ìŠ¤íŠ¸ ì¶•ì•½
        words = text.split()
        target_words = int(max_tokens / 1.3)
        return ' '.join(words[:target_words])

    return text

# 3. ê²°ê³¼ í’ˆì§ˆ ê²€ì¦
def validate_expansion_quality(original_query, expanded_query):
    """í™•ì¥ ê²°ê³¼ í’ˆì§ˆ ê²€ì¦"""
    checks = {
        'length_reasonable': 10 <= len(expanded_query) <= 1000,
        'contains_keywords': any(word in expanded_query.lower()
                               for word in original_query.lower().split()),
        'is_question': '?' in expanded_query or any(word in expanded_query
                                                 for word in ['ë¬´ì—‡', 'ì–´ë–»ê²Œ', 'ì™œ', 'ì–¸ì œ']),
        'no_repetition': expanded_query != original_query
    }

    return all(checks.values()), checks
```

### 2. ì„±ëŠ¥ ìµœì í™”

```python
# ìºì‹± ì‹œìŠ¤í…œ
from functools import lru_cache

@lru_cache(maxsize=1000)
def cached_query_expansion(query, strategy):
    """ì¿¼ë¦¬ í™•ì¥ ê²°ê³¼ ìºì‹±"""
    # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” strategyì— ë”°ë¥¸ ì ì ˆí•œ ì²´ì¸ í˜¸ì¶œ
    pass

# ë°°ì¹˜ ì²˜ë¦¬
def batch_query_expansion(queries, strategy, batch_size=5):
    """ë°°ì¹˜ ë‹¨ìœ„ ì¿¼ë¦¬ í™•ì¥"""
    results = []

    for i in range(0, len(queries), batch_size):
        batch = queries[i:i+batch_size]

        # ë°°ì¹˜ë³„ ë³‘ë ¬ ì²˜ë¦¬ (ì‹¤ì œë¡œëŠ” asyncio ì‚¬ìš© ê¶Œì¥)
        batch_results = [
            expand_single_query(query, strategy)
            for query in batch
        ]

        results.extend(batch_results)

    return results
```

## ğŸ“š ê³ ê¸‰ í™œìš© íŒ¨í„´

### 1. ì ì‘í˜• ì¿¼ë¦¬ í™•ì¥

```python
class AdaptiveQueryExpander:
    """ì‚¬ìš©ì í”¼ë“œë°±ì„ í†µí•œ ì ì‘í˜• í™•ì¥"""

    def __init__(self):
        self.user_preferences = {}
        self.success_history = {}

    def expand_with_learning(self, query, user_id=None):
        """í•™ìŠµ ê¸°ë°˜ ì¿¼ë¦¬ í™•ì¥"""
        # ì‚¬ìš©ìë³„ ì„ í˜¸ë„ ê³ ë ¤
        if user_id and user_id in self.user_preferences:
            preferred_strategy = self.user_preferences[user_id]
        else:
            preferred_strategy = self._get_best_strategy_for_query(query)

        result = self._apply_strategy(query, preferred_strategy)

        return {
            'result': result,
            'strategy_used': preferred_strategy,
            'feedback_id': self._generate_feedback_id()
        }

    def update_from_feedback(self, feedback_id, satisfaction_score, user_id=None):
        """ì‚¬ìš©ì í”¼ë“œë°±ìœ¼ë¡œ ëª¨ë¸ ì—…ë°ì´íŠ¸"""
        # í”¼ë“œë°± ê¸°ë°˜ ì „ëµ ì¡°ì • ë¡œì§
        pass
```

### 2. ë‹¤ì¤‘ ì–¸ì–´ ì§€ì›

```python
class MultilingualQueryExpander:
    """ë‹¤êµ­ì–´ ì¿¼ë¦¬ í™•ì¥ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.language_chains = {
            'ko': korean_expansion_chain,
            'en': english_expansion_chain,
            'ja': japanese_expansion_chain
        }

    def detect_language(self, query):
        """ì–¸ì–´ ê°ì§€"""
        # ê°„ë‹¨í•œ ì–¸ì–´ ê°ì§€ ë¡œì§
        if any(ord(char) >= 0xAC00 and ord(char) <= 0xD7A3 for char in query):
            return 'ko'
        elif any(ord(char) >= 0x3040 and ord(char) <= 0x309F for char in query):
            return 'ja'
        else:
            return 'en'

    def expand_multilingual(self, query):
        """ë‹¤êµ­ì–´ ëŒ€ì‘ í™•ì¥"""
        detected_lang = self.detect_language(query)
        appropriate_chain = self.language_chains.get(detected_lang, self.language_chains['en'])

        return appropriate_chain.invoke({"question": query})
```

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„ ë° ë°œì „ ë°©í–¥

### 1. ê³ ê¸‰ ê¸°ë²• íƒêµ¬
- **Neural Query Expansion**: ë”¥ëŸ¬ë‹ ê¸°ë°˜ í™•ì¥
- **Reinforcement Learning**: ê°•í™”í•™ìŠµì„ í†µí•œ ìµœì í™”
- **Federated Learning**: ë¶„ì‚° í•™ìŠµì„ í†µí•œ ì„±ëŠ¥ í–¥ìƒ

### 2. ì‹¤ë¬´ í†µí•©
- **A/B Testing Framework**: ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œì˜ ì„±ëŠ¥ ë¹„êµ
- **Real-time Optimization**: ì‹¤ì‹œê°„ ì„±ëŠ¥ ìµœì í™”
- **User Experience Integration**: ì‚¬ìš©ì ê²½í—˜ê³¼ í†µí•©ëœ í‰ê°€

### 3. ë„ë©”ì¸ íŠ¹í™”
- **ì˜ë£Œ ì •ë³´ ê²€ìƒ‰**: ì˜ë£Œ ë„ë©”ì¸ íŠ¹í™” í™•ì¥
- **ë²•ë¥  ë¬¸ì„œ ê²€ìƒ‰**: ë²•ë¥  ì „ë¬¸ ìš©ì–´ ì²˜ë¦¬
- **ê¸°ìˆ  ë¬¸ì„œ ê²€ìƒ‰**: ê¸°ìˆ  ì‚¬ì–‘ ì¤‘ì‹¬ í™•ì¥

---

## ğŸ“Š ì‹¤ìŠµ ì™„ë£Œ ìš”ì•½

### ğŸ¯ ì‹¤ìŠµ ì„±ê³¼
1. **5ê°€ì§€ ì¿¼ë¦¬ í™•ì¥ ê¸°ë²• êµ¬í˜„ ì™„ë£Œ**
   - Query Reformulation, MultiQuery, Decomposition, Step-Back, HyDE
   - ê° ê¸°ë²•ë³„ ê¸°ë³¸ ë° ê°œì„ ëœ ë²„ì „ êµ¬í˜„

2. **ì‹¤ì œ ì„±ëŠ¥ ì¸¡ì • ì™„ë£Œ**
   - K-RAG íŒ¨í‚¤ì§€ë¥¼ í™œìš©í•œ ì²´ê³„ì  í‰ê°€
   - Hit Rate, MRR, MAP, NDCG ì§€í‘œ ì¸¡ì •
   - k=2,3,4 ì„¤ì •ì—ì„œ ì„±ëŠ¥ ë¹„êµ

3. **ê²€ìƒ‰ ì„±ëŠ¥ ë¹„êµ ë¶„ì„**
   - ê° ê¸°ë²•ë³„ ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜ ì¸¡ì •
   - ë‹¤ê´€ì  ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„
   - ì„±ëŠ¥ ê°œì„  ë°©í–¥ ë„ì¶œ

### ğŸ“ ì£¼ìš” ì‹¤í—˜ ê²°ê³¼
```python
# ìµœì¢… í‰ê°€ ê²°ê³¼ ì €ì¥
print("ğŸ’¾ ê²°ê³¼ ì €ì¥:")
try:
    results_df.to_csv('multiquery_evaluation_results.csv')
    print("   âœ… ê²°ê³¼ê°€ 'multiquery_evaluation_results.csv'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
except Exception as e:
    print(f"   âŒ ì €ì¥ ì‹¤íŒ¨: {e}")

print("\nğŸ‰ ì‹¤ìŠµ 6 ì™„ë£Œ!")
```

### ğŸ” í•µì‹¬ í•™ìŠµ ë‚´ìš©
1. **ì¿¼ë¦¬ í™•ì¥ì˜ ì¤‘ìš”ì„±**: ì›ë³¸ ì§ˆë¬¸ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  ë” í¬ê´„ì ì¸ ê²€ìƒ‰ ìˆ˜í–‰
2. **ê¸°ë²•ë³„ íŠ¹ì„± ì´í•´**: ê° ê¸°ë²•ì˜ ì¥ë‹¨ì ê³¼ ì ìš© ìƒí™© íŒŒì•…
3. **ì‹¤ë¬´ ì ìš© ë°©ë²•ë¡ **: ìƒí™©ì— ë§ëŠ” ê¸°ë²• ì„ íƒê³¼ í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ë²•

### ğŸ’¡ ì‹¤ë¬´ ì ìš© ê°€ì´ë“œ
- **ë‹¨ìˆœ ì§ˆë¬¸**: Query Reformulation
- **íƒìƒ‰ì  ê²€ìƒ‰**: MultiQuery
- **ë³µí•© ì§ˆë¬¸**: Decomposition
- **ë°°ê²½ ì§€ì‹ í•„ìš”**: Step-Back
- **ì •ë°€ ê²€ìƒ‰**: HyDE

---

**ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸**: ì¿¼ë¦¬ í™•ì¥ì€ ë‹¨ìˆœí•œ ê¸°ë²•ì˜ ì¡°í•©ì´ ì•„ë‹ˆë¼, ì‚¬ìš©ìì˜ ì •ë³´ ìš”êµ¬ë¥¼ ì •í™•íˆ íŒŒì•…í•˜ê³  ì´ë¥¼ ê²€ìƒ‰ ì‹œìŠ¤í…œì´ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ì§€ëŠ¥ì  ì¤‘ê°œ ê³¼ì •ì…ë‹ˆë‹¤. ê° ê¸°ë²•ì˜ íŠ¹ì„±ì„ ì´í•´í•˜ê³  ìƒí™©ì— ë§ê²Œ ì ì ˆíˆ ì¡°í•©í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤. ë³¸ ì‹¤ìŠµì—ì„œëŠ” ì‹¤ì œ í•œêµ­ì–´ ì „ê¸°ì°¨ ë°ì´í„°ë¥¼ ëŒ€ìƒìœ¼ë¡œ ê° ê¸°ë²•ì˜ ì„±ëŠ¥ì„ ì²´ê³„ì ìœ¼ë¡œ ì¸¡ì •í•˜ê³  ë¶„ì„í–ˆìŠµë‹ˆë‹¤.