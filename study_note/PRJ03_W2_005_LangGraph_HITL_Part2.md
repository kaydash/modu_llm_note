# LangGraph HITL (Human-in-the-Loop) - Part 2: ì›¹ ê²€ìƒ‰ ë¦¬ì„œì¹˜ ì‹œìŠ¤í…œ

## ðŸ“š í•™ìŠµ ëª©í‘œ

ì´ ê°€ì´ë“œë¥¼ ì™„ë£Œí•˜ë©´ ë‹¤ìŒì„ í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤:

1. **ì›¹ ê²€ìƒ‰ í†µí•©**: TavilySearchë¥¼ í™œìš©í•œ ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•œë‹¤
2. **êµ¬ì¡°í™”ëœ ì¶œë ¥**: Pydanticì„ ì‚¬ìš©í•˜ì—¬ LLM ì¶œë ¥ì„ ì•ˆì •ì ìœ¼ë¡œ êµ¬ì¡°í™”í•œë‹¤
3. **ë³‘ë ¬ ê²€ìƒ‰**: Sendì™€ ë§µ-ë¦¬ë“€ìŠ¤ íŒ¨í„´ìœ¼ë¡œ íš¨ìœ¨ì ì¸ ë³‘ë ¬ ê²€ìƒ‰ì„ êµ¬í˜„í•œë‹¤
4. **ë‹¤ë‹¨ê³„ HITL**: ì£¼ì œ ë¶„ì„ â†’ ê²€ìƒ‰ â†’ ë³´ê³ ì„œ ìž‘ì„±ì˜ ê° ë‹¨ê³„ì—ì„œ ì‚¬ìš©ìž ê°œìž…ì„ ì ìš©í•œë‹¤
5. **ì¡°ê±´ë¶€ ì›Œí¬í”Œë¡œìš°**: ì‚¬ìš©ìž í”¼ë“œë°±ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì‹¤í–‰ íë¦„ì„ ì œì–´í•œë‹¤
6. **í”¼ë“œë°± ì²˜ë¦¬**: ì‚¬ìš©ìž í”¼ë“œë°±ì„ íŒŒì‹±í•˜ê³  ì ì ˆí•˜ê²Œ ë°˜ì˜í•˜ëŠ” ë¡œì§ì„ êµ¬í˜„í•œë‹¤
7. **ì‹¤ë¬´ ì‹œìŠ¤í…œ êµ¬ì¶•**: ì™„ì „í•œ ë¦¬ì„œì¹˜ ìžë™í™” ì‹œìŠ¤í…œì„ ì²˜ìŒë¶€í„° ëê¹Œì§€ ê°œë°œí•œë‹¤

## ðŸ”‘ í•µì‹¬ ê°œë…

### ì›¹ ê²€ìƒ‰ ë¦¬ì„œì¹˜ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

ì´ ì‹œìŠ¤í…œì€ ì‚¬ìš©ìžê°€ ì œê³µí•œ ì£¼ì œì— ëŒ€í•´ ìžë™ìœ¼ë¡œ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ë³´ê³ ì„œë¥¼ ìž‘ì„±í•˜ëŠ” ì™„ì „í•œ AI ì—ì´ì „íŠ¸ìž…ë‹ˆë‹¤.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì‚¬ìš©ìž ì£¼ì œ  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì£¼ì œ ë¶„ì„       â”‚  â† LLMìœ¼ë¡œ í‚¤ì›Œë“œ ìƒì„±
â”‚  (í‚¤ì›Œë“œ ìƒì„±)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ” HITL 1      â”‚  â† interrupt: ì‚¬ìš©ìžê°€ í‚¤ì›Œë“œ ê²€í† 
â”‚  í‚¤ì›Œë“œ ê²€í†      â”‚     - ìŠ¹ì¸ / ìˆ˜ì • / ê±°ë¶€
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì›¹ ê²€ìƒ‰ (ë³‘ë ¬)  â”‚  â† ê° í‚¤ì›Œë“œë¡œ ë™ì‹œ ê²€ìƒ‰
â”‚  ë§µ-ë¦¬ë“€ìŠ¤ íŒ¨í„´  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ë³´ê³ ì„œ ìƒì„±     â”‚  â† LLMìœ¼ë¡œ ê²€ìƒ‰ ê²°ê³¼ ì¢…í•©
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ” HITL 2      â”‚  â† interrupt: ì‚¬ìš©ìžê°€ ë³´ê³ ì„œ ê²€í† 
â”‚  ë³´ê³ ì„œ ê²€í†      â”‚     - ìŠ¹ì¸ / ìˆ˜ì • ìš”ì²­
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ìµœì¢… ë³´ê³ ì„œ     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### TavilySearch - ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰

**TavilySearch**ëŠ” LangChainì—ì„œ ì œê³µí•˜ëŠ” ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ ë„êµ¬ìž…ë‹ˆë‹¤.

```python
from langchain_tavily import TavilySearch

# ì´ˆê¸°í™” (API í‚¤ í•„ìš”)
search_tool = TavilySearch(max_results=5)

# ê²€ìƒ‰ ì‹¤í–‰
results = search_tool.invoke("ê¸°í›„ë³€í™”")
```

**íŠ¹ì§•:**
- ìµœì‹  ì›¹ ê²€ìƒ‰ ê²°ê³¼ ì œê³µ
- êµ¬ì¡°í™”ëœ ê²°ê³¼ (ì œëª©, URL, ë‚´ìš©)
- ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ ì œí•œ ê°€ëŠ¥
- ë¹ ë¥¸ ì‘ë‹µ ì†ë„

**ê²°ê³¼ í˜•ì‹:**
```python
{
    "results": [
        {
            "title": "ê²€ìƒ‰ ê²°ê³¼ ì œëª©",
            "url": "https://...",
            "content": "ê²€ìƒ‰ ê²°ê³¼ ë‚´ìš©",
            "score": 0.95  # ê´€ë ¨ë„ ì ìˆ˜
        },
        ...
    ]
}
```

### Pydanticì„ ì‚¬ìš©í•œ êµ¬ì¡°í™”ëœ ì¶œë ¥

LLM ì¶œë ¥ì„ ì•ˆì •ì ìœ¼ë¡œ êµ¬ì¡°í™”í•˜ê¸° ìœ„í•´ Pydantic ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

```python
from pydantic import BaseModel, Field

class Keywords(BaseModel):
    """í‚¤ì›Œë“œ ìƒì„± ê²°ê³¼"""
    keywords: List[str] = Field(description="ìƒì„±ëœ í‚¤ì›Œë“œ ëª©ë¡")
    confidence: float = Field(description="í‚¤ì›Œë“œ ì‹ ë¢°ë„ (0-1)")

# LLMê³¼ ì—°ê²°
llm = ChatOpenAI(model="gpt-4o-mini")
structured_llm = llm.with_structured_output(Keywords)

# ì‚¬ìš©
result = structured_llm.invoke("ê¸°í›„ë³€í™”ì— ëŒ€í•œ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ì„¸ìš”")
print(result.keywords)  # ['ê¸°í›„ë³€í™”', 'ì˜¨ì‹¤ê°€ìŠ¤', 'íƒ„ì†Œì¤‘ë¦½']
print(result.confidence)  # 0.9
```

**ìž¥ì :**
- íƒ€ìž… ì•ˆì •ì„± ë³´ìž¥
- ìžë™ ê²€ì¦ (Field ì œì•½ ì¡°ê±´)
- ëª…í™•í•œ ìŠ¤í‚¤ë§ˆ ì •ì˜
- IDE ìžë™ì™„ì„± ì§€ì›

### Sendì™€ ë³‘ë ¬ ê²€ìƒ‰ íŒ¨í„´

LangGraphì˜ `Send`ë¥¼ ì‚¬ìš©í•˜ë©´ ì—¬ëŸ¬ ë…¸ë“œë¥¼ ë³‘ë ¬ë¡œ ì‹¤í–‰í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

```python
from langgraph.types import Send

def dispatch_searches(state: ResearchState) -> List[Send]:
    """ê° í‚¤ì›Œë“œë§ˆë‹¤ search_one ë…¸ë“œë¥¼ ë³‘ë ¬ ì‹¤í–‰"""
    keywords = state["keywords"]
    return [Send("search_one", {"keyword": kw}) for kw in keywords]

def search_one(state: Dict) -> ResearchState:
    """ê°œë³„ ê²€ìƒ‰ ì‹¤í–‰"""
    keyword = state["keyword"]
    results = search_tool.invoke(keyword)
    return {"search_results": [results]}

# ê·¸ëž˜í”„ êµ¬ì„±
workflow.add_node("dispatch", dispatch_searches)
workflow.add_node("search_one", search_one)
```

**ì‹¤í–‰ íë¦„:**
```
dispatch â†’ Send(search_one, kw1)  â”€â”
        â†’ Send(search_one, kw2)  â”€â”¤
        â†’ Send(search_one, kw3)  â”€â”¤â†’ ë³‘ë ¬ ì‹¤í–‰
        â†’ Send(search_one, kw4)  â”€â”¤
        â†’ Send(search_one, kw5)  â”€â”˜
```

**ë§µ-ë¦¬ë“€ìŠ¤ íŒ¨í„´:**
- **Map**: ê° í‚¤ì›Œë“œë¥¼ ê°œë³„ ê²€ìƒ‰ ë…¸ë“œë¡œ ë””ìŠ¤íŒ¨ì¹˜
- **Reduce**: ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ë‹¤ìŒ ë…¸ë“œë¡œ ì „ë‹¬

### ë‹¤ë‹¨ê³„ HITL ì›Œí¬í”Œë¡œìš°

ë³µìž¡í•œ ì›Œí¬í”Œë¡œìš°ì—ì„œëŠ” ì—¬ëŸ¬ ì§€ì ì—ì„œ ì‚¬ìš©ìž ê°œìž…ì´ í•„ìš”í•©ë‹ˆë‹¤.

**íŒ¨í„´ 1: í‚¤ì›Œë“œ ê²€í†  (ì£¼ì œ ë¶„ì„ í›„)**
```python
def review_keywords(state: ResearchState) -> ResearchState:
    keywords = state["keywords"]

    feedback = interrupt({
        "message": "ìƒì„±ëœ í‚¤ì›Œë“œë¥¼ ê²€í† í•´ì£¼ì„¸ìš”",
        "keywords": keywords,
        "options": ["ìŠ¹ì¸", "ìˆ˜ì •", "ê±°ë¶€"]
    })

    return {"feedback": feedback}
```

**íŒ¨í„´ 2: ë³´ê³ ì„œ ê²€í†  (ë³´ê³ ì„œ ìƒì„± í›„)**
```python
def review_report(state: ResearchState) -> ResearchState:
    report = state["report"]

    feedback = interrupt({
        "message": "ë³´ê³ ì„œë¥¼ ê²€í† í•´ì£¼ì„¸ìš”",
        "report": report,
        "options": ["ìŠ¹ì¸", "ìˆ˜ì • ìš”ì²­"]
    })

    return {"report_feedback": feedback}
```

### í”¼ë“œë°± ì²˜ë¦¬ ë¡œì§

ì‚¬ìš©ìž í”¼ë“œë°±ì„ íŒŒì‹±í•˜ì—¬ ì ì ˆí•œ ì•¡ì…˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

```python
def process_feedback(state: ResearchState) -> ResearchState:
    feedback = state.get("feedback", "")

    # í”¼ë“œë°± íŒŒì‹±
    if "ìŠ¹ì¸" in feedback:
        return {"status": "approved"}

    elif "ìˆ˜ì •:" in feedback:
        # "ìˆ˜ì •: í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, ..." í˜•íƒœ
        modified_keywords = feedback.split("ìˆ˜ì •:")[1].strip()
        keywords = [kw.strip() for kw in modified_keywords.split(",")]
        return {"keywords": keywords, "status": "modified"}

    elif "ê±°ë¶€" in feedback:
        # ìž¬ìƒì„± í•„ìš”
        return {"status": "rejected"}

    return {"status": "unknown"}
```

## ðŸ›  í™˜ê²½ ì„¤ì •

### í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

```bash
pip install -qU \
    langgraph \
    langchain-openai \
    langchain-tavily \
    pydantic \
    python-dotenv
```

### API í‚¤ ì„¤ì •

`.env` íŒŒì¼ì— ë‘ ê°œì˜ API í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤:

```bash
OPENAI_API_KEY=your_openai_api_key_here
TAVILY_API_KEY=your_tavily_api_key_here
```

**Tavily API í‚¤ ë°œê¸‰:**
1. [https://tavily.com](https://tavily.com) ë°©ë¬¸
2. íšŒì›ê°€ìž… ë° ë¡œê·¸ì¸
3. API Keys ë©”ë‰´ì—ì„œ í‚¤ ìƒì„±
4. ë¬´ë£Œ í”Œëžœ: ì›” 1,000íšŒ ê²€ìƒ‰ ê°€ëŠ¥

### ê¸°ë³¸ ì„¤ì • ì½”ë“œ

```python
from dotenv import load_dotenv
import os

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# API í‚¤ í™•ì¸
if not os.getenv("OPENAI_API_KEY"):
    raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

if not os.getenv("TAVILY_API_KEY"):
    raise ValueError("TAVILY_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

print("í™˜ê²½ ì„¤ì • ì™„ë£Œ!")
```

## ðŸ’» ë‹¨ê³„ë³„ êµ¬í˜„

### Step 1: ìƒíƒœ ì •ì˜ ë° ë„êµ¬ ì„¤ì •

ì›¹ ê²€ìƒ‰ ë¦¬ì„œì¹˜ ì‹œìŠ¤í…œì— í•„ìš”í•œ ìƒíƒœì™€ ë„êµ¬ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

```python
from typing import List, Dict, Annotated, Optional
from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, START, END, MessagesState
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.types import interrupt, Command, Send
from langchain_openai import ChatOpenAI
from langchain_tavily import TavilySearch
from langchain_core.messages import BaseMessage, AIMessage, HumanMessage
from langchain_core.prompts import ChatPromptTemplate
from IPython.display import Image, display
import uuid

# 1. LLM ì´ˆê¸°í™”
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)

# 2. ì›¹ ê²€ìƒ‰ ë„êµ¬ ì´ˆê¸°í™”
search_tool = TavilySearch(
    max_results=5,  # ê²€ìƒ‰ ê²°ê³¼ ìµœëŒ€ 5ê°œ
    search_depth="advanced"  # ì‹¬í™” ê²€ìƒ‰
)

# 3. ìƒíƒœ íƒ€ìž… ì •ì˜
class ResearchState(MessagesState):
    """ë¦¬ì„œì¹˜ ì‹œìŠ¤í…œ ìƒíƒœ"""
    topic: str                          # ì‚¬ìš©ìž ì£¼ì œ
    keywords: List[str]                 # ìƒì„±ëœ í‚¤ì›Œë“œ
    feedback: str                       # ì‚¬ìš©ìž í”¼ë“œë°±
    search_results: List[Dict]          # ê²€ìƒ‰ ê²°ê³¼ ëª©ë¡
    report: str                         # ìƒì„±ëœ ë³´ê³ ì„œ
    report_feedback: str                # ë³´ê³ ì„œ í”¼ë“œë°±
    ready_for_search: bool              # ê²€ìƒ‰ ì¤€ë¹„ ìƒíƒœ

# 4. Pydantic ëª¨ë¸ (êµ¬ì¡°í™”ëœ ì¶œë ¥ìš©)
class Keywords(BaseModel):
    """í‚¤ì›Œë“œ ìƒì„± ê²°ê³¼"""
    keywords: List[str] = Field(
        description="ìƒì„±ëœ í‚¤ì›Œë“œ ëª©ë¡ (3-7ê°œ)",
        min_items=3,
        max_items=7
    )
    confidence: float = Field(
        description="í‚¤ì›Œë“œ ì‹ ë¢°ë„ (0-1)",
        ge=0.0,
        le=1.0
    )

print("âœ… ìƒíƒœ ë° ë„êµ¬ ì„¤ì • ì™„ë£Œ")
```

**ìƒíƒœ í•„ë“œ ì„¤ëª…:**
- `topic`: ì‚¬ìš©ìžê°€ ìž…ë ¥í•œ ì—°êµ¬ ì£¼ì œ
- `keywords`: LLMì´ ìƒì„±í•œ ê²€ìƒ‰ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
- `feedback`: í‚¤ì›Œë“œì— ëŒ€í•œ ì‚¬ìš©ìž í”¼ë“œë°±
- `search_results`: ê° í‚¤ì›Œë“œì˜ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
- `report`: ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¢…í•©í•œ ë³´ê³ ì„œ
- `report_feedback`: ë³´ê³ ì„œì— ëŒ€í•œ ì‚¬ìš©ìž í”¼ë“œë°±
- `ready_for_search`: ê²€ìƒ‰ ì¤€ë¹„ ì™„ë£Œ í”Œëž˜ê·¸

### Step 2: ì£¼ì œ ë¶„ì„ ë…¸ë“œ êµ¬í˜„

ì‚¬ìš©ìž ì£¼ì œë¥¼ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ê³ , ì‚¬ìš©ìž ê²€í† ë¥¼ ë°›ìŠµë‹ˆë‹¤.

```python
# 1. í‚¤ì›Œë“œ ìƒì„± ë…¸ë“œ
def generate_keywords(state: ResearchState) -> ResearchState:
    """ì£¼ì œë¥¼ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„±"""
    print("--- ì£¼ì œ ë¶„ì„ ì¤‘ ---")

    topic = state.get("topic", "")

    # í”„ë¡¬í”„íŠ¸ ì •ì˜
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ì „ë¬¸ ë¦¬ì„œì¹˜ ë¶„ì„ê°€ë¡œì„œ íš¨ê³¼ì ì¸ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ì„¸ìš”.

ê·œì¹™:
- 3-7ê°œì˜ í•µì‹¬ í‚¤ì›Œë“œ ìƒì„±
- ë‹¤ì–‘í•œ ê´€ì  í¬í•¨ (ê¸°ìˆ , ë¹„ì¦ˆë‹ˆìŠ¤, ì‚¬íšŒì  ì˜í–¥ ë“±)
- ê²€ìƒ‰ì— íš¨ê³¼ì ì¸ ìš©ì–´ ì„ íƒ
- ì‹ ë¢°ë„(0-1)ë„ í•¨ê»˜ ì œê³µ"""),
        ("human", "ì£¼ì œ: {topic}")
    ])

    # êµ¬ì¡°í™”ëœ ì¶œë ¥ ì²´ì¸
    structured_llm = llm.with_structured_output(Keywords)
    chain = prompt | structured_llm

    # í‚¤ì›Œë“œ ìƒì„±
    result = chain.invoke({"topic": topic})

    print(f"ìƒì„±ëœ í‚¤ì›Œë“œ: {result.keywords}")
    print(f"ì‹ ë¢°ë„: {result.confidence:.2f}")

    return {
        "keywords": result.keywords,
        "feedback": ""  # ì´ˆê¸°í™”
    }

# 2. í‚¤ì›Œë“œ ê²€í†  ë…¸ë“œ (HITL)
def review_keywords(state: ResearchState) -> ResearchState:
    """ì‚¬ìš©ìžê°€ ìƒì„±ëœ í‚¤ì›Œë“œë¥¼ ê²€í† """
    print("\n--- í‚¤ì›Œë“œ ê²€í†  ë‹¨ê³„ (HITL) ---")

    keywords = state.get("keywords", [])
    topic = state.get("topic", "")

    # interruptë¡œ ì‚¬ìš©ìž ê²€í†  ìš”ì²­
    feedback = interrupt({
        "message": "ìƒì„±ëœ í‚¤ì›Œë“œë¥¼ ê²€í† í•´ì£¼ì„¸ìš”",
        "topic": topic,
        "keywords": keywords,
        "instructions": """
        - 'ìŠ¹ì¸': í‚¤ì›Œë“œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        - 'ìˆ˜ì •: í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, ...': ì§ì ‘ í‚¤ì›Œë“œ ìž…ë ¥
        - 'ê±°ë¶€': ë‹¤ì‹œ ìƒì„±
        """,
        "options": ["ìŠ¹ì¸", "ìˆ˜ì •: ", "ê±°ë¶€"]
    })

    print(f"ì‚¬ìš©ìž í”¼ë“œë°±: {feedback}")

    return {"feedback": feedback}

# 3. í”¼ë“œë°± ì²˜ë¦¬ ë…¸ë“œ
def process_keyword_feedback(state: ResearchState) -> ResearchState:
    """ì‚¬ìš©ìž í”¼ë“œë°±ì— ë”°ë¼ í‚¤ì›Œë“œ ì²˜ë¦¬"""
    print("\n--- í”¼ë“œë°± ì²˜ë¦¬ ì¤‘ ---")

    feedback = state.get("feedback", "").strip()

    if "ìˆ˜ì •:" in feedback:
        # ì‚¬ìš©ìžê°€ ì§ì ‘ ìž…ë ¥í•œ í‚¤ì›Œë“œ íŒŒì‹±
        print("âœï¸ í‚¤ì›Œë“œ ìˆ˜ì •")
        modified_text = feedback.split("ìˆ˜ì •:")[1].strip()
        keywords = [kw.strip() for kw in modified_text.split(",")]

        print(f"ìˆ˜ì •ëœ í‚¤ì›Œë“œ: {keywords}")
        return {"keywords": keywords}

    elif "ê±°ë¶€" in feedback:
        # ìž¬ìƒì„±ì€ ê·¸ëž˜í”„ íë¦„ì—ì„œ ì²˜ë¦¬
        print("âŒ ê±°ë¶€ - ìž¬ìƒì„± í•„ìš”")
        return {}

    else:  # ìŠ¹ì¸
        print("âœ… ìŠ¹ì¸ - ê²€ìƒ‰ ì§„í–‰")
        return {}

# 4. ì¡°ê±´ë¶€ ë¶„ê¸° í•¨ìˆ˜
def should_continue_after_review(state: ResearchState) -> str:
    """ê²€í†  í›„ ë‹¤ìŒ ë‹¨ê³„ ê²°ì •"""
    feedback = state.get("feedback", "").strip().lower()

    if not feedback or "ìŠ¹ì¸" in feedback:
        return "approved"  # ê²€ìƒ‰ ì§„í–‰

    elif "ìˆ˜ì •:" in feedback:
        return "process_feedback"  # í”¼ë“œë°± ì²˜ë¦¬

    else:  # ê±°ë¶€
        return "regenerate"  # ìž¬ìƒì„±

print("âœ… ì£¼ì œ ë¶„ì„ ë…¸ë“œ êµ¬í˜„ ì™„ë£Œ")
```

### Step 3: ì›Œí¬í”Œë¡œìš° êµ¬ì„± (ì£¼ì œ ë¶„ì„ ë¶€ë¶„)

ì£¼ì œ ë¶„ì„ ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì„±í•˜ê³  í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.

```python
# 1. StateGraph ìƒì„±
workflow = StateGraph(ResearchState)

# 2. ë…¸ë“œ ì¶”ê°€
workflow.add_node("analyze_topic", generate_keywords)
workflow.add_node("review_keywords", review_keywords)
workflow.add_node("process_feedback", process_keyword_feedback)

# 3. ì—£ì§€ ì¶”ê°€
workflow.add_edge(START, "analyze_topic")
workflow.add_edge("analyze_topic", "review_keywords")

# 4. ì¡°ê±´ë¶€ ì—£ì§€
workflow.add_conditional_edges(
    "review_keywords",
    should_continue_after_review,
    {
        "approved": END,  # ìž„ì‹œë¡œ END (ë‚˜ì¤‘ì— ê²€ìƒ‰ ë…¸ë“œë¡œ ì—°ê²°)
        "process_feedback": "process_feedback",
        "regenerate": "analyze_topic"
    }
)

workflow.add_edge("process_feedback", END)  # ìž„ì‹œ

# 5. ì»´íŒŒì¼
checkpointer = InMemorySaver()
research_graph = workflow.compile(checkpointer=checkpointer)

# 6. ê·¸ëž˜í”„ ì‹œê°í™”
display(Image(research_graph.get_graph().draw_mermaid_png()))

print("âœ… ì›Œí¬í”Œë¡œìš° êµ¬ì„± ì™„ë£Œ")
```

### Step 4: ì£¼ì œ ë¶„ì„ í…ŒìŠ¤íŠ¸ (ì‹œë‚˜ë¦¬ì˜¤ë³„)

ë‹¤ì–‘í•œ ì‚¬ìš©ìž í”¼ë“œë°± ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.

#### ì‹œë‚˜ë¦¬ì˜¤ 1: ìŠ¹ì¸

```python
print("=" * 80)
print("=== ì‹œë‚˜ë¦¬ì˜¤ 1: í‚¤ì›Œë“œ ìŠ¹ì¸ ===")
print("=" * 80)

# ìŠ¤ë ˆë“œ ì„¤ì •
thread = {"configurable": {"thread_id": str(uuid.uuid4())}}

# ì´ˆê¸° ì‹¤í–‰
initial_state = {
    "topic": "ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ëž˜ì™€ ì‚¬íšŒì  ì˜í–¥",
    "keywords": [],
    "feedback": "",
    "search_results": [],
    "report": "",
    "report_feedback": "",
    "ready_for_search": False
}

result = research_graph.invoke(initial_state, thread)

# interruptê¹Œì§€ ì‹¤í–‰ë¨
print(f"\nì¤‘ë‹¨ ì‹œì  í‚¤ì›Œë“œ: {result['keywords']}")

# ìƒíƒœ í™•ì¸
state = research_graph.get_state(thread)
print(f"ë‹¤ìŒ ë…¸ë“œ: {state.next}")

# ì‚¬ìš©ìž ìŠ¹ì¸
print("\n>>> ì‚¬ìš©ìžê°€ 'ìŠ¹ì¸'ì„ ì„ íƒí•©ë‹ˆë‹¤")
final_result = research_graph.invoke(Command(resume="ìŠ¹ì¸"), thread)

print(f"\nìµœì¢… í‚¤ì›Œë“œ: {final_result['keywords']}")
print(f"í”¼ë“œë°±: {final_result['feedback']}")
```

**ì‹¤í–‰ ê²°ê³¼:**
```
--- ì£¼ì œ ë¶„ì„ ì¤‘ ---
ìƒì„±ëœ í‚¤ì›Œë“œ: ['ì¸ê³µì§€ëŠ¥', 'AI ìœ¤ë¦¬', 'ìžë™í™”', 'ì¼ìžë¦¬ ë³€í™”', 'ê¸°ìˆ  ë°œì „']
ì‹ ë¢°ë„: 0.85

--- í‚¤ì›Œë“œ ê²€í†  ë‹¨ê³„ (HITL) ---

ì¤‘ë‹¨ ì‹œì  í‚¤ì›Œë“œ: ['ì¸ê³µì§€ëŠ¥', 'AI ìœ¤ë¦¬', 'ìžë™í™”', 'ì¼ìžë¦¬ ë³€í™”', 'ê¸°ìˆ  ë°œì „']
ë‹¤ìŒ ë…¸ë“œ: ('review_keywords',)

>>> ì‚¬ìš©ìžê°€ 'ìŠ¹ì¸'ì„ ì„ íƒí•©ë‹ˆë‹¤
ì‚¬ìš©ìž í”¼ë“œë°±: ìŠ¹ì¸
âœ… ìŠ¹ì¸ - ê²€ìƒ‰ ì§„í–‰

ìµœì¢… í‚¤ì›Œë“œ: ['ì¸ê³µì§€ëŠ¥', 'AI ìœ¤ë¦¬', 'ìžë™í™”', 'ì¼ìžë¦¬ ë³€í™”', 'ê¸°ìˆ  ë°œì „']
```

#### ì‹œë‚˜ë¦¬ì˜¤ 2: ìˆ˜ì •

```python
print("\n" + "=" * 80)
print("=== ì‹œë‚˜ë¦¬ì˜¤ 2: í‚¤ì›Œë“œ ìˆ˜ì • ===")
print("=" * 80)

# ìƒˆë¡œìš´ ìŠ¤ë ˆë“œ
thread2 = {"configurable": {"thread_id": str(uuid.uuid4())}}

# ì´ˆê¸° ì‹¤í–‰
result = research_graph.invoke(initial_state, thread2)

print(f"\nì›ë³¸ í‚¤ì›Œë“œ: {result['keywords']}")

# ì‚¬ìš©ìžê°€ ì§ì ‘ í‚¤ì›Œë“œ ìˆ˜ì •
print("\n>>> ì‚¬ìš©ìžê°€ í‚¤ì›Œë“œë¥¼ ì§ì ‘ ìˆ˜ì •í•©ë‹ˆë‹¤")
modified_keywords = "ìˆ˜ì •: AI ê¸°ìˆ , ë”¥ëŸ¬ë‹, ë¨¸ì‹ ëŸ¬ë‹, ì‚¬íšŒ ë³€í™”, ìœ¤ë¦¬ì  ë¬¸ì œ"

final_result = research_graph.invoke(Command(resume=modified_keywords), thread2)

print(f"\nìˆ˜ì •ëœ í‚¤ì›Œë“œ: {final_result['keywords']}")
```

**ì‹¤í–‰ ê²°ê³¼:**
```
ì›ë³¸ í‚¤ì›Œë“œ: ['ì¸ê³µì§€ëŠ¥', 'AI ìœ¤ë¦¬', 'ìžë™í™”', 'ì¼ìžë¦¬ ë³€í™”', 'ê¸°ìˆ  ë°œì „']

>>> ì‚¬ìš©ìžê°€ í‚¤ì›Œë“œë¥¼ ì§ì ‘ ìˆ˜ì •í•©ë‹ˆë‹¤
ì‚¬ìš©ìž í”¼ë“œë°±: ìˆ˜ì •: AI ê¸°ìˆ , ë”¥ëŸ¬ë‹, ë¨¸ì‹ ëŸ¬ë‹, ì‚¬íšŒ ë³€í™”, ìœ¤ë¦¬ì  ë¬¸ì œ
âœï¸ í‚¤ì›Œë“œ ìˆ˜ì •
ìˆ˜ì •ëœ í‚¤ì›Œë“œ: ['AI ê¸°ìˆ ', 'ë”¥ëŸ¬ë‹', 'ë¨¸ì‹ ëŸ¬ë‹', 'ì‚¬íšŒ ë³€í™”', 'ìœ¤ë¦¬ì  ë¬¸ì œ']
```

#### ì‹œë‚˜ë¦¬ì˜¤ 3: ê±°ë¶€ (ìž¬ìƒì„±)

```python
print("\n" + "=" * 80)
print("=== ì‹œë‚˜ë¦¬ì˜¤ 3: í‚¤ì›Œë“œ ê±°ë¶€ - ìž¬ìƒì„± ===")
print("=" * 80)

# ìƒˆë¡œìš´ ìŠ¤ë ˆë“œ
thread3 = {"configurable": {"thread_id": str(uuid.uuid4())}}

# ì´ˆê¸° ì‹¤í–‰
result = research_graph.invoke(initial_state, thread3)

print(f"\nì²« ë²ˆì§¸ ìƒì„± í‚¤ì›Œë“œ: {result['keywords']}")

# ì‚¬ìš©ìž ê±°ë¶€
print("\n>>> ì‚¬ìš©ìžê°€ 'ê±°ë¶€'ë¥¼ ì„ íƒí•©ë‹ˆë‹¤ (ìž¬ìƒì„±)")
result2 = research_graph.invoke(Command(resume="ê±°ë¶€"), thread3)

# ìž¬ìƒì„±ëœ í‚¤ì›Œë“œê°€ ë‚˜ì˜´
print(f"\nìž¬ìƒì„±ëœ í‚¤ì›Œë“œ: {result2['keywords']}")

# ì´ë²ˆì—ëŠ” ìŠ¹ì¸
print("\n>>> ìž¬ìƒì„±ëœ í‚¤ì›Œë“œë¥¼ ìŠ¹ì¸í•©ë‹ˆë‹¤")
final_result = research_graph.invoke(Command(resume="ìŠ¹ì¸"), thread3)

print(f"\nìµœì¢… í™•ì • í‚¤ì›Œë“œ: {final_result['keywords']}")
```

### Step 5: ë³‘ë ¬ ì›¹ ê²€ìƒ‰ ë…¸ë“œ êµ¬í˜„

ê° í‚¤ì›Œë“œì— ëŒ€í•´ ë³‘ë ¬ë¡œ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

```python
# 1. ê²€ìƒ‰ ì¤€ë¹„ ë…¸ë“œ
def ready_to_search(state: ResearchState) -> ResearchState:
    """ê²€ìƒ‰ ì¤€ë¹„"""
    print("\n--- ì›¹ ê²€ìƒ‰ ì¤€ë¹„ ì¤‘ ---")
    keywords = state.get("keywords", [])
    print(f"ê²€ìƒ‰í•  í‚¤ì›Œë“œ: {keywords}")

    return {"ready_for_search": True, "search_results": []}

# 2. ë³‘ë ¬ ê²€ìƒ‰ ë””ìŠ¤íŒ¨ì¹˜
def dispatch_searches(state: ResearchState) -> List[Send]:
    """ê° í‚¤ì›Œë“œë§ˆë‹¤ ë³‘ë ¬ ê²€ìƒ‰ ìˆ˜í–‰"""
    keywords = state.get("keywords", [])

    print(f"\n--- {len(keywords)}ê°œ í‚¤ì›Œë“œ ë³‘ë ¬ ê²€ìƒ‰ ì‹œìž‘ ---")

    # ê° í‚¤ì›Œë“œë§ˆë‹¤ search_one ë…¸ë“œë¥¼ Sendë¡œ ë””ìŠ¤íŒ¨ì¹˜
    return [Send("search_one", {"keyword": kw}) for kw in keywords]

# 3. ê°œë³„ ê²€ìƒ‰ ë…¸ë“œ
def search_one(state: Dict) -> ResearchState:
    """ê°œë³„ í‚¤ì›Œë“œ ê²€ìƒ‰"""
    keyword = state["keyword"]

    print(f"ðŸ” ê²€ìƒ‰ ì¤‘: {keyword}")

    try:
        # Tavily ê²€ìƒ‰ ì‹¤í–‰
        results = search_tool.invoke(keyword)

        # ê²°ê³¼ ì •ë¦¬
        search_data = []
        if isinstance(results, dict):
            data = results.get("results", results)
        else:
            data = results

        for item in data[:3]:  # ìƒìœ„ 3ê°œë§Œ
            search_data.append({
                "keyword": keyword,
                "title": item.get("title", ""),
                "url": item.get("url", ""),
                "content": item.get("content", "")[:200]  # 200ìž ì œí•œ
            })

        print(f"  âœ… {keyword}: {len(search_data)}ê°œ ê²°ê³¼")

        return {"search_results": search_data}

    except Exception as e:
        print(f"  âŒ {keyword} ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return {"search_results": []}

print("âœ… ì›¹ ê²€ìƒ‰ ë…¸ë“œ êµ¬í˜„ ì™„ë£Œ")
```

**ë³‘ë ¬ ê²€ìƒ‰ íŒ¨í„´:**
```
ready_to_search
    â†“
dispatch_searches â”€â”€â†’ Send(search_one, "AI ê¸°ìˆ ")      â”
                  â”€â”€â†’ Send(search_one, "ë”¥ëŸ¬ë‹")       â”‚
                  â”€â”€â†’ Send(search_one, "ë¨¸ì‹ ëŸ¬ë‹")     â”œâ”€â†’ ë³‘ë ¬ ì‹¤í–‰
                  â”€â”€â†’ Send(search_one, "ì‚¬íšŒ ë³€í™”")    â”‚
                  â”€â”€â†’ Send(search_one, "ìœ¤ë¦¬ì  ë¬¸ì œ")  â”˜
                         â†“
                  (ëª¨ë“  ê²°ê³¼ ìžë™ ìˆ˜ì§‘)
```

### Step 6: ì™„ì „í•œ ì›Œí¬í”Œë¡œìš° êµ¬ì„±

ê²€ìƒ‰ ë…¸ë“œë¥¼ í¬í•¨í•œ ì™„ì „í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.

```python
# 1. StateGraph ìƒì„±
full_workflow = StateGraph(ResearchState)

# 2. ëª¨ë“  ë…¸ë“œ ì¶”ê°€
full_workflow.add_node("analyze_topic", generate_keywords)
full_workflow.add_node("review_keywords", review_keywords)
full_workflow.add_node("process_feedback", process_keyword_feedback)
full_workflow.add_node("ready_search", ready_to_search)
full_workflow.add_node("dispatch", dispatch_searches)
full_workflow.add_node("search_one", search_one)

# 3. ê¸°ë³¸ ì—£ì§€
full_workflow.add_edge(START, "analyze_topic")
full_workflow.add_edge("analyze_topic", "review_keywords")

# 4. í‚¤ì›Œë“œ ê²€í†  í›„ ì¡°ê±´ë¶€ ë¶„ê¸°
full_workflow.add_conditional_edges(
    "review_keywords",
    should_continue_after_review,
    {
        "approved": "ready_search",  # ê²€ìƒ‰ ì§„í–‰
        "process_feedback": "process_feedback",
        "regenerate": "analyze_topic"
    }
)

full_workflow.add_edge("process_feedback", "ready_search")

# 5. ê²€ìƒ‰ íë¦„
full_workflow.add_edge("ready_search", "dispatch")
full_workflow.add_edge("search_one", END)  # ë³‘ë ¬ ê²€ìƒ‰ ì™„ë£Œ í›„ ì¢…ë£Œ

# 6. ì»´íŒŒì¼
checkpointer = InMemorySaver()
full_research_graph = full_workflow.compile(checkpointer=checkpointer)

# 7. ì‹œê°í™”
display(Image(full_research_graph.get_graph().draw_mermaid_png()))

print("âœ… ì™„ì „í•œ ì›Œí¬í”Œë¡œìš° êµ¬ì„± ì™„ë£Œ")
```

### Step 7: ì „ì²´ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ (ì£¼ì œ â†’ ê²€ìƒ‰)

ì „ì²´ ë¦¬ì„œì¹˜ ì‹œìŠ¤í…œì„ ì‹¤í–‰í•˜ì—¬ ì›¹ ê²€ìƒ‰ê¹Œì§€ ì™„ë£Œí•©ë‹ˆë‹¤.

```python
print("=" * 80)
print("=== ì „ì²´ ë¦¬ì„œì¹˜ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ===")
print("=" * 80)

# ìŠ¤ë ˆë“œ ì„¤ì •
thread = {"configurable": {"thread_id": str(uuid.uuid4())}}

# ì´ˆê¸° ìƒíƒœ
initial_state = {
    "topic": "ì–‘ìž ì»´í“¨íŒ…ì˜ í˜„ìž¬ì™€ ë¯¸ëž˜",
    "keywords": [],
    "feedback": "",
    "search_results": [],
    "report": "",
    "report_feedback": "",
    "ready_for_search": False
}

# 1ë‹¨ê³„: í‚¤ì›Œë“œ ìƒì„± ë° ê²€í† ê¹Œì§€
result = full_research_graph.invoke(initial_state, thread)

print(f"\nìƒì„±ëœ í‚¤ì›Œë“œ: {result['keywords']}")

# 2ë‹¨ê³„: ì‚¬ìš©ìž ìŠ¹ì¸
print("\n>>> ì‚¬ìš©ìžê°€ í‚¤ì›Œë“œë¥¼ ìŠ¹ì¸í•©ë‹ˆë‹¤")
final_result = full_research_graph.invoke(Command(resume="ìŠ¹ì¸"), thread)

# 3ë‹¨ê³„: ê²€ìƒ‰ ê²°ê³¼ í™•ì¸
print(f"\nê²€ìƒ‰ ì™„ë£Œ! ì´ {len(final_result['search_results'])}ê°œ ê²°ê³¼")

# ìƒìœ„ 3ê°œ ê²°ê³¼ ì¶œë ¥
for i, result in enumerate(final_result['search_results'][:3], 1):
    print(f"\n{i}. [{result['keyword']}] {result['title']}")
    print(f"   URL: {result['url']}")
    print(f"   ë‚´ìš©: {result['content'][:100]}...")
```

**ì‹¤í–‰ ê²°ê³¼:**
```
--- ì£¼ì œ ë¶„ì„ ì¤‘ ---
ìƒì„±ëœ í‚¤ì›Œë“œ: ['ì–‘ìžì»´í“¨íŒ…', 'íë¹„íŠ¸', 'ì–‘ìžì•Œê³ ë¦¬ì¦˜', 'ì–‘ìžìš°ì›”ì„±', 'ì–‘ìžì•”í˜¸']
ì‹ ë¢°ë„: 0.92

--- í‚¤ì›Œë“œ ê²€í†  ë‹¨ê³„ (HITL) ---

ìƒì„±ëœ í‚¤ì›Œë“œ: ['ì–‘ìžì»´í“¨íŒ…', 'íë¹„íŠ¸', 'ì–‘ìžì•Œê³ ë¦¬ì¦˜', 'ì–‘ìžìš°ì›”ì„±', 'ì–‘ìžì•”í˜¸']

>>> ì‚¬ìš©ìžê°€ í‚¤ì›Œë“œë¥¼ ìŠ¹ì¸í•©ë‹ˆë‹¤
âœ… ìŠ¹ì¸ - ê²€ìƒ‰ ì§„í–‰

--- ì›¹ ê²€ìƒ‰ ì¤€ë¹„ ì¤‘ ---
ê²€ìƒ‰í•  í‚¤ì›Œë“œ: ['ì–‘ìžì»´í“¨íŒ…', 'íë¹„íŠ¸', 'ì–‘ìžì•Œê³ ë¦¬ì¦˜', 'ì–‘ìžìš°ì›”ì„±', 'ì–‘ìžì•”í˜¸']

--- 5ê°œ í‚¤ì›Œë“œ ë³‘ë ¬ ê²€ìƒ‰ ì‹œìž‘ ---
ðŸ” ê²€ìƒ‰ ì¤‘: ì–‘ìžì»´í“¨íŒ…
ðŸ” ê²€ìƒ‰ ì¤‘: íë¹„íŠ¸
ðŸ” ê²€ìƒ‰ ì¤‘: ì–‘ìžì•Œê³ ë¦¬ì¦˜
ðŸ” ê²€ìƒ‰ ì¤‘: ì–‘ìžìš°ì›”ì„±
ðŸ” ê²€ìƒ‰ ì¤‘: ì–‘ìžì•”í˜¸
  âœ… ì–‘ìžì»´í“¨íŒ…: 3ê°œ ê²°ê³¼
  âœ… íë¹„íŠ¸: 3ê°œ ê²°ê³¼
  âœ… ì–‘ìžì•Œê³ ë¦¬ì¦˜: 3ê°œ ê²°ê³¼
  âœ… ì–‘ìžìš°ì›”ì„±: 3ê°œ ê²°ê³¼
  âœ… ì–‘ìžì•”í˜¸: 3ê°œ ê²°ê³¼

ê²€ìƒ‰ ì™„ë£Œ! ì´ 15ê°œ ê²°ê³¼

1. [ì–‘ìžì»´í“¨íŒ…] ì–‘ìžì»´í“¨í„°, ìƒìš©í™”ëŠ” ì–¸ì œ?
   URL: https://...
   ë‚´ìš©: ì–‘ìžì»´í“¨í„°ëŠ” ê¸°ì¡´ ì»´í“¨í„°ì™€ ë‹¤ë¥¸ ì›ë¦¬ë¡œ ìž‘ë™í•˜ì—¬ íŠ¹ì • ë¬¸ì œë¥¼ í›¨ì”¬ ë¹ ë¥´ê²Œ í•´ê²°í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤...

2. [íë¹„íŠ¸] íë¹„íŠ¸ì˜ ì›ë¦¬ì™€ êµ¬í˜„ ë°©ì‹
   URL: https://...
   ë‚´ìš©: íë¹„íŠ¸ëŠ” ì–‘ìžì—­í•™ì˜ ì¤‘ì²© ì›ë¦¬ë¥¼ ì´ìš©í•˜ì—¬ 0ê³¼ 1ì„ ë™ì‹œì— í‘œí˜„í•  ìˆ˜ ìžˆëŠ” ì–‘ìž ì •ë³´ì˜ ê¸°ë³¸ ë‹¨ìœ„ìž…ë‹ˆë‹¤...

3. [ì–‘ìžì•Œê³ ë¦¬ì¦˜] Shor ì•Œê³ ë¦¬ì¦˜ê³¼ ì•”í˜¸ í•´ë…
   URL: https://...
   ë‚´ìš©: ì–‘ìžì•Œê³ ë¦¬ì¦˜ ì¤‘ ê°€ìž¥ ìœ ëª…í•œ Shor ì•Œê³ ë¦¬ì¦˜ì€ í° ìˆ˜ë¥¼ ì¸ìˆ˜ë¶„í•´í•˜ëŠ” ë° ì‚¬ìš©ë˜ë©°...
```

### Step 8: ë³´ê³ ì„œ ìƒì„± ë° ê²€í†  (HITL 2ë‹¨ê³„)

ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ê³  ì‚¬ìš©ìž ê²€í† ë¥¼ ë°›ìŠµë‹ˆë‹¤.

```python
# 1. ë³´ê³ ì„œ ìƒì„± ë…¸ë“œ
def generate_report(state: ResearchState) -> ResearchState:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ë³´ê³ ì„œ ìƒì„±"""
    print("\n--- ë³´ê³ ì„œ ìƒì„± ì¤‘ ---")

    topic = state.get("topic", "")
    search_results = state.get("search_results", [])

    # ê²€ìƒ‰ ê²°ê³¼ ì •ë¦¬
    context = "\n\n".join([
        f"[{r['keyword']}] {r['title']}\n{r['content']}"
        for r in search_results[:10]  # ìƒìœ„ 10ê°œ
    ])

    # ë³´ê³ ì„œ ìƒì„± í”„ë¡¬í”„íŠ¸
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ì „ë¬¸ ë¦¬ì„œì¹˜ ìž‘ê°€ë¡œì„œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì²´ê³„ì ì¸ ë³´ê³ ì„œë¥¼ ìž‘ì„±í•˜ì„¸ìš”.

êµ¬ì¡°:
1. ê°œìš”
2. ì£¼ìš” ë‚´ìš© (3-5ê°œ ì„¹ì…˜)
3. ê²°ë¡  ë° ì‹œì‚¬ì 

ê¸¸ì´: 500-800ìž"""),
        ("human", """ì£¼ì œ: {topic}

ê²€ìƒ‰ ê²°ê³¼:
{context}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œë¥¼ ìž‘ì„±í•˜ì„¸ìš”.""")
    ])

    chain = prompt | llm

    # ë³´ê³ ì„œ ìƒì„±
    response = chain.invoke({"topic": topic, "context": context})
    report = response.content

    print(f"ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ ({len(report)}ìž)")

    return {"report": report}

# 2. ë³´ê³ ì„œ ê²€í†  ë…¸ë“œ (HITL)
def review_report(state: ResearchState) -> ResearchState:
    """ì‚¬ìš©ìžê°€ ë³´ê³ ì„œë¥¼ ê²€í† """
    print("\n--- ë³´ê³ ì„œ ê²€í†  ë‹¨ê³„ (HITL) ---")

    report = state.get("report", "")

    # interruptë¡œ ì‚¬ìš©ìž ê²€í†  ìš”ì²­
    feedback = interrupt({
        "message": "ìƒì„±ëœ ë³´ê³ ì„œë¥¼ ê²€í† í•´ì£¼ì„¸ìš”",
        "report": report,
        "instructions": """
        - 'ìŠ¹ì¸': ë³´ê³ ì„œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        - 'ìˆ˜ì • ìš”ì²­: [ìˆ˜ì • ë‚´ìš©]': íŠ¹ì • ë¶€ë¶„ ìˆ˜ì • ìš”ì²­
        """,
        "options": ["ìŠ¹ì¸", "ìˆ˜ì • ìš”ì²­: "]
    })

    print(f"ì‚¬ìš©ìž í”¼ë“œë°±: {feedback[:50]}...")

    return {"report_feedback": feedback}

# 3. ë³´ê³ ì„œ ìˆ˜ì • ë…¸ë“œ
def revise_report(state: ResearchState) -> ResearchState:
    """ì‚¬ìš©ìž í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ë³´ê³ ì„œ ìˆ˜ì •"""
    print("\n--- ë³´ê³ ì„œ ìˆ˜ì • ì¤‘ ---")

    report = state.get("report", "")
    feedback = state.get("report_feedback", "")

    # í”¼ë“œë°±ì—ì„œ ìˆ˜ì • ë‚´ìš© ì¶”ì¶œ
    if "ìˆ˜ì • ìš”ì²­:" in feedback:
        modification = feedback.split("ìˆ˜ì • ìš”ì²­:")[1].strip()

        # ìˆ˜ì • í”„ë¡¬í”„íŠ¸
        prompt = ChatPromptTemplate.from_messages([
            ("system", "ì‚¬ìš©ìž í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ë³´ê³ ì„œë¥¼ ìˆ˜ì •í•˜ì„¸ìš”."),
            ("human", """ì›ë³¸ ë³´ê³ ì„œ:
{report}

ì‚¬ìš©ìž ìˆ˜ì • ìš”ì²­:
{modification}

ìœ„ í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ë³´ê³ ì„œë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.""")
        ])

        chain = prompt | llm

        # ìˆ˜ì •
        response = chain.invoke({"report": report, "modification": modification})
        revised_report = response.content

        print(f"ë³´ê³ ì„œ ìˆ˜ì • ì™„ë£Œ")

        return {"report": revised_report}

    return {}

# 4. ì¡°ê±´ë¶€ ë¶„ê¸°
def should_continue_after_report_review(state: ResearchState) -> str:
    """ë³´ê³ ì„œ ê²€í†  í›„ ë‹¤ìŒ ë‹¨ê³„ ê²°ì •"""
    feedback = state.get("report_feedback", "").strip()

    if "ìŠ¹ì¸" in feedback:
        return "approved"
    elif "ìˆ˜ì • ìš”ì²­:" in feedback:
        return "revise"
    else:
        return "approved"  # ê¸°ë³¸ê°’

print("âœ… ë³´ê³ ì„œ ìƒì„± ë° ê²€í†  ë…¸ë“œ êµ¬í˜„ ì™„ë£Œ")
```

### Step 9: ìµœì¢… ì™„ì „í•œ ì›Œí¬í”Œë¡œìš°

ë³´ê³ ì„œ ìƒì„± ë° ê²€í† ë¥¼ í¬í•¨í•œ ìµœì¢… ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.

```python
# 1. StateGraph ìƒì„±
final_workflow = StateGraph(ResearchState)

# 2. ëª¨ë“  ë…¸ë“œ ì¶”ê°€
final_workflow.add_node("analyze_topic", generate_keywords)
final_workflow.add_node("review_keywords", review_keywords)
final_workflow.add_node("process_feedback", process_keyword_feedback)
final_workflow.add_node("ready_search", ready_to_search)
final_workflow.add_node("dispatch", dispatch_searches)
final_workflow.add_node("search_one", search_one)
final_workflow.add_node("generate_report", generate_report)
final_workflow.add_node("review_report", review_report)
final_workflow.add_node("revise_report", revise_report)

# 3. ì£¼ì œ ë¶„ì„ íë¦„
final_workflow.add_edge(START, "analyze_topic")
final_workflow.add_edge("analyze_topic", "review_keywords")

final_workflow.add_conditional_edges(
    "review_keywords",
    should_continue_after_review,
    {
        "approved": "ready_search",
        "process_feedback": "process_feedback",
        "regenerate": "analyze_topic"
    }
)

final_workflow.add_edge("process_feedback", "ready_search")

# 4. ê²€ìƒ‰ íë¦„
final_workflow.add_edge("ready_search", "dispatch")
final_workflow.add_edge("dispatch", "generate_report")  # dispatch í›„ ë³´ê³ ì„œ ìƒì„±
final_workflow.add_edge("search_one", "dispatch")  # search_oneì€ dispatchë¡œ ëŒì•„ê° (ë§µ-ë¦¬ë“€ìŠ¤)

# 5. ë³´ê³ ì„œ íë¦„
final_workflow.add_edge("generate_report", "review_report")

final_workflow.add_conditional_edges(
    "review_report",
    should_continue_after_report_review,
    {
        "approved": END,
        "revise": "revise_report"
    }
)

final_workflow.add_edge("revise_report", "review_report")  # ìž¬ê²€í† 

# 6. ì»´íŒŒì¼
checkpointer = InMemorySaver()
final_research_graph = final_workflow.compile(checkpointer=checkpointer)

# 7. ì‹œê°í™”
display(Image(final_research_graph.get_graph().draw_mermaid_png()))

print("âœ… ìµœì¢… ì™„ì „í•œ ì›Œí¬í”Œë¡œìš° êµ¬ì„± ì™„ë£Œ")
```

### Step 10: ìµœì¢… ì‹œìŠ¤í…œ ì „ì²´ í…ŒìŠ¤íŠ¸

ì£¼ì œ ìž…ë ¥ë¶€í„° ë³´ê³ ì„œ ì™„ì„±ê¹Œì§€ ì „ì²´ ê³¼ì •ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.

```python
print("=" * 80)
print("=== ì „ì²´ ë¦¬ì„œì¹˜ ì‹œìŠ¤í…œ - ì™„ì „í•œ í…ŒìŠ¤íŠ¸ ===")
print("=" * 80)

# ìŠ¤ë ˆë“œ ì„¤ì •
thread = {"configurable": {"thread_id": str(uuid.uuid4())}}

# ì´ˆê¸° ìƒíƒœ
initial_state = {
    "topic": "ë©”íƒ€ë²„ìŠ¤ì˜ í˜„ìž¬ì™€ ë¯¸ëž˜ ì „ë§",
    "keywords": [],
    "feedback": "",
    "search_results": [],
    "report": "",
    "report_feedback": "",
    "ready_for_search": False
}

# 1ë‹¨ê³„: í‚¤ì›Œë“œ ìƒì„± ë° ê²€í† 
print("\nã€1ë‹¨ê³„ã€‘ í‚¤ì›Œë“œ ìƒì„±")
result = final_research_graph.invoke(initial_state, thread)

print(f"ìƒì„±ëœ í‚¤ì›Œë“œ: {result['keywords']}")

# ì‚¬ìš©ìž ìŠ¹ì¸
print("\n>>> ì‚¬ìš©ìž: í‚¤ì›Œë“œ ìŠ¹ì¸")
result = final_research_graph.invoke(Command(resume="ìŠ¹ì¸"), thread)

# 2ë‹¨ê³„: ì›¹ ê²€ìƒ‰ (ìžë™ ì‹¤í–‰ë¨)
print(f"\nã€2ë‹¨ê³„ã€‘ ì›¹ ê²€ìƒ‰ ì™„ë£Œ: {len(result.get('search_results', []))}ê°œ ê²°ê³¼")

# 3ë‹¨ê³„: ë³´ê³ ì„œ ìƒì„± ë° ê²€í† 
print("\nã€3ë‹¨ê³„ã€‘ ë³´ê³ ì„œ ìƒì„± ë° ê²€í† ")
state = final_research_graph.get_state(thread)

if "report" in result and result["report"]:
    print(f"\nìƒì„±ëœ ë³´ê³ ì„œ ({len(result['report'])}ìž):")
    print("-" * 80)
    print(result["report"][:300] + "...")
    print("-" * 80)

# ë³´ê³ ì„œ ê²€í†  ë‹¨ê³„ì—ì„œ ì¤‘ë‹¨ë¨
print("\n>>> ì‚¬ìš©ìž: ë³´ê³ ì„œ ìŠ¹ì¸")
final_result = final_research_graph.invoke(Command(resume="ìŠ¹ì¸"), thread)

print("\nã€ì™„ë£Œã€‘ ìµœì¢… ë³´ê³ ì„œ:")
print("=" * 80)
print(final_result["report"])
print("=" * 80)

print(f"\nâœ… ì „ì²´ ë¦¬ì„œì¹˜ ì™„ë£Œ!")
print(f"- ì£¼ì œ: {final_result['topic']}")
print(f"- í‚¤ì›Œë“œ: {len(final_result['keywords'])}ê°œ")
print(f"- ê²€ìƒ‰ ê²°ê³¼: {len(final_result['search_results'])}ê°œ")
print(f"- ë³´ê³ ì„œ: {len(final_result['report'])}ìž")
```

**ì‹¤í–‰ ê²°ê³¼:**
```
================================================================================
=== ì „ì²´ ë¦¬ì„œì¹˜ ì‹œìŠ¤í…œ - ì™„ì „í•œ í…ŒìŠ¤íŠ¸ ===
================================================================================

ã€1ë‹¨ê³„ã€‘ í‚¤ì›Œë“œ ìƒì„±
--- ì£¼ì œ ë¶„ì„ ì¤‘ ---
ìƒì„±ëœ í‚¤ì›Œë“œ: ['ë©”íƒ€ë²„ìŠ¤', 'ê°€ìƒí˜„ì‹¤', 'VR/AR', 'ë””ì§€í„¸ ê²½ì œ', 'ë©”íƒ€ë²„ìŠ¤ í”Œëž«í¼']
ì‹ ë¢°ë„: 0.88

--- í‚¤ì›Œë“œ ê²€í†  ë‹¨ê³„ (HITL) ---

ìƒì„±ëœ í‚¤ì›Œë“œ: ['ë©”íƒ€ë²„ìŠ¤', 'ê°€ìƒí˜„ì‹¤', 'VR/AR', 'ë””ì§€í„¸ ê²½ì œ', 'ë©”íƒ€ë²„ìŠ¤ í”Œëž«í¼']

>>> ì‚¬ìš©ìž: í‚¤ì›Œë“œ ìŠ¹ì¸
âœ… ìŠ¹ì¸ - ê²€ìƒ‰ ì§„í–‰

ã€2ë‹¨ê³„ã€‘ ì›¹ ê²€ìƒ‰ ì™„ë£Œ: 15ê°œ ê²°ê³¼
--- ì›¹ ê²€ìƒ‰ ì¤€ë¹„ ì¤‘ ---
--- 5ê°œ í‚¤ì›Œë“œ ë³‘ë ¬ ê²€ìƒ‰ ì‹œìž‘ ---
ðŸ” ê²€ìƒ‰ ì¤‘: ë©”íƒ€ë²„ìŠ¤
ðŸ” ê²€ìƒ‰ ì¤‘: ê°€ìƒí˜„ì‹¤
ðŸ” ê²€ìƒ‰ ì¤‘: VR/AR
ðŸ” ê²€ìƒ‰ ì¤‘: ë””ì§€í„¸ ê²½ì œ
ðŸ” ê²€ìƒ‰ ì¤‘: ë©”íƒ€ë²„ìŠ¤ í”Œëž«í¼

ã€3ë‹¨ê³„ã€‘ ë³´ê³ ì„œ ìƒì„± ë° ê²€í† 
--- ë³´ê³ ì„œ ìƒì„± ì¤‘ ---
ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ (687ìž)

ìƒì„±ëœ ë³´ê³ ì„œ (687ìž):
--------------------------------------------------------------------------------
# ë©”íƒ€ë²„ìŠ¤ì˜ í˜„ìž¬ì™€ ë¯¸ëž˜ ì „ë§

## 1. ê°œìš”
ë©”íƒ€ë²„ìŠ¤ëŠ” ê°€ìƒí˜„ì‹¤(VR)ê³¼ ì¦ê°•í˜„ì‹¤(AR) ê¸°ìˆ ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ë””ì§€í„¸ ê³µê°„ìœ¼ë¡œ, ì‚¬ìš©ìžë“¤ì´ ì•„ë°”íƒ€ë¥¼ í†µí•´ ìƒí˜¸ìž‘ìš©í•˜ê³  ê²½ì œí™œë™ì„ ìˆ˜í–‰í•˜ëŠ” ê°€ìƒ ì„¸ê³„ìž…ë‹ˆë‹¤...
--------------------------------------------------------------------------------

--- ë³´ê³ ì„œ ê²€í†  ë‹¨ê³„ (HITL) ---

>>> ì‚¬ìš©ìž: ë³´ê³ ì„œ ìŠ¹ì¸

ã€ì™„ë£Œã€‘ ìµœì¢… ë³´ê³ ì„œ:
================================================================================
# ë©”íƒ€ë²„ìŠ¤ì˜ í˜„ìž¬ì™€ ë¯¸ëž˜ ì „ë§

## 1. ê°œìš”
ë©”íƒ€ë²„ìŠ¤ëŠ” ê°€ìƒí˜„ì‹¤(VR)ê³¼ ì¦ê°•í˜„ì‹¤(AR) ê¸°ìˆ ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ë””ì§€í„¸ ê³µê°„ìœ¼ë¡œ, ì‚¬ìš©ìžë“¤ì´ ì•„ë°”íƒ€ë¥¼ í†µí•´ ìƒí˜¸ìž‘ìš©í•˜ê³  ê²½ì œí™œë™ì„ ìˆ˜í–‰í•˜ëŠ” ê°€ìƒ ì„¸ê³„ìž…ë‹ˆë‹¤.

## 2. ì£¼ìš” ë‚´ìš©

### 2.1 ê¸°ìˆ  ë°œì „
VR/AR ê¸°ìˆ ì˜ ë°œì „ìœ¼ë¡œ ë”ìš± ëª°ìž…ê° ìžˆëŠ” ê²½í—˜ì´ ê°€ëŠ¥í•´ì§€ê³  ìžˆìŠµë‹ˆë‹¤. íŠ¹ížˆ í•˜ë“œì›¨ì–´ì˜ ì„±ëŠ¥ í–¥ìƒê³¼ 5G ë„¤íŠ¸ì›Œí¬ì˜ í™•ì‚°ì´ ë©”íƒ€ë²„ìŠ¤ì˜ ì„±ìž¥ì„ ê°€ì†í™”í•˜ê³  ìžˆìŠµë‹ˆë‹¤.

### 2.2 ë©”íƒ€ë²„ìŠ¤ í”Œëž«í¼
ë¡œë¸”ë¡ìŠ¤, ì œíŽ˜í† , ë””ì„¼íŠ¸ëŸ´ëžœë“œ ë“± ë‹¤ì–‘í•œ ë©”íƒ€ë²„ìŠ¤ í”Œëž«í¼ì´ ë“±ìž¥í•˜ì—¬ ê°ê¸° ë‹¤ë¥¸ íŠ¹ìƒ‰ì„ ê°€ì§„ ê°€ìƒ ì„¸ê³„ë¥¼ ì œê³µí•˜ê³  ìžˆìŠµë‹ˆë‹¤.

### 2.3 ë””ì§€í„¸ ê²½ì œ
ë©”íƒ€ë²„ìŠ¤ ë‚´ì—ì„œ NFT, ê°€ìƒ ë¶€ë™ì‚°, ë””ì§€í„¸ ìƒí’ˆ ê±°ëž˜ ë“± ìƒˆë¡œìš´ ê²½ì œ ìƒíƒœê³„ê°€ í˜•ì„±ë˜ê³  ìžˆìŠµë‹ˆë‹¤.

## 3. ê²°ë¡  ë° ì‹œì‚¬ì 
ë©”íƒ€ë²„ìŠ¤ëŠ” ë‹¨ìˆœí•œ ê²Œìž„ì„ ë„˜ì–´ êµìœ¡, ë¹„ì¦ˆë‹ˆìŠ¤, ë¬¸í™” ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ë¡œ í™•ìž¥ë˜ê³  ìžˆìŠµë‹ˆë‹¤. í–¥í›„ ê¸°ìˆ  ë°œì „ê³¼ í•¨ê»˜ ìš°ë¦¬ ì¼ìƒì˜ ì¤‘ìš”í•œ ì¼ë¶€ê°€ ë  ê²ƒìœ¼ë¡œ ì „ë§ë©ë‹ˆë‹¤.
================================================================================

âœ… ì „ì²´ ë¦¬ì„œì¹˜ ì™„ë£Œ!
- ì£¼ì œ: ë©”íƒ€ë²„ìŠ¤ì˜ í˜„ìž¬ì™€ ë¯¸ëž˜ ì „ë§
- í‚¤ì›Œë“œ: 5ê°œ
- ê²€ìƒ‰ ê²°ê³¼: 15ê°œ
- ë³´ê³ ì„œ: 687ìž
```

## ðŸŽ¯ ì‹¤ìŠµ ë¬¸ì œ

### ë¬¸ì œ 1: ê²€ìƒ‰ ê²°ê³¼ í•„í„°ë§ (ë‚œì´ë„: â­â­â­)

ê²€ìƒ‰ ê²°ê³¼ ì¤‘ ì‹ ë¢°ë„ê°€ ë‚®ì€ ê²°ê³¼ë¥¼ í•„í„°ë§í•˜ëŠ” ë…¸ë“œë¥¼ ì¶”ê°€í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
- ê²€ìƒ‰ ê²°ê³¼ì˜ `score` í•„ë“œ í™•ì¸ (0-1 ë²”ìœ„)
- 0.7 ë¯¸ë§Œì˜ ê²°ê³¼ëŠ” ì œì™¸
- í•„í„°ë§ëœ ê²°ê³¼ ê°œìˆ˜ ì¶œë ¥
- í•„í„°ë§ ì „/í›„ ë¹„êµ

**ížŒíŠ¸:**
```python
def filter_search_results(state: ResearchState) -> ResearchState:
    search_results = state.get("search_results", [])

    # scoreê°€ 0.7 ì´ìƒì¸ ê²°ê³¼ë§Œ ë‚¨ê¸°ê¸°
    filtered = [r for r in search_results if r.get("score", 0) >= 0.7]

    print(f"í•„í„°ë§: {len(search_results)}ê°œ â†’ {len(filtered)}ê°œ")

    return {"search_results": filtered}
```

### ë¬¸ì œ 2: ë‹¤êµ­ì–´ ê²€ìƒ‰ ì§€ì› (ë‚œì´ë„: â­â­â­â­)

ì‚¬ìš©ìžê°€ ê²€ìƒ‰ ì–¸ì–´ë¥¼ ì„ íƒí•  ìˆ˜ ìžˆë„ë¡ HITLì„ ì¶”ê°€í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
- í‚¤ì›Œë“œ ìƒì„± í›„, ê²€ìƒ‰ ì–¸ì–´ ì„ íƒ interrupt ì¶”ê°€
- ì„ íƒ ì˜µì…˜: "í•œêµ­ì–´", "ì˜ì–´", "ì¼ë³¸ì–´", "ì¤‘êµ­ì–´"
- ì„ íƒëœ ì–¸ì–´ë¡œ í‚¤ì›Œë“œ ë²ˆì—­
- ë²ˆì—­ëœ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ ìˆ˜í–‰

**ížŒíŠ¸:**
```python
def select_language(state: ResearchState) -> ResearchState:
    language = interrupt({
        "message": "ê²€ìƒ‰í•  ì–¸ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš”",
        "keywords": state.get("keywords", []),
        "options": ["í•œêµ­ì–´", "ì˜ì–´", "ì¼ë³¸ì–´", "ì¤‘êµ­ì–´"]
    })

    if language != "í•œêµ­ì–´":
        # LLMìœ¼ë¡œ í‚¤ì›Œë“œ ë²ˆì—­
        translated_keywords = translate_keywords(
            state["keywords"],
            target_language=language
        )
        return {"keywords": translated_keywords, "search_language": language}

    return {"search_language": "í•œêµ­ì–´"}
```

### ë¬¸ì œ 3: ì‹¬í™” ë¦¬ì„œì¹˜ ëª¨ë“œ (ë‚œì´ë„: â­â­â­â­â­)

ì²« ë²ˆì§¸ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ê°€ ê²€ìƒ‰ì´ í•„ìš”í•œì§€ ì‚¬ìš©ìžì—ê²Œ ë¬¼ì–´ë³´ëŠ” ì‹œìŠ¤í…œì„ êµ¬í˜„í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
- ì²« ë²ˆì§¸ ê²€ìƒ‰ ì™„ë£Œ í›„ ê²°ê³¼ ìš”ì•½ ì œê³µ
- ì‚¬ìš©ìžì—ê²Œ "ì¶”ê°€ ê²€ìƒ‰ í•„ìš”?" interrupt
- í•„ìš” ì‹œ ìƒˆë¡œìš´ í‚¤ì›Œë“œ ìƒì„± ë° ìž¬ê²€ìƒ‰
- ìµœëŒ€ 3íšŒê¹Œì§€ ë°˜ë³µ ê²€ìƒ‰ ê°€ëŠ¥
- ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³‘í•©í•˜ì—¬ ìµœì¢… ë³´ê³ ì„œ ìƒì„±

**ížŒíŠ¸:**
```python
class ResearchState(MessagesState):
    # ê¸°ì¡´ í•„ë“œ
    topic: str
    keywords: List[str]
    search_results: List[Dict]
    report: str

    # ì¶”ê°€ í•„ë“œ
    search_iteration: int  # ê²€ìƒ‰ íšŸìˆ˜
    additional_keywords: List[str]  # ì¶”ê°€ í‚¤ì›Œë“œ
    need_more_search: bool  # ì¶”ê°€ ê²€ìƒ‰ í•„ìš” ì—¬ë¶€

def check_need_more_search(state: ResearchState) -> ResearchState:
    iteration = state.get("search_iteration", 1)

    if iteration >= 3:
        return {"need_more_search": False}

    # í˜„ìž¬ ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
    summary = summarize_search_results(state["search_results"])

    decision = interrupt({
        "message": f"ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ (ê²€ìƒ‰ {iteration}íšŒì°¨)",
        "summary": summary,
        "options": ["ì¶©ë¶„í•¨ - ë³´ê³ ì„œ ìž‘ì„±", "ì¶”ê°€ ê²€ìƒ‰ í•„ìš”"]
    })

    if "ì¶”ê°€ ê²€ìƒ‰" in decision:
        # ì¶”ê°€ í‚¤ì›Œë“œ ìƒì„±
        additional = generate_additional_keywords(
            state["topic"],
            state["keywords"],
            summary
        )
        return {
            "additional_keywords": additional,
            "need_more_search": True,
            "search_iteration": iteration + 1
        }

    return {"need_more_search": False}
```

## âœ… ì†”ë£¨ì…˜ ì˜ˆì‹œ

### ë¬¸ì œ 1 ì†”ë£¨ì…˜: ê²€ìƒ‰ ê²°ê³¼ í•„í„°ë§

```python
from typing import List, Dict
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import InMemorySaver

# 1. í•„í„°ë§ ë…¸ë“œ êµ¬í˜„
def filter_search_results(state: ResearchState) -> ResearchState:
    """ì‹ ë¢°ë„ê°€ ë‚®ì€ ê²€ìƒ‰ ê²°ê³¼ í•„í„°ë§"""
    print("\n--- ê²€ìƒ‰ ê²°ê³¼ í•„í„°ë§ ì¤‘ ---")

    search_results = state.get("search_results", [])
    threshold = 0.7

    print(f"ì›ë³¸ ê²°ê³¼: {len(search_results)}ê°œ")

    # score ê¸°ì¤€ í•„í„°ë§
    filtered_results = []
    for result in search_results:
        score = result.get("score", 0.5)  # ê¸°ë³¸ê°’ 0.5

        if score >= threshold:
            filtered_results.append(result)
        else:
            print(f"  ì œì™¸: {result.get('title', 'Unknown')[:50]} (score: {score:.2f})")

    print(f"í•„í„°ë§ í›„: {len(filtered_results)}ê°œ (ì œê±°: {len(search_results) - len(filtered_results)}ê°œ)")

    return {"search_results": filtered_results}

# 2. ì›Œí¬í”Œë¡œìš°ì— ë…¸ë“œ ì¶”ê°€
workflow = StateGraph(ResearchState)

# ê¸°ì¡´ ë…¸ë“œë“¤...
workflow.add_node("filter_results", filter_search_results)

# ê²€ìƒ‰ í›„ í•„í„°ë§ ì¶”ê°€
workflow.add_edge("search_one", "filter_results")
workflow.add_edge("filter_results", "generate_report")

# ì»´íŒŒì¼
checkpointer = InMemorySaver()
graph = workflow.compile(checkpointer=checkpointer)

# 3. í…ŒìŠ¤íŠ¸
thread = {"configurable": {"thread_id": str(uuid.uuid4())}}

# í…ŒìŠ¤íŠ¸ìš© ê²€ìƒ‰ ê²°ê³¼ (score í¬í•¨)
test_results = [
    {"title": "ê³ í’ˆì§ˆ ê²°ê³¼ 1", "content": "...", "score": 0.95},
    {"title": "ê³ í’ˆì§ˆ ê²°ê³¼ 2", "content": "...", "score": 0.88},
    {"title": "ì €í’ˆì§ˆ ê²°ê³¼ 1", "content": "...", "score": 0.45},
    {"title": "ì¤‘í’ˆì§ˆ ê²°ê³¼", "content": "...", "score": 0.72},
    {"title": "ì €í’ˆì§ˆ ê²°ê³¼ 2", "content": "...", "score": 0.60},
]

result = graph.invoke({
    "topic": "í…ŒìŠ¤íŠ¸",
    "search_results": test_results
}, thread)

print(f"\nìµœì¢… ê²°ê³¼: {len(result['search_results'])}ê°œ")
for r in result["search_results"]:
    print(f"  - {r['title']} (score: {r['score']:.2f})")
```

**ì‹¤í–‰ ê²°ê³¼:**
```
--- ê²€ìƒ‰ ê²°ê³¼ í•„í„°ë§ ì¤‘ ---
ì›ë³¸ ê²°ê³¼: 5ê°œ
  ì œì™¸: ì €í’ˆì§ˆ ê²°ê³¼ 1 (score: 0.45)
  ì œì™¸: ì €í’ˆì§ˆ ê²°ê³¼ 2 (score: 0.60)
í•„í„°ë§ í›„: 3ê°œ (ì œê±°: 2ê°œ)

ìµœì¢… ê²°ê³¼: 3ê°œ
  - ê³ í’ˆì§ˆ ê²°ê³¼ 1 (score: 0.95)
  - ê³ í’ˆì§ˆ ê²°ê³¼ 2 (score: 0.88)
  - ì¤‘í’ˆì§ˆ ê²°ê³¼ (score: 0.72)
```

### ë¬¸ì œ 2 ì†”ë£¨ì…˜: ë‹¤êµ­ì–´ ê²€ìƒ‰ ì§€ì›

```python
from langchain_core.prompts import ChatPromptTemplate
from langgraph.types import interrupt, Command

# 1. ì–¸ì–´ ì„ íƒ ë…¸ë“œ
def select_search_language(state: ResearchState) -> ResearchState:
    """ê²€ìƒ‰ ì–¸ì–´ ì„ íƒ"""
    print("\n--- ê²€ìƒ‰ ì–¸ì–´ ì„ íƒ ---")

    keywords = state.get("keywords", [])

    # ì‚¬ìš©ìžì—ê²Œ ì–¸ì–´ ì„ íƒ ìš”ì²­
    language = interrupt({
        "message": "ê²€ìƒ‰í•  ì–¸ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš”",
        "current_keywords": keywords,
        "options": ["í•œêµ­ì–´ (ê¸°ë³¸)", "ì˜ì–´", "ì¼ë³¸ì–´", "ì¤‘êµ­ì–´"]
    })

    print(f"ì„ íƒëœ ì–¸ì–´: {language}")

    return {"search_language": language}

# 2. í‚¤ì›Œë“œ ë²ˆì—­ ë…¸ë“œ
def translate_keywords(state: ResearchState) -> ResearchState:
    """ì„ íƒëœ ì–¸ì–´ë¡œ í‚¤ì›Œë“œ ë²ˆì—­"""
    print("\n--- í‚¤ì›Œë“œ ë²ˆì—­ ì¤‘ ---")

    language = state.get("search_language", "í•œêµ­ì–´")
    keywords = state.get("keywords", [])

    # í•œêµ­ì–´ë©´ ë²ˆì—­ ë¶ˆí•„ìš”
    if "í•œêµ­ì–´" in language:
        print("í•œêµ­ì–´ ê²€ìƒ‰ - ë²ˆì—­ ë¶ˆí•„ìš”")
        return {}

    # ì–¸ì–´ ì½”ë“œ ë§¤í•‘
    language_map = {
        "ì˜ì–´": "English",
        "ì¼ë³¸ì–´": "Japanese",
        "ì¤‘êµ­ì–´": "Chinese"
    }

    target_lang = language_map.get(language, "English")

    # ë²ˆì—­ í”„ë¡¬í”„íŠ¸
    prompt = ChatPromptTemplate.from_messages([
        ("system", f"í‚¤ì›Œë“œë¥¼ {target_lang}ë¡œ ë²ˆì—­í•˜ì„¸ìš”. ê²€ìƒ‰ì— ìµœì í™”ëœ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."),
        ("human", "í‚¤ì›Œë“œ: {keywords}\n\nê° í‚¤ì›Œë“œë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ë²ˆì—­í•˜ì„¸ìš”.")
    ])

    chain = prompt | llm

    # ë²ˆì—­ ì‹¤í–‰
    response = chain.invoke({"keywords": ", ".join(keywords)})
    translated_text = response.content

    # ë²ˆì—­ëœ í‚¤ì›Œë“œ íŒŒì‹±
    translated_keywords = [kw.strip() for kw in translated_text.split(",")]

    print(f"ì›ë³¸: {keywords}")
    print(f"ë²ˆì—­: {translated_keywords}")

    return {"keywords": translated_keywords}

# 3. ì›Œí¬í”Œë¡œìš° êµ¬ì„±
workflow = StateGraph(ResearchState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("select_language", select_search_language)
workflow.add_node("translate", translate_keywords)

# íë¦„: í‚¤ì›Œë“œ ê²€í†  â†’ ì–¸ì–´ ì„ íƒ â†’ ë²ˆì—­ â†’ ê²€ìƒ‰
workflow.add_edge("review_keywords", "select_language")
workflow.add_edge("select_language", "translate")
workflow.add_edge("translate", "ready_search")

# ì»´íŒŒì¼
checkpointer = InMemorySaver()
multilang_graph = workflow.compile(checkpointer=checkpointer)

# 4. í…ŒìŠ¤íŠ¸
thread = {"configurable": {"thread_id": str(uuid.uuid4())}}

initial_state = {
    "topic": "ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ëž˜",
    "keywords": ["ì¸ê³µì§€ëŠ¥", "ë¨¸ì‹ ëŸ¬ë‹", "ë”¥ëŸ¬ë‹", "AI ìœ¤ë¦¬"],
    "search_language": ""
}

# í‚¤ì›Œë“œ ìŠ¹ì¸ í›„ ì–¸ì–´ ì„ íƒ
result = multilang_graph.invoke(initial_state, thread)

# ì‚¬ìš©ìžê°€ ì˜ì–´ ì„ íƒ
print("\n>>> ì‚¬ìš©ìž: ì˜ì–´ ì„ íƒ")
final_result = multilang_graph.invoke(Command(resume="ì˜ì–´"), thread)

print(f"\nìµœì¢… ê²€ìƒ‰ í‚¤ì›Œë“œ: {final_result['keywords']}")
print(f"ê²€ìƒ‰ ì–¸ì–´: {final_result['search_language']}")
```

**ì‹¤í–‰ ê²°ê³¼:**
```
--- ê²€ìƒ‰ ì–¸ì–´ ì„ íƒ ---

>>> ì‚¬ìš©ìž: ì˜ì–´ ì„ íƒ
ì„ íƒëœ ì–¸ì–´: ì˜ì–´

--- í‚¤ì›Œë“œ ë²ˆì—­ ì¤‘ ---
ì›ë³¸: ['ì¸ê³µì§€ëŠ¥', 'ë¨¸ì‹ ëŸ¬ë‹', 'ë”¥ëŸ¬ë‹', 'AI ìœ¤ë¦¬']
ë²ˆì—­: ['Artificial Intelligence', 'Machine Learning', 'Deep Learning', 'AI Ethics']

ìµœì¢… ê²€ìƒ‰ í‚¤ì›Œë“œ: ['Artificial Intelligence', 'Machine Learning', 'Deep Learning', 'AI Ethics']
ê²€ìƒ‰ ì–¸ì–´: ì˜ì–´
```

### ë¬¸ì œ 3 ì†”ë£¨ì…˜: ì‹¬í™” ë¦¬ì„œì¹˜ ëª¨ë“œ

```python
from typing import List, Dict
from langgraph.graph import StateGraph, START, END
from langgraph.types import interrupt, Command

# 1. í™•ìž¥ëœ ìƒíƒœ ì •ì˜
class AdvancedResearchState(ResearchState):
    search_iteration: int  # í˜„ìž¬ ê²€ìƒ‰ íšŒì°¨
    all_search_results: List[Dict]  # ëª¨ë“  íšŒì°¨ì˜ ê²€ìƒ‰ ê²°ê³¼
    search_history: List[Dict]  # ê²€ìƒ‰ ì´ë ¥
    need_more_search: bool  # ì¶”ê°€ ê²€ìƒ‰ í•„ìš” ì—¬ë¶€

# 2. ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ ë…¸ë“œ
def summarize_search_results(state: AdvancedResearchState) -> AdvancedResearchState:
    """í˜„ìž¬ê¹Œì§€ì˜ ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½"""
    print("\n--- ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ ì¤‘ ---")

    iteration = state.get("search_iteration", 1)
    search_results = state.get("search_results", [])

    # ê°„ë‹¨í•œ ìš”ì•½ ìƒì„±
    keywords_found = set([r.get("keyword", "") for r in search_results])

    summary = {
        "iteration": iteration,
        "total_results": len(search_results),
        "keywords_covered": list(keywords_found),
        "sample_titles": [r.get("title", "") for r in search_results[:5]]
    }

    print(f"ê²€ìƒ‰ íšŒì°¨: {iteration}")
    print(f"ì´ ê²°ê³¼: {len(search_results)}ê°œ")
    print(f"ì»¤ë²„ëœ í‚¤ì›Œë“œ: {keywords_found}")

    return {"search_summary": summary}

# 3. ì¶”ê°€ ê²€ìƒ‰ í•„ìš” ì—¬ë¶€ í™•ì¸ ë…¸ë“œ
def check_need_more_search(state: AdvancedResearchState) -> AdvancedResearchState:
    """ì¶”ê°€ ê²€ìƒ‰ í•„ìš” ì—¬ë¶€ í™•ì¸"""
    print("\n--- ì¶”ê°€ ê²€ìƒ‰ í•„ìš” ì—¬ë¶€ í™•ì¸ ---")

    iteration = state.get("search_iteration", 1)
    max_iterations = 3

    if iteration >= max_iterations:
        print(f"ìµœëŒ€ ê²€ìƒ‰ íšŒì°¨({max_iterations}) ë„ë‹¬ - ë³´ê³ ì„œ ìž‘ì„± ì§„í–‰")
        return {"need_more_search": False}

    summary = state.get("search_summary", {})

    # ì‚¬ìš©ìžì—ê²Œ ì¶”ê°€ ê²€ìƒ‰ ì—¬ë¶€ ì§ˆë¬¸
    decision = interrupt({
        "message": f"ê²€ìƒ‰ ê²°ê³¼ ê²€í†  (íšŒì°¨ {iteration}/{max_iterations})",
        "summary": summary,
        "total_results": summary.get("total_results", 0),
        "options": [
            "ì¶©ë¶„í•¨ - ë³´ê³ ì„œ ìž‘ì„±",
            "ì¶”ê°€ ê²€ìƒ‰ í•„ìš”"
        ]
    })

    if "ì¶”ê°€ ê²€ìƒ‰" in decision:
        print("âœ… ì¶”ê°€ ê²€ìƒ‰ ì§„í–‰")
        return {"need_more_search": True}
    else:
        print("âœ… ë³´ê³ ì„œ ìž‘ì„± ì§„í–‰")
        return {"need_more_search": False}

# 4. ì¶”ê°€ í‚¤ì›Œë“œ ìƒì„± ë…¸ë“œ
def generate_additional_keywords(state: AdvancedResearchState) -> AdvancedResearchState:
    """ê¸°ì¡´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ê°€ í‚¤ì›Œë“œ ìƒì„±"""
    print("\n--- ì¶”ê°€ í‚¤ì›Œë“œ ìƒì„± ì¤‘ ---")

    topic = state.get("topic", "")
    original_keywords = state.get("keywords", [])
    search_results = state.get("search_results", [])

    # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ìžì£¼ ì–¸ê¸‰ëœ ìš©ì–´ ì¶”ì¶œ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
    all_content = " ".join([r.get("content", "") for r in search_results])

    # LLMìœ¼ë¡œ ì¶”ê°€ í‚¤ì›Œë“œ ìƒì„±
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì¶”ê°€ ê²€ìƒ‰ì´ í•„ìš”í•œ ìƒˆë¡œìš´ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ì„¸ìš”."),
        ("human", """ì£¼ì œ: {topic}

ê¸°ì¡´ í‚¤ì›Œë“œ: {original_keywords}

ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½:
{content}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë” ê¹Šì´ ìžˆëŠ” ê²€ìƒ‰ì„ ìœ„í•œ 3-5ê°œì˜ ìƒˆë¡œìš´ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ì„¸ìš”.
ê¸°ì¡´ í‚¤ì›Œë“œì™€ ì¤‘ë³µë˜ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤.""")
    ])

    structured_llm = llm.with_structured_output(Keywords)
    chain = prompt | structured_llm

    result = chain.invoke({
        "topic": topic,
        "original_keywords": ", ".join(original_keywords),
        "content": all_content[:500]  # 500ìž ì œí•œ
    })

    additional_keywords = result.keywords

    print(f"ì¶”ê°€ í‚¤ì›Œë“œ: {additional_keywords}")

    # ê²€ìƒ‰ íšŒì°¨ ì¦ê°€
    iteration = state.get("search_iteration", 1)

    return {
        "keywords": additional_keywords,
        "search_iteration": iteration + 1
    }

# 5. ê²°ê³¼ ë³‘í•© ë…¸ë“œ
def merge_all_results(state: AdvancedResearchState) -> AdvancedResearchState:
    """ëª¨ë“  íšŒì°¨ì˜ ê²€ìƒ‰ ê²°ê³¼ ë³‘í•©"""
    print("\n--- ê²€ìƒ‰ ê²°ê³¼ ë³‘í•© ì¤‘ ---")

    all_results = state.get("all_search_results", [])
    current_results = state.get("search_results", [])

    # ê²°ê³¼ ë³‘í•©
    merged = all_results + current_results

    print(f"ì´ ê²€ìƒ‰ ê²°ê³¼: {len(merged)}ê°œ (íšŒì°¨: {state.get('search_iteration', 1)})")

    return {
        "all_search_results": merged,
        "search_results": []  # ì´ˆê¸°í™”
    }

# 6. ì›Œí¬í”Œë¡œìš° êµ¬ì„±
workflow = StateGraph(AdvancedResearchState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("summarize", summarize_search_results)
workflow.add_node("check_more", check_need_more_search)
workflow.add_node("generate_additional", generate_additional_keywords)
workflow.add_node("merge_results", merge_all_results)

# íë¦„
workflow.add_edge("search_one", "merge_results")
workflow.add_edge("merge_results", "summarize")
workflow.add_edge("summarize", "check_more")

# ì¡°ê±´ë¶€ ë¶„ê¸°
def after_check_decision(state: AdvancedResearchState) -> str:
    if state.get("need_more_search", False):
        return "more_search"
    else:
        return "generate_report"

workflow.add_conditional_edges(
    "check_more",
    after_check_decision,
    {
        "more_search": "generate_additional",
        "generate_report": "generate_report"
    }
)

workflow.add_edge("generate_additional", "dispatch")  # ìž¬ê²€ìƒ‰

# ì»´íŒŒì¼
checkpointer = InMemorySaver()
advanced_graph = workflow.compile(checkpointer=checkpointer)

# 7. í…ŒìŠ¤íŠ¸
print("=" * 80)
print("=== ì‹¬í™” ë¦¬ì„œì¹˜ ëª¨ë“œ í…ŒìŠ¤íŠ¸ ===")
print("=" * 80)

thread = {"configurable": {"thread_id": str(uuid.uuid4())}}

initial_state = {
    "topic": "ë¸”ë¡ì²´ì¸ ê¸°ìˆ ì˜ ì‘ìš©",
    "keywords": ["ë¸”ë¡ì²´ì¸", "ì•”í˜¸í™”í", "ìŠ¤ë§ˆíŠ¸ì»¨íŠ¸ëž™íŠ¸"],
    "search_iteration": 1,
    "all_search_results": [],
    "need_more_search": False
}

# 1ì°¨ ê²€ìƒ‰ ë° ê²€í† 
result = advanced_graph.invoke(initial_state, thread)

print("\n>>> ì‚¬ìš©ìž: ì¶”ê°€ ê²€ìƒ‰ í•„ìš”")
result = advanced_graph.invoke(Command(resume="ì¶”ê°€ ê²€ìƒ‰ í•„ìš”"), thread)

# 2ì°¨ ê²€ìƒ‰ ê²°ê³¼ ê²€í† 
print("\n>>> ì‚¬ìš©ìž: ì¶©ë¶„í•¨ - ë³´ê³ ì„œ ìž‘ì„±")
final_result = advanced_graph.invoke(Command(resume="ì¶©ë¶„í•¨ - ë³´ê³ ì„œ ìž‘ì„±"), thread)

print(f"\nìµœì¢… ê²€ìƒ‰ íšŒì°¨: {final_result.get('search_iteration', 1)}")
print(f"ì´ ê²€ìƒ‰ ê²°ê³¼: {len(final_result.get('all_search_results', []))}ê°œ")
```

**ì‹¤í–‰ ê²°ê³¼:**
```
================================================================================
=== ì‹¬í™” ë¦¬ì„œì¹˜ ëª¨ë“œ í…ŒìŠ¤íŠ¸ ===
================================================================================

--- ê²€ìƒ‰ ê²°ê³¼ ë³‘í•© ì¤‘ ---
ì´ ê²€ìƒ‰ ê²°ê³¼: 9ê°œ (íšŒì°¨: 1)

--- ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ ì¤‘ ---
ê²€ìƒ‰ íšŒì°¨: 1
ì´ ê²°ê³¼: 9ê°œ
ì»¤ë²„ëœ í‚¤ì›Œë“œ: {'ë¸”ë¡ì²´ì¸', 'ì•”í˜¸í™”í', 'ìŠ¤ë§ˆíŠ¸ì»¨íŠ¸ëž™íŠ¸'}

--- ì¶”ê°€ ê²€ìƒ‰ í•„ìš” ì—¬ë¶€ í™•ì¸ ---

>>> ì‚¬ìš©ìž: ì¶”ê°€ ê²€ìƒ‰ í•„ìš”
âœ… ì¶”ê°€ ê²€ìƒ‰ ì§„í–‰

--- ì¶”ê°€ í‚¤ì›Œë“œ ìƒì„± ì¤‘ ---
ì¶”ê°€ í‚¤ì›Œë“œ: ['NFT', 'DeFi', 'ë¶„ì‚°ì›ìž¥', 'Web3']

[2ì°¨ ê²€ìƒ‰ ì§„í–‰...]

--- ê²€ìƒ‰ ê²°ê³¼ ë³‘í•© ì¤‘ ---
ì´ ê²€ìƒ‰ ê²°ê³¼: 21ê°œ (íšŒì°¨: 2)

--- ì¶”ê°€ ê²€ìƒ‰ í•„ìš” ì—¬ë¶€ í™•ì¸ ---

>>> ì‚¬ìš©ìž: ì¶©ë¶„í•¨ - ë³´ê³ ì„œ ìž‘ì„±
âœ… ë³´ê³ ì„œ ìž‘ì„± ì§„í–‰

ìµœì¢… ê²€ìƒ‰ íšŒì°¨: 2
ì´ ê²€ìƒ‰ ê²°ê³¼: 21ê°œ
```

## ðŸš€ ì‹¤ë¬´ í™œìš© ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ì‹œìž¥ ì¡°ì‚¬ ìžë™í™” ì‹œìŠ¤í…œ

ìƒˆë¡œìš´ ì‹œìž¥ì— ì§„ìž…í•˜ê¸° ì „ ìžë™ìœ¼ë¡œ ì‹œìž¥ ì¡°ì‚¬ë¥¼ ìˆ˜í–‰í•˜ëŠ” ì‹œìŠ¤í…œìž…ë‹ˆë‹¤.

```python
# ì‹œìž¥ ì¡°ì‚¬ íŠ¹í™” ìƒíƒœ
class MarketResearchState(ResearchState):
    market_name: str
    competitors: List[str]
    market_size: Dict
    trends: List[str]
    recommendations: List[str]

# íŠ¹í™” ë…¸ë“œë“¤
def analyze_competitors(state: MarketResearchState):
    """ê²½ìŸì‚¬ ë¶„ì„"""
    search_results = state.get("search_results", [])

    # ê²½ìŸì‚¬ ê´€ë ¨ ì •ë³´ ì¶”ì¶œ
    competitor_info = extract_competitor_info(search_results)

    return {"competitors": competitor_info}

def estimate_market_size(state: MarketResearchState):
    """ì‹œìž¥ ê·œëª¨ ì¶”ì •"""
    # LLMìœ¼ë¡œ ì‹œìž¥ ê·œëª¨ ë¶„ì„
    prompt = """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹œìž¥ ê·œëª¨ë¥¼ ì¶”ì •í•˜ì„¸ìš”:
    - í˜„ìž¬ ì‹œìž¥ ê·œëª¨
    - ì—°í‰ê·  ì„±ìž¥ë¥  (CAGR)
    - í–¥í›„ 5ë…„ ì „ë§
    """

    # ... ë¶„ì„ ë¡œì§

    return {"market_size": market_data}

# í™œìš© ì˜ˆì‹œ
result = market_research_graph.invoke({
    "market_name": "AI ì±—ë´‡ ì‹œìž¥",
    "topic": "AI ì±—ë´‡ ì‹œìž¥ ë¶„ì„"
})

print(f"ì‹œìž¥: {result['market_name']}")
print(f"ì£¼ìš” ê²½ìŸì‚¬: {result['competitors']}")
print(f"ì‹œìž¥ ê·œëª¨: {result['market_size']}")
```

### ì˜ˆì‹œ 2: ê¸°ìˆ  íŠ¸ë Œë“œ ëª¨ë‹ˆí„°ë§

ìµœì‹  ê¸°ìˆ  íŠ¸ë Œë“œë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³  ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ëŠ” ì‹œìŠ¤í…œìž…ë‹ˆë‹¤.

```python
import schedule
import time

# ì£¼ê°„ íŠ¸ë Œë“œ ë¦¬í¬íŠ¸ ìƒì„±
def weekly_tech_trends():
    """ë§¤ì£¼ ê¸°ìˆ  íŠ¸ë Œë“œ ë¦¬í¬íŠ¸ ìžë™ ìƒì„±"""

    topics = [
        "ì¸ê³µì§€ëŠ¥ ìµœì‹  ë™í–¥",
        "í´ë¼ìš°ë“œ ì»´í“¨íŒ… íŠ¸ë Œë“œ",
        "ì‚¬ì´ë²„ë³´ì•ˆ ì´ìŠˆ"
    ]

    for topic in topics:
        print(f"\n=== {topic} ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ===")

        thread = {"configurable": {"thread_id": str(uuid.uuid4())}}

        # ìžë™ ì‹¤í–‰ (ì‚¬ìš©ìž ê°œìž… ìµœì†Œí™”)
        result = trend_monitor_graph.invoke({
            "topic": topic,
            "auto_approve": True  # ìžë™ ìŠ¹ì¸ ëª¨ë“œ
        }, thread)

        # ë³´ê³ ì„œ ì €ìž¥
        save_report(topic, result["report"])

        print(f"âœ… {topic} ë¦¬í¬íŠ¸ ì™„ë£Œ")

# ìŠ¤ì¼€ì¤„ ì„¤ì •
schedule.every().monday.at("09:00").do(weekly_tech_trends)

# ì‹¤í–‰
while True:
    schedule.run_pending()
    time.sleep(3600)  # 1ì‹œê°„ë§ˆë‹¤ ì²´í¬
```

### ì˜ˆì‹œ 3: í•™ìˆ  ë…¼ë¬¸ ë¦¬ì„œì¹˜ ë„ìš°ë¯¸

íŠ¹ì • ì£¼ì œì— ëŒ€í•œ í•™ìˆ  ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³  ìš”ì•½í•˜ëŠ” ì‹œìŠ¤í…œìž…ë‹ˆë‹¤.

```python
# í•™ìˆ  ë…¼ë¬¸ íŠ¹í™” ìƒíƒœ
class AcademicResearchState(ResearchState):
    paper_title: str
    authors: List[str]
    publication_year: int
    citations: int
    key_findings: List[str]
    methodology: str

# ë…¼ë¬¸ ê²€ìƒ‰ íŠ¹í™” ë…¸ë“œ
def search_academic_papers(state: AcademicResearchState):
    """í•™ìˆ  ë…¼ë¬¸ ê²€ìƒ‰ (Google Scholar ë“±)"""

    # ë…¼ë¬¸ ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„±
    keywords = state.get("keywords", [])
    academic_keywords = [f"{kw} academic paper" for kw in keywords]

    # ê²€ìƒ‰ ì‹¤í–‰
    papers = []
    for kw in academic_keywords:
        results = search_tool.invoke(kw)
        papers.extend(extract_paper_info(results))

    return {"papers": papers}

def summarize_papers(state: AcademicResearchState):
    """ë…¼ë¬¸ ìš”ì•½"""

    papers = state.get("papers", [])

    # ê° ë…¼ë¬¸ ìš”ì•½
    summaries = []
    for paper in papers:
        summary = llm.invoke(f"""ë‹¤ìŒ ë…¼ë¬¸ì„ ìš”ì•½í•˜ì„¸ìš”:
        ì œëª©: {paper['title']}
        ì´ˆë¡: {paper['abstract']}

        ì£¼ìš” ë‚´ìš©, ë°©ë²•ë¡ , ê²°ë¡ ì„ í¬í•¨í•˜ì—¬ ìš”ì•½í•˜ì„¸ìš”.""")

        summaries.append({
            "title": paper["title"],
            "summary": summary.content
        })

    return {"paper_summaries": summaries}

# í™œìš©
result = academic_graph.invoke({
    "topic": "Transformer ëª¨ë¸ì˜ ìµœì‹  ë°œì „",
    "keywords": []
})

for paper in result["paper_summaries"]:
    print(f"\në…¼ë¬¸: {paper['title']}")
    print(f"ìš”ì•½: {paper['summary']}")
```

## ðŸ“– ì°¸ê³  ìžë£Œ

### ê³µì‹ ë¬¸ì„œ
- [LangGraph HITL ê³µì‹ ê°€ì´ë“œ](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/)
- [TavilySearch API](https://docs.tavily.com/)
- [Pydantic êµ¬ì¡°í™”ëœ ì¶œë ¥](https://docs.pydantic.dev/)
- [Sendì™€ ë³‘ë ¬ ì‹¤í–‰](https://langchain-ai.github.io/langgraph/concepts/low_level/#send)

### ê´€ë ¨ ê¸°ìˆ 
- **ë§µ-ë¦¬ë“€ìŠ¤ íŒ¨í„´**: ë³‘ë ¬ ë°ì´í„° ì²˜ë¦¬ íŒ¨í„´
- **ì›¹ ìŠ¤í¬ëž˜í•‘**: BeautifulSoup, Selenium í™œìš©
- **ìž„ë² ë”© ê²€ìƒ‰**: ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ êµ¬í˜„
- **í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§**: íš¨ê³¼ì ì¸ LLM í™œìš©

### ì¶”ê°€ í•™ìŠµ ìžë£Œ
- LangGraph Advanced Patterns
- Multi-Agent Research Systems
- Production HITL Workflows
- Real-time Web Search Integration

---

**Part 1 ë³µìŠµ**: [PRJ03_W2_005_LangGraph_HITL_Part1.md](./PRJ03_W2_005_LangGraph_HITL_Part1.md)ì—ì„œ HITL ê¸°ë³¸ ê°œë…ê³¼ Breakpoint ì„¤ì • ë°©ë²•ì„ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.

**ì‹¤ë¬´ ì ìš©**: ì´ ì‹œìŠ¤í…œì„ í™•ìž¥í•˜ì—¬ ë‹¤ì–‘í•œ ë„ë©”ì¸(ê¸ˆìœµ, ì˜ë£Œ, ë²•ë¥  ë“±)ì˜ ë¦¬ì„œì¹˜ ìžë™í™”ì— í™œìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
