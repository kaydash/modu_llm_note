# PRJ03_W1_002_LangChain_BuiltIn_Tool

## ğŸ“š í•™ìŠµ ëª©í‘œ

ì´ í•™ìŠµ ê°€ì´ë“œë¥¼ ì™„ë£Œí•˜ë©´ ë‹¤ìŒì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. **LangChain Built-in Tool ì´í•´**: LangChainì—ì„œ ì œê³µí•˜ëŠ” ê¸°ë³¸ ì œê³µ ë„êµ¬ì˜ ì¢…ë¥˜ì™€ í™œìš©ë²• í•™ìŠµ
2. **SQLDatabaseToolkit í™œìš©**: ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬, ìŠ¤í‚¤ë§ˆ ì¡°íšŒ, SQL ê²€ì¦ ë“± SQL ê´€ë ¨ ë„êµ¬ ì‚¬ìš©
3. **Tavily Search í†µí•©**: ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì—ì´ì „íŠ¸ì— í†µí•©
4. **Wikipedia API í™œìš©**: ë°±ê³¼ì‚¬ì „ ì •ë³´ë¥¼ í™œìš©í•˜ëŠ” ë„êµ¬ êµ¬í˜„
5. **ë„êµ¬ ì¡°í•©**: ì—¬ëŸ¬ Built-in Toolì„ ì¡°í•©í•˜ì—¬ ê°•ë ¥í•œ ì—ì´ì „íŠ¸ êµ¬ì¶•

## ğŸ”‘ í•µì‹¬ ê°œë…

### 1. LangChain Built-in Tools

LangChainì€ ë‹¤ì–‘í•œ ì‚¬ì „ êµ¬ì¶•ëœ ë„êµ¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤:

- **SQLDatabaseToolkit**: ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…ì„ ìœ„í•œ ë„êµ¬ ëª¨ìŒ
- **Tavily Search**: ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥
- **Wikipedia**: ë°±ê³¼ì‚¬ì „ ì •ë³´ ì¡°íšŒ
- **ArXiv**: í•™ìˆ  ë…¼ë¬¸ ê²€ìƒ‰
- **Python REPL**: ì½”ë“œ ì‹¤í–‰ ë„êµ¬
- ê·¸ ì™¸ ìˆ˜ì‹­ ê°€ì§€ ë„êµ¬ë“¤

### 2. SQLDatabaseToolkit

ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…ì„ ìœ„í•œ 5ê°€ì§€ í•µì‹¬ ë„êµ¬:

```python
# 1. QuerySQLDatabaseTool: SQL ì¿¼ë¦¬ ì‹¤í–‰
# 2. InfoSQLDatabaseTool: í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¡°íšŒ
# 3. ListSQLDatabaseTool: ì‚¬ìš© ê°€ëŠ¥í•œ í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
# 4. QuerySQLCheckerTool: SQL ì¿¼ë¦¬ ê²€ì¦
# 5. SQL Agent: ìì—°ì–´ë¥¼ SQLë¡œ ë³€í™˜í•˜ì—¬ ì‹¤í–‰
```

### 3. Tavily Search API

ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ì„ ìœ„í•œ AI ì¹œí™”ì  ê²€ìƒ‰ ì—”ì§„:
- ìµœì‹  ì •ë³´ ê²€ìƒ‰
- êµ¬ì¡°í™”ëœ ê²€ìƒ‰ ê²°ê³¼ ì œê³µ
- LLMì— ìµœì í™”ëœ ì‘ë‹µ í˜•ì‹

### 4. Wikipedia API

Wikipedia ì½˜í…ì¸  ì ‘ê·¼:
- ë¬¸ì„œ ê²€ìƒ‰ ë° ìš”ì•½
- ë‹¤êµ­ì–´ ì§€ì›
- ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë°±ê³¼ì‚¬ì „ ì •ë³´ ì œê³µ

## ğŸ›  í™˜ê²½ ì„¤ì •

### í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

```bash
pip install langchain langchain-openai langchain-community
pip install tavily-python wikipedia-api
pip install langchain-chroma chromadb
pip install python-dotenv
```

### í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

`.env` íŒŒì¼ ìƒì„±:

```bash
OPENAI_API_KEY=your_openai_api_key_here
TAVILY_API_KEY=your_tavily_api_key_here
```

### ê¸°ë³¸ ì„í¬íŠ¸

```python
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_community.agent_toolkits import SQLDatabaseToolkit
from langchain_community.utilities import SQLDatabase
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_community.tools import WikipediaQueryRun
from langchain_community.utilities import WikipediaAPIWrapper
from langchain.agents import create_react_agent, AgentExecutor
from langchain_classic import hub

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
```

## ğŸ’» ë‹¨ê³„ë³„ êµ¬í˜„

### Step 1: SQLDatabaseToolkit ê¸°ë³¸ ì‚¬ìš©

#### 1.1 ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° Toolkit ìƒì„±

```python
from langchain_community.utilities import SQLDatabase

# SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° (ì˜ˆ: ETF ë°ì´í„°)
db = SQLDatabase.from_uri("sqlite:///etf_data.db")

# Toolkit ìƒì„±
from langchain_community.agent_toolkits import SQLDatabaseToolkit

toolkit = SQLDatabaseToolkit(
    db=db,
    llm=ChatOpenAI(model="gpt-4o-mini", temperature=0)
)

# ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ í™•ì¸
tools = toolkit.get_tools()
for tool in tools:
    print(f"ë„êµ¬ ì´ë¦„: {tool.name}")
    print(f"ì„¤ëª…: {tool.description}\n")
```

**ì¶œë ¥ ì˜ˆì‹œ:**
```
ë„êµ¬ ì´ë¦„: sql_db_query
ì„¤ëª…: Execute a SQL query against the database and get back the result.

ë„êµ¬ ì´ë¦„: sql_db_schema
ì„¤ëª…: Get the schema and sample rows for the specified SQL tables.

ë„êµ¬ ì´ë¦„: sql_db_list_tables
ì„¤ëª…: List the available tables in the database.

ë„êµ¬ ì´ë¦„: sql_db_query_checker
ì„¤ëª…: Check if your query is correct before executing it.
```

#### 1.2 ê°œë³„ ë„êµ¬ ì‚¬ìš©

```python
# í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
list_tables_tool = next(t for t in tools if t.name == "sql_db_list_tables")
tables = list_tables_tool.invoke("")
print(f"ì‚¬ìš© ê°€ëŠ¥í•œ í…Œì´ë¸”: {tables}")

# ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¡°íšŒ
schema_tool = next(t for t in tools if t.name == "sql_db_schema")
schema = schema_tool.invoke("etf_info")
print(f"ETF í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ:\n{schema}")

# SQL ì¿¼ë¦¬ ì‹¤í–‰
query_tool = next(t for t in tools if t.name == "sql_db_query")
result = query_tool.invoke("SELECT * FROM etf_info LIMIT 5")
print(f"ì¿¼ë¦¬ ê²°ê³¼:\n{result}")
```

#### 1.3 SQL Agent ìƒì„± ë° ì‹¤í–‰

```python
from langchain.agents import create_react_agent, AgentExecutor
from langchain_classic import hub

# ReAct í”„ë¡¬í”„íŠ¸ ë¡œë“œ
prompt = hub.pull("hwchase17/react")

# LLM ì„¤ì •
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# Agent ìƒì„±
agent = create_react_agent(
    llm=llm,
    tools=tools,
    prompt=prompt
)

# AgentExecutor ìƒì„±
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=True,
    handle_parsing_errors=True,
    max_iterations=10
)

# ìì—°ì–´ ì§ˆì˜ ì‹¤í–‰
response = agent_executor.invoke({
    "input": "ETF ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìƒìœ„ 5ê°œì˜ ETF ì´ë¦„ê³¼ ìš´ìš©ì‚¬ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”."
})

print(f"\nìµœì¢… ë‹µë³€: {response['output']}")
```

**ì‹¤í–‰ ê³¼ì • ì˜ˆì‹œ:**
```
> Entering new AgentExecutor chain...
Action: sql_db_list_tables â†’ Observation: etf_info
Action: sql_db_schema â†’ Observation: CREATE TABLE etf_info (name TEXT, company TEXT, ...)
Action: sql_db_query â†’ Observation: [('KODEX 200', 'Samsung'), ...]

Final Answer: ìƒìœ„ 5ê°œ ETFëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
1. KODEX 200 (Samsung)
2. TIGER 200 (Mirae Asset)
...
```

### Step 2: Tavily Search í†µí•©

#### 2.1 Tavily Search ë„êµ¬ ì„¤ì •

```python
from langchain_community.tools.tavily_search import TavilySearchResults

# Tavily Search ë„êµ¬ ìƒì„±
tavily_tool = TavilySearchResults(
    max_results=5,
    search_depth="advanced",  # "basic" ë˜ëŠ” "advanced"
    include_answer=True,
    include_raw_content=False,
    include_images=False
)

# ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
search_results = tavily_tool.invoke("LangChain ìµœì‹  ì—…ë°ì´íŠ¸")
print(search_results)
```

#### 2.2 Tavilyë¥¼ í¬í•¨í•œ Agent ìƒì„±

```python
from langchain.agents import create_react_agent, AgentExecutor
from langchain_classic import hub

# ë„êµ¬ ë¦¬ìŠ¤íŠ¸ (SQL + Tavily)
combined_tools = toolkit.get_tools() + [tavily_tool]

# Agent ìƒì„±
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
prompt = hub.pull("hwchase17/react")

agent = create_react_agent(
    llm=llm,
    tools=combined_tools,
    prompt=prompt
)

agent_executor = AgentExecutor(
    agent=agent,
    tools=combined_tools,
    verbose=True,
    handle_parsing_errors=True
)

# ì‹¤ì‹œê°„ ì •ë³´ì™€ DB ì •ë³´ë¥¼ ê²°í•©í•œ ì§ˆì˜
response = agent_executor.invoke({
    "input": "2024ë…„ ETF ì‹œì¥ ë™í–¥ê³¼ ìš°ë¦¬ ë°ì´í„°ë² ì´ìŠ¤ì˜ ETF ê°œìˆ˜ë¥¼ ë¹„êµí•´ì£¼ì„¸ìš”."
})

print(f"\në‹µë³€: {response['output']}")
```

#### 2.3 Tavily Search íŒŒë¼ë¯¸í„° ìƒì„¸

```python
# ê³ ê¸‰ ì„¤ì • ì˜ˆì‹œ
tavily_advanced = TavilySearchResults(
    max_results=10,           # ìµœëŒ€ ê²°ê³¼ ìˆ˜
    search_depth="advanced",  # ê²€ìƒ‰ ê¹Šì´
    include_answer=True,      # AI ìƒì„± ë‹µë³€ í¬í•¨
    include_raw_content=True, # ì›ë³¸ ì½˜í…ì¸  í¬í•¨
    include_images=True,      # ì´ë¯¸ì§€ URL í¬í•¨
    topic="news"              # ì£¼ì œ: "general" ë˜ëŠ” "news"
)

# ë‰´ìŠ¤ ê²€ìƒ‰ ì˜ˆì‹œ
news_results = tavily_advanced.invoke("AI ì—ì´ì „íŠ¸ ìµœì‹  ë‰´ìŠ¤")
for idx, result in enumerate(news_results, 1):
    print(f"\n{idx}. {result.get('title', 'N/A')}")
    print(f"   URL: {result.get('url', 'N/A')}")
    print(f"   ë‚´ìš©: {result.get('content', 'N/A')[:200]}...")
```

#### 2.4 Tavily Search ì‹¤ìŠµ ë¬¸ì œ

**ì‹¤ìŠµ 1: ì£¼ì œë³„ ê²€ìƒ‰ ê²°ê³¼ ë¹„êµ**

```python
"""
ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•´ Tavily Searchë¡œ ê²€ìƒ‰í•˜ê³  ê²°ê³¼ë¥¼ ë¹„êµí•˜ì„¸ìš”.
"""

def compare_search_results(topics: list[str]) -> dict:
    """
    ì—¬ëŸ¬ ì£¼ì œì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.

    Args:
        topics: ê²€ìƒ‰í•  ì£¼ì œ ë¦¬ìŠ¤íŠ¸

    Returns:
        ì£¼ì œë³„ ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
    """
    # TODO: êµ¬í˜„í•˜ì„¸ìš”
    pass

# í…ŒìŠ¤íŠ¸
topics = ["LangChain AI agents", "OpenAI GPT-4", "Vector databases"]
results = compare_search_results(topics)
```

**ì†”ë£¨ì…˜:**

```python
from langchain_community.tools.tavily_search import TavilySearchResults

def compare_search_results(topics: list[str]) -> dict:
    """ì—¬ëŸ¬ ì£¼ì œì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¹„êµí•©ë‹ˆë‹¤."""

    tavily_tool = TavilySearchResults(
        max_results=3,
        search_depth="advanced",
        include_answer=True
    )

    results = {}

    for topic in topics:
        try:
            search_results = tavily_tool.invoke(topic)

            # ê²°ê³¼ ìš”ì•½
            results[topic] = {
                "result_count": len(search_results) if isinstance(search_results, list) else 1,
                "top_sources": [r.get('url', 'N/A') for r in search_results[:3]] if isinstance(search_results, list) else [],
                "summary": search_results[:300] + "..." if isinstance(search_results, str) and len(search_results) > 300 else search_results,
                "status": "success"
            }
        except Exception as e:
            results[topic] = {
                "status": "error",
                "error": str(e)
            }

    return results

# í…ŒìŠ¤íŠ¸
topics = ["LangChain AI agents", "OpenAI GPT-4", "Vector databases"]
results = compare_search_results(topics)

for topic, data in results.items():
    print(f"\n{'='*60}")
    print(f"ì£¼ì œ: {topic}")
    print(f"ìƒíƒœ: {data['status']}")
    if data['status'] == 'success':
        print(f"ê²°ê³¼ ìˆ˜: {data['result_count']}")
        print(f"ì£¼ìš” ì¶œì²˜: {data['top_sources']}")
```

**ì‹¤ìŠµ 2: ë‰´ìŠ¤ vs ì¼ë°˜ ê²€ìƒ‰ ë¹„êµ**

```python
"""
Tavilyì˜ 'news' ëª¨ë“œì™€ 'general' ëª¨ë“œë¥¼ ë¹„êµí•˜ì„¸ìš”.
"""

def compare_search_modes(query: str) -> dict:
    """
    ë™ì¼í•œ ì¿¼ë¦¬ì— ëŒ€í•´ ë‰´ìŠ¤ ê²€ìƒ‰ê³¼ ì¼ë°˜ ê²€ìƒ‰ì„ ë¹„êµí•©ë‹ˆë‹¤.

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬

    Returns:
        ëª¨ë“œë³„ ê²€ìƒ‰ ê²°ê³¼ ë¹„êµ
    """
    # TODO: êµ¬í˜„í•˜ì„¸ìš”
    pass

# í…ŒìŠ¤íŠ¸
result = compare_search_modes("AI industry trends 2024")
```

**ì†”ë£¨ì…˜:**

```python
from langchain_community.tools.tavily_search import TavilySearchResults

def compare_search_modes(query: str) -> dict:
    """ë™ì¼í•œ ì¿¼ë¦¬ì— ëŒ€í•´ ë‰´ìŠ¤ ê²€ìƒ‰ê³¼ ì¼ë°˜ ê²€ìƒ‰ì„ ë¹„êµí•©ë‹ˆë‹¤."""

    # ë‰´ìŠ¤ ê²€ìƒ‰
    news_search = TavilySearchResults(
        max_results=5,
        topic="news",
        search_depth="advanced",
        include_answer=True
    )

    # ì¼ë°˜ ê²€ìƒ‰
    general_search = TavilySearchResults(
        max_results=5,
        topic="general",
        search_depth="advanced",
        include_answer=True
    )

    try:
        news_results = news_search.invoke(query)
        general_results = general_search.invoke(query)

        comparison = {
            "query": query,
            "news_mode": {
                "result_count": len(news_results) if isinstance(news_results, list) else 1,
                "sample": str(news_results)[:400] + "...",
            },
            "general_mode": {
                "result_count": len(general_results) if isinstance(general_results, list) else 1,
                "sample": str(general_results)[:400] + "...",
            }
        }

        return comparison

    except Exception as e:
        return {"error": str(e)}

# í…ŒìŠ¤íŠ¸
result = compare_search_modes("AI industry trends 2024")
print(f"ì¿¼ë¦¬: {result['query']}")
print(f"\n[ë‰´ìŠ¤ ëª¨ë“œ]")
print(f"ê²°ê³¼ ìˆ˜: {result['news_mode']['result_count']}")
print(f"ìƒ˜í”Œ: {result['news_mode']['sample']}")
print(f"\n[ì¼ë°˜ ëª¨ë“œ]")
print(f"ê²°ê³¼ ìˆ˜: {result['general_mode']['result_count']}")
print(f"ìƒ˜í”Œ: {result['general_mode']['sample']}")
```

**ì‹¤ìŠµ 3: ê²€ìƒ‰ ê¹Šì´ ë¹„êµ (basic vs advanced)**

```python
"""
Tavilyì˜ 'basic'ê³¼ 'advanced' ê²€ìƒ‰ ê¹Šì´ë¥¼ ë¹„êµí•˜ì„¸ìš”.
"""

def compare_search_depth(query: str) -> dict:
    """
    ë™ì¼í•œ ì¿¼ë¦¬ì— ëŒ€í•´ basicê³¼ advanced ê²€ìƒ‰ ê¹Šì´ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬

    Returns:
        ê²€ìƒ‰ ê¹Šì´ë³„ ê²°ê³¼ ë¹„êµ
    """
    # TODO: êµ¬í˜„í•˜ì„¸ìš”
    pass

# í…ŒìŠ¤íŠ¸
result = compare_search_depth("RAG implementation best practices")
```

**ì†”ë£¨ì…˜:**

```python
import time
from langchain_community.tools.tavily_search import TavilySearchResults

def compare_search_depth(query: str) -> dict:
    """ë™ì¼í•œ ì¿¼ë¦¬ì— ëŒ€í•´ basicê³¼ advanced ê²€ìƒ‰ ê¹Šì´ë¥¼ ë¹„êµí•©ë‹ˆë‹¤."""

    # Basic ê²€ìƒ‰
    basic_search = TavilySearchResults(
        max_results=5,
        search_depth="basic"
    )

    # Advanced ê²€ìƒ‰
    advanced_search = TavilySearchResults(
        max_results=5,
        search_depth="advanced"
    )

    try:
        # Basic ê²€ìƒ‰ ì¸¡ì •
        start_time = time.time()
        basic_results = basic_search.invoke(query)
        basic_time = time.time() - start_time

        # Advanced ê²€ìƒ‰ ì¸¡ì •
        start_time = time.time()
        advanced_results = advanced_search.invoke(query)
        advanced_time = time.time() - start_time

        comparison = {
            "query": query,
            "basic": {
                "execution_time": f"{basic_time:.2f}ì´ˆ",
                "result_count": len(basic_results) if isinstance(basic_results, list) else 1,
                "sample": str(basic_results)[:400] + "...",
            },
            "advanced": {
                "execution_time": f"{advanced_time:.2f}ì´ˆ",
                "result_count": len(advanced_results) if isinstance(advanced_results, list) else 1,
                "sample": str(advanced_results)[:400] + "...",
            }
        }

        return comparison

    except Exception as e:
        return {"error": str(e)}

# í…ŒìŠ¤íŠ¸
result = compare_search_depth("RAG implementation best practices")
print(f"ì¿¼ë¦¬: {result['query']}")
print(f"\n[Basic ê²€ìƒ‰]")
print(f"ì‹¤í–‰ ì‹œê°„: {result['basic']['execution_time']}")
print(f"ê²°ê³¼ ìˆ˜: {result['basic']['result_count']}")
print(f"\n[Advanced ê²€ìƒ‰]")
print(f"ì‹¤í–‰ ì‹œê°„: {result['advanced']['execution_time']}")
print(f"ê²°ê³¼ ìˆ˜: {result['advanced']['result_count']}")
```

### Step 3: Wikipedia ë„êµ¬ í™œìš©

#### 3.1 Wikipedia ë„êµ¬ ìƒì„±

```python
from langchain_community.tools import WikipediaQueryRun
from langchain_community.utilities import WikipediaAPIWrapper

# Wikipedia API Wrapper ì„¤ì •
wikipedia_wrapper = WikipediaAPIWrapper(
    top_k_results=2,      # ìƒìœ„ ê²°ê³¼ ìˆ˜
    doc_content_chars_max=4000,  # ìµœëŒ€ ë¬¸ì ìˆ˜
    lang="ko"             # ì–¸ì–´ ì„¤ì • (ko, en ë“±)
)

# Wikipedia ë„êµ¬ ìƒì„±
wikipedia_tool = WikipediaQueryRun(
    api_wrapper=wikipedia_wrapper,
    name="wikipedia",
    description="Wikipediaì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì…ë ¥ì€ ê²€ìƒ‰ ì¿¼ë¦¬ì—¬ì•¼ í•©ë‹ˆë‹¤."
)

# ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
wiki_result = wikipedia_tool.invoke("ì¸ê³µì§€ëŠ¥")
print(wiki_result)
```

#### 3.2 Wikipedia + Agent í†µí•©

```python
# ëª¨ë“  ë„êµ¬ ê²°í•©
all_tools = [
    *toolkit.get_tools(),
    tavily_tool,
    wikipedia_tool
]

# Agent ìƒì„±
from langchain_classic import hub

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
prompt = hub.pull("hwchase17/react")

agent = create_react_agent(llm=llm, tools=all_tools, prompt=prompt)
agent_executor = AgentExecutor(
    agent=agent,
    tools=all_tools,
    verbose=True,
    max_iterations=15
)

# ë³µí•© ì§ˆì˜ ì‹¤í–‰
response = agent_executor.invoke({
    "input": """
    ë‹¤ìŒì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:
    1. Wikipediaì—ì„œ 'ETF'ì— ëŒ€í•œ ì„¤ëª…ì„ ì°¾ìœ¼ì„¸ìš”
    2. ìš°ë¦¬ ë°ì´í„°ë² ì´ìŠ¤ì— ìˆëŠ” ETF ì¢…ë¥˜ë¥¼ í™•ì¸í•˜ì„¸ìš”
    3. ìµœì‹  ETF íŠ¸ë Œë“œë¥¼ ì›¹ì—ì„œ ê²€ìƒ‰í•˜ì„¸ìš”
    4. ì¢…í•©í•˜ì—¬ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”
    """
})

print(f"\n\n=== ìµœì¢… ë¦¬í¬íŠ¸ ===\n{response['output']}")
```

#### 3.3 ë‹¤êµ­ì–´ Wikipedia í™œìš©

```python
# ì˜ì–´ Wikipedia
wikipedia_en = WikipediaQueryRun(
    api_wrapper=WikipediaAPIWrapper(lang="en", top_k_results=1)
)

# í•œêµ­ì–´ Wikipedia
wikipedia_ko = WikipediaQueryRun(
    api_wrapper=WikipediaAPIWrapper(lang="ko", top_k_results=1)
)

# ë¹„êµ ê²€ìƒ‰
topic = "Machine Learning"
en_result = wikipedia_en.invoke(topic)
ko_result = wikipedia_ko.invoke("ë¨¸ì‹ ëŸ¬ë‹")

print(f"ì˜ì–´ ê²°ê³¼:\n{en_result[:300]}...\n")
print(f"í•œêµ­ì–´ ê²°ê³¼:\n{ko_result[:300]}...")
```

### Step 4: í†µí•© ì˜ˆì œ - ê¸ˆìœµ ë¦¬ì„œì¹˜ Agent

```python
from langchain.prompts import PromptTemplate

# ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ìƒì„±
template = """ë‹¹ì‹ ì€ ê¸ˆìœµ ë¦¬ì„œì¹˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”:

ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:
{tools}

ë„êµ¬ ì´ë¦„: {tool_names}

ë‹¤ìŒ í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”:

Question: ë‹µë³€í•´ì•¼ í•  ì§ˆë¬¸
Thought: ë¬´ì—‡ì„ í•´ì•¼ í• ì§€ ìƒê°í•©ë‹ˆë‹¤
Action: ìˆ˜í–‰í•  ì‘ì—… [{tool_names} ì¤‘ í•˜ë‚˜]
Action Input: ì‘ì—…ì— ëŒ€í•œ ì…ë ¥
Observation: ì‘ì—…ì˜ ê²°ê³¼
... (ì´ Thought/Action/Action Input/Observationì„ ë°˜ë³µ)
Thought: ì´ì œ ìµœì¢… ë‹µë³€ì„ ì•Œì•˜ìŠµë‹ˆë‹¤
Final Answer: ì›ë˜ ì§ˆë¬¸ì— ëŒ€í•œ ìµœì¢… ë‹µë³€

ì§ˆë¬¸: {input}
{agent_scratchpad}
"""

prompt = PromptTemplate.from_template(template)

# ê¸ˆìœµ ë„êµ¬ ì„¸íŠ¸
financial_tools = [
    *toolkit.get_tools(),
    tavily_tool,
    wikipedia_tool
]

# Agent ìƒì„±
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
agent = create_react_agent(llm=llm, tools=financial_tools, prompt=prompt)

agent_executor = AgentExecutor(
    agent=agent,
    tools=financial_tools,
    verbose=True,
    max_iterations=20,
    handle_parsing_errors=True
)

# ë³µì¡í•œ ê¸ˆìœµ ì§ˆì˜
query = """
S&P 500 ETFì— ëŒ€í•´ ë‹¤ìŒì„ ì¡°ì‚¬í•´ì£¼ì„¸ìš”:
1. Wikipediaì—ì„œ S&P 500ì˜ ì •ì˜ì™€ ì—­ì‚¬
2. ìµœì‹  S&P 500 ë™í–¥ (ì›¹ ê²€ìƒ‰)
3. ìš°ë¦¬ DBì— S&P 500 ê´€ë ¨ ETFê°€ ìˆëŠ”ì§€ í™•ì¸
4. ì¢…í•© íˆ¬ì ë¦¬í¬íŠ¸ ì‘ì„±
"""

result = agent_executor.invoke({"input": query})
print(f"\n\n{'='*60}\nìµœì¢… ë¦¬í¬íŠ¸\n{'='*60}\n{result['output']}")
```

## ğŸ¯ ì‹¤ìŠµ ë¬¸ì œ

### ë¬¸ì œ 1: Wikipedia ê²€ìƒ‰ ë„êµ¬ ë§Œë“¤ê¸° â­â­

ì—¬ëŸ¬ ì£¼ì œë¥¼ ë™ì‹œì— ê²€ìƒ‰í•˜ëŠ” Wikipedia ë„êµ¬ë¥¼ êµ¬í˜„í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
- ì…ë ¥: ê²€ìƒ‰ ì£¼ì œ ë¦¬ìŠ¤íŠ¸
- ì¶œë ¥: ê° ì£¼ì œì— ëŒ€í•œ ìš”ì•½ ì •ë³´
- í•œêµ­ì–´ì™€ ì˜ì–´ ê²°ê³¼ ëª¨ë‘ ì œê³µ

```python
def multi_topic_wikipedia_search(topics: list[str]) -> dict:
    """
    ì—¬ëŸ¬ ì£¼ì œì— ëŒ€í•œ Wikipedia ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    Args:
        topics: ê²€ìƒ‰í•  ì£¼ì œ ë¦¬ìŠ¤íŠ¸

    Returns:
        ì£¼ì œë³„ ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    # TODO: êµ¬í˜„í•˜ì„¸ìš”
    pass

# í…ŒìŠ¤íŠ¸
topics = ["Python", "LangChain", "OpenAI"]
results = multi_topic_wikipedia_search(topics)
```

### ë¬¸ì œ 2: SQL + Tavily í†µí•© Agent â­â­â­

ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ì™€ ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ì„ ê²°í•©í•˜ëŠ” Agentë¥¼ ë§Œë“œì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
- SQLDatabaseToolkit ì‚¬ìš©
- Tavily Search í†µí•©
- ìì—°ì–´ ì§ˆì˜ ì²˜ë¦¬
- ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜

```python
def create_hybrid_search_agent(db_uri: str, tavily_api_key: str):
    """
    DB ê²€ìƒ‰ê³¼ ì›¹ ê²€ìƒ‰ì„ ê²°í•©í•œ Agentë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        db_uri: ë°ì´í„°ë² ì´ìŠ¤ URI
        tavily_api_key: Tavily API í‚¤

    Returns:
        AgentExecutor ê°ì²´
    """
    # TODO: êµ¬í˜„í•˜ì„¸ìš”
    pass

# í…ŒìŠ¤íŠ¸
agent = create_hybrid_search_agent(
    db_uri="sqlite:///test.db",
    tavily_api_key=os.getenv("TAVILY_API_KEY")
)
```

### ë¬¸ì œ 3: ë„êµ¬ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ â­â­â­

ê° ë„êµ¬ì˜ í˜¸ì¶œ íšŸìˆ˜ì™€ ì‹¤í–‰ ì‹œê°„ì„ ì¶”ì í•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬í˜„í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
- ë„êµ¬ ë˜í¼ í´ë˜ìŠ¤ ì‘ì„±
- ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
- í˜¸ì¶œ í†µê³„ ì €ì¥
- ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±

```python
from typing import Any
import time

class ToolMonitor:
    """ë„êµ¬ ì‹¤í–‰ì„ ëª¨ë‹ˆí„°ë§í•˜ëŠ” ë˜í¼ í´ë˜ìŠ¤"""

    def __init__(self, tool):
        # TODO: êµ¬í˜„í•˜ì„¸ìš”
        pass

    def invoke(self, input: Any) -> Any:
        # TODO: ì‹¤í–‰ ì‹œê°„ ì¸¡ì • ë° í†µê³„ ì €ì¥
        pass

    def get_statistics(self) -> dict:
        # TODO: í†µê³„ ë°˜í™˜
        pass
```

### ë¬¸ì œ 4: ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ Agent â­â­â­â­

SQL, Wikipedia, Tavilyë¥¼ ëª¨ë‘ í™œìš©í•˜ì—¬ ì¢…í•©ì ì¸ ë¦¬ì„œì¹˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” Agentë¥¼ êµ¬í˜„í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
- 3ê°€ì§€ ë„êµ¬ ëª¨ë‘ í™œìš©
- ê²°ê³¼ë¥¼ ë¹„êµ ë¶„ì„
- ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
- Markdown í˜•ì‹ ë¦¬í¬íŠ¸ ìƒì„±

```python
class ResearchAgent:
    """ë©€í‹°ëª¨ë‹¬ ë¦¬ì„œì¹˜ Agent"""

    def __init__(self, db_uri: str, llm):
        # TODO: ë„êµ¬ ì´ˆê¸°í™”
        pass

    def research(self, query: str) -> str:
        """
        ì¢…í•© ë¦¬ì„œì¹˜ë¥¼ ìˆ˜í–‰í•˜ê³  Markdown ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            query: ë¦¬ì„œì¹˜ ì§ˆë¬¸

        Returns:
            Markdown í˜•ì‹ì˜ ë¦¬í¬íŠ¸
        """
        # TODO: êµ¬í˜„í•˜ì„¸ìš”
        pass
```

### ë¬¸ì œ 5: ë„êµ¬ ìë™ ì„ íƒ ì‹œìŠ¤í…œ â­â­â­â­â­

ì§ˆë¬¸ ìœ í˜•ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ë„êµ¬ë¥¼ ìë™ìœ¼ë¡œ ì„ íƒí•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬í˜„í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
- ì§ˆë¬¸ ë¶„ë¥˜ ë¡œì§
- ë„êµ¬ ìš°ì„ ìˆœìœ„ ê²°ì •
- ë™ì  ë„êµ¬ ì¡°í•©
- ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ì „ëµ

```python
class SmartToolSelector:
    """ì§ˆë¬¸ì— ë”°ë¼ ìµœì ì˜ ë„êµ¬ë¥¼ ì„ íƒí•˜ëŠ” ì‹œìŠ¤í…œ"""

    def __init__(self, all_tools: list):
        self.all_tools = all_tools
        # TODO: ì´ˆê¸°í™”

    def classify_query(self, query: str) -> dict:
        """ì§ˆë¬¸ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤"""
        # TODO: êµ¬í˜„í•˜ì„¸ìš”
        pass

    def select_tools(self, query: str) -> list:
        """ì§ˆë¬¸ì— ìµœì í™”ëœ ë„êµ¬ ì„¸íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤"""
        # TODO: êµ¬í˜„í•˜ì„¸ìš”
        pass

    def execute_with_fallback(self, query: str) -> str:
        """ë„êµ¬ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ì „ëµì„ ì‚¬ìš©í•©ë‹ˆë‹¤"""
        # TODO: êµ¬í˜„í•˜ì„¸ìš”
        pass
```

## âœ… ì†”ë£¨ì…˜ ì˜ˆì‹œ

### ì†”ë£¨ì…˜ 1: Wikipedia ê²€ìƒ‰ ë„êµ¬

```python
from langchain_community.tools import WikipediaQueryRun
from langchain_community.utilities import WikipediaAPIWrapper

def multi_topic_wikipedia_search(topics: list[str]) -> dict:
    """
    ì—¬ëŸ¬ ì£¼ì œì— ëŒ€í•œ Wikipedia ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    # í•œêµ­ì–´ Wikipedia
    wiki_ko = WikipediaQueryRun(
        api_wrapper=WikipediaAPIWrapper(lang="ko", top_k_results=1, doc_content_chars_max=1000)
    )

    # ì˜ì–´ Wikipedia
    wiki_en = WikipediaQueryRun(
        api_wrapper=WikipediaAPIWrapper(lang="en", top_k_results=1, doc_content_chars_max=1000)
    )

    results = {}

    for topic in topics:
        try:
            ko_result = wiki_ko.invoke(topic)
            en_result = wiki_en.invoke(topic)

            results[topic] = {
                "korean": ko_result[:500] + "..." if len(ko_result) > 500 else ko_result,
                "english": en_result[:500] + "..." if len(en_result) > 500 else en_result,
                "status": "success"
            }
        except Exception as e:
            results[topic] = {
                "korean": None,
                "english": None,
                "status": "error",
                "error_message": str(e)
            }

    return results

# í…ŒìŠ¤íŠ¸
topics = ["Python", "LangChain", "OpenAI"]
results = multi_topic_wikipedia_search(topics)

for topic, data in results.items():
    print(f"\n{'='*60}")
    print(f"ì£¼ì œ: {topic}")
    print(f"ìƒíƒœ: {data['status']}")
    if data['status'] == 'success':
        print(f"\n[í•œêµ­ì–´]\n{data['korean']}")
        print(f"\n[English]\n{data['english']}")
    else:
        print(f"ì˜¤ë¥˜: {data['error_message']}")
```

### ì†”ë£¨ì…˜ 2: SQL + Tavily í†µí•© Agent

```python
from langchain_community.utilities import SQLDatabase
from langchain_community.agent_toolkits import SQLDatabaseToolkit
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain.agents import create_react_agent, AgentExecutor
from langchain_classic import hub
from langchain_openai import ChatOpenAI

def create_hybrid_search_agent(db_uri: str, tavily_api_key: str):
    """
    DB ê²€ìƒ‰ê³¼ ì›¹ ê²€ìƒ‰ì„ ê²°í•©í•œ Agentë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
    db = SQLDatabase.from_uri(db_uri)

    # LLM ì„¤ì •
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    # SQL Toolkit
    sql_toolkit = SQLDatabaseToolkit(db=db, llm=llm)
    sql_tools = sql_toolkit.get_tools()

    # Tavily Search
    tavily_tool = TavilySearchResults(
        max_results=5,
        search_depth="advanced",
        include_answer=True
    )

    # ë„êµ¬ ê²°í•©
    all_tools = sql_tools + [tavily_tool]

    # í”„ë¡¬í”„íŠ¸
    prompt = hub.pull("hwchase17/react")

    # Agent ìƒì„±
    agent = create_react_agent(llm=llm, tools=all_tools, prompt=prompt)

    # AgentExecutor
    agent_executor = AgentExecutor(
        agent=agent,
        tools=all_tools,
        verbose=True,
        handle_parsing_errors=True,
        max_iterations=15
    )

    return agent_executor

# í…ŒìŠ¤íŠ¸
agent = create_hybrid_search_agent(
    db_uri="sqlite:///etf_data.db",
    tavily_api_key=os.getenv("TAVILY_API_KEY")
)

# í•˜ì´ë¸Œë¦¬ë“œ ì§ˆì˜
response = agent.invoke({
    "input": """
    ë‹¤ìŒì„ ì¡°ì‚¬í•˜ì„¸ìš”:
    1. ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ETF ì´ ê°œìˆ˜ í™•ì¸
    2. ì›¹ì—ì„œ 2024ë…„ ETF ì‹œì¥ ê·œëª¨ ê²€ìƒ‰
    3. ë¹„êµ ë¶„ì„ ë¦¬í¬íŠ¸ ì‘ì„±
    """
})

print(f"\nìµœì¢… ë‹µë³€:\n{response['output']}")
```

### ì†”ë£¨ì…˜ 3: ë„êµ¬ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```python
import time
from typing import Any, Dict
from datetime import datetime

class ToolMonitor:
    """ë„êµ¬ ì‹¤í–‰ì„ ëª¨ë‹ˆí„°ë§í•˜ëŠ” ë˜í¼ í´ë˜ìŠ¤"""

    def __init__(self, tool):
        self.tool = tool
        self.call_count = 0
        self.total_time = 0.0
        self.call_history = []

    def invoke(self, input: Any) -> Any:
        """ë„êµ¬ë¥¼ ì‹¤í–‰í•˜ê³  ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤"""
        start_time = time.time()

        try:
            result = self.tool.invoke(input)
            status = "success"
            error = None
        except Exception as e:
            result = None
            status = "error"
            error = str(e)

        end_time = time.time()
        execution_time = end_time - start_time

        # í†µê³„ ì—…ë°ì´íŠ¸
        self.call_count += 1
        self.total_time += execution_time

        # íˆìŠ¤í† ë¦¬ ì €ì¥
        self.call_history.append({
            "timestamp": datetime.now().isoformat(),
            "input": str(input)[:100],
            "execution_time": execution_time,
            "status": status,
            "error": error
        })

        if status == "error":
            raise Exception(error)

        return result

    def get_statistics(self) -> Dict:
        """í†µê³„ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤"""
        return {
            "tool_name": self.tool.name,
            "total_calls": self.call_count,
            "total_time": round(self.total_time, 3),
            "average_time": round(self.total_time / self.call_count, 3) if self.call_count > 0 else 0,
            "success_rate": sum(1 for h in self.call_history if h["status"] == "success") / len(self.call_history) if self.call_history else 0,
            "recent_calls": self.call_history[-5:]  # ìµœê·¼ 5ê°œ í˜¸ì¶œ
        }

    def print_report(self):
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤"""
        stats = self.get_statistics()
        print(f"\n{'='*60}")
        print(f"ë„êµ¬ ì„±ëŠ¥ ë¦¬í¬íŠ¸: {stats['tool_name']}")
        print(f"{'='*60}")
        print(f"ì´ í˜¸ì¶œ íšŸìˆ˜: {stats['total_calls']}")
        print(f"ì´ ì‹¤í–‰ ì‹œê°„: {stats['total_time']}ì´ˆ")
        print(f"í‰ê·  ì‹¤í–‰ ì‹œê°„: {stats['average_time']}ì´ˆ")
        print(f"ì„±ê³µë¥ : {stats['success_rate']*100:.1f}%")
        print(f"\nìµœê·¼ í˜¸ì¶œ ë‚´ì—­:")
        for idx, call in enumerate(stats['recent_calls'], 1):
            print(f"  {idx}. {call['timestamp']} - {call['status']} ({call['execution_time']:.3f}ì´ˆ)")

# í…ŒìŠ¤íŠ¸
from langchain_community.tools.tavily_search import TavilySearchResults

tavily_tool = TavilySearchResults(max_results=3)
monitored_tavily = ToolMonitor(tavily_tool)

# ì—¬ëŸ¬ ë²ˆ í˜¸ì¶œ
queries = ["LangChain", "OpenAI", "AI Agents"]
for query in queries:
    result = monitored_tavily.invoke(query)
    print(f"ê²€ìƒ‰ ì™„ë£Œ: {query}")

# ë¦¬í¬íŠ¸ ì¶œë ¥
monitored_tavily.print_report()
```

### ì†”ë£¨ì…˜ 4: ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ Agent

```python
from langchain_community.utilities import SQLDatabase
from langchain_community.agent_toolkits import SQLDatabaseToolkit
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_community.tools import WikipediaQueryRun
from langchain_community.utilities import WikipediaAPIWrapper
from langchain.agents import create_react_agent, AgentExecutor
from langchain_openai import ChatOpenAI
from langchain_classic import hub

class ResearchAgent:
    """ë©€í‹°ëª¨ë‹¬ ë¦¬ì„œì¹˜ Agent"""

    def __init__(self, db_uri: str, llm=None):
        # LLM ì´ˆê¸°í™”
        self.llm = llm or ChatOpenAI(model="gpt-4o-mini", temperature=0)

        # ë°ì´í„°ë² ì´ìŠ¤ ë„êµ¬
        db = SQLDatabase.from_uri(db_uri)
        sql_toolkit = SQLDatabaseToolkit(db=db, llm=self.llm)
        self.sql_tools = sql_toolkit.get_tools()

        # Tavily ê²€ìƒ‰
        self.tavily_tool = TavilySearchResults(
            max_results=5,
            search_depth="advanced"
        )

        # Wikipedia
        self.wiki_tool = WikipediaQueryRun(
            api_wrapper=WikipediaAPIWrapper(
                top_k_results=2,
                doc_content_chars_max=2000,
                lang="ko"
            )
        )

        # ëª¨ë“  ë„êµ¬ ê²°í•©
        self.all_tools = self.sql_tools + [self.tavily_tool, self.wiki_tool]

        # Agent ìƒì„±
        from langchain_classic import hub

        prompt = hub.pull("hwchase17/react")
        agent = create_react_agent(
            llm=self.llm,
            tools=self.all_tools,
            prompt=prompt
        )

        self.agent_executor = AgentExecutor(
            agent=agent,
            tools=self.all_tools,
            verbose=True,
            max_iterations=20,
            handle_parsing_errors=True
        )

    def research(self, query: str) -> str:
        """
        ì¢…í•© ë¦¬ì„œì¹˜ë¥¼ ìˆ˜í–‰í•˜ê³  Markdown ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        """
        # Agent ì‹¤í–‰
        result = self.agent_executor.invoke({"input": query})

        # Markdown ë¦¬í¬íŠ¸ ìƒì„±
        report = f"""# ë¦¬ì„œì¹˜ ë¦¬í¬íŠ¸

## ì§ˆë¬¸
{query}

## ì¡°ì‚¬ ê²°ê³¼
{result['output']}

## ì‚¬ìš©ëœ ë„êµ¬
- ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ (SQL)
- ì›¹ ê²€ìƒ‰ (Tavily)
- ë°±ê³¼ì‚¬ì „ (Wikipedia)

## ì‹ ë¢°ë„ í‰ê°€
- ë°ì´í„°ë² ì´ìŠ¤: ë†’ìŒ (ë‚´ë¶€ ë°ì´í„°)
- ì›¹ ê²€ìƒ‰: ì¤‘ê°„ (ì‹¤ì‹œê°„ ì •ë³´)
- Wikipedia: ë†’ìŒ (ê²€ì¦ëœ ì •ë³´)

---
ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        return report

# í…ŒìŠ¤íŠ¸
research_agent = ResearchAgent(db_uri="sqlite:///etf_data.db")

query = """
'ETF'ì— ëŒ€í•´ ë‹¤ìŒì„ ì¡°ì‚¬í•˜ì„¸ìš”:
1. Wikipediaì—ì„œ ETFì˜ ì •ì˜
2. ìµœì‹  ETF ì‹œì¥ ë™í–¥ (ì›¹ ê²€ìƒ‰)
3. ë°ì´í„°ë² ì´ìŠ¤ì˜ ETF í†µê³„
"""

report = research_agent.research(query)
print(report)
```

### ì†”ë£¨ì…˜ 5: ë„êµ¬ ìë™ ì„ íƒ ì‹œìŠ¤í…œ

```python
from typing import List, Dict
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

class SmartToolSelector:
    """ì§ˆë¬¸ì— ë”°ë¼ ìµœì ì˜ ë„êµ¬ë¥¼ ì„ íƒí•˜ëŠ” ì‹œìŠ¤í…œ"""

    def __init__(self, all_tools: list):
        self.all_tools = all_tools
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

        # ë„êµ¬ ì¹´í…Œê³ ë¦¬ ë§¤í•‘
        self.tool_categories = {
            "database": ["sql_db_query", "sql_db_schema", "sql_db_list_tables"],
            "web_search": ["tavily_search_results_json"],
            "encyclopedia": ["wikipedia"]
        }

    def classify_query(self, query: str) -> Dict:
        """ì§ˆë¬¸ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤"""
        classification_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ í•„ìš”í•œ ë„êµ¬ ì¹´í…Œê³ ë¦¬ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

ì¹´í…Œê³ ë¦¬:
- database: ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒê°€ í•„ìš”í•œ ê²½ìš°
- web_search: ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš°
- encyclopedia: ì¼ë°˜ì ì¸ ì§€ì‹/ì •ì˜ê°€ í•„ìš”í•œ ê²½ìš°

ì‘ë‹µ í˜•ì‹:
{{"categories": ["category1", "category2"], "priority": "category1", "reasoning": "ì´ìœ "}}
"""),
            ("user", "{query}")
        ])

        response = self.llm.invoke(
            classification_prompt.format_messages(query=query)
        )

        import json
        try:
            return json.loads(response.content)
        except:
            return {"categories": ["web_search"], "priority": "web_search", "reasoning": "ê¸°ë³¸ê°’"}

    def select_tools(self, query: str) -> List:
        """ì§ˆë¬¸ì— ìµœì í™”ëœ ë„êµ¬ ì„¸íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤"""
        classification = self.classify_query(query)

        selected_tools = []
        for category in classification["categories"]:
            tool_names = self.tool_categories.get(category, [])
            for tool in self.all_tools:
                if tool.name in tool_names:
                    selected_tools.append(tool)

        # ì¤‘ë³µ ì œê±°
        selected_tools = list({tool.name: tool for tool in selected_tools}.values())

        print(f"\nì„ íƒëœ ë„êµ¬: {[t.name for t in selected_tools]}")
        print(f"ì´ìœ : {classification['reasoning']}")

        return selected_tools

    def execute_with_fallback(self, query: str) -> str:
        """ë„êµ¬ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ì „ëµì„ ì‚¬ìš©í•©ë‹ˆë‹¤"""
        from langchain.agents import create_react_agent, AgentExecutor
        from langchain import hub

        # 1ì°¨ ì‹œë„: ìµœì  ë„êµ¬ ì„ íƒ
        selected_tools = self.select_tools(query)

        if not selected_tools:
            return "ì í•©í•œ ë„êµ¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        try:
            prompt = hub.pull("hwchase17/react")
            agent = create_react_agent(
                llm=self.llm,
                tools=selected_tools,
                prompt=prompt
            )

            agent_executor = AgentExecutor(
                agent=agent,
                tools=selected_tools,
                verbose=True,
                max_iterations=10,
                handle_parsing_errors=True
            )

            result = agent_executor.invoke({"input": query})
            return result["output"]

        except Exception as e:
            print(f"\n1ì°¨ ì‹œë„ ì‹¤íŒ¨: {e}")
            print("ëŒ€ì²´ ì „ëµ ì‹¤í–‰: ëª¨ë“  ë„êµ¬ ì‚¬ìš©")

            # 2ì°¨ ì‹œë„: ëª¨ë“  ë„êµ¬ ì‚¬ìš©
            try:
                agent = create_react_agent(
                    llm=self.llm,
                    tools=self.all_tools,
                    prompt=prompt
                )

                agent_executor = AgentExecutor(
                    agent=agent,
                    tools=self.all_tools,
                    verbose=True,
                    max_iterations=15
                )

                result = agent_executor.invoke({"input": query})
                return result["output"]

            except Exception as e2:
                return f"ëª¨ë“  ì‹œë„ ì‹¤íŒ¨: {e2}"

# í…ŒìŠ¤íŠ¸
from langchain_community.utilities import SQLDatabase
from langchain_community.agent_toolkits import SQLDatabaseToolkit
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_community.tools import WikipediaQueryRun
from langchain_community.utilities import WikipediaAPIWrapper

# ë„êµ¬ ì¤€ë¹„
db = SQLDatabase.from_uri("sqlite:///test.db")
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
sql_toolkit = SQLDatabaseToolkit(db=db, llm=llm)

all_tools = [
    *sql_toolkit.get_tools(),
    TavilySearchResults(max_results=3),
    WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(lang="ko"))
]

# SmartToolSelector ìƒì„±
selector = SmartToolSelector(all_tools)

# í…ŒìŠ¤íŠ¸ ì§ˆì˜ë“¤
queries = [
    "ë°ì´í„°ë² ì´ìŠ¤ì— ìˆëŠ” í…Œì´ë¸”ì„ ì•Œë ¤ì£¼ì„¸ìš”",
    "AIì˜ ì •ì˜ê°€ ë¬´ì—‡ì¸ê°€ìš”?",
    "ìµœì‹  AI ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ì£¼ì„¸ìš”"
]

for query in queries:
    print(f"\n{'='*60}")
    print(f"ì§ˆë¬¸: {query}")
    result = selector.execute_with_fallback(query)
    print(f"\në‹µë³€: {result}")
```

## ğŸš€ ì‹¤ë¬´ í™œìš© ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ê¸ˆìœµ ë°ì´í„° ë¶„ì„ ì‹œìŠ¤í…œ

```python
"""
ì‹¤ì‹œê°„ ê¸ˆìœµ ë‰´ìŠ¤ì™€ ë‚´ë¶€ í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°ë¥¼ ê²°í•©í•œ ë¶„ì„ ì‹œìŠ¤í…œ
"""

from langchain_community.utilities import SQLDatabase
from langchain_community.agent_toolkits import SQLDatabaseToolkit
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain.agents import create_react_agent, AgentExecutor
from langchain_openai import ChatOpenAI
from langchain_classic import hub

class FinancialAnalysisAgent:
    def __init__(self, portfolio_db_uri: str):
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

        # í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°ë² ì´ìŠ¤
        db = SQLDatabase.from_uri(portfolio_db_uri)
        toolkit = SQLDatabaseToolkit(db=db, llm=self.llm)

        # ë‰´ìŠ¤ ê²€ìƒ‰
        news_search = TavilySearchResults(
            max_results=5,
            topic="news",
            search_depth="advanced"
        )

        # ë„êµ¬ ê²°í•©
        tools = toolkit.get_tools() + [news_search]

        # Agent ìƒì„±
        from langchain_classic import hub

        prompt = hub.pull("hwchase17/react")
        agent = create_react_agent(self.llm, tools, prompt)
        self.executor = AgentExecutor(
            agent=agent,
            tools=tools,
            verbose=True,
            max_iterations=15
        )

    def analyze_portfolio_risk(self, stock_symbol: str) -> str:
        """íŠ¹ì • ì£¼ì‹ì˜ ë¦¬ìŠ¤í¬ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤"""
        query = f"""
        {stock_symbol}ì— ëŒ€í•´:
        1. ìµœì‹  ë‰´ìŠ¤ ê²€ìƒ‰
        2. í¬íŠ¸í´ë¦¬ì˜¤ ë‚´ ë³´ìœ  í˜„í™© í™•ì¸
        3. ë¦¬ìŠ¤í¬ í‰ê°€ ë¦¬í¬íŠ¸ ì‘ì„±
        """
        result = self.executor.invoke({"input": query})
        return result["output"]

# ì‚¬ìš© ì˜ˆì‹œ
agent = FinancialAnalysisAgent("sqlite:///portfolio.db")
report = agent.analyze_portfolio_risk("AAPL")
print(report)
```

### ì˜ˆì‹œ 2: ê³ ê° ì§€ì› ì±—ë´‡

```python
"""
ì œí’ˆ ë°ì´í„°ë² ì´ìŠ¤ì™€ ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ì„ í™œìš©í•œ ê³ ê° ì§€ì› ì‹œìŠ¤í…œ
"""

class CustomerSupportBot:
    def __init__(self, product_db_uri: str):
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)

        # ì œí’ˆ ë°ì´í„°ë² ì´ìŠ¤
        db = SQLDatabase.from_uri(product_db_uri)
        toolkit = SQLDatabaseToolkit(db=db, llm=self.llm)

        # ì›¹ ê²€ìƒ‰ (ìµœì‹  ì •ë³´)
        web_search = TavilySearchResults(max_results=3)

        # Wikipedia (ì¼ë°˜ ì§€ì‹)
        wiki = WikipediaQueryRun(
            api_wrapper=WikipediaAPIWrapper(lang="ko", top_k_results=1)
        )

        tools = toolkit.get_tools() + [web_search, wiki]

        # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸
        from langchain.prompts import PromptTemplate
        template = """ë‹¹ì‹ ì€ ì¹œì ˆí•œ ê³ ê° ì§€ì› ìƒë‹´ì›ì…ë‹ˆë‹¤.

ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: {tools}
ë„êµ¬ ì´ë¦„: {tool_names}

ì§ˆë¬¸: {input}
{agent_scratchpad}

í•­ìƒ ì¹œì ˆí•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."""

        prompt = PromptTemplate.from_template(template)
        agent = create_react_agent(self.llm, tools, prompt)

        self.executor = AgentExecutor(
            agent=agent,
            tools=tools,
            verbose=False,
            max_iterations=10
        )

    def handle_query(self, customer_query: str) -> str:
        """ê³ ê° ì§ˆì˜ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤"""
        result = self.executor.invoke({"input": customer_query})
        return result["output"]

# ì‚¬ìš© ì˜ˆì‹œ
bot = CustomerSupportBot("sqlite:///products.db")
response = bot.handle_query("ì œí’ˆ Aì˜ ì‚¬ì–‘ì„ ì•Œë ¤ì£¼ì„¸ìš”")
print(response)
```

### ì˜ˆì‹œ 3: ì—°êµ¬ ë³´ì¡° ì‹œìŠ¤í…œ

```python
"""
í•™ìˆ  ì—°êµ¬ë¥¼ ìœ„í•œ Wikipedia + ì›¹ ê²€ìƒ‰ í†µí•© ì‹œìŠ¤í…œ
"""

class ResearchAssistant:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

        # Wikipedia (ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´)
        wiki_ko = WikipediaQueryRun(
            api_wrapper=WikipediaAPIWrapper(lang="ko", top_k_results=2)
        )
        wiki_en = WikipediaQueryRun(
            api_wrapper=WikipediaAPIWrapper(lang="en", top_k_results=2)
        )

        # í•™ìˆ  ê²€ìƒ‰
        academic_search = TavilySearchResults(
            max_results=10,
            search_depth="advanced",
            topic="general"
        )

        tools = [wiki_ko, wiki_en, academic_search]

        prompt = hub.pull("hwchase17/react")
        agent = create_react_agent(self.llm, tools, prompt)

        self.executor = AgentExecutor(
            agent=agent,
            tools=tools,
            verbose=True,
            max_iterations=20
        )

    def research_topic(self, topic: str, language: str = "both") -> dict:
        """ì£¼ì œì— ëŒ€í•œ ì¢…í•© ì—°êµ¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤"""
        query = f"""
        '{topic}'ì— ëŒ€í•´:
        1. Wikipediaì—ì„œ ì •ì˜ì™€ ë°°ê²½ ì¡°ì‚¬ ({language})
        2. ìµœì‹  ì—°êµ¬ ë™í–¥ ê²€ìƒ‰
        3. ì£¼ìš” ë°œê²¬ì‚¬í•­ ì •ë¦¬
        4. ì°¸ê³ ë¬¸í—Œ ë¦¬ìŠ¤íŠ¸ ì‘ì„±
        """

        result = self.executor.invoke({"input": query})

        return {
            "topic": topic,
            "findings": result["output"],
            "language": language
        }

# ì‚¬ìš© ì˜ˆì‹œ
assistant = ResearchAssistant()
report = assistant.research_topic("Transformer Architecture", language="both")
print(report["findings"])
```

### ì˜ˆì‹œ 4: ë¹„ì¦ˆë‹ˆìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤ ëŒ€ì‹œë³´ë“œ

```python
"""
SQL ë¶„ì„ + ì‹œì¥ ë™í–¥ì„ ê²°í•©í•œ BI ì‹œìŠ¤í…œ
"""

class BusinessIntelligenceAgent:
    def __init__(self, analytics_db_uri: str):
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

        # ë¶„ì„ ë°ì´í„°ë² ì´ìŠ¤
        db = SQLDatabase.from_uri(analytics_db_uri)
        toolkit = SQLDatabaseToolkit(db=db, llm=self.llm)

        # ì‹œì¥ ë™í–¥ ê²€ìƒ‰
        market_search = TavilySearchResults(
            max_results=5,
            topic="news",
            search_depth="advanced"
        )

        tools = toolkit.get_tools() + [market_search]

        prompt = hub.pull("hwchase17/react")
        agent = create_react_agent(self.llm, tools, prompt)

        self.executor = AgentExecutor(
            agent=agent,
            tools=tools,
            verbose=True
        )

    def generate_insights(self, metric: str, period: str = "monthly") -> str:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤"""
        query = f"""
        {metric}ì— ëŒ€í•´:
        1. ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ {period} íŠ¸ë Œë“œ ë¶„ì„
        2. ì‹œì¥ ë™í–¥ ê²€ìƒ‰
        3. ì¸ì‚¬ì´íŠ¸ ë° ê¶Œì¥ì‚¬í•­ ì œê³µ
        """

        result = self.executor.invoke({"input": query})
        return result["output"]

# ì‚¬ìš© ì˜ˆì‹œ
bi_agent = BusinessIntelligenceAgent("sqlite:///sales_analytics.db")
insights = bi_agent.generate_insights("ë§¤ì¶œ", "quarterly")
print(insights)
```

## ğŸ“– ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [LangChain Tools Documentation](https://python.langchain.com/docs/modules/agents/tools/)
- [SQLDatabaseToolkit API](https://api.python.langchain.com/en/latest/agent_toolkits/langchain_community.agent_toolkits.sql.toolkit.SQLDatabaseToolkit.html)
- [Tavily Search API](https://docs.tavily.com/)
- [Wikipedia API](https://wikipedia-api.readthedocs.io/)

### ì¶”ê°€ í•™ìŠµ ìë£Œ
- LangChain Agent ê³ ê¸‰ íŒ¨í„´
- SQL Injection ë°©ì§€ ì „ëµ
- ì›¹ ê²€ìƒ‰ ê²°ê³¼ ì‹ ë¢°ë„ í‰ê°€
- ë©€í‹°ëª¨ë‹¬ ë„êµ¬ ì¡°í•© ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

### ê´€ë ¨ ë…¸íŠ¸ë¶
- `PRJ03_W1_001_ToolCalling_Agent_Intro.md` - Tool Calling ê¸°ì´ˆ
- ë‹¤ìŒ: Custom Tool ê°œë°œ ê°€ì´ë“œ

---

**í•™ìŠµ ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸:**
- [ ] SQLDatabaseToolkitì˜ 5ê°€ì§€ ë„êµ¬ ì´í•´
- [ ] Tavily Search API ì„¤ì • ë° ì‚¬ìš©
- [ ] Wikipedia ë„êµ¬ í•œêµ­ì–´/ì˜ì–´ í™œìš©
- [ ] ì—¬ëŸ¬ ë„êµ¬ë¥¼ ì¡°í•©í•œ Agent ìƒì„±
- [ ] ì‹¤ìŠµ ë¬¸ì œ 5ê°œ ì™„ë£Œ
- [ ] ì‹¤ë¬´ ì˜ˆì‹œ ì½”ë“œ ì‹¤í–‰ ë° ì´í•´
