# LangGraph Send ê°ì²´ - ë³‘ë ¬ ë¬¸ì„œ ì²˜ë¦¬ ì‹œìŠ¤í…œ

## ğŸ“š í•™ìŠµ ëª©í‘œ

- **Send ê°ì²´**ì˜ ê°œë…ê³¼ ë™ì‘ ì›ë¦¬ë¥¼ ì´í•´í•œë‹¤
- **ë³‘ë ¬ ì²˜ë¦¬**ë¥¼ í†µí•œ ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ì²˜ë¦¬ ë°©ë²•ì„ ìµíŒë‹¤
- **ë¬¸ì„œ ìš”ì•½ ì‹œìŠ¤í…œ**ì„ StateGraphë¡œ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤
- **ì²­í¬ ë¶„í•  â†’ ë³‘ë ¬ ìš”ì•½ â†’ í†µí•©** ì›Œí¬í”Œë¡œìš°ë¥¼ ì„¤ê³„í•  ìˆ˜ ìˆë‹¤
- **ìˆœì„œ ìœ ì§€**ë¥¼ ë³´ì¥í•˜ë©° ë³‘ë ¬ ì²˜ë¦¬ ê²°ê³¼ë¥¼ í†µí•©í•  ìˆ˜ ìˆë‹¤

## ğŸ”‘ í•µì‹¬ ê°œë…

### Send ê°ì²´ë€?

**Send**ëŠ” LangGraphì—ì„œ í•˜ë‚˜ì˜ ë…¸ë“œê°€ ì—¬ëŸ¬ ê°œì˜ ë³‘ë ¬ ì‘ì—…ì„ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” íŠ¹ë³„í•œ ê°ì²´ì…ë‹ˆë‹¤.

**ì£¼ìš” íŠ¹ì§•:**
- **ë™ì  ë³‘ë ¬ ì‹¤í–‰**: ëŸ°íƒ€ì„ì— ë³‘ë ¬ ì‘ì—… ê°œìˆ˜ ê²°ì •
- **íŒ¬ì•„ì›ƒ-íŒ¬ì¸ íŒ¨í„´**: í•˜ë‚˜ì˜ ì‘ì—…ì„ ì—¬ëŸ¬ ê°œë¡œ ë¶„ì‚° í›„ ë‹¤ì‹œ í†µí•©
- **íš¨ìœ¨ì„±**: ë…ë¦½ì ì¸ ì‘ì—…ë“¤ì„ ë™ì‹œì— ì²˜ë¦¬í•˜ì—¬ ì‹œê°„ ë‹¨ì¶•
- **ìœ ì—°ì„±**: ì¡°ê±´ë¶€ ë¶„ê¸°ë¡œ í•„ìš”í•œ ë§Œí¼ë§Œ ë³‘ë ¬ ì‘ì—… ìƒì„±

### Send vs ì¼ë°˜ ì—£ì§€

| ë¹„êµ í•­ëª© | ì¼ë°˜ ì—£ì§€ | Send ê°ì²´ |
|----------|---------|----------|
| ì‹¤í–‰ ë°©ì‹ | ìˆœì°¨ì  | ë³‘ë ¬ |
| ì‘ì—… ìˆ˜ | ê³ ì • (1ê°œ) | ë™ì  (Nê°œ) |
| ì‚¬ìš© ì‚¬ë¡€ | ì„ í˜• ì›Œí¬í”Œë¡œìš° | ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ |
| ìƒíƒœ ì „ë‹¬ | ì „ì²´ ìƒíƒœ | ë¶€ë¶„ ìƒíƒœ |

### ë¬¸ì„œ ìš”ì•½ ì›Œí¬í”Œë¡œìš°

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ ë¬¸ì„œ ë¡œë“œ        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ ì²­í¬ ë¶„í•         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                 â”‚                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚ ì²­í¬1 ìš”ì•½   â”‚   â”‚ ì²­í¬2 ìš”ì•½   â”‚   â”‚ ì²­í¬3 ìš”ì•½   â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â”‚                 â”‚                 â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ ìµœì¢… ìš”ì•½ í†µí•©   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ê´€ë ¨ ê¸°ìˆ  ìŠ¤íƒ

```python
# LangGraph í•µì‹¬
langgraph              # Graph êµ¬ì„± ë° Send ê°ì²´
langgraph.types        # Send íƒ€ì…
langgraph.graph        # StateGraph, START, END

# LangChain
langchain-openai       # OpenAI LLM
langchain-core         # Document ê°ì²´

# Python
typing                 # íƒ€ì… íŒíŒ…
operator               # reduce ì—°ì‚°ì
```

## ğŸ›  í™˜ê²½ ì„¤ì •

### í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

```bash
pip install langgraph langchain-openai langchain-core
pip install python-dotenv
```

### API í‚¤ ì„¤ì •

```.env
OPENAI_API_KEY=your_openai_api_key_here
```

### ê¸°ë³¸ ì„¤ì • ì½”ë“œ

```python
from dotenv import load_dotenv
import os

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# API í‚¤ í™•ì¸
if not os.getenv("OPENAI_API_KEY"):
    raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

print("âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ!")
```

## ğŸ’» ë‹¨ê³„ë³„ êµ¬í˜„

### 1ë‹¨ê³„: ìƒíƒœ ì •ì˜

#### 1.1 íƒ€ì… ì •ì˜

```python
import operator
from typing import Annotated, List, Dict, Tuple, Any
from typing_extensions import TypedDict
from langchain_core.documents import Document

# ì „ì²´ ì›Œí¬í”Œë¡œìš° ìƒíƒœ
class SummarizationState(TypedDict):
    contents: List[Document]           # ì´ˆê¸° Document ê°ì²´ ë¦¬ìŠ¤íŠ¸
    chunks: List[Dict[str, Any]]       # ì²­í¬ ë¦¬ìŠ¤íŠ¸ (ì¸ë±ìŠ¤, ë‚´ìš©, ë©”íƒ€ë°ì´í„°)
    summaries: Annotated[List[Tuple[int, str]], operator.add]  # (ì¸ë±ìŠ¤, ìš”ì•½) íŠœí”Œ
    final_summary: str                 # ìµœì¢… í†µí•© ìš”ì•½

# ê°œë³„ ì²­í¬ ì²˜ë¦¬ ìƒíƒœ
class DocumentState(TypedDict):
    content: str      # ì²­í¬ ë‚´ìš©
    index: int        # ì²­í¬ ìˆœì„œ (ìˆœì„œ ìœ ì§€ìš©)
```

**ì£¼ìš” í¬ì¸íŠ¸:**
- `Annotated[List[Tuple[int, str]], operator.add]`: ë³‘ë ¬ ì‘ì—… ê²°ê³¼ë¥¼ ìë™ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
- `operator.add`: reduce ì—°ì‚°ìë¡œ ì—¬ëŸ¬ ë…¸ë“œì˜ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í†µí•©
- `index`: ë³‘ë ¬ ì²˜ë¦¬ í›„ì—ë„ ì›ë˜ ìˆœì„œë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•œ ì¸ë±ìŠ¤

### 2ë‹¨ê³„: ë…¸ë“œ í•¨ìˆ˜ êµ¬í˜„

#### 2.1 ë¬¸ì„œ ì²­í¬ ë¶„í•  ë…¸ë“œ

```python
def split_documents(state: SummarizationState):
    """ê° Documentë¥¼ ìˆœì„œë¥¼ ìœ ì§€í•˜ë©° ì²­í¬ë¡œ ë¶„í• """
    chunks = []
    chunk_size = 1000  # ì²­í¬ í¬ê¸° (ë¬¸ì ë‹¨ìœ„)
    global_chunk_index = 0

    # ê° Documentë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬
    for doc_index, document in enumerate(state["contents"]):
        content = document.page_content

        # í•´ë‹¹ ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• 
        for i in range(0, len(content), chunk_size):
            chunk_content = content[i:i + chunk_size]

            # ë¹ˆ ì²­í¬ëŠ” ìŠ¤í‚µ
            if chunk_content.strip():
                chunks.append({
                    "index": global_chunk_index,
                    "content": chunk_content,
                    "source_document": doc_index,
                    "source_metadata": document.metadata
                })
                global_chunk_index += 1

    return {"chunks": chunks}
```

**ì£¼ìš” íŒŒë¼ë¯¸í„°:**
- `chunk_size`: ê° ì²­í¬ì˜ ìµœëŒ€ í¬ê¸° (ë¬¸ì ìˆ˜)
- `global_chunk_index`: ì „ì²´ ì²­í¬ì˜ ìˆœì„œë¥¼ ì¶”ì 
- `source_document`: ì›ë³¸ ë¬¸ì„œ ì¸ë±ìŠ¤ (ì¶”ì ìš©)

#### 2.2 ê°œë³„ ì²­í¬ ìš”ì•½ ë…¸ë“œ

```python
from langchain_openai import ChatOpenAI

# LLM ëª¨ë¸ ì´ˆê¸°í™”
model = ChatOpenAI(model="gpt-4o-mini", temperature=0)

def summarize_document(state: DocumentState):
    """ê°œë³„ ë¬¸ì„œ ì²­í¬ë¥¼ ìš”ì•½"""
    prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:

    {state['content']}
    """

    try:
        response = model.invoke(prompt)
        summary = response.content
    except Exception as e:
        summary = f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

    # ìˆœì„œ ì •ë³´ì™€ í•¨ê»˜ ìš”ì•½ ë°˜í™˜
    return {"summaries": [(state["index"], summary)]}
```

**ìš”ì•½ ì „ëµ:**
- **ê°„ê²°ì„±**: 2-3ë¬¸ì¥ìœ¼ë¡œ ì œí•œí•˜ì—¬ í•µì‹¬ë§Œ ì¶”ì¶œ
- **ì—ëŸ¬ ì²˜ë¦¬**: ì˜ˆì™¸ ë°œìƒ ì‹œì—ë„ ì •ìƒì ìœ¼ë¡œ ì²˜ë¦¬
- **ìˆœì„œ ìœ ì§€**: (index, summary) íŠœí”Œë¡œ ë°˜í™˜

#### 2.3 ì¡°ê±´ë¶€ ì—£ì§€ í•¨ìˆ˜ (Send ìƒì„±)

```python
from langgraph.types import Send

def continue_to_summarization(state: SummarizationState):
    """ê° ì²­í¬ë¥¼ ë³‘ë ¬ë¡œ ìš”ì•½í•˜ë„ë¡ Send ì‘ì—… ìƒì„±"""
    return [
        Send("summarize_document", {
            "content": chunk["content"],
            "index": chunk["index"]
        })
        for chunk in state["chunks"]
    ]
```

**Send ê°ì²´ ì‘ë™ ì›ë¦¬:**
1. ì²­í¬ ê°œìˆ˜ë§Œí¼ `Send` ê°ì²´ ìƒì„±
2. ê° `Send`ëŠ” `summarize_document` ë…¸ë“œë¥¼ í˜¸ì¶œ
3. ëª¨ë“  `Send` ì‘ì—…ì´ ë³‘ë ¬ë¡œ ì‹¤í–‰ë¨
4. ê²°ê³¼ëŠ” `summaries` ë¦¬ìŠ¤íŠ¸ì— ìë™ìœ¼ë¡œ ì¶”ê°€ë¨ (operator.add ë•ë¶„)

#### 2.4 ìµœì¢… ìš”ì•½ í†µí•© ë…¸ë“œ

```python
def create_final_summary(state: SummarizationState):
    """ìˆœì„œë¥¼ ìœ ì§€í•˜ë©° ìµœì¢… ìš”ì•½ ìƒì„±"""
    # ì¸ë±ìŠ¤ë³„ë¡œ ìš”ì•½ì„ ì •ë ¬
    sorted_summaries = sorted(state["summaries"], key=lambda x: x[0])

    # ìˆœì„œëŒ€ë¡œ ìš”ì•½ë“¤ì„ ê²°í•©
    ordered_summaries = [summary for _, summary in sorted_summaries]
    combined_summaries = "\n\n".join(ordered_summaries)

    prompt = f"""ë‹¤ìŒì€ ë¬¸ì„œë¥¼ ì²­í¬ë³„ë¡œ ìš”ì•½í•œ ë‚´ìš©ë“¤ì…ë‹ˆë‹¤.
    ì´ë“¤ì„ ì¢…í•©í•˜ì—¬ í•˜ë‚˜ì˜ í¬ê´„ì ì´ê³  ì¼ê´€ì„± ìˆëŠ” ìµœì¢… ìš”ì•½ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
    ì›ë³¸ ë¬¸ì„œì˜ ìˆœì„œì™€ íë¦„ì„ ìœ ì§€í•˜ë©´ì„œ í•µì‹¬ ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”:

    {combined_summaries}

    ìµœì¢… ìš”ì•½:
    """

    try:
        response = model.invoke(prompt)
        final_summary = response.content
    except Exception as e:
        final_summary = f"ìµœì¢… ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

    return {"final_summary": final_summary}
```

**í†µí•© ì „ëµ:**
1. **ì •ë ¬**: ì¸ë±ìŠ¤ ìˆœì„œëŒ€ë¡œ ìš”ì•½ ì •ë ¬
2. **ê²°í•©**: ìˆœì„œëŒ€ë¡œ ìš”ì•½ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ ê²°í•©
3. **ì¬ìš”ì•½**: LLMì„ ì‚¬ìš©í•˜ì—¬ ì¼ê´€ì„± ìˆëŠ” ìµœì¢… ìš”ì•½ ìƒì„±

### 3ë‹¨ê³„: ê·¸ë˜í”„ êµ¬ì„±

#### 3.1 StateGraph ìƒì„±

```python
from langgraph.graph import END, START, StateGraph

# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(SummarizationState)

# ë…¸ë“œ ì¶”ê°€
builder.add_node("split_documents", split_documents)
builder.add_node("summarize_document", summarize_document)
builder.add_node("create_final_summary", create_final_summary)
```

#### 3.2 ì—£ì§€ ì—°ê²°

```python
# ì—£ì§€ ì—°ê²°
builder.add_edge(START, "split_documents")

# ì¡°ê±´ë¶€ ì—£ì§€ (Send ê°ì²´ ìƒì„±)
builder.add_conditional_edges(
    "split_documents",                    # ì¶œë°œ ë…¸ë“œ
    continue_to_summarization,            # Send ìƒì„± í•¨ìˆ˜
    ["summarize_document"]                # ëª©ì ì§€ ë…¸ë“œ (ë³‘ë ¬ ì‹¤í–‰ë¨)
)

builder.add_edge("summarize_document", "create_final_summary")
builder.add_edge("create_final_summary", END)

# ê·¸ë˜í”„ ì»´íŒŒì¼
graph = builder.compile()
```

**ì—£ì§€ ìœ í˜•:**
- `add_edge`: ì¼ë°˜ ì—£ì§€ (ìˆœì°¨ ì‹¤í–‰)
- `add_conditional_edges`: ì¡°ê±´ë¶€ ì—£ì§€ (Send ê°ì²´ë¡œ ë³‘ë ¬ ì‹¤í–‰)

#### 3.3 ê·¸ë˜í”„ ì‹œê°í™”

```python
from IPython.display import Image, display

# ê·¸ë˜í”„ ì‹œê°í™”
display(Image(graph.get_graph().draw_mermaid_png()))
```

**ê·¸ë˜í”„ êµ¬ì¡°:**
```
START â†’ split_documents â†’ [summarize_document (ë³‘ë ¬)] â†’ create_final_summary â†’ END
```

### 4ë‹¨ê³„: ì‹¤í–‰ ë° í…ŒìŠ¤íŠ¸

#### 4.1 í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„

```python
from langchain_core.documents import Document

# ê¸´ í…ìŠ¤íŠ¸ ìƒì„± (ì—¬ëŸ¬ ì²­í¬ë¡œ ë¶„í• ë  ìˆ˜ ìˆë„ë¡)
test_text = """
LangGraphëŠ” LangChainì˜ ê³ ê¸‰ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ ë„êµ¬ì…ë‹ˆë‹¤.
ì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ë©´ ë³µì¡í•œ ë‹¤ë‹¨ê³„ ì‘ì—…ì„ íš¨ìœ¨ì ìœ¼ë¡œ êµ¬ì„±í•˜ê³  ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
íŠ¹íˆ Send ê°ì²´ë¥¼ í™œìš©í•˜ë©´ ë³‘ë ¬ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•˜ì—¬ ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ì²˜ë¦¬ì— ìœ ìš©í•©ë‹ˆë‹¤.

LangGraphì˜ ì£¼ìš” ê¸°ëŠ¥ ì¤‘ í•˜ë‚˜ëŠ” StateGraphì…ë‹ˆë‹¤.
StateGraphë¥¼ í†µí•´ ìƒíƒœ ê¸°ë°˜ì˜ ì›Œí¬í”Œë¡œìš°ë¥¼ ì •ì˜í•  ìˆ˜ ìˆìœ¼ë©°,
ê° ë…¸ë“œëŠ” íŠ¹ì • ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³  ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
ë…¸ë“œ ê°„ì˜ ì—°ê²°ì€ ì—£ì§€ë¡œ í‘œí˜„ë˜ë©°, ì¡°ê±´ë¶€ ì—£ì§€ë¥¼ í†µí•´ ë™ì ì¸ ì›Œí¬í”Œë¡œìš° êµ¬ì„±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

Send ê°ì²´ëŠ” íŠ¹íˆ ê°•ë ¥í•œ ê¸°ëŠ¥ì…ë‹ˆë‹¤.
ì´ë¥¼ í†µí•´ í•˜ë‚˜ì˜ ë…¸ë“œì—ì„œ ì—¬ëŸ¬ ê°œì˜ ë³‘ë ¬ ì‘ì—…ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì˜ˆë¥¼ ë“¤ì–´, ê¸´ ë¬¸ì„œë¥¼ ì—¬ëŸ¬ ì²­í¬ë¡œ ë‚˜ëˆˆ í›„ ê° ì²­í¬ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì´ëŠ” ì²˜ë¦¬ ì‹œê°„ì„ í¬ê²Œ ë‹¨ì¶•ì‹œí‚¤ê³  íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤.

ë¬¸ì„œ ìš”ì•½ ì‘ì—…ì˜ ê²½ìš°, Sendë¥¼ í™œìš©í•œ ë³‘ë ¬ ì²˜ë¦¬ê°€ ë§¤ìš° íš¨ê³¼ì ì…ë‹ˆë‹¤.
ë¨¼ì € ë¬¸ì„œë¥¼ ì ì ˆí•œ í¬ê¸°ì˜ ì²­í¬ë¡œ ë¶„í• í•œ í›„,
ê° ì²­í¬ë¥¼ ë…ë¦½ì ìœ¼ë¡œ ìš”ì•½í•˜ê³ ,
ë§ˆì§€ë§‰ìœ¼ë¡œ ëª¨ë“  ìš”ì•½ì„ í†µí•©í•˜ì—¬ ìµœì¢… ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.

ì´ëŸ¬í•œ ì ‘ê·¼ ë°©ì‹ì€ ëŒ€ìš©ëŸ‰ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•  ë•Œ íŠ¹íˆ ìœ ìš©í•©ë‹ˆë‹¤.
ê° ì²­í¬ê°€ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬ë˜ë¯€ë¡œ ë³‘ë ¬ì„±ì´ ë†’ê³ ,
ê²°ê³¼ì ìœ¼ë¡œ ì „ì²´ ì²˜ë¦¬ ì‹œê°„ì´ í¬ê²Œ ê°ì†Œí•©ë‹ˆë‹¤.
ë˜í•œ ë©”ëª¨ë¦¬ ì‚¬ìš©ë„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

LangGraphëŠ” ë‹¤ì–‘í•œ ì²´í¬í¬ì¸íŠ¸ ê¸°ëŠ¥ë„ ì œê³µí•©ë‹ˆë‹¤.
MemorySaverë¥¼ í†µí•´ ì„¸ì…˜ ê°„ ìƒíƒœë¥¼ ìœ ì§€í•  ìˆ˜ ìˆìœ¼ë©°,
InMemoryStoreë¥¼ í™œìš©í•˜ë©´ ì¥ê¸° ë©”ëª¨ë¦¬ êµ¬í˜„ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.
ì´ëŸ¬í•œ ê¸°ëŠ¥ë“¤ì„ ì¡°í•©í•˜ë©´ ë³µì¡í•œ ëŒ€í™”í˜• AI ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ë‹¤ì–‘í•œ ê³ ë ¤ì‚¬í•­ì´ ìˆìŠµë‹ˆë‹¤.
ì—ëŸ¬ í•¸ë“¤ë§, ì¬ì‹œë„ ë¡œì§, íƒ€ì„ì•„ì›ƒ ê´€ë¦¬ ë“±ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
LangGraphëŠ” ì´ëŸ¬í•œ ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•  ìˆ˜ ìˆëŠ” ìœ ì—°ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.
ê°œë°œìëŠ” ìì‹ ì˜ ìš”êµ¬ì— ë§ê²Œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ê²°ë¡ ì ìœ¼ë¡œ LangGraphëŠ” í˜„ëŒ€ì ì¸ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì— í•„ìˆ˜ì ì¸ ë„êµ¬ì…ë‹ˆë‹¤.
ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ê°„ë‹¨í•˜ê²Œ ê´€ë¦¬í•˜ê³ ,
ë³‘ë ¬ ì²˜ë¦¬ë¥¼ í†µí•´ ì„±ëŠ¥ì„ ìµœì í™”í•˜ë©°,
ìƒíƒœ ê´€ë¦¬ë¥¼ í†µí•´ ì•ˆì •ì ì¸ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""

# ì—¬ëŸ¬ í˜ì´ì§€ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ê¸° ìœ„í•´ 3ê°œì˜ Document ìƒì„±
documents = [
    Document(
        page_content=test_text,
        metadata={"page": 1, "source": "test_document_1"}
    ),
    Document(
        page_content=test_text + "\n\nì¶”ê°€ ë‚´ìš©: ì´ ë¬¸ì„œëŠ” í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë‘ ë²ˆì§¸ í˜ì´ì§€ì…ë‹ˆë‹¤.",
        metadata={"page": 2, "source": "test_document_2"}
    ),
    Document(
        page_content="ë§ˆì§€ë§‰ í˜ì´ì§€ì˜ ë‚´ìš©ì…ë‹ˆë‹¤. LangGraphë¥¼ í™œìš©í•˜ë©´ íš¨ìœ¨ì ì¸ ë¬¸ì„œ ì²˜ë¦¬ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        metadata={"page": 3, "source": "test_document_3"}
    )
]

print(f"ë¡œë“œëœ í˜ì´ì§€ ìˆ˜: {len(documents)}")
print(f"ì²« ë²ˆì§¸ ë¬¸ì„œ ê¸¸ì´: {len(documents[0].page_content)} ë¬¸ì")
```

**ì¶œë ¥:**
```
ë¡œë“œëœ í˜ì´ì§€ ìˆ˜: 3
ì²« ë²ˆì§¸ ë¬¸ì„œ ê¸¸ì´: 1096 ë¬¸ì
```

#### 4.2 ê·¸ë˜í”„ ì‹¤í–‰

```python
# ì´ˆê¸° ìƒíƒœ ì„¤ì •
initial_state = {
    "contents": documents,
}

# ê·¸ë˜í”„ ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
for step in graph.stream(initial_state, stream_mode="values"):
    if "chunks" in step:
        print(f"ì²˜ë¦¬ ì¤‘ì¸ ì²­í¬ ìˆ˜: {len(step['chunks'])}")
    if "summaries" in step:
        print(f"í˜„ì¬ê¹Œì§€ ìƒì„±ëœ ìš”ì•½ ìˆ˜: {len(step['summaries'])}")
    if "final_summary" in step:
        print("\n" + "="*80)
        print("ìµœì¢… ìš”ì•½:")
        print("="*80)
        print(step["final_summary"])
    print("-"*80)
```

**ì‹¤í–‰ íë¦„:**
```
ì²˜ë¦¬ ì¤‘ì¸ ì²­í¬ ìˆ˜: 5
--------------------------------------------------------------------------------
í˜„ì¬ê¹Œì§€ ìƒì„±ëœ ìš”ì•½ ìˆ˜: 5
--------------------------------------------------------------------------------
================================================================================
ìµœì¢… ìš”ì•½:
================================================================================
LangGraphëŠ” LangChainì˜ ê³ ê¸‰ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ ë„êµ¬ë¡œ, ë³µì¡í•œ ë‹¤ë‹¨ê³„ ì‘ì—…ì„ íš¨ìœ¨ì ìœ¼ë¡œ
êµ¬ì„±í•˜ê³  ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤. ì´ ë„êµ¬ëŠ” Send ê°ì²´ë¥¼ í™œìš©í•œ ë³‘ë ¬ ì²˜ë¦¬ ê¸°ëŠ¥ì„
í†µí•´ ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ì²˜ë¦¬ë¥¼ ìš©ì´í•˜ê²Œ í•˜ë©°, StateGraphë¥¼ í†µí•´ ìƒíƒœ ê¸°ë°˜ì˜ ë™ì ì¸ ì›Œí¬í”Œë¡œìš°ë¥¼
ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ë‹¤ì–‘í•œ ì²´í¬í¬ì¸íŠ¸ ê¸°ëŠ¥ê³¼ ìœ ì—°í•œ ì»¤ìŠ¤í„°ë§ˆì´ì§• ì˜µì…˜ì„ ì œê³µí•˜ì—¬
ë³µì¡í•œ ëŒ€í™”í˜• AI ì‹œìŠ¤í…œ êµ¬ì¶•ì— ì í•©í•©ë‹ˆë‹¤. LangGraphëŠ” ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ê°„ë‹¨í•˜ê²Œ
ê´€ë¦¬í•˜ê³  ì„±ëŠ¥ì„ ìµœì í™”í•˜ë©° ì•ˆì •ì ì¸ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ë° í•„ìˆ˜ì ì¸ ë„êµ¬ì…ë‹ˆë‹¤.
--------------------------------------------------------------------------------
```

#### 4.3 ìµœì¢… ìƒíƒœ í™•ì¸

```python
# ìµœì¢… ìƒíƒœ ì¶œë ¥
final_state = step  # ë§ˆì§€ë§‰ stepì´ ìµœì¢… ìƒíƒœ

print("\nìµœì¢… ìƒíƒœ ìš”ì•½:")
print(f"- ì „ì²´ ë¬¸ì„œ ìˆ˜: {len(final_state.get('contents', []))}")
print(f"- ì „ì²´ ì²­í¬ ìˆ˜: {len(final_state.get('chunks', []))}")
print(f"- ì „ì²´ ìš”ì•½ ìˆ˜: {len(final_state.get('summaries', []))}")
print(f"- ìµœì¢… ìš”ì•½ ê¸¸ì´: {len(final_state.get('final_summary', ''))} ë¬¸ì")
```

**ì¶œë ¥:**
```
ìµœì¢… ìƒíƒœ ìš”ì•½:
- ì „ì²´ ë¬¸ì„œ ìˆ˜: 3
- ì „ì²´ ì²­í¬ ìˆ˜: 5
- ì „ì²´ ìš”ì•½ ìˆ˜: 5
- ìµœì¢… ìš”ì•½ ê¸¸ì´: 458 ë¬¸ì
```

## ğŸ¯ ì‹¤ìŠµ ë¬¸ì œ

### ì‹¤ìŠµ 1: ì²­í¬ í¬ê¸° ìµœì í™” (â­â­)

**ë¬¸ì œ:**
ì²­í¬ í¬ê¸°ë¥¼ ì¡°ì •í•˜ì—¬ ìš”ì•½ í’ˆì§ˆì„ ê°œì„ í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
1. 500ì, 1000ì, 2000ì ì„¸ ê°€ì§€ ì²­í¬ í¬ê¸°ë¡œ í…ŒìŠ¤íŠ¸
2. ê° í¬ê¸°ë³„ë¡œ ìƒì„±ë˜ëŠ” ì²­í¬ ìˆ˜ì™€ ìš”ì•½ ì‹œê°„ ë¹„êµ
3. ìµœì ì˜ ì²­í¬ í¬ê¸° ê²°ì •

**íŒíŠ¸:**
- `chunk_size` íŒŒë¼ë¯¸í„° ì¡°ì •
- `time` ëª¨ë“ˆë¡œ ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
- ìš”ì•½ í’ˆì§ˆì€ ìµœì¢… ìš”ì•½ì˜ ì¼ê´€ì„±ìœ¼ë¡œ í‰ê°€

### ì‹¤ìŠµ 2: PDF íŒŒì¼ ì²˜ë¦¬ (â­â­â­)

**ë¬¸ì œ:**
ì‹¤ì œ PDF íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ìš”ì•½ ì‹œìŠ¤í…œìœ¼ë¡œ ì²˜ë¦¬í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
1. PyPDFLoaderë¥¼ ì‚¬ìš©í•˜ì—¬ PDF íŒŒì¼ ë¡œë“œ
2. í˜ì´ì§€ë³„ë¡œ ë©”íƒ€ë°ì´í„° ìœ ì§€
3. ìµœì¢… ìš”ì•½ì— í˜ì´ì§€ ì¶œì²˜ í¬í•¨

**íŒíŠ¸:**
```python
from langchain_community.document_loaders import PyPDFLoader

loader = PyPDFLoader("document.pdf")
documents = loader.load()
```

### ì‹¤ìŠµ 3: ë‹¤ë‹¨ê³„ ìš”ì•½ ì‹œìŠ¤í…œ (â­â­â­â­)

**ë¬¸ì œ:**
2ë‹¨ê³„ ìš”ì•½ ì‹œìŠ¤í…œì„ êµ¬í˜„í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
1. 1ë‹¨ê³„: ì²­í¬ë³„ ìƒì„¸ ìš”ì•½ (3-5ë¬¸ì¥)
2. 2ë‹¨ê³„: ìƒì„¸ ìš”ì•½ë“¤ì„ ë‹¤ì‹œ ì²­í¬ë¡œ ë‚˜ëˆ  ì¤‘ê°„ ìš”ì•½ ìƒì„±
3. 3ë‹¨ê³„: ì¤‘ê°„ ìš”ì•½ë“¤ì„ í†µí•©í•˜ì—¬ ìµœì¢… ìš”ì•½ ìƒì„±

**íŒíŠ¸:**
- ìƒˆë¡œìš´ ë…¸ë“œ `create_intermediate_summary` ì¶”ê°€
- Send ê°ì²´ë¥¼ ë‘ ë²ˆ ì‚¬ìš© (1ë‹¨ê³„ì™€ 2ë‹¨ê³„)
- ìˆœì„œ ìœ ì§€ë¥¼ ìœ„í•œ ì¸ë±ìŠ¤ ê´€ë¦¬

### ì‹¤ìŠµ 4: ì—ëŸ¬ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜ (â­â­â­â­â­)

**ë¬¸ì œ:**
ì¼ë¶€ ì²­í¬ ìš”ì•½ì´ ì‹¤íŒ¨í•´ë„ ì „ì²´ í”„ë¡œì„¸ìŠ¤ê°€ ê³„ì†ë˜ë„ë¡ ê°œì„ í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
1. ì²­í¬ ìš”ì•½ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë¡œì§ (ìµœëŒ€ 3íšŒ)
2. ì¬ì‹œë„ í›„ì—ë„ ì‹¤íŒ¨í•˜ë©´ í•´ë‹¹ ì²­í¬ ìŠ¤í‚µ
3. ìµœì¢… ìš”ì•½ì— ì‹¤íŒ¨í•œ ì²­í¬ ì •ë³´ í¬í•¨
4. ì‹¤íŒ¨ ë¡œê·¸ ê¸°ë¡

**íŒíŠ¸:**
- `try-except`ë¡œ ì—ëŸ¬ ìº¡ì²˜
- ì¬ì‹œë„ ì¹´ìš´í„° ì¶”ê°€
- ì‹¤íŒ¨ ì •ë³´ë¥¼ ìƒíƒœì— ì €ì¥

## âœ… ì†”ë£¨ì…˜ ì˜ˆì‹œ

### ì‹¤ìŠµ 1 ì†”ë£¨ì…˜: ì²­í¬ í¬ê¸° ìµœì í™”

```python
import time

def test_chunk_sizes(documents, chunk_sizes):
    """ë‹¤ì–‘í•œ ì²­í¬ í¬ê¸°ë¡œ í…ŒìŠ¤íŠ¸"""
    results = {}

    for size in chunk_sizes:
        print(f"\n{'='*80}")
        print(f"ì²­í¬ í¬ê¸°: {size}ì í…ŒìŠ¤íŠ¸ ì¤‘...")
        print('='*80)

        # ì²­í¬ í¬ê¸°ë¥¼ íŒŒë¼ë¯¸í„°ë¡œ ë°›ëŠ” ìˆ˜ì •ëœ split_documents í•¨ìˆ˜
        def split_documents_with_size(state: SummarizationState):
            chunks = []
            global_chunk_index = 0

            for doc_index, document in enumerate(state["contents"]):
                content = document.page_content

                for i in range(0, len(content), size):  # ì²­í¬ í¬ê¸° ë™ì  ì„¤ì •
                    chunk_content = content[i:i + size]

                    if chunk_content.strip():
                        chunks.append({
                            "index": global_chunk_index,
                            "content": chunk_content,
                            "source_document": doc_index,
                            "source_metadata": document.metadata
                        })
                        global_chunk_index += 1

            return {"chunks": chunks}

        # ê·¸ë˜í”„ ì¬êµ¬ì„±
        builder = StateGraph(SummarizationState)
        builder.add_node("split_documents", split_documents_with_size)
        builder.add_node("summarize_document", summarize_document)
        builder.add_node("create_final_summary", create_final_summary)

        builder.add_edge(START, "split_documents")
        builder.add_conditional_edges(
            "split_documents",
            continue_to_summarization,
            ["summarize_document"]
        )
        builder.add_edge("summarize_document", "create_final_summary")
        builder.add_edge("create_final_summary", END)

        graph = builder.compile()

        # ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
        start_time = time.time()

        final_state = None
        for step in graph.stream({"contents": documents}, stream_mode="values"):
            final_state = step

        elapsed_time = time.time() - start_time

        # ê²°ê³¼ ì €ì¥
        results[size] = {
            "chunk_count": len(final_state.get("chunks", [])),
            "summary_count": len(final_state.get("summaries", [])),
            "final_summary": final_state.get("final_summary", ""),
            "elapsed_time": elapsed_time
        }

        print(f"ì²­í¬ ìˆ˜: {results[size]['chunk_count']}")
        print(f"ì‹¤í–‰ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
        print(f"ìµœì¢… ìš”ì•½ ê¸¸ì´: {len(results[size]['final_summary'])}ì")

    return results

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
chunk_sizes = [500, 1000, 2000]
results = test_chunk_sizes(documents, chunk_sizes)

# ê²°ê³¼ ë¹„êµ
print("\n" + "="*80)
print("ì²­í¬ í¬ê¸°ë³„ ê²°ê³¼ ë¹„êµ")
print("="*80)
for size, result in results.items():
    print(f"\nì²­í¬ í¬ê¸°: {size}ì")
    print(f"  - ì²­í¬ ìˆ˜: {result['chunk_count']}")
    print(f"  - ì‹¤í–‰ ì‹œê°„: {result['elapsed_time']:.2f}ì´ˆ")
    print(f"  - ìµœì¢… ìš”ì•½ ê¸¸ì´: {len(result['final_summary'])}ì")
```

**ì˜ˆìƒ ì¶œë ¥:**
```
================================================================================
ì²­í¬ í¬ê¸°ë³„ ê²°ê³¼ ë¹„êµ
================================================================================

ì²­í¬ í¬ê¸°: 500ì
  - ì²­í¬ ìˆ˜: 10
  - ì‹¤í–‰ ì‹œê°„: 8.5ì´ˆ
  - ìµœì¢… ìš”ì•½ ê¸¸ì´: 520ì

ì²­í¬ í¬ê¸°: 1000ì
  - ì²­í¬ ìˆ˜: 5
  - ì‹¤í–‰ ì‹œê°„: 5.2ì´ˆ
  - ìµœì¢… ìš”ì•½ ê¸¸ì´: 458ì

ì²­í¬ í¬ê¸°: 2000ì
  - ì²­í¬ ìˆ˜: 3
  - ì‹¤í–‰ ì‹œê°„: 3.8ì´ˆ
  - ìµœì¢… ìš”ì•½ ê¸¸ì´: 385ì
```

**ë¶„ì„:**
- ì²­í¬ê°€ ì‘ì„ìˆ˜ë¡: ë” ë§ì€ ë³‘ë ¬ ì‘ì—…, ë” ê¸´ ì‹¤í–‰ ì‹œê°„, ë” ìƒì„¸í•œ ìš”ì•½
- ì²­í¬ê°€ í´ìˆ˜ë¡: ì ì€ ë³‘ë ¬ ì‘ì—…, ë¹ ë¥¸ ì‹¤í–‰ ì‹œê°„, ê°„ê²°í•œ ìš”ì•½
- **ìµœì  ì²­í¬ í¬ê¸°**: 1000ì (í’ˆì§ˆê³¼ ì„±ëŠ¥ì˜ ê· í˜•)

### ì‹¤ìŠµ 2 ì†”ë£¨ì…˜: PDF íŒŒì¼ ì²˜ë¦¬

```python
from langchain_community.document_loaders import PyPDFLoader

def summarize_pdf(pdf_path: str):
    """PDF íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ìš”ì•½"""
    print(f"PDF ë¡œë“œ ì¤‘: {pdf_path}")

    # PDF ë¡œë”ë¡œ ë¬¸ì„œ ë¡œë“œ
    loader = PyPDFLoader(pdf_path)
    documents = loader.load()

    print(f"ë¡œë“œëœ í˜ì´ì§€ ìˆ˜: {len(documents)}")

    # í˜ì´ì§€ ì •ë³´ ì¶œë ¥
    for i, doc in enumerate(documents[:3]):  # ì²˜ìŒ 3í˜ì´ì§€ë§Œ
        print(f"\ní˜ì´ì§€ {i+1} ë©”íƒ€ë°ì´í„°:")
        print(f"  - source: {doc.metadata.get('source', 'N/A')}")
        print(f"  - page: {doc.metadata.get('page', 'N/A')}")
        print(f"  - ê¸¸ì´: {len(doc.page_content)}ì")

    # ê·¸ë˜í”„ ì‹¤í–‰
    initial_state = {"contents": documents}

    final_state = None
    for step in graph.stream(initial_state, stream_mode="values"):
        if "final_summary" in step:
            final_state = step

    # ìµœì¢… ìš”ì•½ì— í˜ì´ì§€ ì¶œì²˜ ì¶”ê°€
    print("\n" + "="*80)
    print("PDF ë¬¸ì„œ ìš”ì•½")
    print("="*80)
    print(f"íŒŒì¼: {pdf_path}")
    print(f"ì´ í˜ì´ì§€: {len(documents)}")
    print(f"ì²­í¬ ìˆ˜: {len(final_state.get('chunks', []))}")
    print("\nìµœì¢… ìš”ì•½:")
    print(final_state.get("final_summary", "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"))

    return final_state

# ì‹¤í–‰
pdf_result = summarize_pdf("data/sample_document.pdf")
```

**í˜ì´ì§€ ì¶œì²˜ë¥¼ í¬í•¨í•œ ê°œì„ ëœ ìš”ì•½:**

```python
def create_final_summary_with_sources(state: SummarizationState):
    """í˜ì´ì§€ ì¶œì²˜ë¥¼ í¬í•¨í•œ ìµœì¢… ìš”ì•½ ìƒì„±"""
    # ì¸ë±ìŠ¤ë³„ë¡œ ìš”ì•½ì„ ì •ë ¬
    sorted_summaries = sorted(state["summaries"], key=lambda x: x[0])

    # ì²­í¬ë³„ ì¶œì²˜ ì •ë³´ ìˆ˜ì§‘
    chunk_sources = {}
    for chunk in state["chunks"]:
        chunk_sources[chunk["index"]] = chunk["source_metadata"]

    # ìš”ì•½ê³¼ ì¶œì²˜ë¥¼ í•¨ê»˜ ê²°í•©
    summaries_with_sources = []
    for idx, summary in sorted_summaries:
        source_info = chunk_sources.get(idx, {})
        page = source_info.get("page", "Unknown")
        summaries_with_sources.append(f"[í˜ì´ì§€ {page}] {summary}")

    combined_summaries = "\n\n".join(summaries_with_sources)

    prompt = f"""ë‹¤ìŒì€ PDF ë¬¸ì„œë¥¼ í˜ì´ì§€ë³„ë¡œ ìš”ì•½í•œ ë‚´ìš©ë“¤ì…ë‹ˆë‹¤.
    ì´ë“¤ì„ ì¢…í•©í•˜ì—¬ í•˜ë‚˜ì˜ í¬ê´„ì ì¸ ìµœì¢… ìš”ì•½ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
    ì¤‘ìš”í•œ ë‚´ìš©ì—ëŠ” í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ì°¸ì¡°í•´ì£¼ì„¸ìš”:

    {combined_summaries}

    ìµœì¢… ìš”ì•½ (í˜ì´ì§€ ì°¸ì¡° í¬í•¨):
    """

    response = model.invoke(prompt)
    return {"final_summary": response.content}
```

### ì‹¤ìŠµ 3 ì†”ë£¨ì…˜: ë‹¤ë‹¨ê³„ ìš”ì•½ ì‹œìŠ¤í…œ

```python
# ë‹¤ë‹¨ê³„ ìš”ì•½ì„ ìœ„í•œ í™•ì¥ëœ ìƒíƒœ
class MultiStageSummarizationState(TypedDict):
    contents: List[Document]
    chunks: List[Dict[str, Any]]
    detailed_summaries: Annotated[List[Tuple[int, str]], operator.add]  # 1ë‹¨ê³„ ìƒì„¸ ìš”ì•½
    intermediate_chunks: List[Dict[str, Any]]                            # ì¤‘ê°„ ì²­í¬
    intermediate_summaries: Annotated[List[Tuple[int, str]], operator.add]  # 2ë‹¨ê³„ ì¤‘ê°„ ìš”ì•½
    final_summary: str

def create_detailed_summary(state: DocumentState):
    """1ë‹¨ê³„: ì²­í¬ë³„ ìƒì„¸ ìš”ì•½ (3-5ë¬¸ì¥)"""
    prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ 3-5ë¬¸ì¥ìœ¼ë¡œ ìƒì„¸í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.
    ì¤‘ìš”í•œ ì„¸ë¶€ì‚¬í•­ê³¼ í•µì‹¬ ê°œë…ì„ ëª¨ë‘ í¬í•¨í•˜ì„¸ìš”:

    {state['content']}
    """

    response = model.invoke(prompt)
    return {"detailed_summaries": [(state["index"], response.content)]}

def create_intermediate_chunks(state: MultiStageSummarizationState):
    """ìƒì„¸ ìš”ì•½ë“¤ì„ ë‹¤ì‹œ ì²­í¬ë¡œ ë¶„í• """
    # ìƒì„¸ ìš”ì•½ë“¤ì„ ì •ë ¬
    sorted_summaries = sorted(state["detailed_summaries"], key=lambda x: x[0])

    # ìƒì„¸ ìš”ì•½ë“¤ì„ ê²°í•©
    all_summaries = "\n\n".join([s for _, s in sorted_summaries])

    # ì¤‘ê°„ ì²­í¬ë¡œ ë¶„í•  (ì²­í¬ í¬ê¸°: 1500ì)
    chunk_size = 1500
    intermediate_chunks = []

    for i in range(0, len(all_summaries), chunk_size):
        chunk_content = all_summaries[i:i + chunk_size]
        if chunk_content.strip():
            intermediate_chunks.append({
                "index": len(intermediate_chunks),
                "content": chunk_content
            })

    return {"intermediate_chunks": intermediate_chunks}

def create_intermediate_summary(state: DocumentState):
    """2ë‹¨ê³„: ì¤‘ê°„ ìš”ì•½ ìƒì„±"""
    prompt = f"""ë‹¤ìŒì€ ë¬¸ì„œì˜ ìƒì„¸ ìš”ì•½ë“¤ì…ë‹ˆë‹¤.
    ì´ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ì••ì¶•í•˜ì—¬ í•µì‹¬ë§Œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

    {state['content']}
    """

    response = model.invoke(prompt)
    return {"intermediate_summaries": [(state["index"], response.content)]}

def continue_to_intermediate_summarization(state: MultiStageSummarizationState):
    """ì¤‘ê°„ ìš”ì•½ì„ ìœ„í•œ Send ìƒì„±"""
    return [
        Send("create_intermediate_summary", {
            "content": chunk["content"],
            "index": chunk["index"]
        })
        for chunk in state["intermediate_chunks"]
    ]

def create_final_summary_multistage(state: MultiStageSummarizationState):
    """3ë‹¨ê³„: ìµœì¢… ìš”ì•½ ìƒì„±"""
    # ì¤‘ê°„ ìš”ì•½ë“¤ì„ ì •ë ¬í•˜ê³  ê²°í•©
    sorted_summaries = sorted(state["intermediate_summaries"], key=lambda x: x[0])
    combined_summaries = "\n\n".join([s for _, s in sorted_summaries])

    prompt = f"""ë‹¤ìŒì€ ë¬¸ì„œì˜ ì¤‘ê°„ ìš”ì•½ë“¤ì…ë‹ˆë‹¤.
    ì´ë“¤ì„ ì¢…í•©í•˜ì—¬ í¬ê´„ì ì´ê³  ì¼ê´€ì„± ìˆëŠ” ìµœì¢… ìš”ì•½ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

    {combined_summaries}

    ìµœì¢… ìš”ì•½:
    """

    response = model.invoke(prompt)
    return {"final_summary": response.content}

# ë‹¤ë‹¨ê³„ ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(MultiStageSummarizationState)

# ë…¸ë“œ ì¶”ê°€
builder.add_node("split_documents", split_documents)
builder.add_node("create_detailed_summary", create_detailed_summary)
builder.add_node("create_intermediate_chunks", create_intermediate_chunks)
builder.add_node("create_intermediate_summary", create_intermediate_summary)
builder.add_node("create_final_summary", create_final_summary_multistage)

# ì—£ì§€ ì—°ê²°
builder.add_edge(START, "split_documents")
builder.add_conditional_edges(
    "split_documents",
    continue_to_summarization,
    ["create_detailed_summary"]
)
builder.add_edge("create_detailed_summary", "create_intermediate_chunks")
builder.add_conditional_edges(
    "create_intermediate_chunks",
    continue_to_intermediate_summarization,
    ["create_intermediate_summary"]
)
builder.add_edge("create_intermediate_summary", "create_final_summary")
builder.add_edge("create_final_summary", END)

# ì»´íŒŒì¼ ë° ì‹¤í–‰
multistage_graph = builder.compile()

# ì‹¤í–‰
result = multistage_graph.invoke({"contents": documents})

print("="*80)
print("ë‹¤ë‹¨ê³„ ìš”ì•½ ê²°ê³¼")
print("="*80)
print(f"1ë‹¨ê³„ ìƒì„¸ ìš”ì•½ ìˆ˜: {len(result['detailed_summaries'])}")
print(f"2ë‹¨ê³„ ì¤‘ê°„ ì²­í¬ ìˆ˜: {len(result['intermediate_chunks'])}")
print(f"2ë‹¨ê³„ ì¤‘ê°„ ìš”ì•½ ìˆ˜: {len(result['intermediate_summaries'])}")
print(f"\nìµœì¢… ìš”ì•½:\n{result['final_summary']}")
```

**ë‹¤ë‹¨ê³„ ìš”ì•½ì˜ ì¥ì :**
- âœ… ë” ì •í™•í•œ ìš”ì•½ (ë‹¨ê³„ë³„ ì •ì œ)
- âœ… ê¸´ ë¬¸ì„œì— íš¨ê³¼ì  (ê³„ì¸µì  ì²˜ë¦¬)
- âœ… ì„¸ë¶€ì‚¬í•­ ë³´ì¡´ (1ë‹¨ê³„ ìƒì„¸ ìš”ì•½)
- âœ… ì¼ê´€ì„± í–¥ìƒ (2ë‹¨ê³„ í†µí•©)

### ì‹¤ìŠµ 4 ì†”ë£¨ì…˜: ì—ëŸ¬ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜

```python
# ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ìƒíƒœ
class ResilientSummarizationState(TypedDict):
    contents: List[Document]
    chunks: List[Dict[str, Any]]
    summaries: Annotated[List[Tuple[int, str]], operator.add]
    failed_chunks: List[Dict[str, Any]]  # ì‹¤íŒ¨í•œ ì²­í¬ ì •ë³´
    final_summary: str

class DocumentStateWithRetry(TypedDict):
    content: str
    index: int
    retry_count: int  # ì¬ì‹œë„ íšŸìˆ˜

def summarize_document_with_retry(state: DocumentStateWithRetry):
    """ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ìš”ì•½ í•¨ìˆ˜"""
    max_retries = 3
    retry_count = state.get("retry_count", 0)

    prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:

    {state['content']}
    """

    try:
        # LLM í˜¸ì¶œ ì‹œë„
        response = model.invoke(prompt)
        summary = response.content

        # ì„±ê³µ ì‹œ ìš”ì•½ ë°˜í™˜
        return {"summaries": [(state["index"], summary)]}

    except Exception as e:
        print(f"âš ï¸ ì²­í¬ {state['index']} ìš”ì•½ ì‹¤íŒ¨ (ì‹œë„ {retry_count + 1}/{max_retries}): {str(e)}")

        # ì¬ì‹œë„ ê°€ëŠ¥í•˜ë©´ ì¬ì‹œë„
        if retry_count < max_retries - 1:
            import time
            time.sleep(1)  # 1ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„

            # ì¬ì‹œë„ ì¹´ìš´í„° ì¦ê°€í•˜ì—¬ ì¬ê·€ í˜¸ì¶œ
            return summarize_document_with_retry({
                "content": state["content"],
                "index": state["index"],
                "retry_count": retry_count + 1
            })
        else:
            # ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼ ì‹œ ì‹¤íŒ¨ ì²˜ë¦¬
            print(f"âŒ ì²­í¬ {state['index']} ìš”ì•½ ìµœì¢… ì‹¤íŒ¨")

            # ì‹¤íŒ¨ ì •ë³´ë¥¼ ë³„ë„ë¡œ ê¸°ë¡
            failed_info = {
                "index": state["index"],
                "error": str(e),
                "retry_count": retry_count + 1
            }

            # ì‹¤íŒ¨í•œ ì²­í¬ëŠ” ê¸°ë³¸ ë©”ì‹œì§€ë¡œ ëŒ€ì²´
            return {
                "summaries": [(state["index"], f"[ìš”ì•½ ì‹¤íŒ¨: ì²­í¬ {state['index']}]")],
                "failed_chunks": [failed_info]
            }

def create_final_summary_resilient(state: ResilientSummarizationState):
    """ì‹¤íŒ¨ ì •ë³´ë¥¼ í¬í•¨í•œ ìµœì¢… ìš”ì•½ ìƒì„±"""
    # ìš”ì•½ ì •ë ¬
    sorted_summaries = sorted(state["summaries"], key=lambda x: x[0])
    ordered_summaries = [summary for _, summary in sorted_summaries]
    combined_summaries = "\n\n".join(ordered_summaries)

    # ì‹¤íŒ¨í•œ ì²­í¬ ì •ë³´
    failed_chunks = state.get("failed_chunks", [])
    failed_info = ""
    if failed_chunks:
        failed_indices = [chunk["index"] for chunk in failed_chunks]
        failed_info = f"\n\nâš ï¸ ì£¼ì˜: ì²­í¬ {failed_indices}ì˜ ìš”ì•½ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

    prompt = f"""ë‹¤ìŒì€ ë¬¸ì„œë¥¼ ì²­í¬ë³„ë¡œ ìš”ì•½í•œ ë‚´ìš©ë“¤ì…ë‹ˆë‹¤.
    ì´ë“¤ì„ ì¢…í•©í•˜ì—¬ í•˜ë‚˜ì˜ í¬ê´„ì ì¸ ìµœì¢… ìš”ì•½ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

    {combined_summaries}
    {failed_info}

    ìµœì¢… ìš”ì•½:
    """

    try:
        response = model.invoke(prompt)
        final_summary = response.content

        # ì‹¤íŒ¨ ì •ë³´ ì¶”ê°€
        if failed_chunks:
            final_summary += f"\n\nâš ï¸ ì¼ë¶€ ì²­í¬({len(failed_chunks)}ê°œ)ì˜ ìš”ì•½ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

        return {"final_summary": final_summary}

    except Exception as e:
        return {"final_summary": f"ìµœì¢… ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {str(e)}"}

# ë³µì›ë ¥ ìˆëŠ” ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(ResilientSummarizationState)
builder.add_node("split_documents", split_documents)
builder.add_node("summarize_document", summarize_document_with_retry)
builder.add_node("create_final_summary", create_final_summary_resilient)

builder.add_edge(START, "split_documents")
builder.add_conditional_edges(
    "split_documents",
    continue_to_summarization,
    ["summarize_document"]
)
builder.add_edge("summarize_document", "create_final_summary")
builder.add_edge("create_final_summary", END)

resilient_graph = builder.compile()

# ì‹¤í–‰
result = resilient_graph.invoke({"contents": documents})

print("="*80)
print("ë³µì›ë ¥ ìˆëŠ” ìš”ì•½ ì‹œìŠ¤í…œ ê²°ê³¼")
print("="*80)
print(f"ì„±ê³µí•œ ìš”ì•½ ìˆ˜: {len(result['summaries']) - len(result.get('failed_chunks', []))}")
print(f"ì‹¤íŒ¨í•œ ì²­í¬ ìˆ˜: {len(result.get('failed_chunks', []))}")
print(f"\nìµœì¢… ìš”ì•½:\n{result['final_summary']}")
```

**ì—ëŸ¬ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜ì˜ ì¥ì :**
- âœ… ì¼ì‹œì  ì˜¤ë¥˜ ë³µêµ¬ (ë„¤íŠ¸ì›Œí¬ ì´ìŠˆ ë“±)
- âœ… ë¶€ë¶„ ì‹¤íŒ¨ í—ˆìš© (ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì¤‘ë‹¨ ë°©ì§€)
- âœ… ì‹¤íŒ¨ ì¶”ì  (ë¬¸ì œ ë””ë²„ê¹… ìš©ì´)
- âœ… ì‚¬ìš©ì í”¼ë“œë°± (ì‹¤íŒ¨ ì •ë³´ ëª…ì‹œ)

## ğŸš€ ì‹¤ë¬´ í™œìš© ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ëŒ€ìš©ëŸ‰ ë²•ë¥  ë¬¸ì„œ ìš”ì•½ ì‹œìŠ¤í…œ

```python
from langchain_community.document_loaders import PyPDFLoader
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class LegalDocumentSummarizer:
    """ë²•ë¥  ë¬¸ì„œ ì „ìš© ìš”ì•½ ì‹œìŠ¤í…œ"""

    def __init__(self, model_name="gpt-4o-mini"):
        self.model = ChatOpenAI(model=model_name, temperature=0)
        self.graph = self._build_graph()

    def _build_graph(self):
        """ë²•ë¥  ë¬¸ì„œìš© ì»¤ìŠ¤í„°ë§ˆì´ì§•ëœ ê·¸ë˜í”„ êµ¬ì„±"""
        builder = StateGraph(SummarizationState)

        # ë²•ë¥  ë¬¸ì„œ ì „ìš© ìš”ì•½ í•¨ìˆ˜
        def summarize_legal_chunk(state: DocumentState):
            prompt = f"""ë‹¤ìŒ ë²•ë¥  ë¬¸ì„œì˜ ë‚´ìš©ì„ ì „ë¬¸ì ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.

            ìš”ì•½ ì‹œ í¬í•¨í•´ì•¼ í•  ì‚¬í•­:
            - ì£¼ìš” ë²•ì  ì¡°í•­
            - ê¶Œë¦¬ì™€ ì˜ë¬´
            - ì¤‘ìš”í•œ ë‚ ì§œì™€ ê¸°í•œ
            - ë²•ì  ìš©ì–´ ì„¤ëª…

            í…ìŠ¤íŠ¸:
            {state['content']}

            ì „ë¬¸ì ì¸ ë²•ë¥  ìš”ì•½:
            """

            try:
                response = self.model.invoke(prompt)
                return {"summaries": [(state["index"], response.content)]}
            except Exception as e:
                logger.error(f"ì²­í¬ {state['index']} ìš”ì•½ ì‹¤íŒ¨: {e}")
                return {"summaries": [(state["index"], f"[ìš”ì•½ ì‹¤íŒ¨: {str(e)}]")]}

        # ë…¸ë“œ ì¶”ê°€
        builder.add_node("split_documents", split_documents)
        builder.add_node("summarize_document", summarize_legal_chunk)
        builder.add_node("create_final_summary", self._create_legal_final_summary)

        # ì—£ì§€ ì—°ê²°
        builder.add_edge(START, "split_documents")
        builder.add_conditional_edges(
            "split_documents",
            continue_to_summarization,
            ["summarize_document"]
        )
        builder.add_edge("summarize_document", "create_final_summary")
        builder.add_edge("create_final_summary", END)

        return builder.compile()

    def _create_legal_final_summary(self, state: SummarizationState):
        """ë²•ë¥  ë¬¸ì„œ ì „ìš© ìµœì¢… ìš”ì•½"""
        sorted_summaries = sorted(state["summaries"], key=lambda x: x[0])
        ordered_summaries = [summary for _, summary in sorted_summaries]
        combined_summaries = "\n\n".join(ordered_summaries)

        prompt = f"""ë‹¤ìŒì€ ë²•ë¥  ë¬¸ì„œë¥¼ ë¶€ë¶„ë³„ë¡œ ìš”ì•½í•œ ë‚´ìš©ì…ë‹ˆë‹¤.
        ì´ë¥¼ ì¢…í•©í•˜ì—¬ ë²•ë¥  ì „ë¬¸ê°€ë¥¼ ìœ„í•œ í¬ê´„ì ì¸ ìš”ì•½ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

        í¬í•¨ ì‚¬í•­:
        1. ë¬¸ì„œì˜ ì£¼ìš” ëª©ì ê³¼ ë²”ìœ„
        2. í•µì‹¬ ë²•ì  ì¡°í•­ ë° ì˜ë¬´ì‚¬í•­
        3. ì¤‘ìš” ë‚ ì§œ ë° ê¸°í•œ
        4. ì£¼ì˜ì‚¬í•­ ë° ë²•ì  ìœ„í—˜ ìš”ì†Œ

        ë¶€ë¶„ë³„ ìš”ì•½:
        {combined_summaries}

        ## ë²•ë¥  ë¬¸ì„œ ì¢…í•© ìš”ì•½
        """

        try:
            response = self.model.invoke(prompt)
            return {"final_summary": response.content}
        except Exception as e:
            logger.error(f"ìµœì¢… ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return {"final_summary": f"ìµœì¢… ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {str(e)}"}

    def summarize_pdf(self, pdf_path: str):
        """PDF ë²•ë¥  ë¬¸ì„œ ìš”ì•½"""
        logger.info(f"ë²•ë¥  ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘: {pdf_path}")

        # PDF ë¡œë“œ
        loader = PyPDFLoader(pdf_path)
        documents = loader.load()

        logger.info(f"ë¡œë“œëœ í˜ì´ì§€ ìˆ˜: {len(documents)}")

        # ê·¸ë˜í”„ ì‹¤í–‰
        result = self.graph.invoke({"contents": documents})

        logger.info("ìš”ì•½ ì™„ë£Œ")

        return {
            "file": pdf_path,
            "pages": len(documents),
            "chunks": len(result.get("chunks", [])),
            "summary": result.get("final_summary", "")
        }

# ì‚¬ìš© ì˜ˆì‹œ
summarizer = LegalDocumentSummarizer()

# ì—¬ëŸ¬ ë²•ë¥  ë¬¸ì„œ ì²˜ë¦¬
legal_docs = [
    "contracts/service_agreement.pdf",
    "contracts/nda.pdf",
    "contracts/employment_contract.pdf"
]

for doc_path in legal_docs:
    result = summarizer.summarize_pdf(doc_path)

    print(f"\n{'='*80}")
    print(f"íŒŒì¼: {result['file']}")
    print(f"í˜ì´ì§€: {result['pages']}, ì²­í¬: {result['chunks']}")
    print('='*80)
    print(result['summary'])
    print('='*80)
```

### ì˜ˆì‹œ 2: ë‹¤êµ­ì–´ ë¬¸ì„œ ìš”ì•½ ì‹œìŠ¤í…œ

```python
from langchain_community.document_loaders import UnstructuredFileLoader

class MultilingualDocumentSummarizer:
    """ë‹¤êµ­ì–´ ë¬¸ì„œ ìš”ì•½ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.model = ChatOpenAI(model="gpt-4o-mini", temperature=0)
        self.supported_languages = {
            "ko": "í•œêµ­ì–´",
            "en": "ì˜ì–´",
            "ja": "ì¼ë³¸ì–´",
            "zh": "ì¤‘êµ­ì–´"
        }

    def detect_language(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì–¸ì–´ ê°ì§€"""
        prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ê°ì§€í•˜ê³  ì–¸ì–´ ì½”ë“œë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš”.
        (ko, en, ja, zh ì¤‘ í•˜ë‚˜)

        í…ìŠ¤íŠ¸: {text[:200]}

        ì–¸ì–´ ì½”ë“œ:
        """

        response = self.model.invoke(prompt)
        lang_code = response.content.strip().lower()
        return lang_code if lang_code in self.supported_languages else "en"

    def summarize_multilingual_chunk(self, content: str, index: int, target_lang: str = "ko"):
        """ë‹¤êµ­ì–´ ì²­í¬ ìš”ì•½ (ëª©í‘œ ì–¸ì–´ë¡œ ë³€í™˜)"""
        # ì›ë³¸ ì–¸ì–´ ê°ì§€
        source_lang = self.detect_language(content)

        prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•˜ê³  {self.supported_languages[target_lang]}ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”.

        ì›ë³¸ ì–¸ì–´: {self.supported_languages.get(source_lang, 'ì•Œ ìˆ˜ ì—†ìŒ')}
        ëª©í‘œ ì–¸ì–´: {self.supported_languages[target_lang]}

        í…ìŠ¤íŠ¸:
        {content}

        {self.supported_languages[target_lang]} ìš”ì•½:
        """

        try:
            response = self.model.invoke(prompt)
            return {
                "summaries": [(index, response.content)],
                "language": source_lang
            }
        except Exception as e:
            return {
                "summaries": [(index, f"[ìš”ì•½ ì‹¤íŒ¨: {str(e)}]")],
                "language": "unknown"
            }

    def process_document(self, file_path: str, target_lang: str = "ko"):
        """ë‹¤êµ­ì–´ ë¬¸ì„œ ì²˜ë¦¬"""
        # íŒŒì¼ ë¡œë“œ
        loader = UnstructuredFileLoader(file_path)
        documents = loader.load()

        print(f"ì²˜ë¦¬ ì¤‘: {file_path}")
        print(f"ëª©í‘œ ì–¸ì–´: {self.supported_languages[target_lang]}")

        # ë¬¸ì„œë³„ ì–¸ì–´ ê°ì§€
        detected_languages = []
        for doc in documents:
            lang = self.detect_language(doc.page_content)
            detected_languages.append(lang)

        print(f"ê°ì§€ëœ ì–¸ì–´: {set(detected_languages)}")

        # ì²­í¬ ë¶„í•  ë° ìš”ì•½
        all_summaries = []
        for i, doc in enumerate(documents):
            result = self.summarize_multilingual_chunk(
                doc.page_content,
                i,
                target_lang
            )
            all_summaries.extend(result["summaries"])

        # ìµœì¢… ìš”ì•½ í†µí•©
        sorted_summaries = sorted(all_summaries, key=lambda x: x[0])
        combined = "\n\n".join([s for _, s in sorted_summaries])

        final_prompt = f"""ë‹¤ìŒì€ ë‹¤êµ­ì–´ ë¬¸ì„œë¥¼ {self.supported_languages[target_lang]}ë¡œ ìš”ì•½í•œ ë‚´ìš©ë“¤ì…ë‹ˆë‹¤.
        ì´ë¥¼ í•˜ë‚˜ì˜ ì¼ê´€ì„± ìˆëŠ” {self.supported_languages[target_lang]} ìš”ì•½ìœ¼ë¡œ í†µí•©í•´ì£¼ì„¸ìš”:

        {combined}

        ìµœì¢… {self.supported_languages[target_lang]} ìš”ì•½:
        """

        final_response = self.model.invoke(final_prompt)

        return {
            "file": file_path,
            "source_languages": list(set(detected_languages)),
            "target_language": target_lang,
            "final_summary": final_response.content
        }

# ì‚¬ìš© ì˜ˆì‹œ
multilingual_summarizer = MultilingualDocumentSummarizer()

# ë‹¤ì–‘í•œ ì–¸ì–´ì˜ ë¬¸ì„œ ì²˜ë¦¬
documents = [
    {"file": "docs/english_report.pdf", "target": "ko"},
    {"file": "docs/japanese_manual.pdf", "target": "ko"},
    {"file": "docs/korean_contract.pdf", "target": "en"}
]

for doc_info in documents:
    result = multilingual_summarizer.process_document(
        doc_info["file"],
        doc_info["target"]
    )

    print(f"\n{'='*80}")
    print(f"íŒŒì¼: {result['file']}")
    print(f"ì›ë³¸ ì–¸ì–´: {result['source_languages']}")
    print(f"ëª©í‘œ ì–¸ì–´: {result['target_language']}")
    print('='*80)
    print(result['final_summary'])
```

## ğŸ“– ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [LangGraph ê³µì‹ ë¬¸ì„œ](https://langchain-ai.github.io/langgraph/)
- [LangGraph Send ê°ì²´](https://langchain-ai.github.io/langgraph/concepts/low_level/#send)
- [StateGraph API](https://langchain-ai.github.io/langgraph/reference/graphs/)
- [LangChain Document Loaders](https://python.langchain.com/docs/modules/data_connection/document_loaders/)

### Send íŒ¨í„´ ê´€ë ¨
- [Map-Reduce íŒ¨í„´](https://langchain-ai.github.io/langgraph/how-tos/map-reduce/)
- [ë³‘ë ¬ ì²˜ë¦¬ ê°€ì´ë“œ](https://langchain-ai.github.io/langgraph/how-tos/branching/)
- [ë™ì  ê·¸ë˜í”„ êµ¬ì„±](https://langchain-ai.github.io/langgraph/how-tos/dynamic-breakpoints/)

### ë¬¸ì„œ ì²˜ë¦¬
- [PDF ì²˜ë¦¬ ê°€ì´ë“œ](https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf)
- [í…ìŠ¤íŠ¸ ë¶„í•  ì „ëµ](https://python.langchain.com/docs/modules/data_connection/document_transformers/)
- [ë¬¸ì„œ ìš”ì•½ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤](https://python.langchain.com/docs/use_cases/summarization)

### ì¶”ê°€ í•™ìŠµ ìë£Œ
- [LangGraph íŠœí† ë¦¬ì–¼](https://github.com/langchain-ai/langgraph/tree/main/examples)
- [ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”](https://docs.python.org/3/library/concurrent.futures.html)
- [LangChain Expression Language (LCEL)](https://python.langchain.com/docs/expression_language/)
