# LangGraph í™œìš© - ReAct ì—ì´ì „íŠ¸

## ğŸ“š í•™ìŠµ ëª©í‘œ

ì´ ê°€ì´ë“œë¥¼ ì™„ë£Œí•˜ë©´ ë‹¤ìŒì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- **ReAct ì—ì´ì „íŠ¸ íŒ¨í„´**ì„ ì´í•´í•˜ê³  LangGraphì—ì„œ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤
- **@tool ë°ì½”ë ˆì´í„°**ë¥¼ ì‚¬ìš©í•˜ì—¬ ì»¤ìŠ¤í…€ ë„êµ¬ë¥¼ ì •ì˜í•˜ê³  LLMì— ë°”ì¸ë”©í•  ìˆ˜ ìˆë‹¤
- **ToolNode**ë¥¼ í™œìš©í•˜ì—¬ ë„êµ¬ í˜¸ì¶œì„ ìë™ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆë‹¤
- **ì¡°ê±´ë¶€ ì—£ì§€**ë¥¼ êµ¬í˜„í•˜ì—¬ ì—ì´ì „íŠ¸ì˜ ë„êµ¬ ì‚¬ìš© íë¦„ì„ ì œì–´í•  ìˆ˜ ìˆë‹¤
- **ë‹¤êµ­ì–´ RAG ì‹œìŠ¤í…œ**ì—ì„œ ReAct íŒ¨í„´ì„ ì ìš©í•˜ì—¬ ì–¸ì–´ë³„ ë¼ìš°íŒ…ì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤

## ğŸ”‘ í•µì‹¬ ê°œë…

### ReAct íŒ¨í„´ì´ë€?

**ReAct (Reasoning and Acting)**ì€ ê°€ì¥ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ë¡œ, LLMì´ ë‹¤ìŒ ì„¸ ë‹¨ê³„ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤:

1. **Reasoning (ì¶”ë¡ )**: ì£¼ì–´ì§„ ì§ˆë¬¸ê³¼ ì´ì „ ê´€ì°°ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í–‰ë™ì„ ê²°ì •
2. **Acting (í–‰ë™)**: íŠ¹ì • ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì—¬ ì •ë³´ë¥¼ ìˆ˜ì§‘
3. **Observing (ê´€ì°°)**: ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°›ì•„ ë‹¤ìŒ ì¶”ë¡ ì— í™œìš©

```
ì‚¬ìš©ì ì§ˆë¬¸
    â†“
[Reasoning] â†’ ì–´ë–¤ ë„êµ¬ë¥¼ ì‚¬ìš©í• ì§€ ê²°ì •
    â†“
[Acting] â†’ ë„êµ¬ í˜¸ì¶œ ì‹¤í–‰
    â†“
[Observing] â†’ ë„êµ¬ ê²°ê³¼ í™•ì¸
    â†“
[Reasoning] â†’ ê²°ê³¼ê°€ ì¶©ë¶„í•œê°€?
    â”œâ”€ ì˜ˆ â†’ ìµœì¢… ë‹µë³€ ìƒì„±
    â””â”€ ì•„ë‹ˆì˜¤ â†’ ë‹¤ì‹œ Acting ë‹¨ê³„ë¡œ
```

### LangChain Tool System

LangChainì€ LLMì´ ì™¸ë¶€ ê¸°ëŠ¥ì„ í˜¸ì¶œí•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë„êµ¬(Tool) ì‹œìŠ¤í…œì„ ì œê³µí•©ë‹ˆë‹¤:

**ë„êµ¬ì˜ 3ê°€ì§€ í•µì‹¬ ì†ì„±**:
- `name`: ë„êµ¬ì˜ ê³ ìœ  ì´ë¦„
- `description`: ë„êµ¬ì˜ ê¸°ëŠ¥ ì„¤ëª… (LLMì´ ì´ë¥¼ ë³´ê³  ë„êµ¬ ì„ íƒ)
- `args_schema`: ë„êµ¬ê°€ ë°›ëŠ” ë§¤ê°œë³€ìˆ˜ì˜ ìŠ¤í‚¤ë§ˆ

**ë„êµ¬ ì •ì˜ ë°©ë²•**:
1. `@tool` ë°ì½”ë ˆì´í„° (ê°„ë‹¨í•œ í•¨ìˆ˜í˜•)
2. `StructuredTool` í´ë˜ìŠ¤ (ë³µì¡í•œ ë„êµ¬)
3. LangChain ë‚´ì¥ ë„êµ¬ (`TavilySearchResults`, `ArxivQueryRun` ë“±)

### ToolNodeì˜ ì—­í• 

**ToolNode**ëŠ” LangGraphì˜ ì‚¬ì „ êµ¬ì¶•ëœ ì»´í¬ë„ŒíŠ¸ë¡œ, AI ëª¨ë¸ì´ ìš”ì²­í•œ ë„êµ¬ í˜¸ì¶œì„ ìë™ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.

**ì‘ë™ ë°©ì‹**:
1. ê°€ì¥ ìµœê·¼ `AIMessage`ì—ì„œ `tool_calls` ì¶”ì¶œ
2. ìš”ì²­ëœ ëª¨ë“  ë„êµ¬ë¥¼ **ë³‘ë ¬ë¡œ** ì‹¤í–‰
3. ê° ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ë¥¼ `ToolMessage`ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜

```python
from langgraph.prebuilt import ToolNode

# ë„êµ¬ ë…¸ë“œ ìƒì„±
tool_node = ToolNode(tools=[search_tool, calculator_tool])

# AIMessageì˜ tool_callsë¥¼ ìë™ìœ¼ë¡œ ì‹¤í–‰
results = tool_node.invoke({"messages": [ai_message]})
# â†’ {'messages': [ToolMessage(...), ToolMessage(...)]}
```

### ì¡°ê±´ë¶€ ì—£ì§€ì™€ ë„êµ¬ ë¼ìš°íŒ…

ReAct ì—ì´ì „íŠ¸ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì€ **"ë„êµ¬ë¥¼ ë” í˜¸ì¶œí•  ê²ƒì¸ê°€, ë‹µë³€ì„ ìƒì„±í•  ê²ƒì¸ê°€"**ë¥¼ ê²°ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

**ë°©ë²• 1: ì‚¬ìš©ì ì •ì˜ ì¡°ê±´ í•¨ìˆ˜**
```python
def should_continue(state: GraphState):
    last_message = state["messages"][-1]
    if last_message.tool_calls:  # ë„êµ¬ í˜¸ì¶œì´ ìˆìœ¼ë©´
        return "execute_tools"
    return END  # ì—†ìœ¼ë©´ ì¢…ë£Œ
```

**ë°©ë²• 2: LangGraph ë‚´ì¥ `tools_condition`**
```python
from langgraph.prebuilt import tools_condition

# tools_conditionì´ ìë™ìœ¼ë¡œ íŒë‹¨
builder.add_conditional_edges("agent", tools_condition)
```

`tools_condition`ì˜ ì¥ì :
- ë³„ë„ í•¨ìˆ˜ ì‘ì„± ë¶ˆí•„ìš”
- ë„êµ¬ í˜¸ì¶œ ìœ ë¬´ë¥¼ ìë™ìœ¼ë¡œ íŒë‹¨
- `END` ë˜ëŠ” `"tools"` ë…¸ë“œë¡œ ìë™ ë¼ìš°íŒ…

## ğŸ›  í™˜ê²½ ì„¤ì •

### í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

```bash
pip install langchain langchain-openai langchain-community langchain-chroma
pip install langgraph
pip install python-dotenv
pip install tavily-python  # ì›¹ ê²€ìƒ‰ ë„êµ¬ìš©
```

### API í‚¤ ì„¤ì •

`.env` íŒŒì¼ì„ ìƒì„±í•˜ê³  ë‹¤ìŒ ë‚´ìš©ì„ ì¶”ê°€í•©ë‹ˆë‹¤:

```
OPENAI_API_KEY=your_openai_api_key_here
TAVILY_API_KEY=your_tavily_api_key_here  # ì›¹ ê²€ìƒ‰ ì‚¬ìš© ì‹œ
```

### ê¸°ë³¸ ì„¤ì • ì½”ë“œ

```python
from dotenv import load_dotenv
import os

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
from pprint import pprint
import json

# LangChain ë° LangGraph
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.tools import tool
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_core.documents import Document
from langgraph.graph import MessagesState, StateGraph, START, END
from langgraph.prebuilt import ToolNode, tools_condition
from typing import List, Literal

print("í™˜ê²½ ì„¤ì • ì™„ë£Œ!")
```

## ğŸ’» ë‹¨ê³„ë³„ êµ¬í˜„

### 1ë‹¨ê³„: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¤€ë¹„

ReAct ì—ì´ì „íŠ¸ê°€ ì‚¬ìš©í•  ì§€ì‹ ë² ì´ìŠ¤ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤. ì´ ì˜ˆì œì—ì„œëŠ” ë ˆìŠ¤í† ë‘ ë©”ë‰´ì™€ ì™€ì¸ ì •ë³´ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.

```python
from langchain_classic.document_loaders import TextLoader
from langchain_text_splitters import CharacterTextSplitter
import re

# ë©”ë‰´ ë°ì´í„° ë¡œë“œ
loader = TextLoader("./data/restaurant_menu.txt", encoding="utf-8")
documents = loader.load()

# ë©”ë‰´ í•­ëª©ë³„ë¡œ ë¶„í• í•˜ëŠ” í•¨ìˆ˜
def split_menu_items(document):
    """ë©”ë‰´ í•­ëª©ì„ ê°œë³„ Document ê°ì²´ë¡œ ë¶„ë¦¬"""
    pattern = r'(\d+\.\s.*?)(?=\n\n\d+\.|$)'
    menu_items = re.findall(pattern, document.page_content, re.DOTALL)

    menu_documents = []
    for i, item in enumerate(menu_items, 1):
        menu_name = item.split('\n')[0].split('.', 1)[1].strip()

        menu_doc = Document(
            page_content=item.strip(),
            metadata={
                "source": document.metadata['source'],
                "menu_number": i,
                "menu_name": menu_name
            }
        )
        menu_documents.append(menu_doc)

    return menu_documents

# ë©”ë‰´ ë¬¸ì„œ ë¶„í• 
menu_documents = []
for doc in documents:
    menu_documents += split_menu_items(doc)

print(f"ì´ {len(menu_documents)}ê°œì˜ ë©”ë‰´ í•­ëª© ìƒì„±ë¨")

# ì™€ì¸ ë°ì´í„°ë„ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
wine_loader = TextLoader("./data/restaurant_wine.txt", encoding="utf-8")
wine_docs = wine_loader.load()
wine_documents = []
for doc in wine_docs:
    wine_documents += split_menu_items(doc)

print(f"ì´ {len(wine_documents)}ê°œì˜ ì™€ì¸ í•­ëª© ìƒì„±ë¨")
```

**ë²¡í„°ìŠ¤í† ì–´ì— ì €ì¥**:

```python
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings

# ì„ë² ë”© ëª¨ë¸ ìƒì„±
embeddings_model = OpenAIEmbeddings(model="text-embedding-3-small")

# ë©”ë‰´ DB ìƒì„±
menu_db = Chroma.from_documents(
    documents=menu_documents,
    embedding=embeddings_model,
    collection_name="restaurant_menu",
    persist_directory="./chroma_db"
)

# ì™€ì¸ DB ìƒì„±
wine_db = Chroma.from_documents(
    documents=wine_documents,
    embedding=embeddings_model,
    collection_name="restaurant_wine",
    persist_directory="./chroma_db"
)

print("ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ!")
```

**ê²€ìƒ‰ í…ŒìŠ¤íŠ¸**:

```python
# ë©”ë‰´ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
menu_retriever = menu_db.as_retriever(search_kwargs={'k': 2})
query = "ì‹œê·¸ë‹ˆì²˜ ìŠ¤í…Œì´í¬ì˜ ê°€ê²©ì€?"
docs = menu_retriever.invoke(query)

print(f"ê²€ìƒ‰ ê²°ê³¼: {len(docs)}ê°œ")
for doc in docs:
    print(f"- {doc.metadata['menu_name']}")
```

### 2ë‹¨ê³„: ì»¤ìŠ¤í…€ ë„êµ¬ ì •ì˜ (@tool ë°ì½”ë ˆì´í„°)

`@tool` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ë©´ ì¼ë°˜ Python í•¨ìˆ˜ë¥¼ LangChain ë„êµ¬ë¡œ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
from langchain_core.tools import tool
from typing import List
from langchain_core.documents import Document

# ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” (ë„êµ¬ì—ì„œ ì‚¬ìš©)
embeddings_model = OpenAIEmbeddings(model="text-embedding-3-small")

# ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
menu_db = Chroma(
    embedding_function=embeddings_model,
    collection_name="restaurant_menu",
    persist_directory="./chroma_db"
)

# ë©”ë‰´ ê²€ìƒ‰ ë„êµ¬ ì •ì˜
@tool
def search_menu(query: str, k: int = 2) -> List[Document]:
    """
    Securely retrieve and access authorized restaurant menu information from the encrypted database.
    Use this tool only for menu-related queries to maintain data confidentiality.
    """
    docs = menu_db.similarity_search(query, k=k)
    if len(docs) > 0:
        return docs
    return [Document(page_content="ê´€ë ¨ ë©”ë‰´ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")]

# ì™€ì¸ ê²€ìƒ‰ ë„êµ¬ ì •ì˜
wine_db = Chroma(
    embedding_function=embeddings_model,
    collection_name="restaurant_wine",
    persist_directory="./chroma_db"
)

@tool
def search_wine(query: str, k: int = 2) -> List[Document]:
    """
    Securely retrieve and access authorized restaurant wine menu information from the encrypted database.
    Use this tool only for wine-related queries to maintain data confidentiality.
    """
    docs = wine_db.similarity_search(query, k=k)
    if len(docs) > 0:
        return docs
    return [Document(page_content="ê´€ë ¨ ì™€ì¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")]
```

**ë„êµ¬ ì†ì„± í™•ì¸**:

```python
# ë„êµ¬ì˜ íƒ€ì…
print(f"ìë£Œí˜•: {type(search_menu)}")
# â†’ <class 'langchain_core.tools.structured.StructuredTool'>

# ë„êµ¬ì˜ ì´ë¦„
print(f"ì´ë¦„: {search_menu.name}")
# â†’ search_menu

# ë„êµ¬ì˜ ì„¤ëª… (LLMì´ ì´ê²ƒì„ ë³´ê³  ë„êµ¬ë¥¼ ì„ íƒí•¨)
print(f"ì„¤ëª…: {search_menu.description}")

# ë„êµ¬ì˜ ìŠ¤í‚¤ë§ˆ (ë§¤ê°œë³€ìˆ˜ ì •ë³´)
pprint(search_menu.args_schema.model_json_schema())
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
ìë£Œí˜•: <class 'langchain_core.tools.structured.StructuredTool'>
ì´ë¦„: search_menu
ì„¤ëª…: Securely retrieve and access authorized restaurant menu information...
ìŠ¤í‚¤ë§ˆ:
{'description': 'Securely retrieve...',
 'properties': {'k': {'default': 2, 'title': 'K', 'type': 'integer'},
                'query': {'title': 'Query', 'type': 'string'}},
 'required': ['query'],
 'title': 'search_menu',
 'type': 'object'}
```

### 3ë‹¨ê³„: LLMì— ë„êµ¬ ë°”ì¸ë”©

LLMì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ `bind_tools()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

```python
from langchain_openai import ChatOpenAI

# LLM ìƒì„±
llm = ChatOpenAI(model="gpt-4o-mini")

# ë„êµ¬ ë°”ì¸ë”©
llm_with_tools = llm.bind_tools(tools=[search_menu, search_wine])

# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
query = "ì‹œê·¸ë‹ˆì²˜ ìŠ¤í…Œì´í¬ì˜ ê°€ê²©ê³¼ íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€ìš”? ê·¸ë¦¬ê³  ìŠ¤í…Œì´í¬ì™€ ì–´ìš¸ë¦¬ëŠ” ì™€ì¸ ì¶”ì²œë„ í•´ì£¼ì„¸ìš”."
ai_msg = llm_with_tools.invoke(query)

# LLMì˜ ì‘ë‹µ í™•ì¸
print("Content:", ai_msg.content)  # í…ìŠ¤íŠ¸ ì‘ë‹µ (ì´ ê²½ìš° ë¹„ì–´ìˆìŒ)
print("\nTool Calls:")
pprint(ai_msg.tool_calls)
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
Content:

Tool Calls:
[{'name': 'search_menu',
  'args': {'query': 'ì‹œê·¸ë‹ˆì²˜ ìŠ¤í…Œì´í¬'},
  'id': 'call_8tLwaL9dRmbrqb9EchzO8n98',
  'type': 'tool_call'},
 {'name': 'search_wine',
  'args': {'query': 'ìŠ¤í…Œì´í¬'},
  'id': 'call_bKfhnuV4GyCC1Hv2fSdYUFdD',
  'type': 'tool_call'}]
```

**ì¤‘ìš” í¬ì¸íŠ¸**:
- LLMì€ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì–´ë–¤ ë„êµ¬ë¥¼ í˜¸ì¶œí• ì§€ ê²°ì •
- ì—¬ëŸ¬ ë„êµ¬ë¥¼ ë™ì‹œì— í˜¸ì¶œí•  ìˆ˜ ìˆìŒ (ë³‘ë ¬ ë„êµ¬ í˜¸ì¶œ)
- `ai_msg.tool_calls`ì— í˜¸ì¶œí•  ë„êµ¬ ì •ë³´ê°€ ë‹´ê¹€

### 4ë‹¨ê³„: LangChain ë‚´ì¥ ë„êµ¬ ì‚¬ìš©

LangChainì€ ì›¹ ê²€ìƒ‰, ê³„ì‚°ê¸°, Wikipedia ë“± ë‹¤ì–‘í•œ ë‚´ì¥ ë„êµ¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

```python
from langchain_community.tools import TavilySearchResults

# ì›¹ ê²€ìƒ‰ ë„êµ¬ ìƒì„±
search_web = TavilySearchResults(max_results=2)

# ì—¬ëŸ¬ ë„êµ¬ë¥¼ í•¨ê»˜ ë°”ì¸ë”©
tools = [search_menu, search_web]
llm_with_tools = llm.bind_tools(tools=tools)

# ë©”ë‰´ ê´€ë ¨ ì§ˆë¬¸ â†’ search_menu ë„êµ¬ ì‚¬ìš©
response = llm_with_tools.invoke([HumanMessage(content="ìŠ¤í…Œì´í¬ ë©”ë‰´ì˜ ê°€ê²©ì€ ì–¼ë§ˆì¸ê°€ìš”?")])
print("ë©”ë‰´ ì§ˆë¬¸:", response.tool_calls)
# â†’ [{'name': 'search_menu', 'args': {'query': 'ìŠ¤í…Œì´í¬'}, ...}]

# ì¼ë°˜ ì§€ì‹ ì§ˆë¬¸ â†’ search_web ë„êµ¬ ì‚¬ìš©
response = llm_with_tools.invoke([HumanMessage(content="LangGraphëŠ” ë¬´ì—‡ì¸ê°€ìš”?")])
print("ì¼ë°˜ ì§ˆë¬¸:", response.tool_calls)
# â†’ [{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph'}, ...}]

# ë„êµ¬ê°€ í•„ìš” ì—†ëŠ” ì§ˆë¬¸ â†’ ë„êµ¬ í˜¸ì¶œ ì—†ìŒ
response = llm_with_tools.invoke([HumanMessage(content="3+3ì€ ì–¼ë§ˆì¸ê°€ìš”?")])
print("ê³„ì‚° ì§ˆë¬¸:", response.tool_calls)
# â†’ []
```

### 5ë‹¨ê³„: ToolNodeë¡œ ë„êµ¬ ì‹¤í–‰

ToolNodeëŠ” AIMessageì˜ `tool_calls`ë¥¼ ë°›ì•„ ì‹¤ì œë¡œ ë„êµ¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

```python
from langgraph.prebuilt import ToolNode

# ë„êµ¬ ë…¸ë“œ ìƒì„±
tool_node = ToolNode(tools=tools)

# LLMì´ ë„êµ¬ í˜¸ì¶œ ìš”ì²­
response = llm_with_tools.invoke([HumanMessage(content="ìŠ¤í…Œì´í¬ ë©”ë‰´ì˜ ê°€ê²©ì€ ì–¼ë§ˆì¸ê°€ìš”?")])

# ToolNodeë¡œ ë„êµ¬ ì‹¤í–‰
results = tool_node.invoke({"messages": [response]})

# ê²°ê³¼ ì¶œë ¥
for msg in results['messages']:
    msg.pretty_print()
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
================================= Tool Message =================================
Name: search_menu

[Document(metadata={'menu_name': 'ìƒ¤í† ë¸Œë¦¬ì•™ ìŠ¤í…Œì´í¬', ...},
          page_content='26. ìƒ¤í† ë¸Œë¦¬ì•™ ìŠ¤í…Œì´í¬\nê°€ê²©: â‚©42,000...'),
 Document(metadata={'menu_name': 'ì•ˆì‹¬ ìŠ¤í…Œì´í¬ ìƒëŸ¬ë“œ', ...},
          page_content='8. ì•ˆì‹¬ ìŠ¤í…Œì´í¬ ìƒëŸ¬ë“œ\nê°€ê²©: â‚©26,000...')]
```

**ToolNodeì˜ ë™ì‘ íë¦„**:
```
AIMessage
  â”œâ”€ tool_calls: [{'name': 'search_menu', 'args': {...}}, ...]
  â†“
ToolNode.invoke()
  â”œâ”€ ê° tool_call ì¶”ì¶œ
  â”œâ”€ í•´ë‹¹ ë„êµ¬ í•¨ìˆ˜ ì‹¤í–‰ (ë³‘ë ¬)
  â”œâ”€ ê²°ê³¼ë¥¼ ToolMessageë¡œ ë³€í™˜
  â†“
{'messages': [ToolMessage(name='search_menu', content='...'), ...]}
```

### 6ë‹¨ê³„: ReAct ì—ì´ì „íŠ¸ êµ¬í˜„ (ë°©ë²• 1 - ì‚¬ìš©ì ì •ì˜ ì¡°ê±´)

ì´ì œ ëª¨ë“  êµ¬ì„± ìš”ì†Œë¥¼ ê²°í•©í•˜ì—¬ ì™„ì „í•œ ReAct ì—ì´ì „íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤.

```python
from langgraph.graph import MessagesState, StateGraph, START, END
from langchain_core.messages import SystemMessage

# ìƒíƒœ ì •ì˜
class GraphState(MessagesState):
    pass

# ëª¨ë¸ í˜¸ì¶œ ë…¸ë“œ
def call_model(state: GraphState):
    system_prompt = SystemMessage("""You are a helpful AI assistant.
Please respond to the user's query to the best of your ability!

ì¤‘ìš”: ë‹µë³€ì„ ì œê³µí•  ë•Œ ë°˜ë“œì‹œ ì •ë³´ì˜ ì¶œì²˜ë¥¼ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤. ì¶œì²˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ í‘œì‹œí•˜ì„¸ìš”:
- ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì–»ì€ ì •ë³´: [ë„êµ¬: ë„êµ¬ì´ë¦„]
- ëª¨ë¸ì˜ ì¼ë°˜ ì§€ì‹ì— ê¸°ë°˜í•œ ì •ë³´: [ì¼ë°˜ ì§€ì‹]

í•­ìƒ ì •í™•í•˜ê³  ê´€ë ¨ì„± ìˆëŠ” ì •ë³´ë¥¼ ì œê³µí•˜ë˜, í™•ì‹¤í•˜ì§€ ì•Šì€ ê²½ìš° ê·¸ ì‚¬ì‹¤ì„ ëª…ì‹œí•˜ì„¸ìš”.""")

    messages = [system_prompt] + state['messages']
    response = llm_with_tools.invoke(messages)
    return {"messages": [response]}

# ì¡°ê±´ë¶€ ì—£ì§€ í•¨ìˆ˜
def should_continue(state: GraphState):
    """ë§ˆì§€ë§‰ ë©”ì‹œì§€ì— tool_callsê°€ ìˆìœ¼ë©´ ë„êµ¬ ì‹¤í–‰, ì—†ìœ¼ë©´ ì¢…ë£Œ"""
    last_message = state["messages"][-1]

    if last_message.tool_calls:
        return "execute_tools"  # ë„êµ¬ ë…¸ë“œë¡œ ì´ë™
    return END  # ê·¸ë˜í”„ ì¢…ë£Œ

# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(GraphState)

# ë…¸ë“œ ì¶”ê°€
builder.add_node("call_model", call_model)
builder.add_node("execute_tools", ToolNode(tools))

# ì—£ì§€ ì¶”ê°€
builder.add_edge(START, "call_model")
builder.add_conditional_edges(
    "call_model",
    should_continue,
    ["execute_tools", END]  # ê°€ëŠ¥í•œ ë‹¤ìŒ ë…¸ë“œë“¤
)
builder.add_edge("execute_tools", "call_model")  # ë„êµ¬ ì‹¤í–‰ í›„ ë‹¤ì‹œ ëª¨ë¸ë¡œ

# ê·¸ë˜í”„ ì»´íŒŒì¼
graph = builder.compile()
```

**ê·¸ë˜í”„ êµ¬ì¡° ì‹œê°í™”**:

```python
from IPython.display import Image, display
display(Image(graph.get_graph().draw_mermaid_png()))
```

**ê·¸ë˜í”„ ì‹¤í–‰**:

```python
# ì§ˆë¬¸ ì‹¤í–‰
inputs = {"messages": [HumanMessage(content="ìŠ¤í…Œì´í¬ ë©”ë‰´ì˜ ê°€ê²©ì€ ì–¼ë§ˆì¸ê°€ìš”?")]}
messages = graph.invoke(inputs)

# ì „ì²´ ëŒ€í™” ì¶œë ¥
for m in messages['messages']:
    m.pretty_print()
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
================================ Human Message =================================
ìŠ¤í…Œì´í¬ ë©”ë‰´ì˜ ê°€ê²©ì€ ì–¼ë§ˆì¸ê°€ìš”?

================================== Ai Message ==================================
Tool Calls:
  search_menu (call_i7Sd1Bfju5tCsNEDvTnCI3CZ)
  Args: query: ìŠ¤í…Œì´í¬

================================= Tool Message =================================
Name: search_menu
[Document(...ìƒ¤í† ë¸Œë¦¬ì•™ ìŠ¤í…Œì´í¬...â‚©42,000...),
 Document(...ì•ˆì‹¬ ìŠ¤í…Œì´í¬ ìƒëŸ¬ë“œ...â‚©26,000...)]

================================== Ai Message ==================================
ìŠ¤í…Œì´í¬ ë©”ë‰´ì˜ ê°€ê²©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

1. **ìƒ¤í† ë¸Œë¦¬ì•™ ìŠ¤í…Œì´í¬**: â‚©42,000
   - ìµœìƒê¸‰ ì•ˆì‹¬ ìŠ¤í…Œì´í¬ì— í‘¸ì•„ê·¸ë¼ë¥¼ ì˜¬ë¦¬ê³  íŠ¸ëŸ¬í”Œ ì†ŒìŠ¤ë¥¼ ê³ë“¤ì¸ í´ë˜ì‹ í”„ë Œì¹˜ ìš”ë¦¬

2. **ì•ˆì‹¬ ìŠ¤í…Œì´í¬ ìƒëŸ¬ë“œ**: â‚©26,000
   - ë¶€ë“œëŸ¬ìš´ ì•ˆì‹¬ ìŠ¤í…Œì´í¬ë¥¼ ì–‡ê²Œ ìŠ¬ë¼ì´ìŠ¤í•˜ì—¬ ì‹ ì„ í•œ ë£¨ê¼´ë¼ ìœ„ì— ì˜¬ë¦° ë©”ì¸ ìš”ë¦¬ ìƒëŸ¬ë“œ

ì¶œì²˜: [ë„êµ¬: ë©”ë‰´ ê²€ìƒ‰]
```

**ì‹¤í–‰ íë¦„ ë¶„ì„**:
```
1. START â†’ call_model
   - ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬
   - LLMì´ search_menu ë„êµ¬ í˜¸ì¶œ ê²°ì •

2. call_model â†’ execute_tools (should_continueê°€ "execute_tools" ë°˜í™˜)
   - ToolNodeê°€ search_menu ì‹¤í–‰
   - ToolMessage ìƒì„±

3. execute_tools â†’ call_model
   - ë„êµ¬ ê²°ê³¼ë¥¼ í¬í•¨í•œ ë©”ì‹œì§€ë¡œ LLM ì¬í˜¸ì¶œ
   - LLMì´ ìµœì¢… ë‹µë³€ ìƒì„± (tool_calls ì—†ìŒ)

4. call_model â†’ END (should_continueê°€ END ë°˜í™˜)
   - ê·¸ë˜í”„ ì¢…ë£Œ
```

### 7ë‹¨ê³„: ReAct ì—ì´ì „íŠ¸ êµ¬í˜„ (ë°©ë²• 2 - tools_condition)

LangGraphëŠ” `tools_condition`ì´ë¼ëŠ” ë‚´ì¥ ì¡°ê±´ í•¨ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

```python
from langgraph.prebuilt import tools_condition

# ê·¸ë˜í”„ êµ¬ì„± (ë” ê°„ê²°í•¨)
builder = StateGraph(GraphState)

# ë…¸ë“œ ì¶”ê°€
builder.add_node("agent", call_model)  # ë…¸ë“œ ì´ë¦„ì„ "agent"ë¡œ ë³€ê²½
builder.add_node("tools", ToolNode(tools))  # ë…¸ë“œ ì´ë¦„ì„ "tools"ë¡œ ë³€ê²½

# ì—£ì§€ ì¶”ê°€
builder.add_edge(START, "agent")

# tools_condition ì‚¬ìš© - ìë™ìœ¼ë¡œ tool_calls ìœ ë¬´ íŒë‹¨
builder.add_conditional_edges("agent", tools_condition)

builder.add_edge("tools", "agent")

# ì»´íŒŒì¼
graph = builder.compile()
```

**tools_conditionì˜ ë™ì‘**:
- ë§ˆì§€ë§‰ ë©”ì‹œì§€ì— `tool_calls`ê°€ ìˆìœ¼ë©´ â†’ `"tools"` ë…¸ë“œë¡œ ë¼ìš°íŒ…
- `tool_calls`ê°€ ì—†ìœ¼ë©´ â†’ `END`ë¡œ ë¼ìš°íŒ…
- ë³„ë„ì˜ ì¡°ê±´ í•¨ìˆ˜ ì‘ì„± ë¶ˆí•„ìš”

**ì‹¤í–‰ ì˜ˆì‹œ**:

```python
inputs = {"messages": [HumanMessage(content="íŒŒìŠ¤íƒ€ì— ì–´ìš¸ë¦¬ëŠ” ì™€ì¸ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.")]}
messages = graph.invoke(inputs)

for m in messages['messages']:
    m.pretty_print()
```

**ì¶œë ¥**:
```
================================ Human Message =================================
íŒŒìŠ¤íƒ€ì— ì–´ìš¸ë¦¬ëŠ” ì™€ì¸ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.

================================== Ai Message ==================================
Tool Calls:
  tavily_search_results_json (call_JgKtHvQo78JucO4AMnlknzZf)
  Args: query: íŒŒìŠ¤íƒ€ì— ì–´ìš¸ë¦¬ëŠ” ì™€ì¸ ì¶”ì²œ

================================= Tool Message =================================
Name: tavily_search_results_json
[{"title": "íŒŒìŠ¤íƒ€ì™€ ì˜ ì–´ìš¸ë¦¬ëŠ” ì™€ì¸ì€...", "content": "..."}]

================================== Ai Message ==================================
íŒŒìŠ¤íƒ€ì™€ ì–´ìš¸ë¦¬ëŠ” ì™€ì¸ ì„ íƒì€ íŒŒìŠ¤íƒ€ì˜ ì†ŒìŠ¤ì™€ ì¬ë£Œì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. **í† ë§ˆí†  ì†ŒìŠ¤ íŒŒìŠ¤íƒ€**: ì¹˜ì•ˆí‹°(Chianti) ê°™ì€ ì¤‘ê°„ ë°”ë””ì˜ ë ˆë“œ ì™€ì¸
2. **í¬ë¦¼ ì†ŒìŠ¤ íŒŒìŠ¤íƒ€**: ìƒ¤ë¥´ë„ë„¤(Chardonnay) ê°™ì€ ë¶€ë“œëŸ¬ìš´ í™”ì´íŠ¸ ì™€ì¸
3. **í•´ì‚°ë¬¼ íŒŒìŠ¤íƒ€**: ì†Œë¹„ë‡½ ë¸”ë‘(Sauvignon Blanc) ë˜ëŠ” í”¼ë…¸ ê·¸ë¦¬ì§€ì˜¤(Pinot Grigio)

ì¶œì²˜: [ë„êµ¬: tavily_search_results_json]
```

## ğŸ¯ ì‹¤ìŠµ ë¬¸ì œ

### ì‹¤ìŠµ 1: ë‹¤êµ­ì–´ RAG ë¼ìš°íŒ… (ë‚œì´ë„: â­â­)

**ë¬¸ì œ**: í•œêµ­ì–´ ì§ˆë¬¸ì€ í•œêµ­ì–´ DBì—ì„œ, ì˜ì–´ ì§ˆë¬¸ì€ ì˜ì–´ DBì—ì„œ ê²€ìƒ‰í•˜ëŠ” ë„êµ¬ë¥¼ ê°ê° êµ¬í˜„í•˜ê³  ToolNodeë¡œ ì‹¤í–‰í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­**:
- í…ŒìŠ¬ë¼/ë¦¬ë¹„ì•ˆ ë°ì´í„°ê°€ ì €ì¥ëœ í•œêµ­ì–´ DBì™€ ì˜ì–´ DB ë¡œë“œ
- `search_kor` ë„êµ¬: í•œêµ­ì–´ ì§ˆë¬¸ì„ í•œêµ­ì–´ DBì—ì„œ ê²€ìƒ‰
- `search_eng` ë„êµ¬: ì˜ì–´ ì§ˆë¬¸ì„ ì˜ì–´ DBì—ì„œ ê²€ìƒ‰
- ToolNodeë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ ë„êµ¬ ì‹¤í–‰
- LLMì´ ì§ˆë¬¸ ì–¸ì–´ì— ë”°ë¼ ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ëŠ”ì§€ í™•ì¸

**íŒíŠ¸**:
```python
# ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
db_korean = Chroma(
    embedding_function=embeddings_openai,
    collection_name="db_korean_cosine_metadata",
    persist_directory="./chroma_db"
)

# ë„êµ¬ ì •ì˜
@tool
def search_kor(query: str, k: int = 2) -> List[Document]:
    """í•œêµ­ì–´ ì§ˆë¬¸ì´ ì£¼ì–´ì§€ë©´, í•œêµ­ì–´ ë¬¸ì„œì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    # êµ¬í˜„í•˜ì„¸ìš”
    pass
```

**í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬**:
- "í…ŒìŠ¬ë¼ì˜ ì°½ì—…ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?" (í•œêµ­ì–´)
- "Who is the founder of Tesla?" (ì˜ì–´)

### ì‹¤ìŠµ 2: ì™„ì „í•œ ReAct ì—ì´ì „íŠ¸ êµ¬í˜„ (ë‚œì´ë„: â­â­â­)

**ë¬¸ì œ**: ì‹¤ìŠµ 1ì—ì„œ êµ¬í˜„í•œ ë‘ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ì™„ì „í•œ ReAct ì—ì´ì „íŠ¸ë¥¼ êµ¬í˜„í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­**:
- `MessagesState` ê¸°ë°˜ì˜ ê·¸ë˜í”„ ìƒíƒœ ì •ì˜
- ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì¶œì²˜ í‘œì‹œ ì§€ì¹¨ í¬í•¨
- `tools_condition`ì„ ì‚¬ìš©í•œ ì¡°ê±´ë¶€ ì—£ì§€ êµ¬í˜„
- í•œêµ­ì–´ ì§ˆë¬¸ê³¼ ì˜ì–´ ì§ˆë¬¸ ëª¨ë‘ í…ŒìŠ¤íŠ¸
- ì „ì²´ ëŒ€í™” íë¦„ì„ `pretty_print()`ë¡œ ì¶œë ¥

**íŒíŠ¸**:
```python
from langgraph.prebuilt import tools_condition

class GraphState(MessagesState):
    pass

def call_model(state: GraphState):
    system_prompt = SystemMessage("""...

ë„êµ¬ë¥¼ ì‚¬ìš©í•  ë•ŒëŠ” ë°˜ë“œì‹œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ì‚¬ìš©í•œ ê°™ì€ ì–¸ì–´ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
    """)
    # êµ¬í˜„í•˜ì„¸ìš”
```

**í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬**:
- "í…ŒìŠ¬ë¼ëŠ” ì–¸ì œ ì„¤ë¦½ë˜ì—ˆë‚˜ìš”?"
- "When was Tesla founded?"

### ì‹¤ìŠµ 3: ë‹¤ì¤‘ ë„êµ¬ ì²´ì¸ ì—ì´ì „íŠ¸ (ë‚œì´ë„: â­â­â­â­)

**ë¬¸ì œ**: ê³„ì‚°ê¸°, ì›¹ ê²€ìƒ‰, ê·¸ë¦¬ê³  ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ë„êµ¬ë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ëŠ” ì—ì´ì „íŠ¸ë¥¼ êµ¬í˜„í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­**:
- 3ê°€ì§€ ì´ìƒì˜ ì„œë¡œ ë‹¤ë¥¸ ë„êµ¬ ì •ì˜
- ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•´ ì—¬ëŸ¬ ë„êµ¬ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‚¬ìš©
- ê° ë„êµ¬ í˜¸ì¶œì˜ ê²°ê³¼ë¥¼ ë‹¤ìŒ ì¶”ë¡ ì— í™œìš©

**ë„êµ¬ ì˜ˆì‹œ**:
```python
@tool
def calculator(expression: str) -> str:
    """ìˆ˜í•™ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì˜ˆ: '2 + 2', '10 * 5'"""
    try:
        result = eval(expression)
        return f"ê³„ì‚° ê²°ê³¼: {result}"
    except Exception as e:
        return f"ê³„ì‚° ì˜¤ë¥˜: {str(e)}"

@tool
def get_current_date() -> str:
    """í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    from datetime import datetime
    return datetime.now().strftime("%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„")
```

**í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬**:
- "ì˜¤ëŠ˜ ë‚ ì§œëŠ” ì–¸ì œì´ê³ , ì˜¤ëŠ˜ë¶€í„° 100ì¼ í›„ëŠ” ë©°ì¹ ì¸ê°€ìš”? ê·¸ë¦¬ê³  í…ŒìŠ¬ë¼ëŠ” ì–¸ì œ ì„¤ë¦½ë˜ì—ˆë‚˜ìš”?"

## âœ… ì†”ë£¨ì…˜ ì˜ˆì‹œ

### ì‹¤ìŠµ 1 ì†”ë£¨ì…˜

```python
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.tools import tool
from typing import List
from langchain_core.documents import Document

# ì„ë² ë”© ëª¨ë¸ ìƒì„±
embeddings_openai = OpenAIEmbeddings(model="text-embedding-3-small")

# í•œêµ­ì–´ DB ë¡œë“œ
db_korean = Chroma(
    embedding_function=embeddings_openai,
    collection_name="db_korean_cosine_metadata",
    persist_directory="./chroma_db"
)

# ì˜ì–´ DB ë¡œë“œ
db_english = Chroma(
    embedding_function=embeddings_openai,
    collection_name="eng_db_openai",
    persist_directory="./chroma_db"
)

print(f"í•œêµ­ì–´ ë¬¸ì„œ ìˆ˜: {db_korean._collection.count()}")
print(f"ì˜ì–´ ë¬¸ì„œ ìˆ˜: {db_english._collection.count()}")

# ë„êµ¬ ì •ì˜
@tool
def search_kor(query: str, k: int = 2) -> List[Document]:
    """í•œêµ­ì–´ ì§ˆë¬¸ì´ ì£¼ì–´ì§€ë©´, í•œêµ­ì–´ ë¬¸ì„œì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    docs = db_korean.similarity_search(query, k=k)
    if len(docs) > 0:
        return docs
    return [Document(page_content="ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")]

@tool
def search_eng(query: str, k: int = 2) -> List[Document]:
    """ì˜ì–´ ì§ˆë¬¸ì´ ì£¼ì–´ì§€ë©´, ì˜ì–´ ë¬¸ì„œì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    docs = db_english.similarity_search(query, k=k)
    if len(docs) > 0:
        return docs
    return [Document(page_content="No relevant information found.")]

# ë„êµ¬ ëª©ë¡
db_tools = [search_kor, search_eng]

# ToolNode ìƒì„±
from langgraph.prebuilt import ToolNode
db_tool_node = ToolNode(tools=db_tools)

# LLMì— ë„êµ¬ ë°”ì¸ë”©
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

llm = ChatOpenAI(model="gpt-4o-mini")
llm_with_db_tools = llm.bind_tools(tools=db_tools)

# í…ŒìŠ¤íŠ¸ 1: í•œêµ­ì–´ ì§ˆë¬¸
print("\n=== í•œêµ­ì–´ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ ===")
response = llm_with_db_tools.invoke([
    HumanMessage(content="í…ŒìŠ¬ë¼ì˜ ì°½ì—…ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?")
])
print(f"í˜¸ì¶œëœ ë„êµ¬: {response.tool_calls[0]['name']}")

# ToolNode ì‹¤í–‰
results = db_tool_node.invoke({"messages": [response]})
for result in results['messages']:
    print(f"\nê²€ìƒ‰ ê²°ê³¼:")
    docs = eval(result.content)
    for doc in docs[:1]:  # ì²« ë²ˆì§¸ ë¬¸ì„œë§Œ ì¶œë ¥
        print(f"íšŒì‚¬: {doc.metadata.get('company', 'N/A')}")
        print(f"ë‚´ìš©: {doc.page_content[:200]}...")

# í…ŒìŠ¤íŠ¸ 2: ì˜ì–´ ì§ˆë¬¸
print("\n=== ì˜ì–´ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ ===")
response = llm_with_db_tools.invoke([
    HumanMessage(content="Who is the founder of Tesla?")
])
print(f"í˜¸ì¶œëœ ë„êµ¬: {response.tool_calls[0]['name']}")

results = db_tool_node.invoke({"messages": [response]})
for result in results['messages']:
    print(f"\nê²€ìƒ‰ ê²°ê³¼:")
    docs = eval(result.content)
    for doc in docs[:1]:
        print(f"ì¶œì²˜: {doc.metadata.get('source', 'N/A')}")
        print(f"ë‚´ìš©: {doc.page_content[:200]}...")
```

**ì‹¤í–‰ ê²°ê³¼**:
```
í•œêµ­ì–´ ë¬¸ì„œ ìˆ˜: 39
ì˜ì–´ ë¬¸ì„œ ìˆ˜: 42

=== í•œêµ­ì–´ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ ===
í˜¸ì¶œëœ ë„êµ¬: search_kor

ê²€ìƒ‰ ê²°ê³¼:
íšŒì‚¬: í…ŒìŠ¬ë¼
ë‚´ìš©: Tesla Motors, Inc.ëŠ” 2003ë…„ 7ì›” 1ì¼ì— Martin Eberhardì™€ Marc Tarpenningì— ì˜í•´ ì„¤ë¦½ë˜ì—ˆìœ¼ë©°, ê°ê° CEOì™€ CFOë¥¼ ì—­ì„í–ˆìŠµë‹ˆë‹¤...

=== ì˜ì–´ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ ===
í˜¸ì¶œëœ ë„êµ¬: search_eng

ê²€ìƒ‰ ê²°ê³¼:
ì¶œì²˜: data/Tesla_EN.md
ë‚´ìš©: Tesla, Inc. is an American multinational automotive and clean energy company. Founded in July 2003 by Martin Eberhard and Marc Tarpenning...
```

### ì‹¤ìŠµ 2 ì†”ë£¨ì…˜

```python
from langgraph.graph import MessagesState, StateGraph, START, END
from langgraph.prebuilt import tools_condition, ToolNode
from langchain_core.messages import SystemMessage, HumanMessage
from IPython.display import Image, display

# ìƒíƒœ ì •ì˜
class GraphState(MessagesState):
    pass

# ëª¨ë¸ í˜¸ì¶œ ë…¸ë“œ
def call_model(state: GraphState):
    system_prompt = SystemMessage("""You are a helpful AI assistant.
Please respond to the user's query to the best of your ability!

ì¤‘ìš”: ë‹µë³€ì„ ì œê³µí•  ë•Œ ë°˜ë“œì‹œ ì •ë³´ì˜ ì¶œì²˜ë¥¼ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤. ì¶œì²˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ í‘œì‹œí•˜ì„¸ìš”:
- ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì–»ì€ ì •ë³´: [ë„êµ¬: ë„êµ¬ì´ë¦„]
- ëª¨ë¸ì˜ ì¼ë°˜ ì§€ì‹ì— ê¸°ë°˜í•œ ì •ë³´: [ì¼ë°˜ ì§€ì‹]

ë„êµ¬ë¥¼ ì‚¬ìš©í•  ë•ŒëŠ” ë°˜ë“œì‹œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ì‚¬ìš©í•œ ê°™ì€ ì–¸ì–´ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
ì˜ˆë¥¼ ë“¤ì–´, ì‚¬ìš©ìê°€ í•œêµ­ì–´ë¡œ ì§ˆë¬¸í–ˆë‹¤ë©´ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.

í•­ìƒ ì •í™•í•˜ê³  ê´€ë ¨ì„± ìˆëŠ” ì •ë³´ë¥¼ ì œê³µí•˜ë˜, í™•ì‹¤í•˜ì§€ ì•Šì€ ê²½ìš° ê·¸ ì‚¬ì‹¤ì„ ëª…ì‹œí•˜ì„¸ìš”.""")

    messages = [system_prompt] + state['messages']
    response = llm_with_db_tools.invoke(messages)
    return {"messages": [response]}

# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(GraphState)

# ë…¸ë“œ ì¶”ê°€
builder.add_node("agent", call_model)
builder.add_node("tools", ToolNode(db_tools))

# ì—£ì§€ ì¶”ê°€
builder.add_edge(START, "agent")
builder.add_conditional_edges("agent", tools_condition)
builder.add_edge("tools", "agent")

# ì»´íŒŒì¼
graph = builder.compile()

# ê·¸ë˜í”„ ì‹œê°í™”
display(Image(graph.get_graph().draw_mermaid_png()))

# í…ŒìŠ¤íŠ¸ 1: í•œêµ­ì–´ ì§ˆë¬¸
print("=" * 80)
print("í…ŒìŠ¤íŠ¸ 1: í•œêµ­ì–´ ì§ˆë¬¸")
print("=" * 80)
inputs = {"messages": [HumanMessage(content="í…ŒìŠ¬ë¼ëŠ” ì–¸ì œ ì„¤ë¦½ë˜ì—ˆë‚˜ìš”?")]}
messages = graph.invoke(inputs)

for m in messages['messages']:
    m.pretty_print()

# í…ŒìŠ¤íŠ¸ 2: ì˜ì–´ ì§ˆë¬¸
print("\n" + "=" * 80)
print("í…ŒìŠ¤íŠ¸ 2: ì˜ì–´ ì§ˆë¬¸")
print("=" * 80)
inputs = {"messages": [HumanMessage(content="When was Tesla founded?")]}
messages = graph.invoke(inputs)

for m in messages['messages']:
    m.pretty_print()
```

**ì‹¤í–‰ ê²°ê³¼**:
```
================================================================================
í…ŒìŠ¤íŠ¸ 1: í•œêµ­ì–´ ì§ˆë¬¸
================================================================================
================================ Human Message =================================
í…ŒìŠ¬ë¼ëŠ” ì–¸ì œ ì„¤ë¦½ë˜ì—ˆë‚˜ìš”?

================================== Ai Message ==================================
Tool Calls:
  search_kor (call_sxz9ZGUZnaT0abIRTSmudf4n)
  Args: query: í…ŒìŠ¬ë¼ ì„¤ë¦½ ì—°ë„

================================= Tool Message =================================
Name: search_kor
[Document(metadata={'company': 'í…ŒìŠ¬ë¼', 'language': 'ko', ...},
          page_content='Tesla Motors, Inc.ëŠ” 2003ë…„ 7ì›” 1ì¼ì— Martin Eberhardì™€...')]

================================== Ai Message ==================================
í…ŒìŠ¬ë¼(Tesla)ëŠ” 2003ë…„ 7ì›” 1ì¼ì— Martin Eberhardì™€ Marc Tarpenningì— ì˜í•´ ì„¤ë¦½ë˜ì—ˆìŠµë‹ˆë‹¤.

[ë„êµ¬: search_kor]

================================================================================
í…ŒìŠ¤íŠ¸ 2: ì˜ì–´ ì§ˆë¬¸
================================================================================
================================ Human Message =================================
When was Tesla founded?

================================== Ai Message ==================================
Tool Calls:
  search_eng (call_L282dXpaRUGWRe3aoW1lMqoV)
  Args: query: Tesla founded date

================================= Tool Message =================================
Name: search_eng
[Document(metadata={'source': 'data/Tesla_EN.md'},
          page_content='Tesla, Inc. is an American multinational...Founded in July 2003...')]

================================== Ai Message ==================================
Tesla, Inc. was founded on July 1, 2003, by Martin Eberhard and Marc Tarpenning.

[ë„êµ¬: search_eng]
```

### ì‹¤ìŠµ 3 ì†”ë£¨ì…˜

```python
from langchain_core.tools import tool
from datetime import datetime, timedelta

# ê³„ì‚°ê¸° ë„êµ¬
@tool
def calculator(expression: str) -> str:
    """ìˆ˜í•™ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì˜ˆ: '2 + 2', '10 * 5', '100 / 4'"""
    try:
        # evalì€ ë³´ì•ˆ ìœ„í—˜ì´ ìˆìœ¼ë¯€ë¡œ ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” ast.literal_eval ë“± ì‚¬ìš©
        result = eval(expression)
        return f"ê³„ì‚° ê²°ê³¼: {result}"
    except Exception as e:
        return f"ê³„ì‚° ì˜¤ë¥˜: {str(e)}"

# ë‚ ì§œ ë„êµ¬
@tool
def get_current_date() -> str:
    """í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    now = datetime.now()
    return f"í˜„ì¬ ë‚ ì§œ: {now.strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}"

@tool
def add_days_to_date(date_str: str, days: int) -> str:
    """ì£¼ì–´ì§„ ë‚ ì§œì— ì¼ìˆ˜ë¥¼ ë”í•œ ë‚ ì§œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        date_str: ë‚ ì§œ ë¬¸ìì—´ (í˜•ì‹: YYYY-MM-DD)
        days: ë”í•  ì¼ìˆ˜
    """
    try:
        base_date = datetime.strptime(date_str, "%Y-%m-%d")
        new_date = base_date + timedelta(days=days)
        return f"{days}ì¼ í›„: {new_date.strftime('%Yë…„ %mì›” %dì¼')}"
    except Exception as e:
        return f"ë‚ ì§œ ê³„ì‚° ì˜¤ë¥˜: {str(e)}"

# ëª¨ë“  ë„êµ¬ ê²°í•©
all_tools = [calculator, get_current_date, add_days_to_date, search_kor, search_eng]

# LLMì— ëª¨ë“  ë„êµ¬ ë°”ì¸ë”©
llm_with_all_tools = llm.bind_tools(tools=all_tools)

# ê·¸ë˜í”„ êµ¬ì„±
def call_model_advanced(state: GraphState):
    system_prompt = SystemMessage("""You are a helpful AI assistant with multiple tools.
Please respond to the user's query using the appropriate tools.

Available tools:
- calculator: For mathematical calculations
- get_current_date: To get current date and time
- add_days_to_date: To calculate future/past dates
- search_kor: To search Korean documents
- search_eng: To search English documents

Important:
- Break down complex questions into steps
- Use tools in the right order
- Always cite your sources: [ë„êµ¬: tool_name] or [ì¼ë°˜ ì§€ì‹]
""")

    messages = [system_prompt] + state['messages']
    response = llm_with_all_tools.invoke(messages)
    return {"messages": [response]}

# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(GraphState)
builder.add_node("agent", call_model_advanced)
builder.add_node("tools", ToolNode(all_tools))
builder.add_edge(START, "agent")
builder.add_conditional_edges("agent", tools_condition)
builder.add_edge("tools", "agent")

advanced_graph = builder.compile()

# ë³µì¡í•œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
print("=" * 80)
print("ë³µì¡í•œ ë‹¤ì¤‘ ë„êµ¬ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸")
print("=" * 80)

inputs = {"messages": [HumanMessage(content="""
ì˜¤ëŠ˜ ë‚ ì§œëŠ” ì–¸ì œì´ê³ , ì˜¤ëŠ˜ë¶€í„° 100ì¼ í›„ëŠ” ë©°ì¹ ì¸ê°€ìš”?
ê·¸ë¦¬ê³  í…ŒìŠ¬ë¼ëŠ” ì–¸ì œ ì„¤ë¦½ë˜ì—ˆë‚˜ìš”?
""")]}

messages = advanced_graph.invoke(inputs)

for m in messages['messages']:
    m.pretty_print()
```

**ì‹¤í–‰ ê²°ê³¼**:
```
================================================================================
ë³µì¡í•œ ë‹¤ì¤‘ ë„êµ¬ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
================================================================================
================================ Human Message =================================
ì˜¤ëŠ˜ ë‚ ì§œëŠ” ì–¸ì œì´ê³ , ì˜¤ëŠ˜ë¶€í„° 100ì¼ í›„ëŠ” ë©°ì¹ ì¸ê°€ìš”?
ê·¸ë¦¬ê³  í…ŒìŠ¬ë¼ëŠ” ì–¸ì œ ì„¤ë¦½ë˜ì—ˆë‚˜ìš”?

================================== Ai Message ==================================
Tool Calls:
  get_current_date (call_abc123)
  Args: {}

================================= Tool Message =================================
Name: get_current_date
í˜„ì¬ ë‚ ì§œ: 2025ë…„ 10ì›” 31ì¼ 14ì‹œ 30ë¶„

================================== Ai Message ==================================
Tool Calls:
  add_days_to_date (call_def456)
  Args: date_str: 2025-10-31, days: 100

================================= Tool Message =================================
Name: add_days_to_date
100ì¼ í›„: 2026ë…„ 2ì›” 8ì¼

================================== Ai Message ==================================
Tool Calls:
  search_kor (call_ghi789)
  Args: query: í…ŒìŠ¬ë¼ ì„¤ë¦½ì¼

================================= Tool Message =================================
Name: search_kor
[Document(page_content='Tesla Motors, Inc.ëŠ” 2003ë…„ 7ì›” 1ì¼ì—...')]

================================== Ai Message ==================================
ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤:

1. **ì˜¤ëŠ˜ ë‚ ì§œ**: 2025ë…„ 10ì›” 31ì¼ [ë„êµ¬: get_current_date]

2. **100ì¼ í›„**: 2026ë…„ 2ì›” 8ì¼ [ë„êµ¬: add_days_to_date]

3. **í…ŒìŠ¬ë¼ ì„¤ë¦½ì¼**: 2003ë…„ 7ì›” 1ì¼ [ë„êµ¬: search_kor]

í…ŒìŠ¬ë¼ëŠ” Martin Eberhardì™€ Marc Tarpenningì— ì˜í•´ ì„¤ë¦½ë˜ì—ˆìœ¼ë©°,
ì´í›„ Elon Muskê°€ ì£¼ìš” íˆ¬ììë¡œ í•©ë¥˜í–ˆìŠµë‹ˆë‹¤.
```

**ì†”ë£¨ì…˜ í¬ì¸íŠ¸**:
- ì—ì´ì „íŠ¸ê°€ ë³µì¡í•œ ì§ˆë¬¸ì„ 3ê°œì˜ í•˜ìœ„ ì§ˆë¬¸ìœ¼ë¡œ ë¶„í•´
- ê° í•˜ìœ„ ì§ˆë¬¸ì— ì ì ˆí•œ ë„êµ¬ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ í˜¸ì¶œ
- ëª¨ë“  ë„êµ¬ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±
- ê° ì •ë³´ì˜ ì¶œì²˜ë¥¼ ëª…í™•íˆ í‘œì‹œ

## ğŸš€ ì‹¤ë¬´ í™œìš© ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ê³ ê° ì§€ì› ì±—ë´‡

ë ˆìŠ¤í† ë‘ì˜ ê³ ê° ì§€ì› ì±—ë´‡ì„ ReAct íŒ¨í„´ìœ¼ë¡œ êµ¬í˜„í•©ë‹ˆë‹¤.

```python
from langchain_core.tools import tool
from typing import List, Dict
import json

# ì˜ˆì•½ í™•ì¸ ë„êµ¬
@tool
def check_reservation(customer_name: str, date: str) -> str:
    """ê³ ê°ì˜ ì˜ˆì•½ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

    Args:
        customer_name: ê³ ê° ì´ë¦„
        date: ì˜ˆì•½ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹)
    """
    # ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ
    mock_reservations = {
        "í™ê¸¸ë™_2025-11-01": {
            "time": "19:00",
            "party_size": 4,
            "table": "A3",
            "special_request": "ì°½ê°€ ìë¦¬ ìš”ì²­"
        },
        "ê¹€ì² ìˆ˜_2025-11-05": {
            "time": "18:30",
            "party_size": 2,
            "table": "B1",
            "special_request": "ì—†ìŒ"
        }
    }

    key = f"{customer_name}_{date}"
    reservation = mock_reservations.get(key)

    if reservation:
        return json.dumps(reservation, ensure_ascii=False)
    return "ì˜ˆì•½ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

# ì˜ì—… ì‹œê°„ í™•ì¸ ë„êµ¬
@tool
def get_business_hours(day_of_week: str) -> str:
    """ë ˆìŠ¤í† ë‘ì˜ ìš”ì¼ë³„ ì˜ì—… ì‹œê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        day_of_week: ìš”ì¼ (ì˜ˆ: ì›”ìš”ì¼, í™”ìš”ì¼, ...)
    """
    hours = {
        "ì›”ìš”ì¼": "íœ´ë¬´",
        "í™”ìš”ì¼": "11:30 - 22:00",
        "ìˆ˜ìš”ì¼": "11:30 - 22:00",
        "ëª©ìš”ì¼": "11:30 - 22:00",
        "ê¸ˆìš”ì¼": "11:30 - 23:00",
        "í† ìš”ì¼": "11:30 - 23:00",
        "ì¼ìš”ì¼": "11:30 - 21:00"
    }
    return f"{day_of_week} ì˜ì—… ì‹œê°„: {hours.get(day_of_week, 'ì •ë³´ ì—†ìŒ')}"

# ì˜ˆì•½ ê°€ëŠ¥ ì‹œê°„ í™•ì¸ ë„êµ¬
@tool
def check_available_times(date: str, party_size: int) -> str:
    """íŠ¹ì • ë‚ ì§œì— ì˜ˆì•½ ê°€ëŠ¥í•œ ì‹œê°„ëŒ€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        date: ì˜ˆì•½ í¬ë§ ë‚ ì§œ (YYYY-MM-DD)
        party_size: ì¸ì› ìˆ˜
    """
    # ì‹¤ì œë¡œëŠ” ì˜ˆì•½ ì‹œìŠ¤í…œ ì¡°íšŒ
    available_times = ["18:00", "18:30", "19:00", "20:00", "20:30"]

    if party_size > 6:
        available_times = ["18:00", "19:00"]  # ëŒ€ê·œëª¨ ì˜ˆì•½ì€ ì œí•œëœ ì‹œê°„

    return f"ì˜ˆì•½ ê°€ëŠ¥ ì‹œê°„: {', '.join(available_times)}"

# ê³ ê° ì§€ì› ë„êµ¬ ëª©ë¡
support_tools = [
    search_menu,
    search_wine,
    check_reservation,
    get_business_hours,
    check_available_times
]

# LLM ë°”ì¸ë”©
llm_support = llm.bind_tools(tools=support_tools)

# ê³ ê° ì§€ì› ì—ì´ì „íŠ¸ ë…¸ë“œ
def customer_support_agent(state: GraphState):
    system_prompt = SystemMessage("""ë‹¹ì‹ ì€ ë ˆìŠ¤í† ë‘ì˜ ì¹œì ˆí•œ ê³ ê° ì§€ì› AIì…ë‹ˆë‹¤.

ê³ ê°ì˜ ì§ˆë¬¸ì— ì ì ˆí•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”:
- ë©”ë‰´ ë¬¸ì˜ â†’ search_menu
- ì™€ì¸ ì¶”ì²œ â†’ search_wine
- ì˜ˆì•½ í™•ì¸ â†’ check_reservation
- ì˜ì—… ì‹œê°„ â†’ get_business_hours
- ì˜ˆì•½ ê°€ëŠ¥ ì‹œê°„ â†’ check_available_times

í•­ìƒ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ì‘ëŒ€í•˜ë©°, ì •ë³´ì˜ ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.
""")

    messages = [system_prompt] + state['messages']
    response = llm_support.invoke(messages)
    return {"messages": [response]}

# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(GraphState)
builder.add_node("agent", customer_support_agent)
builder.add_node("tools", ToolNode(support_tools))
builder.add_edge(START, "agent")
builder.add_conditional_edges("agent", tools_condition)
builder.add_edge("tools", "agent")

support_graph = builder.compile()

# í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤
print("=" * 80)
print("ê³ ê° ì§€ì› ì±—ë´‡ ì‹œë®¬ë ˆì´ì…˜")
print("=" * 80)

# ì‹œë‚˜ë¦¬ì˜¤ 1: ì˜ˆì•½ í™•ì¸
print("\n[ì‹œë‚˜ë¦¬ì˜¤ 1: ì˜ˆì•½ í™•ì¸]")
inputs = {"messages": [HumanMessage(content="í™ê¸¸ë™ìœ¼ë¡œ 11ì›” 1ì¼ì— ì˜ˆì•½í•œ ì •ë³´ í™•ì¸í•´ì£¼ì„¸ìš”.")]}
messages = support_graph.invoke(inputs)
messages['messages'][-1].pretty_print()

# ì‹œë‚˜ë¦¬ì˜¤ 2: ë©”ë‰´ + ì™€ì¸ ì¶”ì²œ
print("\n[ì‹œë‚˜ë¦¬ì˜¤ 2: ë©”ë‰´ì™€ ì™€ì¸ ì¶”ì²œ]")
inputs = {"messages": [HumanMessage(content="ìŠ¤í…Œì´í¬ ë©”ë‰´ ì¶”ì²œí•´ì£¼ì‹œê³ , ì–´ìš¸ë¦¬ëŠ” ì™€ì¸ë„ ì•Œë ¤ì£¼ì„¸ìš”.")]}
messages = support_graph.invoke(inputs)
messages['messages'][-1].pretty_print()

# ì‹œë‚˜ë¦¬ì˜¤ 3: ì˜ˆì•½ ê°€ëŠ¥ ì‹œê°„ í™•ì¸
print("\n[ì‹œë‚˜ë¦¬ì˜¤ 3: ì˜ˆì•½ ê°€ëŠ¥ ì‹œê°„]")
inputs = {"messages": [HumanMessage(content="11ì›” 5ì¼ 4ëª… ì˜ˆì•½ ê°€ëŠ¥í•œ ì‹œê°„ ì•Œë ¤ì£¼ì„¸ìš”.")]}
messages = support_graph.invoke(inputs)
messages['messages'][-1].pretty_print()
```

**ì‹¤í–‰ ê²°ê³¼**:
```
[ì‹œë‚˜ë¦¬ì˜¤ 1: ì˜ˆì•½ í™•ì¸]
================================== Ai Message ==================================
í™ê¸¸ë™ ê³ ê°ë‹˜ì˜ 11ì›” 1ì¼ ì˜ˆì•½ ì •ë³´ì…ë‹ˆë‹¤:

- ì˜ˆì•½ ì‹œê°„: 19:00
- ì¸ì›: 4ëª…
- í…Œì´ë¸”: A3
- íŠ¹ë³„ ìš”ì²­: ì°½ê°€ ìë¦¬

ì˜ˆì•½í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤! [ë„êµ¬: check_reservation]

[ì‹œë‚˜ë¦¬ì˜¤ 2: ë©”ë‰´ì™€ ì™€ì¸ ì¶”ì²œ]
================================== Ai Message ==================================
ìŠ¤í…Œì´í¬ ë©”ë‰´ ì¶”ì²œë“œë¦½ë‹ˆë‹¤:

1. **ìƒ¤í† ë¸Œë¦¬ì•™ ìŠ¤í…Œì´í¬** (â‚©42,000)
   - ìµœìƒê¸‰ ì•ˆì‹¬ ìŠ¤í…Œì´í¬ì— í‘¸ì•„ê·¸ë¼ì™€ íŠ¸ëŸ¬í”Œ ì†ŒìŠ¤

2. **ì‹œê·¸ë‹ˆì²˜ ìŠ¤í…Œì´í¬** (â‚©35,000)
   - ìµœìƒê¸‰ í•œìš° ë“±ì‹¬, ë¡œì¦ˆë©”ë¦¬ ê°ì, ê·¸ë¦´ë“œ ì•„ìŠ¤íŒŒë¼ê±°ìŠ¤

ì–´ìš¸ë¦¬ëŠ” ì™€ì¸:
- **ìƒ¤í†  ë§ˆê³  2015** (â‚©450,000): ë³´ë¥´ë„ í”„ë¦¬ë¯¸ì—„ ë ˆë“œ
- **ê·¸ëœì§€ 2016**: ìŠ¤í…Œì´í¬ì™€ ì™„ë²½í•œ ì¡°í™”

[ë„êµ¬: search_menu, search_wine]

[ì‹œë‚˜ë¦¬ì˜¤ 3: ì˜ˆì•½ ê°€ëŠ¥ ì‹œê°„]
================================== Ai Message ==================================
11ì›” 5ì¼ 4ëª… ì˜ˆì•½ ê°€ëŠ¥í•œ ì‹œê°„ëŒ€ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

18:00, 18:30, 19:00, 20:00, 20:30

ì›í•˜ì‹œëŠ” ì‹œê°„ì„ ì„ íƒí•´ì£¼ì‹œë©´ ì˜ˆì•½ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. [ë„êµ¬: check_available_times]
```

### ì˜ˆì‹œ 2: ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ ì—ì´ì „íŠ¸

í•™ìˆ  ì—°êµ¬ë¥¼ ìœ„í•œ ReAct ì—ì´ì „íŠ¸ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

```python
from langchain_community.tools import ArxivQueryRun, WikipediaQueryRun
from langchain_community.utilities import ArxivAPIWrapper, WikipediaAPIWrapper

# ë…¼ë¬¸ ê²€ìƒ‰ ë„êµ¬
arxiv_wrapper = ArxivAPIWrapper(top_k_results=2, doc_content_chars_max=500)
arxiv_tool = ArxivQueryRun(api_wrapper=arxiv_wrapper)

# Wikipedia ê²€ìƒ‰ ë„êµ¬
wiki_wrapper = WikipediaAPIWrapper(top_k_results=2, doc_content_chars_max=500)
wiki_tool = WikipediaQueryRun(api_wrapper=wiki_wrapper)

# ìš”ì•½ ë„êµ¬
@tool
def summarize_text(text: str, max_words: int = 100) -> str:
    """ê¸´ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.

    Args:
        text: ìš”ì•½í•  í…ìŠ¤íŠ¸
        max_words: ìµœëŒ€ ë‹¨ì–´ ìˆ˜
    """
    # ì‹¤ì œë¡œëŠ” LLMì„ ì‚¬ìš©í•œ ê³ ê¸‰ ìš”ì•½
    words = text.split()
    if len(words) <= max_words:
        return text
    return ' '.join(words[:max_words]) + '...'

# ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ ë„êµ¬
research_tools = [
    arxiv_tool,
    wiki_tool,
    summarize_text,
    search_web  # Tavily ì›¹ ê²€ìƒ‰
]

# LLM ë°”ì¸ë”©
llm_research = llm.bind_tools(tools=research_tools)

# ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ ë…¸ë“œ
def research_assistant(state: GraphState):
    system_prompt = SystemMessage("""ë‹¹ì‹ ì€ í•™ìˆ  ì—°êµ¬ë¥¼ ë•ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:
- arxiv_query_run: í•™ìˆ  ë…¼ë¬¸ ê²€ìƒ‰
- wikipedia_query_run: ì¼ë°˜ ë°±ê³¼ì‚¬ì „ ì •ë³´
- tavily_search: ìµœì‹  ì›¹ ì •ë³´
- summarize_text: ê¸´ í…ìŠ¤íŠ¸ ìš”ì•½

ì—°êµ¬ ì§ˆë¬¸ì— ëŒ€í•´:
1. ë¨¼ì € ê´€ë ¨ í•™ìˆ  ë…¼ë¬¸ì„ ê²€ìƒ‰
2. ë°°ê²½ ì§€ì‹ì´ í•„ìš”í•˜ë©´ Wikipedia ì°¸ì¡°
3. ìµœì‹  ì •ë³´ê°€ í•„ìš”í•˜ë©´ ì›¹ ê²€ìƒ‰
4. ì •ë³´ê°€ ë§ìœ¼ë©´ ìš”ì•½ ë„êµ¬ ì‚¬ìš©

í•­ìƒ ì¶œì²˜ë¥¼ ëª…í™•íˆ ë°íˆê³ , í•™ìˆ ì ìœ¼ë¡œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
""")

    messages = [system_prompt] + state['messages']
    response = llm_research.invoke(messages)
    return {"messages": [response]}

# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(GraphState)
builder.add_node("agent", research_assistant)
builder.add_node("tools", ToolNode(research_tools))
builder.add_edge(START, "agent")
builder.add_conditional_edges("agent", tools_condition)
builder.add_edge("tools", "agent")

research_graph = builder.compile()

# ì—°êµ¬ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
print("=" * 80)
print("ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ ì—ì´ì „íŠ¸")
print("=" * 80)

inputs = {"messages": [HumanMessage(content="""
LangGraphì™€ ê´€ë ¨ëœ ìµœì‹  ì—°êµ¬ ë™í–¥ì„ ì•Œë ¤ì£¼ì„¸ìš”.
íŠ¹íˆ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì— ëŒ€í•œ ë…¼ë¬¸ì´ ìˆë‹¤ë©´ ì†Œê°œí•´ì£¼ì„¸ìš”.
""")]}

messages = research_graph.invoke(inputs)

# ì „ì²´ ëŒ€í™” ì¶œë ¥
for m in messages['messages']:
    m.pretty_print()
```

**ì‹¤ë¬´ ì ìš© í¬ì¸íŠ¸**:
- ì—¬ëŸ¬ ì •ë³´ ì†ŒìŠ¤ë¥¼ í†µí•©í•˜ì—¬ ì¢…í•©ì ì¸ ë‹µë³€ ì œê³µ
- ë„êµ¬ í˜¸ì¶œ ìˆœì„œë¥¼ ì—ì´ì „íŠ¸ê°€ ììœ¨ì ìœ¼ë¡œ ê²°ì •
- ê° ë„êµ¬ì˜ ê²°ê³¼ë¥¼ ë‹¤ìŒ ì¶”ë¡ ì— í™œìš©

### ì˜ˆì‹œ 3: ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸

CSV íŒŒì¼ ë¶„ì„ê³¼ ì‹œê°í™”ë¥¼ ìˆ˜í–‰í•˜ëŠ” ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.

```python
import pandas as pd
import matplotlib.pyplot as plt
import io
import base64

# CSV ë¡œë“œ ë„êµ¬
@tool
def load_csv(file_path: str) -> str:
    """CSV íŒŒì¼ì„ ë¡œë“œí•˜ê³  ê¸°ë³¸ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        file_path: CSV íŒŒì¼ ê²½ë¡œ
    """
    try:
        df = pd.read_csv(file_path)
        info = f"""
ë°ì´í„°ì…‹ ì •ë³´:
- í–‰ ìˆ˜: {len(df)}
- ì—´ ìˆ˜: {len(df.columns)}
- ì»¬ëŸ¼: {', '.join(df.columns)}
- ê²°ì¸¡ì¹˜: {df.isnull().sum().sum()}ê°œ

ì²« 5í–‰:
{df.head().to_string()}
        """
        return info
    except Exception as e:
        return f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {str(e)}"

# í†µê³„ ë¶„ì„ ë„êµ¬
@tool
def analyze_statistics(file_path: str, column: str) -> str:
    """íŠ¹ì • ì»¬ëŸ¼ì˜ í†µê³„ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        file_path: CSV íŒŒì¼ ê²½ë¡œ
        column: ë¶„ì„í•  ì»¬ëŸ¼ ì´ë¦„
    """
    try:
        df = pd.read_csv(file_path)
        stats = df[column].describe()
        return f"{column} í†µê³„:\n{stats.to_string()}"
    except Exception as e:
        return f"ë¶„ì„ ì˜¤ë¥˜: {str(e)}"

# ë°ì´í„° í•„í„°ë§ ë„êµ¬
@tool
def filter_data(file_path: str, condition: str) -> str:
    """ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤.

    Args:
        file_path: CSV íŒŒì¼ ê²½ë¡œ
        condition: í•„í„° ì¡°ê±´ (ì˜ˆ: "age > 30", "city == 'Seoul'")
    """
    try:
        df = pd.read_csv(file_path)
        filtered = df.query(condition)
        return f"í•„í„° ê²°ê³¼ ({len(filtered)}í–‰):\n{filtered.head(10).to_string()}"
    except Exception as e:
        return f"í•„í„°ë§ ì˜¤ë¥˜: {str(e)}"

# ë°ì´í„° ë¶„ì„ ë„êµ¬
data_tools = [load_csv, analyze_statistics, filter_data]

# ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸
def data_analyst(state: GraphState):
    system_prompt = SystemMessage("""ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ì „ë¬¸ AIì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ë°ì´í„° ë¶„ì„ ìš”ì²­ì— ëŒ€í•´:
1. ë¨¼ì € ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ êµ¬ì¡° íŒŒì•…
2. í•„ìš”í•œ í†µê³„ ë¶„ì„ ìˆ˜í–‰
3. í•„í„°ë§ì´ë‚˜ ì§‘ê³„ê°€ í•„ìš”í•˜ë©´ í•´ë‹¹ ë„êµ¬ ì‚¬ìš©
4. ë¶„ì„ ê²°ê³¼ë¥¼ ëª…í™•í•˜ê²Œ ì„¤ëª…

í•­ìƒ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ê°ê´€ì ì¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”.
""")

    messages = [system_prompt] + state['messages']
    llm_analyst = llm.bind_tools(tools=data_tools)
    response = llm_analyst.invoke(messages)
    return {"messages": [response]}

# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(GraphState)
builder.add_node("agent", data_analyst)
builder.add_node("tools", ToolNode(data_tools))
builder.add_edge(START, "agent")
builder.add_conditional_edges("agent", tools_condition)
builder.add_edge("tools", "agent")

analyst_graph = builder.compile()

# ë°ì´í„° ë¶„ì„ ìš”ì²­ ì˜ˆì‹œ
print("=" * 80)
print("ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸")
print("=" * 80)

# ì‹¤ì œ ì‚¬ìš© ì‹œì—ëŠ” CSV íŒŒì¼ ê²½ë¡œë¥¼ ì œê³µ
inputs = {"messages": [HumanMessage(content="""
sales_data.csv íŒŒì¼ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.
íŠ¹íˆ ë§¤ì¶œì´ 100ë§Œì› ì´ìƒì¸ ê±°ë˜ë§Œ í•„í„°ë§í•˜ê³ ,
í‰ê·  ë§¤ì¶œê³¼ ìµœëŒ€ ë§¤ì¶œì„ ì•Œë ¤ì£¼ì„¸ìš”.
""")]}

# messages = analyst_graph.invoke(inputs)
# for m in messages['messages']:
#     m.pretty_print()
```

**ì‹¤ë¬´ í™œìš© ê°€ì¹˜**:
- ë°˜ë³µì ì¸ ë°ì´í„° ë¶„ì„ ì‘ì—… ìë™í™”
- ë¹„ê¸°ìˆ  ì‚¬ìš©ìë„ ìì—°ì–´ë¡œ ë°ì´í„° ë¶„ì„ ê°€ëŠ¥
- ë³µì¡í•œ ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ ì—ì´ì „íŠ¸ê°€ ììœ¨ì ìœ¼ë¡œ êµ¬ì„±

## ğŸ“– ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [LangGraph ê³µì‹ ë¬¸ì„œ](https://langchain-ai.github.io/langgraph/)
- [LangGraph ReAct Agent ê°€ì´ë“œ](https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/)
- [LangChain Tools ë¬¸ì„œ](https://python.langchain.com/docs/modules/tools/)
- [ToolNode API ì°¸ì¡°](https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode)

### ReAct íŒ¨í„´ ë…¼ë¬¸
- [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629)
- ì› ë…¼ë¬¸ì—ì„œ ì œì•ˆëœ Reasoning-Acting ê²°í•© ì ‘ê·¼ë²•

### ë„êµ¬ ì •ì˜ íŒ¨í„´
- [@tool ë°ì½”ë ˆì´í„° ì‚¬ìš©ë²•](https://python.langchain.com/docs/how_to/custom_tools/)
- [StructuredTool í´ë˜ìŠ¤](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.structured.StructuredTool.html)
- [LangChain ë‚´ì¥ ë„êµ¬ ëª©ë¡](https://python.langchain.com/docs/integrations/tools/)

### ì¶”ê°€ í•™ìŠµ ìë£Œ
- [LangGraph íŠœí† ë¦¬ì–¼ ì‹œë¦¬ì¦ˆ](https://github.com/langchain-ai/langgraph/tree/main/examples)
- [ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬í˜„](https://langchain-ai.github.io/langgraph/tutorials/multi_agent/)
- [Human-in-the-Loop íŒ¨í„´](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/)

### ê´€ë ¨ ë¸”ë¡œê·¸ ë° íŠœí† ë¦¬ì–¼
- [Building Agentic RAG with LangGraph](https://blog.langchain.dev/agentic-rag-with-langgraph/)
- [Tool Calling in Production](https://python.langchain.com/docs/use_cases/tool_use/)
- [Debugging LangGraph Applications](https://langchain-ai.github.io/langgraph/how-tos/debugging/)

---

**ë‹¤ìŒ í•™ìŠµ**: [LangGraph ê³ ê¸‰ íŒ¨í„´ - Human-in-the-Loop, ë©”ëª¨ë¦¬ ê´€ë¦¬, ìŠ¤íŠ¸ë¦¬ë°]
