# W2_007_Retriever.md - RAG ì²´ì¸ê³¼ ê²€ìƒ‰ê¸° êµ¬í˜„

## ğŸ¯ í•™ìŠµ ëª©í‘œ

- RAG ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œì˜ êµ¬ì„± ìš”ì†Œì™€ ë™ì‘ ì›ë¦¬ë¥¼ ì´í•´í•©ë‹ˆë‹¤
- ë‹¤ì–‘í•œ ê²€ìƒ‰ ì „ëµ(Top-K, ì„ê³„ê°’, MMR, í•„í„°ë§)ì„ í™œìš©í•œ ê²€ìƒ‰ê¸°ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤
- LangChainì˜ LCEL ë¬¸ë²•ì„ ì‚¬ìš©í•œ RAG ì²´ì¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤
- Gradioë¥¼ í™œìš©í•œ ìŠ¤íŠ¸ë¦¬ë° ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤
- ì‹¤ë¬´ì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” Naive RAG ì‹œìŠ¤í…œì„ ì™„ì„±í•©ë‹ˆë‹¤

## ğŸ“š í•µì‹¬ ê°œë…

### 1. RAG(Retrieval-Augmented Generation) ì²´ê³„

RAGëŠ” ì •ë³´ ê²€ìƒ‰ê³¼ ìƒì„±ì„ ê²°í•©í•œ AI ì‹œìŠ¤í…œìœ¼ë¡œ, ë‹¤ìŒ ì„¸ ë‹¨ê³„ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:

```python
# RAG íŒŒì´í”„ë¼ì¸ êµ¬ì¡°
query â†’ retrieval â†’ augmentation â†’ generation
```

**ì£¼ìš” êµ¬ì„± ìš”ì†Œ:**
- **Retriever**: ì§ˆì˜ì™€ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” êµ¬ì„± ìš”ì†Œ
- **Prompt Template**: ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ì™€ ì§ˆì˜ë¥¼ êµ¬ì¡°í™”
- **LLM**: ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µì„ ìƒì„±
- **Output Parser**: ì‘ë‹µì„ ì›í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜

### 2. ê²€ìƒ‰ê¸°(Retriever) ìœ í˜•

#### 2.1 Top-K ê²€ìƒ‰
ê°€ì¥ ìœ ì‚¬í•œ ìƒìœ„ Kê°œ ë¬¸ì„œë¥¼ ë°˜í™˜í•˜ëŠ” ê¸°ë³¸ì ì¸ ê²€ìƒ‰ ë°©ì‹ì…ë‹ˆë‹¤.

```python
retriever = vectorstore.as_retriever(
    search_kwargs={"k": 5}  # ìƒìœ„ 5ê°œ ë¬¸ì„œ ê²€ìƒ‰
)
```

#### 2.2 Similarity Score Threshold
ìœ ì‚¬ë„ ì ìˆ˜ê°€ ì„ê³„ê°’ ì´ìƒì¸ ë¬¸ì„œë§Œ ê²€ìƒ‰í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.

```python
retriever = vectorstore.as_retriever(
    search_type='similarity_score_threshold',
    search_kwargs={'score_threshold': 0.7, 'k': 10}
)
```

#### 2.3 MMR(Maximal Marginal Relevance)
ê´€ë ¨ì„±ê³¼ ë‹¤ì–‘ì„±ì„ ë™ì‹œì— ê³ ë ¤í•˜ì—¬ ê²€ìƒ‰í•˜ëŠ” ê³ ê¸‰ ê¸°ë²•ì…ë‹ˆë‹¤.

```python
retriever = vectorstore.as_retriever(
    search_type='mmr',
    search_kwargs={
        'k': 5,              # ìµœì¢… ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜
        'fetch_k': 20,       # í›„ë³´ ë¬¸ì„œ ìˆ˜
        'lambda_mult': 0.5   # ê´€ë ¨ì„± vs ë‹¤ì–‘ì„± ê· í˜• (0~1)
    }
)
```

**MMR ìˆ˜ì‹:**
```
MMR = argmax[D_i âˆˆ R\S] [Î» * Simâ‚(D_i, Q) - (1-Î») * max[D_j âˆˆ S] Simâ‚‚(D_i, D_j)]
```

#### 2.4 ë©”íƒ€ë°ì´í„° í•„í„°ë§
ë¬¸ì„œì˜ ë©”íƒ€ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ ë²”ìœ„ë¥¼ ì œí•œí•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.

```python
retriever = vectorstore.as_retriever(
    search_kwargs={
        'filter': {'source': 'document.pdf', 'category': 'technical'},
        'k': 5
    }
)
```

### 3. LCEL(LangChain Expression Language)

LangChainì˜ íŒŒì´í”„ë¼ì¸ êµ¬ì„± ë¬¸ë²•ìœ¼ë¡œ, ì²´ì¸ì„ ì§ê´€ì ìœ¼ë¡œ ì—°ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)
```

## ğŸ”§ í™˜ê²½ ì„¤ì •

### 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

```bash
# uv ì‚¬ìš© (ê¶Œì¥)
uv add langchain langchain-community langchain-openai langchain-chroma langchain-huggingface
uv add faiss-cpu gradio python-dotenv pypdf2

# pip ì‚¬ìš©
pip install langchain langchain-community langchain-openai langchain-chroma langchain-huggingface
pip install faiss-cpu gradio python-dotenv pypdf2
```

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
# .env íŒŒì¼ì— ì¶”ê°€
OPENAI_API_KEY=your_openai_api_key
HUGGINGFACEHUB_API_TOKEN=your_huggingface_token
```

### 3. ê¸°ë³¸ ì„í¬íŠ¸

```python
import os
from dotenv import load_dotenv
from pprint import pprint
import json
import uuid
from typing import Iterator, List, Dict, Any

# LangChain ê´€ë ¨
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface.embeddings import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_community.vectorstores import FAISS
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬
import faiss
import gradio as gr

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
```

## ğŸ’» ì½”ë“œ ì˜ˆì œ

### 1. ë¬¸ì„œ ë¡œë”© ë° ì „ì²˜ë¦¬

```python
class DocumentProcessor:
    def __init__(self, embedding_model: str = "BAAI/bge-m3"):
        """ë¬¸ì„œ ì²˜ë¦¬ í´ë˜ìŠ¤ ì´ˆê¸°í™”"""
        self.embeddings = HuggingFaceEmbeddings(model_name=embedding_model)
        self.tokenizer = self.embeddings._client.tokenizer

    def count_tokens(self, text: str) -> int:
        """í…ìŠ¤íŠ¸ì˜ í† í° ìˆ˜ ê³„ì‚°"""
        return len(self.tokenizer(text)['input_ids'])

    def load_and_split_pdf(
        self,
        pdf_path: str,
        chunk_size: int = 500,
        chunk_overlap: int = 100
    ) -> List[Dict[str, Any]]:
        """PDF ë¬¸ì„œ ë¡œë”© ë° ì²­í¬ ë¶„í• """

        # PDF ë¡œë” ì´ˆê¸°í™”
        loader = PyPDFLoader(pdf_path)
        documents = loader.load()

        # í…ìŠ¤íŠ¸ ë¶„í• ê¸° ìƒì„±
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            length_function=self.count_tokens,
            separators=["\n\n", "\n", " ", ""]
        )

        # ë¬¸ì„œ ë¶„í• 
        chunks = splitter.split_documents(documents)

        print(f"ì›ë³¸ ë¬¸ì„œ ìˆ˜: {len(documents)}")
        print(f"ìƒì„±ëœ ì²­í¬ ìˆ˜: {len(chunks)}")
        print(f"í‰ê·  ì²­í¬ í† í° ìˆ˜: {sum(self.count_tokens(chunk.page_content) for chunk in chunks) / len(chunks):.1f}")

        return chunks

# ì‚¬ìš© ì˜ˆì‹œ
processor = DocumentProcessor()
chunks = processor.load_and_split_pdf('./data/transformer.pdf')
```

### 2. ë‹¤ì–‘í•œ ê²€ìƒ‰ê¸° êµ¬í˜„

```python
class AdvancedRetrieverManager:
    def __init__(self, chunks: List[Dict[str, Any]], embedding_model: str = "BAAI/bge-m3"):
        """ê³ ê¸‰ ê²€ìƒ‰ê¸° ê´€ë¦¬ í´ë˜ìŠ¤"""
        self.chunks = chunks
        self.embeddings = HuggingFaceEmbeddings(model_name=embedding_model)
        self.vectorstores = {}
        self.retrievers = {}

    def create_chroma_vectorstore(self, collection_name: str = "documents") -> None:
        """Chroma ë²¡í„° ìŠ¤í† ì–´ ìƒì„±"""
        self.vectorstores['chroma'] = Chroma.from_documents(
            documents=self.chunks,
            embedding=self.embeddings,
            collection_name=collection_name,
            persist_directory="./chroma_db",
            collection_metadata={'hnsw:space': 'cosine'}
        )

    def create_faiss_vectorstore(self) -> None:
        """FAISS ë²¡í„° ìŠ¤í† ì–´ ìƒì„±"""
        # ì„ë² ë”© ì°¨ì› í™•ì¸
        test_embedding = self.embeddings.embed_query("test")
        dim = len(test_embedding)

        # FAISS ì¸ë±ìŠ¤ ìƒì„± (ìœ í´ë¦¬ë“œ ê±°ë¦¬)
        faiss_index = faiss.IndexFlatL2(dim)

        # FAISS ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
        faiss_db = FAISS(
            embedding_function=self.embeddings,
            index=faiss_index,
            docstore=InMemoryDocstore(),
            index_to_docstore_id={}
        )

        # ë¬¸ì„œ ì¶”ê°€
        doc_ids = [str(uuid.uuid4()) for _ in range(len(self.chunks))]
        faiss_db.add_documents(self.chunks, ids=doc_ids)

        self.vectorstores['faiss'] = faiss_db

    def create_top_k_retriever(self, vectorstore_type: str = "chroma", k: int = 5) -> None:
        """Top-K ê²€ìƒ‰ê¸° ìƒì„±"""
        if vectorstore_type not in self.vectorstores:
            raise ValueError(f"ë²¡í„° ìŠ¤í† ì–´ '{vectorstore_type}'ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        self.retrievers[f'{vectorstore_type}_top_k'] = self.vectorstores[vectorstore_type].as_retriever(
            search_kwargs={"k": k}
        )

    def create_threshold_retriever(
        self,
        vectorstore_type: str = "chroma",
        threshold: float = 0.5,
        k: int = 10
    ) -> None:
        """ì„ê³„ê°’ ê¸°ë°˜ ê²€ìƒ‰ê¸° ìƒì„±"""
        if vectorstore_type not in self.vectorstores:
            raise ValueError(f"ë²¡í„° ìŠ¤í† ì–´ '{vectorstore_type}'ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        self.retrievers[f'{vectorstore_type}_threshold'] = self.vectorstores[vectorstore_type].as_retriever(
            search_type='similarity_score_threshold',
            search_kwargs={'score_threshold': threshold, 'k': k}
        )

    def create_mmr_retriever(
        self,
        vectorstore_type: str = "chroma",
        k: int = 5,
        fetch_k: int = 20,
        lambda_mult: float = 0.5
    ) -> None:
        """MMR ê²€ìƒ‰ê¸° ìƒì„±"""
        if vectorstore_type not in self.vectorstores:
            raise ValueError(f"ë²¡í„° ìŠ¤í† ì–´ '{vectorstore_type}'ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        self.retrievers[f'{vectorstore_type}_mmr'] = self.vectorstores[vectorstore_type].as_retriever(
            search_type='mmr',
            search_kwargs={
                'k': k,
                'fetch_k': fetch_k,
                'lambda_mult': lambda_mult
            }
        )

    def create_metadata_retriever(
        self,
        vectorstore_type: str = "chroma",
        filter_dict: Dict[str, Any] = None,
        k: int = 5
    ) -> None:
        """ë©”íƒ€ë°ì´í„° í•„í„°ë§ ê²€ìƒ‰ê¸° ìƒì„±"""
        if vectorstore_type not in self.vectorstores:
            raise ValueError(f"ë²¡í„° ìŠ¤í† ì–´ '{vectorstore_type}'ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        if filter_dict is None:
            filter_dict = {}

        self.retrievers[f'{vectorstore_type}_metadata'] = self.vectorstores[vectorstore_type].as_retriever(
            search_kwargs={'filter': filter_dict, 'k': k}
        )

    def test_retrievers(self, query: str) -> Dict[str, List[Dict[str, Any]]]:
        """ëª¨ë“  ê²€ìƒ‰ê¸° í…ŒìŠ¤íŠ¸"""
        results = {}

        for retriever_name, retriever in self.retrievers.items():
            try:
                docs = retriever.invoke(query)
                results[retriever_name] = [
                    {
                        'content': doc.page_content[:100] + "..." if len(doc.page_content) > 100 else doc.page_content,
                        'metadata': doc.metadata,
                        'full_content_length': len(doc.page_content)
                    }
                    for doc in docs
                ]
            except Exception as e:
                results[retriever_name] = f"ì˜¤ë¥˜: {str(e)}"

        return results

    def get_retriever(self, name: str):
        """íŠ¹ì • ê²€ìƒ‰ê¸° ë°˜í™˜"""
        if name not in self.retrievers:
            raise ValueError(f"ê²€ìƒ‰ê¸° '{name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ê²€ìƒ‰ê¸°: {list(self.retrievers.keys())}")
        return self.retrievers[name]

# ì‚¬ìš© ì˜ˆì‹œ
retriever_manager = AdvancedRetrieverManager(chunks)

# ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
retriever_manager.create_chroma_vectorstore()
retriever_manager.create_faiss_vectorstore()

# ë‹¤ì–‘í•œ ê²€ìƒ‰ê¸° ìƒì„±
retriever_manager.create_top_k_retriever("chroma", k=3)
retriever_manager.create_mmr_retriever("faiss", k=3, lambda_mult=0.3)
retriever_manager.create_threshold_retriever("chroma", threshold=0.6)

# ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
test_query = "ëŒ€í‘œì ì¸ ì‹œí€€ìŠ¤ ëª¨ë¸ì€ ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”?"
results = retriever_manager.test_retrievers(test_query)

for retriever_name, result in results.items():
    print(f"\n=== {retriever_name} ===")
    if isinstance(result, str):
        print(result)
    else:
        for i, doc in enumerate(result, 1):
            print(f"{i}. {doc['content']}")
```

### 3. RAG ì²´ì¸ êµ¬ì„±

```python
class RAGChain:
    def __init__(self, retriever, model_name: str = "gpt-4.1-mini", temperature: float = 0.0):
        """RAG ì²´ì¸ í´ë˜ìŠ¤"""
        self.retriever = retriever
        self.llm = ChatOpenAI(model=model_name, temperature=temperature)
        self.prompt = self._create_prompt()
        self.chain = self._build_chain()

    def _create_prompt(self) -> ChatPromptTemplate:
        """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±"""
        template = """ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”. ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³ , ëª¨ë¥´ê² ë‹¤ê³  ë‹µí•˜ì„¸ìš”.

[ì‘ì—… ì§€ì¹¨]
- ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ì˜ ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”
- ì™¸ë¶€ ì§€ì‹ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ë§ê³  ëª…í™•íˆ í‘œì‹œí•˜ì„¸ìš”
- ë‹µë³€í•  ìˆ˜ ì—†ë‹¤ë©´ ì†”ì§íˆ ë§í•˜ì„¸ìš”

[ì»¨í…ìŠ¤íŠ¸]
{context}

[ì§ˆë¬¸]
{question}

[ë‹µë³€]
ìœ„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤:

**í•µì‹¬ ë‹µë³€:**

**ê·¼ê±°:**

**ì¶”ê°€ ì„¤ëª… (í•´ë‹¹ë˜ëŠ” ê²½ìš°):**

ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë©°, ì‚¬ì‹¤ì— ê¸°ë°˜í•˜ì—¬ ëª…í™•í•˜ê²Œ ì œì‹œí•˜ê² ìŠµë‹ˆë‹¤."""

        return ChatPromptTemplate.from_template(template)

    def _format_docs(self, docs) -> str:
        """ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        return "\n\n".join([f"ë¬¸ì„œ {i+1}:\n{doc.page_content}" for i, doc in enumerate(docs)])

    def _build_chain(self):
        """LCELì„ ì‚¬ìš©í•œ ì²´ì¸ êµ¬ì„±"""
        return (
            {
                "context": self.retriever | self._format_docs,
                "question": RunnablePassthrough()
            }
            | self.prompt
            | self.llm
            | StrOutputParser()
        )

    def invoke(self, query: str) -> str:
        """ë™ê¸° ì‹¤í–‰"""
        return self.chain.invoke(query)

    def stream(self, query: str):
        """ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰"""
        return self.chain.stream(query)

    async def ainvoke(self, query: str) -> str:
        """ë¹„ë™ê¸° ì‹¤í–‰"""
        return await self.chain.ainvoke(query)

    async def astream(self, query: str):
        """ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰"""
        return self.chain.astream(query)

    def get_context_and_answer(self, query: str) -> Dict[str, Any]:
        """ì»¨í…ìŠ¤íŠ¸ì™€ ë‹µë³€ì„ í•¨ê»˜ ë°˜í™˜"""
        # ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ ê°€ì ¸ì˜¤ê¸°
        retrieved_docs = self.retriever.invoke(query)

        # ì²´ì¸ ì‹¤í–‰
        answer = self.invoke(query)

        return {
            'question': query,
            'context_docs': [
                {
                    'content': doc.page_content,
                    'metadata': doc.metadata
                }
                for doc in retrieved_docs
            ],
            'answer': answer,
            'num_context_docs': len(retrieved_docs)
        }

# ì‚¬ìš© ì˜ˆì‹œ
# ê²€ìƒ‰ê¸° ì„ íƒ (ì•ì„œ ìƒì„±í•œ ê²€ìƒ‰ê¸° ì‚¬ìš©)
selected_retriever = retriever_manager.get_retriever("faiss_mmr")

# RAG ì²´ì¸ ìƒì„±
rag_chain = RAGChain(
    retriever=selected_retriever,
    model_name="gpt-4.1-mini",
    temperature=0.0
)

# ì§ˆì˜ì‘ë‹µ í…ŒìŠ¤íŠ¸
test_queries = [
    "ëŒ€í‘œì ì¸ ì‹œí€€ìŠ¤ ëª¨ë¸ì€ ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”?",
    "Transformerì˜ ì£¼ìš” íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?"
]

for query in test_queries:
    print(f"\nì§ˆë¬¸: {query}")
    result = rag_chain.get_context_and_answer(query)
    print(f"ë‹µë³€: {result['answer']}")
    print(f"ì°¸ì¡° ë¬¸ì„œ ìˆ˜: {result['num_context_docs']}")
```

### 4. Gradio ìŠ¤íŠ¸ë¦¬ë° ì¸í„°í˜ì´ìŠ¤

```python
class RAGChatInterface:
    def __init__(self, rag_chain: RAGChain):
        """RAG ì±„íŒ… ì¸í„°í˜ì´ìŠ¤"""
        self.rag_chain = rag_chain

    def streaming_response(self, message: str, history) -> Iterator[str]:
        """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±"""
        response = ""
        try:
            for chunk in self.rag_chain.stream(message):
                if isinstance(chunk, str):
                    response += chunk
                    yield response
        except Exception as e:
            yield f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def create_interface(self) -> gr.ChatInterface:
        """Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""
        interface = gr.ChatInterface(
            fn=self.streaming_response,
            title="ğŸ¤– RAG ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ",
            description="PDF ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.",
            examples=[
                "ëŒ€í‘œì ì¸ ì‹œí€€ìŠ¤ ëª¨ë¸ì€ ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”?",
                "Transformerì˜ ì£¼ìš” íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                "ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?",
                "ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                "RNNê³¼ CNNì˜ í•œê³„ì ì€ ë¬´ì—‡ì¸ê°€ìš”?"
            ],
            cache_examples=False,
            theme=gr.themes.Soft(),
            css="""
            .gradio-container {
                max-width: 800px !important;
                margin: auto !important;
            }
            .chat-message {
                font-size: 14px !important;
            }
            """
        )
        return interface

    def launch(self, **kwargs):
        """ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰"""
        interface = self.create_interface()
        return interface.launch(**kwargs)

# ì‚¬ìš© ì˜ˆì‹œ
chat_interface = RAGChatInterface(rag_chain)

# ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰ (ê°œë°œ í™˜ê²½)
if __name__ == "__main__":
    demo = chat_interface.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,  # ê³µê°œ ë§í¬ ìƒì„± ì—¬ë¶€
        debug=True    # ë””ë²„ê·¸ ëª¨ë“œ
    )
```

## ğŸš€ ì‹¤ìŠµí•´ë³´ê¸°

### ì‹¤ìŠµ 1: ë‹¤ì¤‘ ê²€ìƒ‰ ì „ëµ ë¹„êµ ì‹œìŠ¤í…œ

ë‹¤ì–‘í•œ ê²€ìƒ‰ ì „ëµì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬í˜„í•´ë³´ì„¸ìš”.

```python
# ì—¬ëŸ¬ ê²€ìƒ‰ê¸°ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ëŠ” ì‹œìŠ¤í…œ êµ¬í˜„
class RetrieverComparison:
    def __init__(self, chunks, test_queries):
        # ì´ˆê¸°í™” ì½”ë“œ ì‘ì„±
        pass

    def compare_retrievers(self, query):
        # ì—¬ëŸ¬ ê²€ìƒ‰ê¸° ê²°ê³¼ ë¹„êµ ì½”ë“œ ì‘ì„±
        pass

    def evaluate_relevance(self, query, docs):
        # ê²€ìƒ‰ ê²°ê³¼ì˜ ê´€ë ¨ì„± í‰ê°€ ì½”ë“œ ì‘ì„±
        pass
```

### ì‹¤ìŠµ 2: ì ì‘í˜• ê²€ìƒ‰ê¸° êµ¬í˜„

ì§ˆë¬¸ì˜ íŠ¹ì„±ì— ë”°ë¼ ìµœì ì˜ ê²€ìƒ‰ ì „ëµì„ ìë™ ì„ íƒí•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬í˜„í•´ë³´ì„¸ìš”.

```python
# ì§ˆë¬¸ ë¶„ì„ í›„ ìµœì  ê²€ìƒ‰ê¸° ì„ íƒ ì‹œìŠ¤í…œ
class AdaptiveRetriever:
    def __init__(self, retriever_manager):
        # ì´ˆê¸°í™” ì½”ë“œ ì‘ì„±
        pass

    def analyze_query_type(self, query):
        # ì§ˆë¬¸ ìœ í˜• ë¶„ì„ ì½”ë“œ ì‘ì„±
        pass

    def select_best_retriever(self, query):
        # ìµœì  ê²€ìƒ‰ê¸° ì„ íƒ ì½”ë“œ ì‘ì„±
        pass
```

### ì‹¤ìŠµ 3: ë©€í‹°ëª¨ë‹¬ RAG ì‹œìŠ¤í…œ

í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ëª¨ë‘ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” RAG ì‹œìŠ¤í…œì„ êµ¬í˜„í•´ë³´ì„¸ìš”.

```python
# í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ í•¨ê»˜ ì²˜ë¦¬í•˜ëŠ” RAG ì‹œìŠ¤í…œ
class MultimodalRAG:
    def __init__(self):
        # ì´ˆê¸°í™” ì½”ë“œ ì‘ì„± (í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ ì„ë² ë”© ëª¨ë¸)
        pass

    def process_multimodal_documents(self, documents):
        # ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ ì²˜ë¦¬ ì½”ë“œ ì‘ì„±
        pass

    def hybrid_search(self, query, query_type="text"):
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì½”ë“œ ì‘ì„±
        pass
```

## ğŸ“‹ í•´ë‹µ

### ì‹¤ìŠµ 1: ë‹¤ì¤‘ ê²€ìƒ‰ ì „ëµ ë¹„êµ ì‹œìŠ¤í…œ

```python
class RetrieverComparison:
    def __init__(self, chunks: List[Dict[str, Any]], test_queries: List[str]):
        """ê²€ìƒ‰ê¸° ë¹„êµ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.chunks = chunks
        self.test_queries = test_queries
        self.embeddings = HuggingFaceEmbeddings(model_name="BAAI/bge-m3")

        # ì—¬ëŸ¬ ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
        self.retriever_manager = AdvancedRetrieverManager(chunks)
        self.retriever_manager.create_chroma_vectorstore()
        self.retriever_manager.create_faiss_vectorstore()

        # ë‹¤ì–‘í•œ ê²€ìƒ‰ê¸° ìƒì„±
        self.retriever_manager.create_top_k_retriever("chroma", k=3)
        self.retriever_manager.create_mmr_retriever("chroma", k=3, lambda_mult=0.5)
        self.retriever_manager.create_mmr_retriever("faiss", k=3, lambda_mult=0.3)
        self.retriever_manager.create_threshold_retriever("chroma", threshold=0.6)

    def calculate_cosine_similarity(self, query: str, doc_content: str) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        query_embedding = self.embeddings.embed_query(query)
        doc_embedding = self.embeddings.embed_query(doc_content)

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        dot_product = sum(a * b for a, b in zip(query_embedding, doc_embedding))
        norm_a = sum(a * a for a in query_embedding) ** 0.5
        norm_b = sum(b * b for b in doc_embedding) ** 0.5

        return dot_product / (norm_a * norm_b) if norm_a * norm_b > 0 else 0.0

    def evaluate_relevance(self, query: str, docs: List[Any]) -> Dict[str, float]:
        """ê²€ìƒ‰ ê²°ê³¼ì˜ ê´€ë ¨ì„± í‰ê°€"""
        if not docs:
            return {'avg_similarity': 0.0, 'max_similarity': 0.0, 'num_docs': 0}

        similarities = []
        for doc in docs:
            similarity = self.calculate_cosine_similarity(query, doc.page_content)
            similarities.append(similarity)

        return {
            'avg_similarity': sum(similarities) / len(similarities),
            'max_similarity': max(similarities),
            'min_similarity': min(similarities),
            'num_docs': len(docs),
            'similarity_std': (sum((s - sum(similarities)/len(similarities))**2 for s in similarities) / len(similarities))**0.5
        }

    def compare_retrievers(self, query: str) -> Dict[str, Dict[str, Any]]:
        """ì—¬ëŸ¬ ê²€ìƒ‰ê¸° ê²°ê³¼ ë¹„êµ"""
        results = {}

        for retriever_name, retriever in self.retriever_manager.retrievers.items():
            try:
                # ê²€ìƒ‰ ì‹¤í–‰
                docs = retriever.invoke(query)

                # ê´€ë ¨ì„± í‰ê°€
                relevance_metrics = self.evaluate_relevance(query, docs)

                # ê²°ê³¼ ì €ì¥
                results[retriever_name] = {
                    'retrieved_docs': [
                        {
                            'content': doc.page_content[:150] + "...",
                            'metadata': doc.metadata,
                            'similarity': self.calculate_cosine_similarity(query, doc.page_content)
                        }
                        for doc in docs
                    ],
                    'metrics': relevance_metrics,
                    'execution_time': None  # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì‹œê°„ ì¸¡ì • ì¶”ê°€
                }

            except Exception as e:
                results[retriever_name] = {
                    'error': str(e),
                    'retrieved_docs': [],
                    'metrics': {'avg_similarity': 0.0}
                }

        return results

    def run_comprehensive_evaluation(self) -> Dict[str, Any]:
        """ì¢…í•© í‰ê°€ ì‹¤í–‰"""
        overall_results = {}

        for query in self.test_queries:
            print(f"\ní‰ê°€ ì¤‘ì¸ ì§ˆë¬¸: {query}")
            query_results = self.compare_retrievers(query)
            overall_results[query] = query_results

        # ì „ì²´ ì„±ëŠ¥ ìš”ì•½
        summary = self._generate_summary(overall_results)

        return {
            'detailed_results': overall_results,
            'summary': summary
        }

    def _generate_summary(self, results: Dict[str, Any]) -> Dict[str, float]:
        """ì „ì²´ ê²°ê³¼ ìš”ì•½ ìƒì„±"""
        retriever_scores = {}

        for query, query_results in results.items():
            for retriever_name, retriever_result in query_results.items():
                if 'metrics' in retriever_result:
                    if retriever_name not in retriever_scores:
                        retriever_scores[retriever_name] = []
                    retriever_scores[retriever_name].append(
                        retriever_result['metrics']['avg_similarity']
                    )

        # í‰ê·  ì„±ëŠ¥ ê³„ì‚°
        summary = {}
        for retriever_name, scores in retriever_scores.items():
            summary[retriever_name] = {
                'avg_performance': sum(scores) / len(scores) if scores else 0,
                'query_count': len(scores)
            }

        return summary

# ì‹¤ìŠµ 1 í…ŒìŠ¤íŠ¸
test_queries = [
    "ëŒ€í‘œì ì¸ ì‹œí€€ìŠ¤ ëª¨ë¸ì€ ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”?",
    "Transformerì˜ ì£¼ìš” íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?"
]

comparison_system = RetrieverComparison(chunks, test_queries)
evaluation_results = comparison_system.run_comprehensive_evaluation()

# ê²°ê³¼ ì¶œë ¥
print("\n=== ê²€ìƒ‰ê¸° ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ ===")
for retriever_name, performance in evaluation_results['summary'].items():
    print(f"{retriever_name}: {performance['avg_performance']:.3f}")
```

### ì‹¤ìŠµ 2: ì ì‘í˜• ê²€ìƒ‰ê¸° êµ¬í˜„

```python
class AdaptiveRetriever:
    def __init__(self, retriever_manager: AdvancedRetrieverManager):
        """ì ì‘í˜• ê²€ìƒ‰ê¸° ì´ˆê¸°í™”"""
        self.retriever_manager = retriever_manager
        self.embeddings = HuggingFaceEmbeddings(model_name="BAAI/bge-m3")

        # ì§ˆë¬¸ ìœ í˜•ë³„ ìµœì  ê²€ìƒ‰ê¸° ë§¤í•‘
        self.strategy_mapping = {
            'factual': 'chroma_top_k',      # ì‚¬ì‹¤ì  ì§ˆë¬¸
            'comparative': 'faiss_mmr',     # ë¹„êµ ì§ˆë¬¸
            'conceptual': 'chroma_mmr',     # ê°œë…ì  ì§ˆë¬¸
            'specific': 'chroma_threshold', # íŠ¹ì • ì •ë³´ ì§ˆë¬¸
            'broad': 'faiss_mmr'           # ê´‘ë²”ìœ„í•œ ì§ˆë¬¸
        }

        # ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜ë¥¼ ìœ„í•œ í‚¤ì›Œë“œ
        self.type_keywords = {
            'factual': ['ë¬´ì—‡ì¸', 'ëˆ„êµ¬', 'ì–¸ì œ', 'ì–´ë””ì„œ', 'ëª‡', 'ì–¼ë§ˆë‚˜'],
            'comparative': ['ì°¨ì´', 'ë¹„êµ', 'ëŒ€ë¹„', 'vs', 'ë‹¤ë¥¸', 'ê°™ì€', 'ìœ ì‚¬í•œ'],
            'conceptual': ['ê°œë…', 'ì›ë¦¬', 'ì´ë¡ ', 'ë°©ì‹', 'ë°©ë²•', 'ê³¼ì •'],
            'specific': ['êµ¬ì²´ì ', 'ìì„¸íˆ', 'ì •í™•íˆ', 'ì˜ˆì‹œ', 'ì‚¬ë¡€'],
            'broad': ['ì „ë°˜ì ', 'ì¼ë°˜ì ', 'ëŒ€ëµ', 'ëŒ€ì²´ë¡œ', 'ì¢…í•©ì ']
        }

    def analyze_query_type(self, query: str) -> str:
        """ì§ˆë¬¸ ìœ í˜• ë¶„ì„"""
        query_lower = query.lower()

        # í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜
        type_scores = {}
        for query_type, keywords in self.type_keywords.items():
            score = sum(1 for keyword in keywords if keyword in query_lower)
            if score > 0:
                type_scores[query_type] = score

        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ìœ í˜• ë°˜í™˜
        if type_scores:
            return max(type_scores, key=type_scores.get)

        # ê¸°ë³¸ê°’: ê°œë…ì  ì§ˆë¬¸ìœ¼ë¡œ ë¶„ë¥˜
        return 'conceptual'

    def analyze_query_complexity(self, query: str) -> str:
        """ì§ˆë¬¸ ë³µì¡ë„ ë¶„ì„"""
        # ì§ˆë¬¸ ê¸¸ì´ ê¸°ë°˜ ë³µì¡ë„ ì¶”ì •
        if len(query) > 50:
            return 'complex'
        elif len(query) > 20:
            return 'medium'
        else:
            return 'simple'

    def select_best_retriever(self, query: str) -> tuple:
        """ìµœì  ê²€ìƒ‰ê¸° ì„ íƒ"""
        query_type = self.analyze_query_type(query)
        complexity = self.analyze_query_complexity(query)

        # ê¸°ë³¸ ê²€ìƒ‰ê¸° ì„ íƒ
        base_retriever_name = self.strategy_mapping.get(query_type, 'chroma_mmr')

        # ë³µì¡ë„ì— ë”°ë¥¸ ì¡°ì •
        if complexity == 'complex' and 'mmr' not in base_retriever_name:
            # ë³µì¡í•œ ì§ˆë¬¸ì€ MMR ì‚¬ìš©
            base_retriever_name = base_retriever_name.replace('top_k', 'mmr')

        # ê²€ìƒ‰ê¸° ë°˜í™˜
        try:
            retriever = self.retriever_manager.get_retriever(base_retriever_name)
            return retriever, base_retriever_name, query_type
        except ValueError:
            # ê¸°ë³¸ ê²€ìƒ‰ê¸°ë¡œ í´ë°±
            fallback_name = 'chroma_top_k'
            retriever = self.retriever_manager.get_retriever(fallback_name)
            return retriever, fallback_name, query_type

    def adaptive_search(self, query: str) -> Dict[str, Any]:
        """ì ì‘í˜• ê²€ìƒ‰ ì‹¤í–‰"""
        # ìµœì  ê²€ìƒ‰ê¸° ì„ íƒ
        retriever, retriever_name, query_type = self.select_best_retriever(query)

        # ê²€ìƒ‰ ì‹¤í–‰
        docs = retriever.invoke(query)

        # ê²°ê³¼ ë°˜í™˜
        return {
            'query': query,
            'selected_retriever': retriever_name,
            'query_type': query_type,
            'retrieved_docs': [
                {
                    'content': doc.page_content,
                    'metadata': doc.metadata
                }
                for doc in docs
            ],
            'num_docs': len(docs)
        }

    def batch_adaptive_search(self, queries: List[str]) -> List[Dict[str, Any]]:
        """ì—¬ëŸ¬ ì§ˆë¬¸ì— ëŒ€í•œ ì ì‘í˜• ê²€ìƒ‰"""
        results = []

        for query in queries:
            result = self.adaptive_search(query)
            results.append(result)

            print(f"ì§ˆë¬¸: {query}")
            print(f"ì„ íƒëœ ê²€ìƒ‰ê¸°: {result['selected_retriever']}")
            print(f"ì§ˆë¬¸ ìœ í˜•: {result['query_type']}")
            print(f"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {result['num_docs']}")
            print("-" * 50)

        return results

# ì‹¤ìŠµ 2 í…ŒìŠ¤íŠ¸
adaptive_retriever = AdaptiveRetriever(retriever_manager)

test_queries = [
    "RNNê³¼ CNNì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",  # comparative
    "ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì´ë€?",              # conceptual
    "Transformerì—ì„œ ì‚¬ìš©ë˜ëŠ” êµ¬ì²´ì ì¸ ìˆ˜ì‹ì„ ì•Œë ¤ì£¼ì„¸ìš”",  # specific
    "ë”¥ëŸ¬ë‹ì—ì„œ ì‹œí€€ìŠ¤ ì²˜ë¦¬ ë°©ë²•ë“¤ì„ ì „ë°˜ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”"  # broad
]

adaptive_results = adaptive_retriever.batch_adaptive_search(test_queries)
```

### ì‹¤ìŠµ 3: ë©€í‹°ëª¨ë‹¬ RAG ì‹œìŠ¤í…œ

```python
class MultimodalRAG:
    def __init__(self):
        """ë©€í‹°ëª¨ë‹¬ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        # í…ìŠ¤íŠ¸ ì„ë² ë”© ëª¨ë¸
        self.text_embeddings = HuggingFaceEmbeddings(model_name="BAAI/bge-m3")

        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” CLIP ê°™ì€ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ ì‚¬ìš©
        # ì—¬ê¸°ì„œëŠ” í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜

        self.text_vectorstore = None
        self.image_metadata_store = []
        self.multimodal_index = {}

    def extract_image_descriptions(self, image_path: str) -> str:
        """ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì„¤ëª… ì¶”ì¶œ (ì‹œë®¬ë ˆì´ì…˜)"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” OCR, ì´ë¯¸ì§€ ìº¡ì…”ë‹ ëª¨ë¸ ì‚¬ìš©
        import os
        filename = os.path.basename(image_path)

        # íŒŒì¼ëª… ê¸°ë°˜ ì„¤ëª… ìƒì„± (ì‹¤ì œë¡œëŠ” AI ëª¨ë¸ ì‚¬ìš©)
        descriptions = {
            'attention_diagram.png': 'Attention mechanism diagram showing query, key, value matrices',
            'transformer_architecture.png': 'Complete Transformer architecture with encoder and decoder',
            'positional_encoding.png': 'Positional encoding visualization with sinusoidal patterns'
        }

        return descriptions.get(filename, f"Image content from {filename}")

    def process_multimodal_documents(self, text_documents: List[Any], image_paths: List[str]) -> None:
        """ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ ì²˜ë¦¬"""
        all_documents = []

        # í…ìŠ¤íŠ¸ ë¬¸ì„œ ì²˜ë¦¬
        for doc in text_documents:
            doc.metadata['content_type'] = 'text'
            all_documents.append(doc)

        # ì´ë¯¸ì§€ ë¬¸ì„œ ì²˜ë¦¬
        for img_path in image_paths:
            description = self.extract_image_descriptions(img_path)

            # ì´ë¯¸ì§€ë¥¼ í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¬¸ì„œë¡œ ë³€í™˜
            from langchain.schema import Document
            img_document = Document(
                page_content=f"ì´ë¯¸ì§€ ì„¤ëª…: {description}",
                metadata={
                    'source': img_path,
                    'content_type': 'image',
                    'image_path': img_path
                }
            )
            all_documents.append(img_document)

            # ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì €ì¥
            self.image_metadata_store.append({
                'path': img_path,
                'description': description,
                'doc_id': len(all_documents) - 1
            })

        # í†µí•© ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
        self.text_vectorstore = FAISS.from_documents(
            all_documents,
            self.text_embeddings
        )

        print(f"ì²˜ë¦¬ëœ ë¬¸ì„œ ìˆ˜: {len(all_documents)}")
        print(f"í…ìŠ¤íŠ¸ ë¬¸ì„œ: {len(text_documents)}")
        print(f"ì´ë¯¸ì§€ ë¬¸ì„œ: {len(image_paths)}")

    def hybrid_search(self, query: str, query_type: str = "text", k: int = 5) -> Dict[str, Any]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰"""
        if self.text_vectorstore is None:
            raise ValueError("ë¨¼ì € process_multimodal_documents()ë¥¼ í˜¸ì¶œí•˜ì—¬ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ì„¸ìš”.")

        # ê¸°ë³¸ ìœ ì‚¬ë„ ê²€ìƒ‰
        retriever = self.text_vectorstore.as_retriever(
            search_type='mmr',
            search_kwargs={'k': k, 'lambda_mult': 0.5}
        )

        docs = retriever.invoke(query)

        # ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¡œ ë¶„ë¥˜
        text_results = []
        image_results = []

        for doc in docs:
            if doc.metadata.get('content_type') == 'text':
                text_results.append(doc)
            elif doc.metadata.get('content_type') == 'image':
                image_results.append(doc)

        return {
            'query': query,
            'query_type': query_type,
            'text_results': [
                {
                    'content': doc.page_content[:200] + "...",
                    'metadata': doc.metadata
                }
                for doc in text_results
            ],
            'image_results': [
                {
                    'description': doc.page_content,
                    'image_path': doc.metadata.get('image_path'),
                    'metadata': doc.metadata
                }
                for doc in image_results
            ],
            'total_results': len(docs)
        }

    def create_multimodal_rag_chain(self, model_name: str = "gpt-4.1-mini"):
        """ë©€í‹°ëª¨ë‹¬ RAG ì²´ì¸ ìƒì„±"""
        from langchain.prompts import ChatPromptTemplate
        from langchain_openai import ChatOpenAI
        from langchain_core.output_parsers import StrOutputParser
        from langchain_core.runnables import RunnablePassthrough

        # ë©€í‹°ëª¨ë‹¬ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        template = """ë‹¤ìŒ í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ì„¤ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

[í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸]
{text_context}

[ì´ë¯¸ì§€ ì„¤ëª…]
{image_context}

[ì§ˆë¬¸]
{question}

[ë‹µë³€]
í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤:

**í•µì‹¬ ë‹µë³€:**

**í…ìŠ¤íŠ¸ ê¸°ë°˜ ê·¼ê±°:**

**ì´ë¯¸ì§€ ê¸°ë°˜ ê·¼ê±°:**

**ì¢…í•© ì„¤ëª…:**
"""

        prompt = ChatPromptTemplate.from_template(template)
        llm = ChatOpenAI(model=model_name, temperature=0)

        def format_multimodal_context(query: str) -> Dict[str, str]:
            """ë©€í‹°ëª¨ë‹¬ ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…"""
            search_results = self.hybrid_search(query)

            text_context = "\n\n".join([
                result['content'] for result in search_results['text_results']
            ])

            image_context = "\n\n".join([
                f"ì´ë¯¸ì§€: {result['description']}"
                for result in search_results['image_results']
            ])

            return {
                'text_context': text_context or "ê´€ë ¨ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                'image_context': image_context or "ê´€ë ¨ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                'question': query
            }

        # LCEL ì²´ì¸ êµ¬ì„±
        multimodal_chain = (
            RunnablePassthrough()
            | (lambda x: format_multimodal_context(x))
            | prompt
            | llm
            | StrOutputParser()
        )

        return multimodal_chain

# ì‹¤ìŠµ 3 í…ŒìŠ¤íŠ¸
multimodal_rag = MultimodalRAG()

# ì‹œë®¬ë ˆì´ì…˜ì„ ìœ„í•œ ì´ë¯¸ì§€ ê²½ë¡œ
image_paths = [
    './images/attention_diagram.png',
    './images/transformer_architecture.png',
    './images/positional_encoding.png'
]

# ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ ì²˜ë¦¬
multimodal_rag.process_multimodal_documents(chunks, image_paths)

# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
hybrid_results = multimodal_rag.hybrid_search("ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì˜ êµ¬ì¡°ë¥¼ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì£¼ì„¸ìš”")

print("=== í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼ ===")
print(f"í…ìŠ¤íŠ¸ ê²°ê³¼: {len(hybrid_results['text_results'])}ê°œ")
print(f"ì´ë¯¸ì§€ ê²°ê³¼: {len(hybrid_results['image_results'])}ê°œ")

for img_result in hybrid_results['image_results']:
    print(f"ì´ë¯¸ì§€: {img_result['image_path']}")
    print(f"ì„¤ëª…: {img_result['description']}")

# ë©€í‹°ëª¨ë‹¬ RAG ì²´ì¸ í…ŒìŠ¤íŠ¸
multimodal_chain = multimodal_rag.create_multimodal_rag_chain()
multimodal_answer = multimodal_chain.invoke("ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ ì‹œê°ì  ìë£Œì™€ í•¨ê»˜ ì„¤ëª…í•´ì£¼ì„¸ìš”")

print("\n=== ë©€í‹°ëª¨ë‹¬ RAG ë‹µë³€ ===")
print(multimodal_answer)
```

## ğŸ” ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [LangChain Retrievers](https://python.langchain.com/docs/modules/data_connection/retrievers/)
- [LangChain Expression Language (LCEL)](https://python.langchain.com/docs/expression_language/)
- [Chroma Vector Database](https://docs.trychroma.com/)
- [FAISS Documentation](https://faiss.ai/cpp_api/)
- [Gradio Documentation](https://gradio.app/docs/)

### í•™ìˆ  ìë£Œ
- Karpukhin, V., et al. (2020). "Dense Passage Retrieval for Open-Domain Question Answering"
- Lewis, P., et al. (2020). "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
- Zhu, F., et al. (2021). "Retrieving and Reading: A Comprehensive Survey on Open-domain Question Answering"

### ì‹¤ë¬´ ê°€ì´ë“œ
- [RAG System Design Patterns](https://docs.google.com/document/d/1example)
- [Vector Database Performance Comparison](https://example.com/vector-db-comparison)
- [Production RAG Deployment Guide](https://example.com/rag-deployment)

### ì¶”ê°€ í•™ìŠµ ìë£Œ
- [Hugging Face Embeddings Models](https://huggingface.co/models?pipeline_tag=feature-extraction)
- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)
- [Advanced RAG Techniques](https://example.com/advanced-rag)

---

**ë‹¤ìŒ í•™ìŠµ**: W3_001_Prompt_Engineering_Basic.md - í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê¸°ì´ˆì™€ íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ ì‘ì„±ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.