# W1_004_LangSmith_LCEL.md - LangSmithì™€ LCEL ë§ˆìŠ¤í„°í•˜ê¸°

## ğŸ¯ í•™ìŠµ ëª©í‘œ
- Langfuseë¥¼ í™œìš©í•œ LLM Observability êµ¬ì¶• ëŠ¥ë ¥ ìŠµë“
- LCEL(LangChain Expression Language) íŒŒì´í”„ë¼ì¸ êµ¬ì„±ë²• í•™ìŠµ
- Runnable ì¸í„°í˜ì´ìŠ¤ì˜ ë‹¤ì–‘í•œ ì‹¤í–‰ íŒ¨í„´ ì´í•´
- ë³µì¡í•œ ì²´ì¸ êµ¬ì¡° ì„¤ê³„ ë° ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ê¸°ë²• ìŠµë“

## ğŸ“š í•µì‹¬ ê°œë…

### Langfuse (LLM Observability)
- **ê´€ì°°ì„±(Observability)**: LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì‹¤í–‰ ê³¼ì •ê³¼ ì„±ëŠ¥ ì¶”ì 
- **ë””ë²„ê¹…**: ì²´ì¸ê³¼ ì—ì´ì „íŠ¸ì˜ íš¨ê³¼ì ì¸ ë””ë²„ê¹… ì§€ì›
- **ì„±ëŠ¥ ì¸¡ì •**: í† í° ì‚¬ìš©ëŸ‰, ì‹¤í–‰ ì‹œê°„, ë¹„ìš© ë¶„ì„
- **ì¶”ì **: ì „ì²´ íŒŒì´í”„ë¼ì¸ì˜ ë°ì´í„° íë¦„ ì‹œê°í™”

### LCEL (LangChain Expression Language)
- **ì„ ì–¸ì  ì²´ì´ë‹**: `|` ì—°ì‚°ìë¥¼ ì‚¬ìš©í•œ ì»´í¬ë„ŒíŠ¸ ì—°ê²°
- **ì¬ì‚¬ìš©ì„±**: ì •ì˜ëœ ì²´ì¸ì„ ë‹¤ë¥¸ ì²´ì¸ì˜ ì»´í¬ë„ŒíŠ¸ë¡œ í™œìš© ê°€ëŠ¥
- **ë‹¤ì–‘í•œ ì‹¤í–‰ ë°©ì‹**: `.invoke()`, `.batch()`, `.stream()`, `.astream()` ì§€ì›
- **ìë™ ìµœì í™”**: ë°°ì¹˜ ì²˜ë¦¬ ì‹œ íš¨ìœ¨ì ì¸ ì‘ì—… ìˆ˜í–‰

## ğŸ”§ í™˜ê²½ ì„¤ì •

### Langfuse ì„¤ì •

#### 1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
```bash
# .env íŒŒì¼
LANGFUSE_ENABLED=true
LANGFUSE_HOST=your_langfuse_host_url
LANGFUSE_SECRET_KEY=your_secret_key
LANGFUSE_PUBLIC_KEY=your_public_key
```

#### 2. Langfuse ì´ˆê¸°í™”
```python
from dotenv import load_dotenv
import os
from langfuse import Langfuse
from langfuse.langchain import CallbackHandler

load_dotenv()

# Langfuse í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
langfuse_client = Langfuse(
    public_key=os.getenv('LANGFUSE_PUBLIC_KEY'),
    secret_key=os.getenv('LANGFUSE_SECRET_KEY'),
    host=os.getenv('LANGFUSE_HOST')
)

# CallbackHandler ì´ˆê¸°í™”
langfuse_handler = CallbackHandler()

print("âœ… Langfuse ì´ˆê¸°í™” ì™„ë£Œ")
```

#### 3. ì—°ê²° ìƒíƒœ ì§„ë‹¨
```python
import requests

# ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸
host = os.getenv('LANGFUSE_HOST')
response = requests.get(f"{host}/api/public/health", timeout=10)
print(f"ì„œë²„ ìƒíƒœ: {response.status_code}")

# ì¸ì¦ ì •ë³´ í™•ì¸
public_key = os.getenv('LANGFUSE_PUBLIC_KEY')
secret_key = os.getenv('LANGFUSE_SECRET_KEY')
print(f"PUBLIC_KEY: {public_key[:10]}...")
print(f"SECRET_KEY: {secret_key[:10]}...")
```

## ğŸ’» LCEL ê¸°ë³¸ êµ¬ì¡°

### 1. Prompt + LLM ì²´ì¸

#### ê¸°ë³¸ êµ¬ì¡°
```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

# Langfuse ì¶”ì ì´ í™œì„±í™”ëœ ëª¨ë¸
llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0.3,
    callbacks=[langfuse_handler]
)

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
prompt = PromptTemplate.from_template(
    "ë‹¹ì‹ ì€ {topic} ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. {topic}ì— ê´€í•œ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\nì§ˆë¬¸: {question}\në‹µë³€:"
)

# ì²´ì¸ êµ¬ì„±
chain = prompt | llm

# ì‹¤í–‰
response = chain.invoke({
    "topic": "í™”í•™(Chemistry)",
    "question": "íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
})

print(f"ë‹µë³€: {response.content}")
```

### 2. Prompt + LLM + Output Parser

#### ì™„ì „í•œ íŒŒì´í”„ë¼ì¸
```python
# ì¶œë ¥ íŒŒì„œ ì¶”ê°€
output_parser = StrOutputParser()

# ì „ì²´ íŒŒì´í”„ë¼ì¸
chain = prompt | llm | output_parser

# ì‹¤í–‰ ê²°ê³¼ëŠ” ë¬¸ìì—´
result = chain.invoke({
    "topic": "í™”í•™(Chemistry)",
    "question": "íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
})

print(f"ê²°ê³¼: {result}")  # ë¬¸ìì—´ ì¶œë ¥
```

#### ì…ë ¥ ìŠ¤í‚¤ë§ˆ í™•ì¸
```python
# ì²´ì¸ì˜ ì…ë ¥ êµ¬ì¡° í™•ì¸
schema = chain.input_schema.model_json_schema()
print(f"í•„ìˆ˜ ì…ë ¥: {schema['required']}")
print(f"ì†ì„±: {list(schema['properties'].keys())}")
```

## ğŸ”„ Runnable ì¸í„°í˜ì´ìŠ¤

### 1. RunnableSequence (ìˆœì°¨ ì‹¤í–‰)

```python
from langchain_core.runnables import RunnableSequence

# ë²ˆì—­ ì²´ì¸ êµ¬ì„±
translation_prompt = PromptTemplate.from_template("'{text}'ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ë²ˆì—­ëœ ë¬¸ì¥ë§Œì„ ì¶œë ¥í•´ì£¼ì„¸ìš”.")

# RunnableSequence ìƒì„±
translation_chain = RunnableSequence(
    first=translation_prompt,
    middle=[llm],
    last=output_parser
)

# ì‹¤í–‰
result = translation_chain.invoke({"text": "ì•ˆë…•í•˜ì„¸ìš”"})
print(f"ë²ˆì—­ ê²°ê³¼: {result}")  # "Hello"
```

### 2. RunnableParallel (ë³‘ë ¬ ì‹¤í–‰)

#### ì§ˆë¬¸ ë¶„ì„ ì²´ì¸
```python
from langchain_core.runnables import RunnableParallel
from operator import itemgetter

# ì§ˆë¬¸ ë¶„ë¥˜ ì²´ì¸
question_prompt = PromptTemplate.from_template("""
ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ì…ë ¥ì„ ë¶„ë¥˜í•˜ì„¸ìš”:
- í™”í•™(Chemistry)
- ë¬¼ë¦¬(Physics)
- ìƒë¬¼(Biology)

ì§ˆë¬¸: {question}
ë¶„ë¥˜:""")

question_chain = question_prompt | llm | output_parser

# ì–¸ì–´ ê°ì§€ ì²´ì¸
language_prompt = PromptTemplate.from_template("""
ì…ë ¥ëœ í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ë¶„ë¥˜í•˜ì„¸ìš”:
- ì˜ì–´(English)
- í•œêµ­ì–´(Korean)
- ê¸°íƒ€(Others)

ì…ë ¥: {question}
ì–¸ì–´:""")

language_chain = language_prompt | llm | output_parser

# ë³‘ë ¬ ì‹¤í–‰ ì²´ì¸
parallel_chain = RunnableParallel({
    "topic": question_chain,
    "language": language_chain,
    "question": itemgetter("question")
})

# ì‹¤í–‰
result = parallel_chain.invoke({
    "question": "íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
})

print(f"ì£¼ì œ: {result['topic']}")      # í™”í•™(Chemistry)
print(f"ì–¸ì–´: {result['language']}")   # í•œêµ­ì–´(Korean)
print(f"ì§ˆë¬¸: {result['question']}")   # ì›ë³¸ ì§ˆë¬¸
```

### 3. RunnablePassthrough (ë°ì´í„° íˆ¬ê³¼)

```python
from langchain_core.runnables import RunnablePassthrough
import re

# ì…ë ¥ ë°ì´í„°ë¥¼ ë³´ì¡´í•˜ë©° ë³€í™˜
runnable = RunnableParallel({
    "passed": RunnablePassthrough(),  # ì›ë³¸ ë³´ì¡´
    "modified": lambda x: int(re.search(r'\d+', x).group())  # ìˆ«ì ì¶”ì¶œ
})

result = runnable.invoke('íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” 6ì…ë‹ˆë‹¤.')
print(f"ì›ë³¸: {result['passed']}")     # 'íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” 6ì…ë‹ˆë‹¤.'
print(f"ì¶”ì¶œëœ ìˆ«ì: {result['modified']}")  # 6
```

### 4. RunnableLambda (ì»¤ìŠ¤í…€ í•¨ìˆ˜)

```python
from langchain_core.runnables import RunnableLambda

# ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_text(text: str) -> str:
    return text.strip().lower()

# í›„ì²˜ë¦¬ í•¨ìˆ˜
def postprocess_response(response) -> dict:
    response_text = response.content
    return {
        "processed_response": response_text.upper(),
        "length": len(response_text)
    }

# ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì„±
processing_chain = (
    RunnableLambda(preprocess_text) |
    PromptTemplate.from_template("ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ì˜ì–´ í•œ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”: {0}") |
    llm |
    RunnableLambda(postprocess_response)
)

# ì‹¤í–‰
result = processing_chain.invoke("  Artificial Intelligence  ")
print(f"ì²˜ë¦¬ëœ ì‘ë‹µ: {result['processed_response']}")
print(f"ì‘ë‹µ ê¸¸ì´: {result['length']}")
```

## ğŸš€ ì‹¤ìŠµí•´ë³´ê¸°

### ì‹¤ìŠµ: í…ìŠ¤íŠ¸ ìš”ì•½ ë° ê°ì • ë¶„ì„ ì‹œìŠ¤í…œ

**ëª©í‘œ**: ì‚¬ìš©ì ì…ë ¥ì„ ìš”ì•½í•˜ê³  ê°ì •ì„ ë¶„ì„í•˜ëŠ” LCEL íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

#### ë‹¨ê³„ë³„ êµ¬í˜„
```python
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableParallel
from operator import itemgetter

# ëª¨ë¸ ì„¤ì • (Langfuse ì¶”ì  í¬í•¨)
model = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0.3,
    callbacks=[langfuse_handler]
)

# ìš”ì•½ í”„ë¡¬í”„íŠ¸
summarize_prompt = PromptTemplate.from_template(
    "ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ í•µì‹¬ ë‚´ìš©ë§Œ ê°„ë‹¨íˆ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{text}\n\nìš”ì•½:"
)

# ê°ì • ë¶„ì„ í”„ë¡¬í”„íŠ¸
sentiment_prompt = PromptTemplate.from_template(
    "ë‹¤ìŒ ìš”ì•½ëœ ë‚´ìš©ì˜ ê°ì •ì„ ë¶„ì„í•´ì£¼ì„¸ìš”. 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½' ì¤‘ í•˜ë‚˜ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”:\n\n{summary}\n\nê°ì •:"
)

# ì¶œë ¥ íŒŒì„œ
output_parser = StrOutputParser()

# ì²´ì¸ êµ¬ì„±
summarize_chain = summarize_prompt | model | output_parser
sentiment_chain = sentiment_prompt | model | output_parser

# ì „ì²´ íŒŒì´í”„ë¼ì¸
chain = (
    {"text": itemgetter("text")} |          # ì…ë ¥ í…ìŠ¤íŠ¸ ì „ë‹¬
    {"summary": summarize_chain} |          # ìš”ì•½ ì‹¤í–‰
    RunnableParallel({
        "summary": itemgetter("summary"),   # ìš”ì•½ ê²°ê³¼ ì „ë‹¬
        "sentiment": sentiment_chain        # ê°ì • ë¶„ì„ ì‹¤í–‰
    })
)

# í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
text = """ì˜¤ëŠ˜ ì‹œí—˜ì„ ë´¤ìŠµë‹ˆë‹¤. ì¤€ë¹„ë¥¼ ì—´ì‹¬íˆ í–ˆê¸° ë•Œë¬¸ì— ê¸´ì¥í–ˆì§€ë§Œ ë¬¸ì œë¥¼ ì˜ í’€ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.
ê²°ê³¼ì ìœ¼ë¡œ ë§Œì ì„ ë°›ì•˜ê³  ë§¤ìš° ê¸°ë»¤ìŠµë‹ˆë‹¤.
ì„ ìƒë‹˜ê»˜ì„œë„ ì¹­ì°¬í•´ ì£¼ì…”ì„œ ë³´ëŒì„ ëŠê¼ˆìŠµë‹ˆë‹¤.
ë…¸ë ¥í•˜ë©´ ì¢‹ì€ ê²°ê³¼ê°€ ë”°ë¥¸ë‹¤ëŠ” ê²ƒì„ ë‹¤ì‹œ ê¹¨ë‹¬ì•˜ìŠµë‹ˆë‹¤."""

# ì‹¤í–‰
result = chain.invoke({"text": text})

print(f"ìš”ì•½: {result['summary']}")
print(f"ê°ì •: {result['sentiment']}")
```

## ğŸ“‹ í•´ë‹µ

### í…ìŠ¤íŠ¸ ìš”ì•½ ë° ê°ì • ë¶„ì„ ì‹œìŠ¤í…œ í•´ë‹µ

```python
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableParallel
from operator import itemgetter

# Langfuse ì¶”ì ì´ í™œì„±í™”ëœ ëª¨ë¸
model = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0.3,
    callbacks=[langfuse_handler]
)

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
summarize_prompt = PromptTemplate.from_template(
    "ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ í•µì‹¬ ë‚´ìš©ë§Œ ê°„ë‹¨íˆ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{text}\n\nìš”ì•½:"
)

sentiment_prompt = PromptTemplate.from_template(
    "ë‹¤ìŒ ìš”ì•½ëœ ë‚´ìš©ì˜ ê°ì •ì„ ë¶„ì„í•´ì£¼ì„¸ìš”. 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½' ì¤‘ í•˜ë‚˜ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”:\n\n{summary}\n\nê°ì •:"
)

# ì¶œë ¥ íŒŒì„œ
output_parser = StrOutputParser()

# ê°œë³„ ì²´ì¸ êµ¬ì„±
summarize_chain = summarize_prompt | model | output_parser
sentiment_chain = sentiment_prompt | model | output_parser

# ì „ì²´ íŒŒì´í”„ë¼ì¸ êµ¬ì„±
chain = (
    {"text": itemgetter("text")} |
    {"summary": summarize_chain} |
    RunnableParallel({
        "summary": itemgetter("summary"),
        "sentiment": sentiment_chain
    })
)

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
test_text = """ì˜¤ëŠ˜ ì‹œí—˜ì„ ë´¤ìŠµë‹ˆë‹¤. ì¤€ë¹„ë¥¼ ì—´ì‹¬íˆ í–ˆê¸° ë•Œë¬¸ì— ê¸´ì¥í–ˆì§€ë§Œ ë¬¸ì œë¥¼ ì˜ í’€ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.
ê²°ê³¼ì ìœ¼ë¡œ ë§Œì ì„ ë°›ì•˜ê³  ë§¤ìš° ê¸°ë»¤ìŠµë‹ˆë‹¤.
ì„ ìƒë‹˜ê»˜ì„œë„ ì¹­ì°¬í•´ ì£¼ì…”ì„œ ë³´ëŒì„ ëŠê¼ˆìŠµë‹ˆë‹¤.
ë…¸ë ¥í•˜ë©´ ì¢‹ì€ ê²°ê³¼ê°€ ë”°ë¥¸ë‹¤ëŠ” ê²ƒì„ ë‹¤ì‹œ ê¹¨ë‹¬ì•˜ìŠµë‹ˆë‹¤."""

result = chain.invoke({"text": test_text})

print("=== ì²˜ë¦¬ ê²°ê³¼ ===")
print(f"ìš”ì•½: {result['summary']}")          # ì‹œí—˜ì—ì„œ ë§Œì ì„ ë°›ì•„ ê¸°ì˜ê³ , ë…¸ë ¥ì˜ ì¤‘ìš”ì„±ì„ ë‹¤ì‹œ ê¹¨ë‹¬ì•˜ë‹¤.
print(f"ê°ì •: {result['sentiment']}")        # ê¸ì •

# Langfuse ë°ì´í„° ì „ì†¡
langfuse_client.flush()
print("âœ… Langfuse ì¶”ì  ë°ì´í„° ì „ì†¡ ì™„ë£Œ")
```

## ğŸ” Langfuse ëª¨ë‹ˆí„°ë§

### ì£¼ìš” ì¶”ì  ê¸°ëŠ¥

#### 1. ì²´ì¸ ì‹¤í–‰ ì¶”ì 
- ê° ì»´í¬ë„ŒíŠ¸ë³„ ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
- ì…ë ¥/ì¶œë ¥ ë°ì´í„° ê¸°ë¡
- í† í° ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ë¶„ì„

#### 2. ì„±ëŠ¥ ë¶„ì„
- ë³‘ëª© ì§€ì  ì‹ë³„
- ìµœì í™” í¬ì¸íŠ¸ ë°œê²¬
- ë°°ì¹˜ ì²˜ë¦¬ íš¨ìœ¨ì„± ì¸¡ì •

#### 3. ë””ë²„ê¹… ì§€ì›
- ì „ì²´ ë°ì´í„° íë¦„ ì‹œê°í™”
- ì—ëŸ¬ ë°œìƒ ì§€ì  ì¶”ì 
- íŒŒë¼ë¯¸í„° ë³€í™”ì— ë”°ë¥¸ ì„±ëŠ¥ ë¹„êµ

### ì›¹ ì¸í„°í˜ì´ìŠ¤ í™œìš©
```python
# Langfuse ì›¹ì—ì„œ í™•ì¸ ê°€ëŠ¥í•œ ì •ë³´
print(f"ğŸ”— Langfuse ì›¹ ì¸í„°í˜ì´ìŠ¤: {os.getenv('LANGFUSE_HOST')}")
print("ğŸ“Š í™•ì¸ ê°€ëŠ¥í•œ ì •ë³´:")
print("- íŠ¸ë ˆì´ìŠ¤ë³„ ì‹¤í–‰ ì‹œê°„")
print("- í† í° ì‚¬ìš©ëŸ‰ ë° ë¹„ìš©")
print("- í”„ë¡¬í”„íŠ¸ì™€ ì‘ë‹µ ë°ì´í„°")
print("- ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë° ë¶„ì„")
```

## ğŸ¯ ê³ ê¸‰ í™œìš©ë²•

### 1. ë°°ì¹˜ ì²˜ë¦¬
```python
# ì—¬ëŸ¬ ì…ë ¥ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬
inputs = [
    {"text": "ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸..."},
    {"text": "ë‘ ë²ˆì§¸ í…ìŠ¤íŠ¸..."},
    {"text": "ì„¸ ë²ˆì§¸ í…ìŠ¤íŠ¸..."}
]

# ë°°ì¹˜ ì‹¤í–‰
results = chain.batch(inputs)

for i, result in enumerate(results):
    print(f"ê²°ê³¼ {i+1}: ìš”ì•½={result['summary']}, ê°ì •={result['sentiment']}")
```

### 2. ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
```python
# ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°
for chunk in chain.stream({"text": "ë¶„ì„í•  í…ìŠ¤íŠ¸..."}):
    print(f"ì²˜ë¦¬ ì¤‘: {chunk}")
```

### 3. ë¹„ë™ê¸° ì²˜ë¦¬
```python
import asyncio

async def process_async():
    result = await chain.ainvoke({"text": "ë¹„ë™ê¸° ì²˜ë¦¬í•  í…ìŠ¤íŠ¸..."})
    return result

# ë¹„ë™ê¸° ì‹¤í–‰
result = asyncio.run(process_async())
```

## ğŸ“š ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [LangChain LCEL ê°€ì´ë“œ](https://python.langchain.com/docs/concepts/lcel/)
- [Langfuse ë¬¸ì„œ](https://langfuse.com/docs)
- [Runnable ì¸í„°í˜ì´ìŠ¤](https://python.langchain.com/docs/concepts/runnables/)
- [CallbackHandler ì‚¬ìš©ë²•](https://python.langchain.com/docs/integrations/providers/langfuse/)

### í•™ìŠµ ìë£Œ
- [LCEL ì¿¡ë¶](https://github.com/langchain-ai/langchain/tree/master/cookbook)
- [Langfuse ì˜ˆì œ ëª¨ìŒ](https://github.com/langfuse/langfuse/tree/main/cookbook)
- [ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œ](https://python.langchain.com/docs/how_to/chain_performance/)

### ê°œë°œ ë„êµ¬
- [Langfuse Cloud](https://cloud.langfuse.com/) - í´ë¼ìš°ë“œ ë²„ì „
- [Langfuse Self-hosted](https://github.com/langfuse/langfuse) - ìì²´ í˜¸ìŠ¤íŒ…
- [LangSmith](https://smith.langchain.com/) - LangChain ê³µì‹ ëª¨ë‹ˆí„°ë§

### ì¶”ê°€ í•™ìŠµ
- ë³µì¡í•œ ì²´ì¸ êµ¬ì¡° ì„¤ê³„ íŒ¨í„´
- ì„±ëŠ¥ ìµœì í™” ë° ë¹„ìš© ê´€ë¦¬
- í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œì˜ ëª¨ë‹ˆí„°ë§ ì „ëµ
- A/B í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì²´ì¸ ë¹„êµ ë°©ë²•