# LangGraph ë©”ëª¨ë¦¬ ê´€ë¦¬ - Part 1: ë‹¨ê¸° ë©”ëª¨ë¦¬

## ğŸ“š í•™ìŠµ ëª©í‘œ

ì´ ê°€ì´ë“œë¥¼ ì™„ë£Œí•˜ë©´ ë‹¤ìŒì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- **ì²´í¬í¬ì¸íŠ¸ (Checkpoints)**ì˜ ê°œë…ê³¼ ì—­í• ì„ ì´í•´í•˜ê³  êµ¬í˜„í•  ìˆ˜ ìˆë‹¤
- **MemorySaver**ë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ì„¸ì…˜ ê¸°ë°˜ì˜ ë‹¨ê¸° ë©”ëª¨ë¦¬ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤
- **thread_id**ë¥¼ í†µí•´ ë…ë¦½ì ì¸ ëŒ€í™” ì„¸ì…˜ì„ ê´€ë¦¬í•  ìˆ˜ ìˆë‹¤
- **ìƒíƒœ íˆìŠ¤í† ë¦¬**ë¥¼ ì¡°íšŒí•˜ê³  íŠ¹ì • ì²´í¬í¬ì¸íŠ¸ë¡œ ì¬ìƒ(Replay)í•  ìˆ˜ ìˆë‹¤
- **ìƒíƒœ ì—…ë°ì´íŠ¸**ë¥¼ í†µí•´ ê·¸ë˜í”„ ì‹¤í–‰ ì¤‘ ìƒíƒœë¥¼ ì§ì ‘ ìˆ˜ì •í•  ìˆ˜ ìˆë‹¤
- **ê¸´ ëŒ€í™” ê´€ë¦¬**ë¥¼ ìœ„í•œ ë©”ì‹œì§€ ì‚­ì œ ì „ëµì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤
- **RemoveMessage**ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ íƒì ìœ¼ë¡œ ë©”ì‹œì§€ë¥¼ ì œê±°í•  ìˆ˜ ìˆë‹¤

## ğŸ”‘ í•µì‹¬ ê°œë…

### ì²´í¬í¬ì¸íŠ¸ (Checkpoints)ë€?

**ì²´í¬í¬ì¸íŠ¸**ëŠ” ê·¸ë˜í”„ ì²˜ë¦¬ ê³¼ì •ì˜ ìƒíƒœë¥¼ ì €ì¥í•˜ê³  ê´€ë¦¬í•˜ëŠ” ì‹œìŠ¤í…œìœ¼ë¡œ, LangGraphì˜ **ë‹¨ê¸° ë©”ëª¨ë¦¬**ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

ì²´í¬í¬ì¸íŠ¸ëŠ” ê° ì‹¤í–‰ ë‹¨ê³„ì—ì„œ ìƒì„±ë˜ëŠ” ê·¸ë˜í”„ ìƒíƒœì˜ **ìŠ¤ëƒ…ìƒ·(Snapshot)**ìœ¼ë¡œ êµ¬ì„±ë˜ë©°, ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤:

```python
class StateSnapshot:
    config: dict          # ì²´í¬í¬ì¸íŠ¸ ê´€ë ¨ ì„¤ì • (thread_id, checkpoint_id)
    metadata: dict        # ë©”íƒ€ë°ì´í„° (source, step, parents)
    values: dict          # í•´ë‹¹ ì‹œì ì˜ ìƒíƒœ ì±„ë„ ê°’
    next: tuple          # ë‹¤ìŒì— ì‹¤í–‰í•  ë…¸ë“œ ì´ë¦„
    tasks: tuple         # ë‹¤ìŒì— ì‹¤í–‰í•  ì‘ì—… ì •ë³´ (PregelTask ê°ì²´)
```

**ì²´í¬í¬ì¸íŠ¸ì˜ í™œìš©**:
- ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€
- íŠ¹ì • ì‹œì ìœ¼ë¡œ ë˜ëŒë¦¬ê¸° (Time Travel)
- ìƒíƒœ íˆìŠ¤í† ë¦¬ ì¶”ì 
- ì˜¤ë¥˜ ë°œìƒ ì‹œ ë³µêµ¬

### MemorySaver: ìŠ¤ë ˆë“œ ê¸°ë°˜ ë‹¨ê¸° ë©”ëª¨ë¦¬

**MemorySaver**ëŠ” LangGraphì—ì„œ ì œê³µí•˜ëŠ” ì¸ë©”ëª¨ë¦¬ ì²´í¬í¬ì¸í„°ë¡œ, ë””ë²„ê¹…ê³¼ í…ŒìŠ¤íŠ¸ ìš©ë„ë¡œ ì í•©í•©ë‹ˆë‹¤.

**íŠ¹ì§•**:
- **ìŠ¤ë ˆë“œ ê¸°ë°˜**: `thread_id`ë¡œ ë…ë¦½ì ì¸ ëŒ€í™” ì„¸ì…˜ ê´€ë¦¬
- **ë‹¨ê¸° ë©”ëª¨ë¦¬**: í•˜ë‚˜ì˜ ëŒ€í™” ì„¸ì…˜ ë™ì•ˆë§Œ ì •ë³´ ìœ ì§€
- **ìë™ ì €ì¥**: ê·¸ë˜í”„ì˜ ê° ë‹¨ê³„ë§ˆë‹¤ ìƒíƒœë¥¼ ìë™ìœ¼ë¡œ ê¸°ë¡
- **ë©”ëª¨ë¦¬ ì €ì¥**: í”„ë¡œì„¸ìŠ¤ ë©”ëª¨ë¦¬ì— ì €ì¥ (ì¬ì‹œì‘ ì‹œ ì†Œì‹¤)

**í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ”**:
- `SqliteSaver`: ë¡œì»¬ íŒŒì¼ ê¸°ë°˜ ì˜êµ¬ ì €ì¥
- `PostgresSaver`: ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ í™•ì¥ ê°€ëŠ¥í•œ ì €ì¥
- ì»¤ìŠ¤í…€ ì²´í¬í¬ì¸í„°: íŠ¹ì • ìš”êµ¬ì‚¬í•­ì— ë§ê²Œ êµ¬í˜„

### thread_id: ëŒ€í™” ì„¸ì…˜ ì‹ë³„ì

`thread_id`ëŠ” ë…ë¦½ì ì¸ ëŒ€í™” ì„¸ì…˜ì„ êµ¬ë¶„í•˜ëŠ” ì‹ë³„ìì…ë‹ˆë‹¤.

```python
# ì‚¬ìš©ì Aì˜ ëŒ€í™”
config_a = {"configurable": {"thread_id": "user_a"}}
graph.invoke({"messages": [HumanMessage("ì•ˆë…•í•˜ì„¸ìš”")]}, config_a)

# ì‚¬ìš©ì Bì˜ ëŒ€í™” (ì™„ì „íˆ ë…ë¦½ì )
config_b = {"configurable": {"thread_id": "user_b"}}
graph.invoke({"messages": [HumanMessage("Hello")]}, config_b)
```

**thread_id í™œìš© ì‹œë‚˜ë¦¬ì˜¤**:
- ì‚¬ìš©ìë³„ ëŒ€í™” ê´€ë¦¬: `thread_id = f"user_{user_id}"`
- ì„¸ì…˜ë³„ ëŒ€í™” ê´€ë¦¬: `thread_id = f"session_{session_id}"`
- ì£¼ì œë³„ ëŒ€í™” ê´€ë¦¬: `thread_id = f"topic_{topic_name}"`

### ìƒíƒœ ì¬ìƒ (Replay)

íŠ¹ì • ì²´í¬í¬ì¸íŠ¸ë¶€í„° ê·¸ë˜í”„ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ì¬ìƒì˜ íŠ¹ì§•**:
- ì´ì „ ë‹¨ê³„ëŠ” **ì‹¤ì œë¡œ ì¬ì‹¤í–‰í•˜ì§€ ì•Šê³ ** ê²°ê³¼ë§Œ ê°€ì ¸ì˜´
- ë¶ˆí•„ìš”í•œ ì¬ì‹¤í–‰ ë°©ì§€ (íš¨ìœ¨ì , ë¹„ìš© ì ˆê°)
- ì²´í¬í¬ì¸íŠ¸ ì´í›„ ë‹¨ê³„ë§Œ ì‹¤í–‰

```python
# íŠ¹ì • ì²´í¬í¬ì¸íŠ¸ ì´í›„ë¶€í„° ì¬ìƒ
config_with_checkpoint = {
    "configurable": {
        "thread_id": "1",
        "checkpoint_id": "abc-123-def"
    }
}
graph.invoke(None, config_with_checkpoint)  # ì´ì „ ì…ë ¥ ì¬ì‚¬ìš©
```

### ë©”ì‹œì§€ ê´€ë¦¬ ì „ëµ

ê¸´ ëŒ€í™”ì—ì„œ LLMì˜ ì»¨í…ìŠ¤íŠ¸ ì œí•œì„ ì´ˆê³¼í•˜ì§€ ì•Šê¸° ìœ„í•œ ì „ëµ:

**1. ì§ì ‘ ì‚­ì œ ë°©ì‹**:
- ì»¤ìŠ¤í…€ ë¦¬ë“€ì„œë¡œ ë©”ì‹œì§€ ê°œìˆ˜ ì œí•œ
- ìµœê·¼ Nê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€
- Tool Callê³¼ Response ìŒ ë³´ì¡´

**2. RemoveMessage ë°©ì‹**:
- LangGraph ë‚´ì¥ ë©”ì»¤ë‹ˆì¦˜
- ë©”ì‹œì§€ ID ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê²Œ ì‚­ì œ
- ë” ì•ˆì „í•˜ê³  ê¶Œì¥ë˜ëŠ” ë°©ë²•

**3. ìš”ì•½ ë°©ì‹** (Part 2ì—ì„œ ë‹¤ë£¸):
- ì˜¤ë˜ëœ ë©”ì‹œì§€ë¥¼ ìš”ì•½ìœ¼ë¡œ ì••ì¶•
- ì»¨í…ìŠ¤íŠ¸ëŠ” ìœ ì§€í•˜ë©´ì„œ í† í° ì ˆì•½

## ğŸ›  í™˜ê²½ ì„¤ì •

### í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

```bash
pip install langchain langchain-openai langchain-chroma
pip install langgraph
pip install python-dotenv
```

### API í‚¤ ì„¤ì •

`.env` íŒŒì¼:
```
OPENAI_API_KEY=your_openai_api_key_here
```

### ê¸°ë³¸ ì„¤ì • ì½”ë“œ

```python
from dotenv import load_dotenv
load_dotenv()

# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os
from glob import glob
from pprint import pprint
import json

# LangChain ë° LangGraph
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.tools import tool
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate

from langgraph.graph import StateGraph, START, END, MessagesState
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import ToolNode, tools_condition

from typing import List, Annotated, Optional, Union
from typing_extensions import TypedDict
from operator import add

print("í™˜ê²½ ì„¤ì • ì™„ë£Œ!")
```

### ë ˆìŠ¤í† ë‘ ë©”ë‰´ ë„êµ¬ ì„¤ì •

ì´ ê°€ì´ë“œì—ì„œëŠ” ë ˆìŠ¤í† ë‘ ë©”ë‰´/ì™€ì¸ ê²€ìƒ‰ ë„êµ¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

```python
# ì„ë² ë”© ëª¨ë¸
embeddings_model = OpenAIEmbeddings(model="text-embedding-3-small")

# ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
menu_db = Chroma(
    embedding_function=embeddings_model,
    collection_name="restaurant_menu",
    persist_directory="./chroma_db"
)

wine_db = Chroma(
    embedding_function=embeddings_model,
    collection_name="restaurant_wine",
    persist_directory="./chroma_db"
)

# ë„êµ¬ ì •ì˜
@tool
def search_menu(query: str, k: int = 2) -> List[Document]:
    """ë ˆìŠ¤í† ë‘ ë©”ë‰´ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    docs = menu_db.similarity_search(query, k=k)
    if len(docs) > 0:
        return docs
    return [Document(page_content="ê´€ë ¨ ë©”ë‰´ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")]

@tool
def search_wine(query: str, k: int = 2) -> List[Document]:
    """ë ˆìŠ¤í† ë‘ ì™€ì¸ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    docs = wine_db.similarity_search(query, k=k)
    if len(docs) > 0:
        return docs
    return [Document(page_content="ê´€ë ¨ ì™€ì¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")]
```

## ğŸ’» ë‹¨ê³„ë³„ êµ¬í˜„

### 1ë‹¨ê³„: MemorySaverë¡œ ë‹¨ê¸° ë©”ëª¨ë¦¬ êµ¬í˜„

#### ìƒíƒœ ì •ì˜

```python
from typing import Annotated, Optional
from typing_extensions import TypedDict
from operator import add

class State(TypedDict):
    query: str                                # ì‚¬ìš©ì ì§ˆë¬¸
    search_results: Annotated[list[str], add] # ê²€ìƒ‰ ê²°ê³¼ (ëˆ„ì )
    summary: Optional[str]                    # ìš”ì•½
```

**í¬ì¸íŠ¸**:
- `search_results`ëŠ” `add` ë¦¬ë“€ì„œë¡œ ëˆ„ì 
- `summary`ëŠ” `Optional`ë¡œ ì´ˆê¸°ê°’ ì—†ì„ ìˆ˜ ìˆìŒ

#### ë…¸ë“œ ì •ì˜

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langgraph.prebuilt import ToolNode

# LLMì— ë„êµ¬ ë°”ì¸ë”©
llm = ChatOpenAI(model="gpt-4o-mini")
tools = [search_menu, search_wine]
llm_with_tools = llm.bind_tools(tools)

# ë„êµ¬ ë…¸ë“œ
tool_node = ToolNode(tools=tools)

# ìš”ì•½ ì²´ì¸
system_prompt = """
You are an AI assistant helping a user find information about a restaurant menu and wine list.
Answer in the same language as the user's query.
"""

user_prompt = """
Summarize the following search results.

[GUIDELINES]
- Provide a brief summary of the search results.
- Include the key information from the search results.
- Use 1-2 sentences to summarize the information.

[Search Results]
{search_results}

[Summary]
"""

summary_prompt = ChatPromptTemplate.from_messages([
    ("system", system_prompt),
    ("user", user_prompt)
])

summary_chain = summary_prompt | llm

# ê²€ìƒ‰ ë…¸ë“œ
def search_node(state: State):
    """ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ìˆ˜í–‰"""
    query = state['query']

    # LLMì´ ë„êµ¬ ì„ íƒ
    tool_call = llm_with_tools.invoke(query)
    # ë„êµ¬ ì‹¤í–‰
    tool_results = tool_node.invoke({"messages": [tool_call]})

    if tool_results['messages']:
        print(f"ê²€ìƒ‰ ë¬¸ì„œ ê°œìˆ˜: {len(tool_results['messages'])}")
        return {"search_results": tool_results['messages']}

    return {"query": query}

# ìš”ì•½ ë…¸ë“œ
def summarize_node(state: State):
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìš”ì•½"""
    search_results = state['search_results']

    if search_results:
        summary_text = summary_chain.invoke({"search_results": search_results})
        summary = f"Summary of results for '{state['query']}': {summary_text.content.strip()}"
    else:
        summary = "No results found."

    return {"summary": summary}
```

#### ê·¸ë˜í”„ êµ¬ì„± ë° ì»´íŒŒì¼

```python
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver

# StateGraph ìƒì„±
workflow = StateGraph(State)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("search", search_node)
workflow.add_node("summarize", summarize_node)

# ì—£ì§€ ì—°ê²°
workflow.add_edge(START, "search")
workflow.add_edge("search", "summarize")
workflow.add_edge("summarize", END)

# ë©”ëª¨ë¦¬ ì €ì¥ì†Œ ìƒì„±
checkpointer = MemorySaver()

# ì²´í¬í¬ì¸í„°ë¥¼ ì§€ì •í•˜ì—¬ ì»´íŒŒì¼
graph_memory = workflow.compile(checkpointer=checkpointer)
```

**ì¤‘ìš” í¬ì¸íŠ¸**:
- `checkpointer=checkpointer` íŒŒë¼ë¯¸í„°ë¡œ ë©”ëª¨ë¦¬ ì €ì¥ì†Œ ì§€ì •
- ì´ì œ `graph_memory`ëŠ” ëª¨ë“  ì‹¤í–‰ ë‹¨ê³„ì—ì„œ ìƒíƒœë¥¼ ìë™ ì €ì¥

#### ê·¸ë˜í”„ ì‹œê°í™”

```python
from IPython.display import Image, display
display(Image(graph_memory.get_graph().draw_mermaid_png()))
```

### 2ë‹¨ê³„: thread_idë¡œ ëŒ€í™” ì„¸ì…˜ ê´€ë¦¬

```python
# thread_id ì„¤ì •
config = {"configurable": {"thread_id": "1"}}

# ì´ˆê¸° ì¿¼ë¦¬
initial_input = {
    "query": "ìŠ¤í…Œì´í¬ ë©”ë‰´ê°€ ìˆë‚˜ìš”? ì–´ìš¸ë¦¬ëŠ” ì™€ì¸ë„ ì¶”ì²œí•´ì£¼ì„¸ìš”."
}

# ê·¸ë˜í”„ ì‹¤í–‰
output = graph_memory.invoke(initial_input, config)

# ê²°ê³¼ ì¶œë ¥
pprint(output)
```

**ì‹¤í–‰ ê²°ê³¼**:
```
ê²€ìƒ‰ ë¬¸ì„œ ê°œìˆ˜: 2
{'query': 'ìŠ¤í…Œì´í¬ ë©”ë‰´ê°€ ìˆë‚˜ìš”? ì–´ìš¸ë¦¬ëŠ” ì™€ì¸ë„ ì¶”ì²œí•´ì£¼ì„¸ìš”.',
 'search_results': [ToolMessage(...ìƒ¤í† ë¸Œë¦¬ì•™ ìŠ¤í…Œì´í¬...),
                    ToolMessage(...ì™€ì¸ ì¶”ì²œ...)],
 'summary': "Summary of results for '...': ìƒ¤í† ë¸Œë¦¬ì•™ ìŠ¤í…Œì´í¬..."}
```

**ì—¬ëŸ¬ ìŠ¤ë ˆë“œ ê´€ë¦¬**:

```python
# ìŠ¤ë ˆë“œ 1: ì²« ë²ˆì§¸ ì‚¬ìš©ì
config_1 = {"configurable": {"thread_id": "user_1"}}
graph_memory.invoke({"query": "íŒŒìŠ¤íƒ€ ë©”ë‰´ ì•Œë ¤ì£¼ì„¸ìš”"}, config_1)

# ìŠ¤ë ˆë“œ 2: ë‘ ë²ˆì§¸ ì‚¬ìš©ì (ë…ë¦½ì )
config_2 = {"configurable": {"thread_id": "user_2"}}
graph_memory.invoke({"query": "ë””ì €íŠ¸ ë©”ë‰´ ì¶”ì²œí•´ì£¼ì„¸ìš”"}, config_2)

# ìŠ¤ë ˆë“œ 1ë¡œ ëŒì•„ê°€ê¸° (ì´ì „ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ë¨)
graph_memory.invoke({"query": "ê·¸ íŒŒìŠ¤íƒ€ ê°€ê²©ì€ìš”?"}, config_1)
```

### 3ë‹¨ê³„: ìƒíƒœ ì¡°íšŒ ë° íˆìŠ¤í† ë¦¬

#### í˜„ì¬ ìƒíƒœ ì¡°íšŒ

```python
# ìµœì‹  ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
current_state = graph_memory.get_state(config)

print(f"Config: {current_state.config}")
print(f"Metadata: {current_state.metadata}")
print(f"Next: {current_state.next}")
print(f"Tasks: {current_state.tasks}")
print(f"Values: {current_state.values}")
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
Config: {'configurable': {'thread_id': '1', 'checkpoint_id': '1f0b5877-...'}}
Metadata: {'source': 'loop', 'step': 2, 'parents': {}}
Next: ()
Tasks: ()
Values: {'query': '...', 'search_results': [...], 'summary': '...'}
```

**StateSnapshot ì†ì„±**:
- `config`: thread_idì™€ checkpoint_id í¬í•¨
- `metadata`: ì‹¤í–‰ ì •ë³´ (source, step, parents)
- `next`: ë‹¤ìŒ ì‹¤í–‰í•  ë…¸ë“œ (ë¹ˆ íŠœí”Œì´ë©´ ì™„ë£Œ)
- `tasks`: ë‹¤ìŒ ì‘ì—… ì •ë³´
- `values`: í˜„ì¬ ìƒíƒœ ê°’

#### ìƒíƒœ íˆìŠ¤í† ë¦¬ ì¡°íšŒ

```python
# ì „ì²´ ì‹¤í–‰ íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
state_history = list(graph_memory.get_state_history(config))

for i, snapshot in enumerate(state_history):
    print(f"Checkpoint {i}:")
    print(f"  Next: {snapshot.next}")
    print(f"  Metadata: {snapshot.metadata}")
    print(f"  Values (query): {snapshot.values.get('query', 'N/A')}")
    print("-" * 80)
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
Checkpoint 0:
  Next: ()
  Metadata: {'source': 'loop', 'step': 2, 'parents': {}}
  Values (query): ìŠ¤í…Œì´í¬ ë©”ë‰´ê°€ ìˆë‚˜ìš”?
--------------------------------------------------------------------------------
Checkpoint 1:
  Next: ('summarize',)
  Metadata: {'source': 'loop', 'step': 1, 'parents': {}}
  Values (query): ìŠ¤í…Œì´í¬ ë©”ë‰´ê°€ ìˆë‚˜ìš”?
--------------------------------------------------------------------------------
Checkpoint 2:
  Next: ('search',)
  Metadata: {'source': 'loop', 'step': 0, 'parents': {}}
  Values (query): ìŠ¤í…Œì´í¬ ë©”ë‰´ê°€ ìˆë‚˜ìš”?
```

**íˆìŠ¤í† ë¦¬ ìˆœì„œ**:
- ì¸ë±ìŠ¤ 0: ê°€ì¥ ìµœê·¼ ì²´í¬í¬ì¸íŠ¸
- ì¸ë±ìŠ¤ N: ê°€ì¥ ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸
- ì—­ìˆœìœ¼ë¡œ ì €ì¥ë¨

### 4ë‹¨ê³„: ìƒíƒœ ì¬ìƒ (Replay)

íŠ¹ì • ì²´í¬í¬ì¸íŠ¸ë¶€í„° ê·¸ë˜í”„ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•©ë‹ˆë‹¤.

```python
# 'summarize' ë…¸ë“œê°€ ì‹¤í–‰ë˜ê¸° ì§ì „ ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°
snapshot_before_summarize = None
for snapshot in state_history:
    if snapshot.next == ('summarize',):
        snapshot_before_summarize = snapshot
        break

print(f"Found snapshot: {snapshot_before_summarize.config}")

# í•´ë‹¹ ì²´í¬í¬ì¸íŠ¸ë¶€í„° ì¬ìƒ
output = graph_memory.invoke(None, snapshot_before_summarize.config)

# Noneì„ ì „ë‹¬í•˜ë©´ ì´ì „ ì…ë ¥ì„ ì¬ì‚¬ìš©
# 'search' ë…¸ë“œëŠ” ì¬ì‹¤í–‰í•˜ì§€ ì•Šê³ , 'summarize' ë…¸ë“œë§Œ ì‹¤í–‰
```

**ì¬ìƒ íë¦„**:
```
[Checkpoint: search ì™„ë£Œ]
  â†“ (ì¬ìƒ ì‹œì‘ì )
[summarize ë…¸ë“œ ì‹¤í–‰]
  â†“
[END]
```

**ì¬ìƒ í›„ íˆìŠ¤í† ë¦¬ í™•ì¸**:

```python
# ì¬ìƒ í›„ íˆìŠ¤í† ë¦¬ í™•ì¸
new_history = list(graph_memory.get_state_history(snapshot_before_summarize.config))

print(f"ì¬ìƒ í›„ ì²´í¬í¬ì¸íŠ¸ ìˆ˜: {len(new_history)}")
for i, snapshot in enumerate(new_history[:3]):
    print(f"Checkpoint {i}: next={snapshot.next}, step={snapshot.metadata['step']}")
```

**ì¬ìƒì˜ ì¥ì **:
- ë¶ˆí•„ìš”í•œ ì¬ì‹¤í–‰ ë°©ì§€ (ì‹œê°„ ì ˆì•½)
- API í˜¸ì¶œ ë¹„ìš© ì ˆê° (LLM, ë„êµ¬ í˜¸ì¶œ ì¬ì‚¬ìš©)
- ë””ë²„ê¹… ë° í…ŒìŠ¤íŠ¸ì— ìœ ìš©

### 5ë‹¨ê³„: ìƒíƒœ ì—…ë°ì´íŠ¸

ì‹¤í–‰ ì¤‘ì¸ ê·¸ë˜í”„ì˜ ìƒíƒœë¥¼ ì§ì ‘ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
# íŠ¹ì • ì²´í¬í¬ì¸íŠ¸ ì„ íƒ
checkpoint_config = snapshot_before_summarize.config

# ì¿¼ë¦¬ ìˆ˜ì •
update_input = {
    "query": "ë©”ë‰´ ì´ë¦„ê³¼ ê°€ê²© ì •ë³´ë§Œ ê°„ë‹¨í•˜ê²Œ ì¶œë ¥í•˜ì„¸ìš”."
}

# ìƒíƒœ ì—…ë°ì´íŠ¸
graph_memory.update_state(checkpoint_config, update_input)

# ì—…ë°ì´íŠ¸ëœ ìƒíƒœ í™•ì¸
updated_state = graph_memory.get_state(config)
print(f"ì—…ë°ì´íŠ¸ëœ ì¿¼ë¦¬: {updated_state.values['query']}")
```

**ìƒíƒœ ì—…ë°ì´íŠ¸ íŒŒë¼ë¯¸í„°**:
- `config`: ì—…ë°ì´íŠ¸í•  ì²´í¬í¬ì¸íŠ¸ ì„¤ì •
- `values`: ì—…ë°ì´íŠ¸í•  ê°’ (ë”•ì…”ë„ˆë¦¬)
- `as_node`: ì—…ë°ì´íŠ¸ë¥¼ ìˆ˜í–‰í•  ë…¸ë“œ ì§€ì • (ì„ íƒ ì‚¬í•­)

**ì—…ë°ì´íŠ¸ í›„ ì¬ìƒ**:

```python
# ì—…ë°ì´íŠ¸ëœ ìƒíƒœë¡œ ì´ì–´ì„œ ì‹¤í–‰
output = graph_memory.invoke(None, config)

# ìµœì¢… ìƒíƒœ í™•ì¸
final_state = graph_memory.get_state(config)
pprint(final_state.values)
```

**í™œìš© ì‹œë‚˜ë¦¬ì˜¤**:
- ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜: "ë” ìì„¸íˆ", "ë” ê°„ë‹¨í•˜ê²Œ"
- ì˜¤ë¥˜ ìˆ˜ì •: ì˜ëª»ëœ ì…ë ¥ êµì •
- ë””ë²„ê¹…: íŠ¹ì • ìƒíƒœ ê°’ìœ¼ë¡œ í…ŒìŠ¤íŠ¸

### 6ë‹¨ê³„: ê¸´ ëŒ€í™” ê´€ë¦¬ - ì§ì ‘ ë©”ì‹œì§€ ì‚­ì œ

#### ì»¤ìŠ¤í…€ ë©”ì‹œì§€ ê´€ë¦¬ì êµ¬í˜„

```python
from typing import Union, Annotated

def manage_list(existing: list, updates: Union[list, dict]):
    """ì»¤ìŠ¤í…€ ë©”ì‹œì§€ ê´€ë¦¬ ë¦¬ë“€ì„œ"""

    # ì—…ë°ì´íŠ¸ê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°: ê¸°ì¡´ ë©”ì‹œì§€ì— ì¶”ê°€
    if isinstance(updates, list):
        return existing + updates

    # ì—…ë°ì´íŠ¸ê°€ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°: ë©”ì‹œì§€ ê´€ë¦¬ ì‘ì—… ìˆ˜í–‰
    elif isinstance(updates, dict) and updates["type"] == "keep":
        # ì§€ì •ëœ ë²”ìœ„ì˜ ë©”ì‹œì§€ë§Œ ì„ íƒ
        recent_messages = existing[updates["from"]:updates["to"]]

        # Tool Callê³¼ Response ìŒ + ì¼ë°˜ ë©”ì‹œì§€ ë³´ì¡´
        kept_indices = set()

        for i, msg in enumerate(recent_messages):
            # Tool Callì´ ìˆëŠ” ë©”ì‹œì§€
            if hasattr(msg, 'tool_calls') and msg.tool_calls:
                # ë‹¤ìŒ ë©”ì‹œì§€ê°€ ToolMessageì¸ì§€ í™•ì¸
                if i+1 < len(recent_messages) and isinstance(recent_messages[i+1], ToolMessage):
                    kept_indices.add(i)     # Tool Call ë©”ì‹œì§€
                    kept_indices.add(i+1)   # Tool Response ë©”ì‹œì§€
            # ì¼ë°˜ ë©”ì‹œì§€ (Tool Call ì•„ë‹˜)
            elif not isinstance(msg, ToolMessage):
                kept_indices.add(i)

        # ì›ë³¸ ìˆœì„œ ìœ ì§€í•˜ë©´ì„œ ì„ íƒëœ ë©”ì‹œì§€ë§Œ ë°˜í™˜
        return [msg for i, msg in enumerate(recent_messages) if i in kept_indices]

    return existing

# ìƒíƒœ ì •ì˜
class GraphState(MessagesState):
    messages: Annotated[list, manage_list]  # ì»¤ìŠ¤í…€ ë¦¬ë“€ì„œ ì ìš©
```

#### ë©”ì‹œì§€ ê´€ë¦¬ ë…¸ë“œ êµ¬í˜„

```python
def message_manager(state: GraphState):
    """ìµœê·¼ 5ê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€"""
    return {
        "messages": {"type": "keep", "from": -5, "to": None}
    }

# ì—ì´ì „íŠ¸ ë…¸ë“œ
def call_model(state: GraphState):
    system_prompt = SystemMessage("""You are a helpful AI assistant...""")

    messages = [system_prompt] + state['messages']
    response = llm_with_tools.invoke(messages)

    return {"messages": [response]}
```

#### ê·¸ë˜í”„ êµ¬ì„±

```python
# LLMì— ë„êµ¬ ë°”ì¸ë”©
llm_with_tools = llm.bind_tools(tools=[search_menu, search_wine])

# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(GraphState)

builder.add_node("agent", call_model)
builder.add_node("tools", ToolNode(tools))
builder.add_node("message_manager", message_manager)

# ì—£ì§€ ì—°ê²°
builder.add_edge(START, "message_manager")  # ë¨¼ì € ë©”ì‹œì§€ ê´€ë¦¬
builder.add_edge("message_manager", "agent")
builder.add_conditional_edges("agent", tools_condition)
builder.add_edge("tools", "message_manager")  # ë„êµ¬ ì‹¤í–‰ í›„ ë‹¤ì‹œ ë©”ì‹œì§€ ê´€ë¦¬

# ë©”ëª¨ë¦¬ì™€ í•¨ê»˜ ì»´íŒŒì¼
memory = MemorySaver()
graph = builder.compile(checkpointer=memory)
```

**ê·¸ë˜í”„ íë¦„**:
```
START â†’ message_manager â†’ agent â†’ tools â†’ message_manager â†’ agent â†’ END
         (ìµœê·¼ 5ê°œ ìœ ì§€)            (ë„êµ¬ ì‹¤í–‰)   (ìµœê·¼ 5ê°œ ìœ ì§€)
```

#### í…ŒìŠ¤íŠ¸

```python
config = {"configurable": {"thread_id": "test_1"}}

# ì—¬ëŸ¬ ì§ˆë¬¸ ì—°ì† ì‹¤í–‰
questions = [
    "ìŠ¤í…Œì´í¬ ë©”ë‰´ê°€ ìˆë‚˜ìš”?",
    "ê°€ê²©ì€ ì–¼ë§ˆì¸ê°€ìš”?",
    "ì–´ìš¸ë¦¬ëŠ” ì™€ì¸ ì¶”ì²œí•´ì£¼ì„¸ìš”",
    "ë‹¤ë¥¸ ë©”ë‰´ë„ ìˆë‚˜ìš”?",
    "ë””ì €íŠ¸ ë©”ë‰´ëŠ”ìš”?",
    "ê°€ì¥ ì¸ê¸° ìˆëŠ” ë©”ë‰´ëŠ”?",
]

for q in questions:
    print(f"\nì§ˆë¬¸: {q}")
    result = graph.invoke({"messages": [HumanMessage(content=q)]}, config)

    # í˜„ì¬ ë©”ì‹œì§€ ìˆ˜ í™•ì¸
    current_state = graph.get_state(config)
    print(f"ë©”ì‹œì§€ ìˆ˜: {len(current_state.values['messages'])}")

    # ë§ˆì§€ë§‰ ì‘ë‹µ ì¶œë ¥
    result['messages'][-1].pretty_print()
```

**ê²°ê³¼**:
- ë©”ì‹œì§€ ìˆ˜ê°€ 5ê°œë¡œ ì œí•œë¨
- Tool Callê³¼ Response ìŒì€ ë³´ì¡´ë¨
- ì˜¤ë˜ëœ ë©”ì‹œì§€ëŠ” ìë™ìœ¼ë¡œ ì‚­ì œë¨

### 7ë‹¨ê³„: RemoveMessageë¥¼ ì‚¬ìš©í•œ ë©”ì‹œì§€ ì‚­ì œ

LangGraph ë‚´ì¥ ë°©ì‹ìœ¼ë¡œ ë” ì•ˆì „í•˜ê²Œ ë©”ì‹œì§€ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.

#### RemoveMessage ê°œë…

```python
from langgraph.graph import MessagesState
from langchain_core.messages import RemoveMessage

# RemoveMessageëŠ” ë©”ì‹œì§€ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚­ì œ
remove_msg = RemoveMessage(id="message_id_to_remove")
```

**íŠ¹ì§•**:
- ë©”ì‹œì§€ ID ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê²Œ ì‚­ì œ
- Tool Callê³¼ Response ê´€ê³„ ìœ ì§€
- add_messages ë¦¬ë“€ì„œì™€ ìë™ í†µí•©

#### ë©”ì‹œì§€ í•„í„° ë…¸ë“œ êµ¬í˜„

```python
def filter_messages(state: GraphState):
    """ì˜¤ë˜ëœ ë©”ì‹œì§€ ì‚­ì œ"""
    messages = state['messages']

    # ìµœê·¼ 6ê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€ (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì œì™¸)
    if len(messages) > 6:
        # ì‚­ì œí•  ë©”ì‹œì§€ ID ìˆ˜ì§‘
        messages_to_remove = []

        for msg in messages[:-6]:  # ë§ˆì§€ë§‰ 6ê°œ ì œì™¸í•œ ë‚˜ë¨¸ì§€
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” ìœ ì§€
            if not isinstance(msg, SystemMessage):
                messages_to_remove.append(RemoveMessage(id=msg.id))

        return {"messages": messages_to_remove}

    return {}  # ì‚­ì œí•  ë©”ì‹œì§€ ì—†ìŒ
```

#### ê·¸ë˜í”„ êµ¬ì„±

```python
# ìƒíƒœ ì •ì˜ (ì¼ë°˜ MessagesState ì‚¬ìš©)
class GraphState(MessagesState):
    pass

# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(GraphState)

builder.add_node("agent", call_model)
builder.add_node("tools", ToolNode(tools))
builder.add_node("filter", filter_messages)

# ì—£ì§€ ì—°ê²°
builder.add_edge(START, "filter")  # ë¨¼ì € í•„í„°ë§
builder.add_edge("filter", "agent")
builder.add_conditional_edges("agent", tools_condition)
builder.add_edge("tools", "filter")  # ë„êµ¬ ì‹¤í–‰ í›„ ë‹¤ì‹œ í•„í„°ë§

# ì»´íŒŒì¼
memory = MemorySaver()
graph = builder.compile(checkpointer=memory)
```

#### í…ŒìŠ¤íŠ¸ ë° ê²€ì¦

```python
config = {"configurable": {"thread_id": "remove_test"}}

# 10ê°œì˜ ì§ˆë¬¸ ì—°ì† ì‹¤í–‰
for i in range(10):
    result = graph.invoke({
        "messages": [HumanMessage(content=f"ì§ˆë¬¸ {i+1}: ë©”ë‰´ ì¶”ì²œí•´ì£¼ì„¸ìš”")]
    }, config)

    # ë©”ì‹œì§€ ìˆ˜ í™•ì¸
    state = graph.get_state(config)
    msg_count = len(state.values['messages'])
    print(f"ì§ˆë¬¸ {i+1} í›„ ë©”ì‹œì§€ ìˆ˜: {msg_count}")

# ìµœì¢… ë©”ì‹œì§€ í™•ì¸
final_state = graph.get_state(config)
for msg in final_state.values['messages']:
    print(f"{type(msg).__name__}: {msg.content[:50]}...")
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
ì§ˆë¬¸ 1 í›„ ë©”ì‹œì§€ ìˆ˜: 2
ì§ˆë¬¸ 2 í›„ ë©”ì‹œì§€ ìˆ˜: 4
ì§ˆë¬¸ 3 í›„ ë©”ì‹œì§€ ìˆ˜: 6
ì§ˆë¬¸ 4 í›„ ë©”ì‹œì§€ ìˆ˜: 6  # ìµœëŒ€ 6ê°œ ìœ ì§€
ì§ˆë¬¸ 5 í›„ ë©”ì‹œì§€ ìˆ˜: 6
...
```

## ğŸ¯ ì‹¤ìŠµ ë¬¸ì œ

### ì‹¤ìŠµ 1: ì²´í¬í¬ì¸í„°ë¥¼ ì‚¬ìš©í•œ ë‹¤êµ­ì–´ RAG (ë‚œì´ë„: â­â­â­)

**ë¬¸ì œ**: í•œêµ­ì–´/ì˜ì–´ DBë¥¼ ì‚¬ìš©í•˜ëŠ” ReAct ì—ì´ì „íŠ¸ì— ì²´í¬í¬ì¸í„°ë¥¼ ì¶”ê°€í•˜ì—¬ ëŒ€í™” ê¸°ë¡ì„ ìœ ì§€í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­**:
- í•œêµ­ì–´ DB ë„êµ¬ (`search_kor`)ì™€ ì˜ì–´ DB ë„êµ¬ (`search_eng`) ì •ì˜
- ReAct ì—ì´ì „íŠ¸ ê·¸ë˜í”„ êµ¬ì„± (`tools_condition` ì‚¬ìš©)
- `MemorySaver`ë¥¼ ì‚¬ìš©í•œ ì²´í¬í¬ì¸í„° ì¶”ê°€
- ì—°ì†ëœ ëŒ€í™”ì—ì„œ ì´ì „ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ í™•ì¸
- ìƒíƒœ íˆìŠ¤í† ë¦¬ ì¡°íšŒ ë° ì¶œë ¥

**íŒíŠ¸**:
```python
# ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
db_korean = Chroma(
    embedding_function=embeddings_openai,
    collection_name="db_korean_cosine_metadata",
    persist_directory="./chroma_db"
)

# ë„êµ¬ ì •ì˜
@tool
def search_kor(query: str, k: int = 2) -> List[Document]:
    """í•œêµ­ì–´ ì§ˆë¬¸ì´ ì£¼ì–´ì§€ë©´, í•œêµ­ì–´ ë¬¸ì„œì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    # êµ¬í˜„í•˜ì„¸ìš”
    pass
```

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
1. "í…ŒìŠ¬ë¼ì˜ ì°½ì—…ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?" (í•œêµ­ì–´)
2. "ì„¤ë¦½ ë…„ë„ëŠ” ì–¸ì œì¸ê°€ìš”?" (ì´ì „ ëŒ€í™” ì°¸ì¡°)
3. "Who is the CEO of Tesla?" (ì˜ì–´, ìƒˆë¡œìš´ ì»¨í…ìŠ¤íŠ¸)
4. ìƒíƒœ íˆìŠ¤í† ë¦¬ ì¶œë ¥

### ì‹¤ìŠµ 2: ì„ íƒì  ë©”ì‹œì§€ ì œê±° (ë‚œì´ë„: â­â­â­)

**ë¬¸ì œ**: Tool Callì´ ìˆëŠ” ë©”ì‹œì§€ë§Œ ì„ íƒì ìœ¼ë¡œ ì œê±°í•˜ëŠ” í•„í„°ë¥¼ êµ¬í˜„í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­**:
- Tool Call ë©”ì‹œì§€ì™€ ToolMessage ìŒì„ ì„ íƒì ìœ¼ë¡œ ì‚­ì œ
- ì¼ë°˜ ëŒ€í™” ë©”ì‹œì§€ëŠ” ëª¨ë‘ ë³´ì¡´
- ìµœê·¼ 2ê°œì˜ Tool Call ìŒë§Œ ìœ ì§€
- RemoveMessage ì‚¬ìš©

**íŒíŠ¸**:
```python
def filter_tool_messages(state: GraphState):
    """Tool Call ë©”ì‹œì§€ë§Œ ì„ íƒì ìœ¼ë¡œ ì œê±°"""
    messages = state['messages']

    # Tool Callì´ ìˆëŠ” ë©”ì‹œì§€ ìŒ ì°¾ê¸°
    tool_pairs = []
    for i, msg in enumerate(messages):
        if hasattr(msg, 'tool_calls') and msg.tool_calls:
            if i+1 < len(messages) and isinstance(messages[i+1], ToolMessage):
                tool_pairs.append((i, i+1))

    # ìµœê·¼ 2ê°œ ìŒë§Œ ìœ ì§€, ë‚˜ë¨¸ì§€ ì‚­ì œ
    if len(tool_pairs) > 2:
        # êµ¬í˜„í•˜ì„¸ìš”
        pass
```

**í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬**:
- "ë©”ë‰´ ì¶”ì²œí•´ì£¼ì„¸ìš”" (Tool Call ë°œìƒ)
- "ì™€ì¸ë„ ì¶”ì²œí•´ì£¼ì„¸ìš”" (Tool Call ë°œìƒ)
- "ê°ì‚¬í•©ë‹ˆë‹¤" (ì¼ë°˜ ë©”ì‹œì§€)
- "ê°€ê²©ì€ ì–¼ë§ˆì¸ê°€ìš”?" (Tool Call ë°œìƒ)
- "ì¢‹ì•„ìš”" (ì¼ë°˜ ë©”ì‹œì§€)

**ê¸°ëŒ€ ê²°ê³¼**:
- 3ê°œì˜ Tool Call ìŒ ì¤‘ 2ê°œë§Œ ìœ ì§€
- ëª¨ë“  ì¼ë°˜ ë©”ì‹œì§€ëŠ” ë³´ì¡´

### ì‹¤ìŠµ 3: ì‚¬ìš©ìë³„ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ (ë‚œì´ë„: â­â­â­â­)

**ë¬¸ì œ**: ì—¬ëŸ¬ ì‚¬ìš©ìì˜ ë…ë¦½ì ì¸ ëŒ€í™”ë¥¼ ê´€ë¦¬í•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬í˜„í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­**:
- ì‚¬ìš©ìë³„ thread_id ìë™ ìƒì„±
- ì‚¬ìš©ìë³„ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ì¡°íšŒ í•¨ìˆ˜
- ì‚¬ìš©ìë³„ ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™” ê¸°ëŠ¥
- ìµœì†Œ 3ëª…ì˜ ì‚¬ìš©ì ë™ì‹œ ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜

**íŒíŠ¸**:
```python
class ConversationManager:
    def __init__(self, graph):
        self.graph = graph

    def get_config(self, user_id: str):
        """ì‚¬ìš©ìë³„ config ìƒì„±"""
        return {"configurable": {"thread_id": f"user_{user_id}"}}

    def chat(self, user_id: str, message: str):
        """ì‚¬ìš©ì ë©”ì‹œì§€ ì²˜ë¦¬"""
        config = self.get_config(user_id)
        # êµ¬í˜„í•˜ì„¸ìš”

    def get_history(self, user_id: str):
        """ì‚¬ìš©ìì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        # êµ¬í˜„í•˜ì„¸ìš”

    def clear_history(self, user_id: str):
        """ì‚¬ìš©ìì˜ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        # êµ¬í˜„í•˜ì„¸ìš”
```

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
```python
manager = ConversationManager(graph)

# ì‚¬ìš©ì A
manager.chat("alice", "ìŠ¤í…Œì´í¬ ë©”ë‰´ ì•Œë ¤ì£¼ì„¸ìš”")
manager.chat("alice", "ê°€ê²©ì€ìš”?")

# ì‚¬ìš©ì B (ë…ë¦½ì )
manager.chat("bob", "íŒŒìŠ¤íƒ€ ë©”ë‰´ ì¶”ì²œí•´ì£¼ì„¸ìš”")
manager.chat("bob", "ì™€ì¸ë„ ì¶”ì²œí•´ì£¼ì„¸ìš”")

# ì‚¬ìš©ì C (ë…ë¦½ì )
manager.chat("charlie", "ë””ì €íŠ¸ ë©”ë‰´ëŠ”ìš”?")

# ê° ì‚¬ìš©ìì˜ íˆìŠ¤í† ë¦¬ ì¡°íšŒ
print(manager.get_history("alice"))
print(manager.get_history("bob"))
print(manager.get_history("charlie"))
```

## âœ… ì†”ë£¨ì…˜ ì˜ˆì‹œ

### ì‹¤ìŠµ 1 ì†”ë£¨ì…˜

```python
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from langgraph.graph import MessagesState, StateGraph, START, END
from langgraph.prebuilt import ToolNode, tools_condition
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_openai import ChatOpenAI
from langgraph.checkpoint.memory import MemorySaver

# ì„ë² ë”© ëª¨ë¸
embeddings_openai = OpenAIEmbeddings(model="text-embedding-3-small")

# ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
db_korean = Chroma(
    embedding_function=embeddings_openai,
    collection_name="db_korean_cosine_metadata",
    persist_directory="./chroma_db"
)

db_english = Chroma(
    embedding_function=embeddings_openai,
    collection_name="eng_db_openai",
    persist_directory="./chroma_db"
)

print(f"í•œêµ­ì–´ ë¬¸ì„œ ìˆ˜: {db_korean._collection.count()}")
print(f"ì˜ì–´ ë¬¸ì„œ ìˆ˜: {db_english._collection.count()}")

# ë„êµ¬ ì •ì˜
@tool
def search_kor(query: str, k: int = 2) -> List[Document]:
    """í•œêµ­ì–´ ì§ˆë¬¸ì´ ì£¼ì–´ì§€ë©´, í•œêµ­ì–´ ë¬¸ì„œì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    docs = db_korean.similarity_search(query, k=k)
    if len(docs) > 0:
        return docs
    return [Document(page_content="ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")]

@tool
def search_eng(query: str, k: int = 2) -> List[Document]:
    """ì˜ì–´ ì§ˆë¬¸ì´ ì£¼ì–´ì§€ë©´, ì˜ì–´ ë¬¸ì„œì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    docs = db_english.similarity_search(query, k=k)
    if len(docs) > 0:
        return docs
    return [Document(page_content="No relevant information found.")]

# ìƒíƒœ ì •ì˜
class GraphState(MessagesState):
    pass

# LLM ë° ë„êµ¬
llm = ChatOpenAI(model="gpt-4o-mini")
tools = [search_kor, search_eng]
llm_with_tools = llm.bind_tools(tools=tools)

# ì—ì´ì „íŠ¸ ë…¸ë“œ
def call_model(state: GraphState):
    system_prompt = SystemMessage("""You are a helpful AI assistant.
Please respond to the user's query to the best of your ability!

ì¤‘ìš”: ì‚¬ìš©ìì˜ ì§ˆë¬¸ ì–¸ì–´ì™€ ë™ì¼í•œ ì–¸ì–´ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
ë‹µë³€ ì‹œ ë°˜ë“œì‹œ ì •ë³´ì˜ ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš”: [ë„êµ¬: ë„êµ¬ì´ë¦„]""")

    messages = [system_prompt] + state['messages']
    response = llm_with_tools.invoke(messages)
    return {"messages": [response]}

# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(GraphState)
builder.add_node("agent", call_model)
builder.add_node("tools", ToolNode(tools))
builder.add_edge(START, "agent")
builder.add_conditional_edges("agent", tools_condition)
builder.add_edge("tools", "agent")

# ë©”ëª¨ë¦¬ ì¶”ê°€
memory = MemorySaver()
graph_memory = builder.compile(checkpointer=memory)

# í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤
config = {"configurable": {"thread_id": "multilang_test"}}

print("\n" + "="*80)
print("ì§ˆë¬¸ 1: í…ŒìŠ¬ë¼ì˜ ì°½ì—…ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?")
print("="*80)
result = graph_memory.invoke({
    "messages": [HumanMessage(content="í…ŒìŠ¬ë¼ì˜ ì°½ì—…ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?")]
}, config)
result['messages'][-1].pretty_print()

print("\n" + "="*80)
print("ì§ˆë¬¸ 2: ì„¤ë¦½ ë…„ë„ëŠ” ì–¸ì œì¸ê°€ìš”?")
print("="*80)
result = graph_memory.invoke({
    "messages": [HumanMessage(content="ì„¤ë¦½ ë…„ë„ëŠ” ì–¸ì œì¸ê°€ìš”?")]
}, config)
result['messages'][-1].pretty_print()

print("\n" + "="*80)
print("ì§ˆë¬¸ 3: Who is the CEO of Tesla?")
print("="*80)
result = graph_memory.invoke({
    "messages": [HumanMessage(content="Who is the CEO of Tesla?")]
}, config)
result['messages'][-1].pretty_print()

# ìƒíƒœ íˆìŠ¤í† ë¦¬ ì¶œë ¥
print("\n" + "="*80)
print("ìƒíƒœ íˆìŠ¤í† ë¦¬")
print("="*80)
history = list(graph_memory.get_state_history(config))
print(f"ì´ ì²´í¬í¬ì¸íŠ¸ ìˆ˜: {len(history)}")
for i, snapshot in enumerate(history[:5]):  # ìµœê·¼ 5ê°œë§Œ
    print(f"\nCheckpoint {i}:")
    print(f"  Next: {snapshot.next}")
    print(f"  Step: {snapshot.metadata.get('step', 'N/A')}")
    print(f"  Messages: {len(snapshot.values['messages'])}")
```

**ì‹¤í–‰ ê²°ê³¼**:
```
================================================================================
ì§ˆë¬¸ 1: í…ŒìŠ¬ë¼ì˜ ì°½ì—…ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?
================================================================================
================================== Ai Message ==================================
í…ŒìŠ¬ë¼(Tesla)ëŠ” 2003ë…„ 7ì›” 1ì¼ì— Martin Eberhardì™€ Marc Tarpenningì— ì˜í•´ ì„¤ë¦½ë˜ì—ˆìŠµë‹ˆë‹¤.
[ë„êµ¬: search_kor]

================================================================================
ì§ˆë¬¸ 2: ì„¤ë¦½ ë…„ë„ëŠ” ì–¸ì œì¸ê°€ìš”?
================================================================================
================================== Ai Message ==================================
í…ŒìŠ¬ë¼ëŠ” 2003ë…„ì— ì„¤ë¦½ë˜ì—ˆìŠµë‹ˆë‹¤. [ë„êµ¬: search_kor]

================================================================================
ì§ˆë¬¸ 3: Who is the CEO of Tesla?
================================================================================
================================== Ai Message ==================================
Elon Musk is the CEO of Tesla. He became CEO in 2008. [ë„êµ¬: search_eng]

================================================================================
ìƒíƒœ íˆìŠ¤í† ë¦¬
================================================================================
ì´ ì²´í¬í¬ì¸íŠ¸ ìˆ˜: 15

Checkpoint 0:
  Next: ()
  Step: 8
  Messages: 6

Checkpoint 1:
  Next: ('agent',)
  Step: 7
  Messages: 6
...
```

**ì†”ë£¨ì…˜ í¬ì¸íŠ¸**:
- ì²´í¬í¬ì¸í„°ë¡œ ëŒ€í™” ê¸°ë¡ ìœ ì§€
- ì§ˆë¬¸ 2ì—ì„œ "í…ŒìŠ¬ë¼"ë¥¼ ëª…ì‹œí•˜ì§€ ì•Šì•„ë„ ì´ì „ ì»¨í…ìŠ¤íŠ¸ í™œìš©
- í•œêµ­ì–´/ì˜ì–´ ë„êµ¬ê°€ ìë™ìœ¼ë¡œ ì„ íƒë¨
- ìƒíƒœ íˆìŠ¤í† ë¦¬ì—ì„œ ì „ì²´ ì‹¤í–‰ íë¦„ í™•ì¸ ê°€ëŠ¥

### ì‹¤ìŠµ 2 ì†”ë£¨ì…˜

```python
from langchain_core.messages import RemoveMessage

def filter_tool_messages(state: GraphState):
    """Tool Call ë©”ì‹œì§€ë§Œ ì„ íƒì ìœ¼ë¡œ ì œê±° (ìµœê·¼ 2ê°œ ìŒ ìœ ì§€)"""
    messages = state['messages']

    # Tool Call ìŒ ì°¾ê¸° (AIMessage with tool_calls + ToolMessage)
    tool_pairs = []
    for i, msg in enumerate(messages):
        if hasattr(msg, 'tool_calls') and msg.tool_calls:
            # ë‹¤ìŒ ë©”ì‹œì§€ê°€ ToolMessageì¸ì§€ í™•ì¸
            if i+1 < len(messages) and isinstance(messages[i+1], ToolMessage):
                tool_pairs.append((i, i+1, msg.id, messages[i+1].id))

    # ìµœê·¼ 2ê°œ ìŒë§Œ ìœ ì§€í•˜ê³  ë‚˜ë¨¸ì§€ ì‚­ì œ
    if len(tool_pairs) > 2:
        # ì‚­ì œí•  ë©”ì‹œì§€ ID ìˆ˜ì§‘ (ì˜¤ë˜ëœ ìŒë“¤)
        messages_to_remove = []
        for pair in tool_pairs[:-2]:  # ë§ˆì§€ë§‰ 2ê°œ ì œì™¸
            messages_to_remove.append(RemoveMessage(id=pair[2]))  # AIMessage
            messages_to_remove.append(RemoveMessage(id=pair[3]))  # ToolMessage

        return {"messages": messages_to_remove}

    return {}

# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(GraphState)
builder.add_node("agent", call_model)
builder.add_node("tools", ToolNode([search_menu, search_wine]))
builder.add_node("filter", filter_tool_messages)

builder.add_edge(START, "filter")
builder.add_edge("filter", "agent")
builder.add_conditional_edges("agent", tools_condition)
builder.add_edge("tools", "filter")

memory = MemorySaver()
graph = builder.compile(checkpointer=memory)

# í…ŒìŠ¤íŠ¸
config = {"configurable": {"thread_id": "filter_test"}}

queries = [
    "ë©”ë‰´ ì¶”ì²œí•´ì£¼ì„¸ìš”",          # Tool Call 1
    "ì™€ì¸ë„ ì¶”ì²œí•´ì£¼ì„¸ìš”",         # Tool Call 2
    "ê°ì‚¬í•©ë‹ˆë‹¤",                 # ì¼ë°˜ ë©”ì‹œì§€
    "ê°€ê²©ì€ ì–¼ë§ˆì¸ê°€ìš”?",          # Tool Call 3
    "ì¢‹ì•„ìš”",                     # ì¼ë°˜ ë©”ì‹œì§€
]

for q in queries:
    print(f"\nì§ˆë¬¸: {q}")
    result = graph.invoke({"messages": [HumanMessage(content=q)]}, config)

    # í˜„ì¬ ìƒíƒœ í™•ì¸
    state = graph.get_state(config)
    messages = state.values['messages']

    # Tool Call ìŒ ìˆ˜ ì„¸ê¸°
    tool_count = sum(1 for msg in messages if hasattr(msg, 'tool_calls') and msg.tool_calls)
    print(f"í˜„ì¬ ë©”ì‹œì§€ ìˆ˜: {len(messages)}, Tool Call ìŒ: {tool_count}")

# ìµœì¢… ë©”ì‹œì§€ í™•ì¸
print("\n" + "="*80)
print("ìµœì¢… ë©”ì‹œì§€ ëª©ë¡")
print("="*80)
final_state = graph.get_state(config)
for i, msg in enumerate(final_state.values['messages']):
    msg_type = type(msg).__name__
    content = msg.content[:50] if hasattr(msg, 'content') else "N/A"
    has_tools = "Yes" if hasattr(msg, 'tool_calls') and msg.tool_calls else "No"
    print(f"{i+1}. {msg_type} (Tool Call: {has_tools}): {content}...")
```

**ì‹¤í–‰ ê²°ê³¼**:
```
ì§ˆë¬¸: ë©”ë‰´ ì¶”ì²œí•´ì£¼ì„¸ìš”
í˜„ì¬ ë©”ì‹œì§€ ìˆ˜: 2, Tool Call ìŒ: 1

ì§ˆë¬¸: ì™€ì¸ë„ ì¶”ì²œí•´ì£¼ì„¸ìš”
í˜„ì¬ ë©”ì‹œì§€ ìˆ˜: 4, Tool Call ìŒ: 2

ì§ˆë¬¸: ê°ì‚¬í•©ë‹ˆë‹¤
í˜„ì¬ ë©”ì‹œì§€ ìˆ˜: 6, Tool Call ìŒ: 2

ì§ˆë¬¸: ê°€ê²©ì€ ì–¼ë§ˆì¸ê°€ìš”?
í˜„ì¬ ë©”ì‹œì§€ ìˆ˜: 6, Tool Call ìŒ: 2  # Tool Call 1ì´ ì‚­ì œë¨

ì§ˆë¬¸: ì¢‹ì•„ìš”
í˜„ì¬ ë©”ì‹œì§€ ìˆ˜: 8, Tool Call ìŒ: 2

================================================================================
ìµœì¢… ë©”ì‹œì§€ ëª©ë¡
================================================================================
1. HumanMessage (Tool Call: No): ì™€ì¸ë„ ì¶”ì²œí•´ì£¼ì„¸ìš”...
2. AIMessage (Tool Call: Yes): ...
3. ToolMessage (Tool Call: No): [Document(...)]
4. HumanMessage (Tool Call: No): ê°ì‚¬í•©ë‹ˆë‹¤...
5. AIMessage (Tool Call: No): ì²œë§Œì—ìš”...
6. HumanMessage (Tool Call: No): ê°€ê²©ì€ ì–¼ë§ˆì¸ê°€ìš”?...
7. AIMessage (Tool Call: Yes): ...
8. ToolMessage (Tool Call: No): [Document(...)]
9. HumanMessage (Tool Call: No): ì¢‹ì•„ìš”...
10. AIMessage (Tool Call: No): ê°ì‚¬í•©ë‹ˆë‹¤...
```

**ì†”ë£¨ì…˜ í¬ì¸íŠ¸**:
- Tool Call ìŒë§Œ ì„ íƒì ìœ¼ë¡œ ì‚­ì œ
- ì¼ë°˜ ëŒ€í™” ë©”ì‹œì§€ëŠ” ëª¨ë‘ ë³´ì¡´
- ìµœê·¼ 2ê°œ Tool Call ìŒ ìœ ì§€
- RemoveMessageë¡œ ì•ˆì „í•˜ê²Œ ì‚­ì œ

### ì‹¤ìŠµ 3 ì†”ë£¨ì…˜

```python
class ConversationManager:
    """ì—¬ëŸ¬ ì‚¬ìš©ìì˜ ëŒ€í™”ë¥¼ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self, graph):
        self.graph = graph

    def get_config(self, user_id: str):
        """ì‚¬ìš©ìë³„ config ìƒì„±"""
        return {"configurable": {"thread_id": f"user_{user_id}"}}

    def chat(self, user_id: str, message: str):
        """ì‚¬ìš©ì ë©”ì‹œì§€ ì²˜ë¦¬"""
        config = self.get_config(user_id)

        print(f"\n[{user_id}] {message}")
        result = self.graph.invoke({
            "messages": [HumanMessage(content=message)]
        }, config)

        # ë§ˆì§€ë§‰ ì‘ë‹µ ì¶œë ¥
        response = result['messages'][-1]
        print(f"[Assistant] {response.content[:100]}...")

        return result

    def get_history(self, user_id: str, limit: int = 10):
        """ì‚¬ìš©ìì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        config = self.get_config(user_id)
        state = self.graph.get_state(config)

        messages = state.values.get('messages', [])

        print(f"\n{'='*80}")
        print(f"ëŒ€í™” íˆìŠ¤í† ë¦¬: {user_id}")
        print('='*80)
        print(f"ì´ ë©”ì‹œì§€ ìˆ˜: {len(messages)}")

        for i, msg in enumerate(messages[-limit:], 1):
            msg_type = type(msg).__name__
            content = msg.content[:60] if hasattr(msg, 'content') else "N/A"
            print(f"{i}. {msg_type}: {content}...")

        return messages

    def clear_history(self, user_id: str):
        """ì‚¬ìš©ìì˜ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        config = self.get_config(user_id)

        # ìƒˆë¡œìš´ ì´ˆê¸° ìƒíƒœë¡œ ì—…ë°ì´íŠ¸
        self.graph.update_state(config, {"messages": []})

        print(f"\n[{user_id}] ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def get_all_users(self):
        """í™œì„± ì‚¬ìš©ì ëª©ë¡ ì¡°íšŒ"""
        # MemorySaverëŠ” ì‹¤ì œë¡œ ëª¨ë“  thread_idë¥¼ ì¡°íšŒí•˜ëŠ” ê¸°ëŠ¥ì´ ì—†ìœ¼ë¯€ë¡œ
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë³„ë„ ì¶”ì  í•„ìš”
        print("í™œì„± ì‚¬ìš©ì ì¶”ì ì€ ë³„ë„ êµ¬í˜„ í•„ìš”")

# í…ŒìŠ¤íŠ¸
manager = ConversationManager(graph_memory)

print("="*80)
print("ë‹¤ì¤‘ ì‚¬ìš©ì ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜")
print("="*80)

# ì‚¬ìš©ì A (Alice)
manager.chat("alice", "ìŠ¤í…Œì´í¬ ë©”ë‰´ ì•Œë ¤ì£¼ì„¸ìš”")
manager.chat("alice", "ê°€ê²©ì€ìš”?")

# ì‚¬ìš©ì B (Bob) - ë…ë¦½ì 
manager.chat("bob", "íŒŒìŠ¤íƒ€ ë©”ë‰´ ì¶”ì²œí•´ì£¼ì„¸ìš”")
manager.chat("bob", "ì™€ì¸ë„ ì¶”ì²œí•´ì£¼ì„¸ìš”")

# ì‚¬ìš©ì C (Charlie) - ë…ë¦½ì 
manager.chat("charlie", "ë””ì €íŠ¸ ë©”ë‰´ëŠ”ìš”?")

# ê° ì‚¬ìš©ìë¡œ ë‹¤ì‹œ ëŒ€í™” (ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ í™•ì¸)
manager.chat("alice", "ê·¸ ìŠ¤í…Œì´í¬ ì£¼ë¬¸í• ê²Œìš”")  # ì´ì „ ëŒ€í™” ì°¸ì¡°
manager.chat("bob", "ê·¸ ì™€ì¸ ê°€ê²©ì€ìš”?")         # ì´ì „ ëŒ€í™” ì°¸ì¡°

# íˆìŠ¤í† ë¦¬ ì¡°íšŒ
manager.get_history("alice")
manager.get_history("bob")
manager.get_history("charlie")

# Aliceì˜ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
manager.clear_history("alice")

# ì´ˆê¸°í™” í›„ ëŒ€í™”
manager.chat("alice", "ì•ˆë…•í•˜ì„¸ìš”")  # ì´ì „ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ
manager.get_history("alice")
```

**ì‹¤í–‰ ê²°ê³¼**:
```
================================================================================
ë‹¤ì¤‘ ì‚¬ìš©ì ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜
================================================================================

[alice] ìŠ¤í…Œì´í¬ ë©”ë‰´ ì•Œë ¤ì£¼ì„¸ìš”
[Assistant] ì €í¬ ë ˆìŠ¤í† ë‘ì˜ ìŠ¤í…Œì´í¬ ë©”ë‰´ë¥¼ ì†Œê°œí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤: 1. ìƒ¤í† ë¸Œë¦¬ì•™ ìŠ¤í…Œì´í¬ (â‚©42,000) ...

[alice] ê°€ê²©ì€ìš”?
[Assistant] ìƒ¤í† ë¸Œë¦¬ì•™ ìŠ¤í…Œì´í¬ëŠ” â‚©42,000ì…ë‹ˆë‹¤. [ë„êµ¬: search_menu]

[bob] íŒŒìŠ¤íƒ€ ë©”ë‰´ ì¶”ì²œí•´ì£¼ì„¸ìš”
[Assistant] ì €í¬ ë ˆìŠ¤í† ë‘ì˜ íŒŒìŠ¤íƒ€ ë©”ë‰´ë¥¼ ì¶”ì²œí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤...

[bob] ì™€ì¸ë„ ì¶”ì²œí•´ì£¼ì„¸ìš”
[Assistant] íŒŒìŠ¤íƒ€ì™€ ì˜ ì–´ìš¸ë¦¬ëŠ” ì™€ì¸ì„ ì¶”ì²œí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤...

[charlie] ë””ì €íŠ¸ ë©”ë‰´ëŠ”ìš”?
[Assistant] ë””ì €íŠ¸ ë©”ë‰´ë¥¼ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤...

[alice] ê·¸ ìŠ¤í…Œì´í¬ ì£¼ë¬¸í• ê²Œìš”
[Assistant] ìƒ¤í† ë¸Œë¦¬ì•™ ìŠ¤í…Œì´í¬ ì£¼ë¬¸ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤...

[bob] ê·¸ ì™€ì¸ ê°€ê²©ì€ìš”?
[Assistant] ì¶”ì²œí•´ë“œë¦° ì™€ì¸ì˜ ê°€ê²©ì€ ...

================================================================================
ëŒ€í™” íˆìŠ¤í† ë¦¬: alice
================================================================================
ì´ ë©”ì‹œì§€ ìˆ˜: 6
1. HumanMessage: ìŠ¤í…Œì´í¬ ë©”ë‰´ ì•Œë ¤ì£¼ì„¸ìš”...
2. AIMessage: ì €í¬ ë ˆìŠ¤í† ë‘ì˜ ìŠ¤í…Œì´í¬ ë©”ë‰´ë¥¼...
3. HumanMessage: ê°€ê²©ì€ìš”?...
4. AIMessage: ìƒ¤í† ë¸Œë¦¬ì•™ ìŠ¤í…Œì´í¬ëŠ” â‚©42,000ì…ë‹ˆë‹¤...
5. HumanMessage: ê·¸ ìŠ¤í…Œì´í¬ ì£¼ë¬¸í• ê²Œìš”...
6. AIMessage: ìƒ¤í† ë¸Œë¦¬ì•™ ìŠ¤í…Œì´í¬ ì£¼ë¬¸ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤...

[alice] ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.

[alice] ì•ˆë…•í•˜ì„¸ìš”
[Assistant] ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?...
```

**ì†”ë£¨ì…˜ í¬ì¸íŠ¸**:
- ì‚¬ìš©ìë³„ ë…ë¦½ì ì¸ thread_id ê´€ë¦¬
- ê° ì‚¬ìš©ìì˜ ì»¨í…ìŠ¤íŠ¸ ì™„ì „ ë¶„ë¦¬
- ì´ì „ ëŒ€í™” ì°¸ì¡° ê°€ëŠ¥ ("ê·¸ ìŠ¤í…Œì´í¬", "ê·¸ ì™€ì¸")
- ëŒ€í™” ì´ˆê¸°í™” ê¸°ëŠ¥ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ ë¦¬ì…‹

## ğŸš€ ì‹¤ë¬´ í™œìš© ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ì±—ë´‡ ëŒ€í™” ê¸°ë¡ ê´€ë¦¬

ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©ìë³„ ì±—ë´‡ ëŒ€í™”ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.

```python
from datetime import datetime
import uuid

class ChatbotSession:
    """ì±—ë´‡ ì„¸ì…˜ ê´€ë¦¬ì"""

    def __init__(self, graph):
        self.graph = graph
        self.sessions = {}  # session_id -> user_info

    def create_session(self, user_id: str, metadata: dict = None):
        """ìƒˆ ì„¸ì…˜ ìƒì„±"""
        session_id = str(uuid.uuid4())
        self.sessions[session_id] = {
            "user_id": user_id,
            "created_at": datetime.now(),
            "metadata": metadata or {}
        }

        config = {"configurable": {"thread_id": session_id}}
        return session_id, config

    def send_message(self, session_id: str, message: str):
        """ë©”ì‹œì§€ ì „ì†¡"""
        if session_id not in self.sessions:
            raise ValueError("Invalid session ID")

        config = {"configurable": {"thread_id": session_id}}
        result = self.graph.invoke({
            "messages": [HumanMessage(content=message)]
        }, config)

        # ë§ˆì§€ë§‰ ì‘ë‹µ ë°˜í™˜
        return result['messages'][-1].content

    def get_conversation(self, session_id: str):
        """ëŒ€í™” ë‚´ì—­ ì¡°íšŒ"""
        if session_id not in self.sessions:
            raise ValueError("Invalid session ID")

        config = {"configurable": {"thread_id": session_id}}
        state = self.graph.get_state(config)

        conversation = []
        for msg in state.values['messages']:
            if isinstance(msg, HumanMessage):
                conversation.append({"role": "user", "content": msg.content})
            elif isinstance(msg, AIMessage):
                conversation.append({"role": "assistant", "content": msg.content})

        return conversation

    def end_session(self, session_id: str):
        """ì„¸ì…˜ ì¢…ë£Œ"""
        if session_id in self.sessions:
            del self.sessions[session_id]
            print(f"Session {session_id} ended")

# ì‚¬ìš© ì˜ˆì‹œ
chatbot = ChatbotSession(graph_memory)

# ì‚¬ìš©ì 1 ì„¸ì…˜
session1, config1 = chatbot.create_session(
    "user_001",
    metadata={"name": "í™ê¸¸ë™", "language": "ko"}
)

print(chatbot.send_message(session1, "ì•ˆë…•í•˜ì„¸ìš”"))
print(chatbot.send_message(session1, "ë©”ë‰´ ì¶”ì²œí•´ì£¼ì„¸ìš”"))

# ì‚¬ìš©ì 2 ì„¸ì…˜ (ë…ë¦½ì )
session2, config2 = chatbot.create_session(
    "user_002",
    metadata={"name": "John", "language": "en"}
)

print(chatbot.send_message(session2, "Hello"))
print(chatbot.send_message(session2, "Recommend a menu"))

# ëŒ€í™” ë‚´ì—­ ì¡°íšŒ
conv1 = chatbot.get_conversation(session1)
print(f"\nUser 1 Conversation: {len(conv1)} messages")
for msg in conv1:
    print(f"  {msg['role']}: {msg['content'][:50]}...")

# ì„¸ì…˜ ì¢…ë£Œ
chatbot.end_session(session1)
```

### ì˜ˆì‹œ 2: ê³ ê° ì§€ì› í‹°ì¼“ ì‹œìŠ¤í…œ

ê³ ê° ì§€ì› í‹°ì¼“ì— ëŒ€í™” ê¸°ë¡ì„ ì—°ê²°í•©ë‹ˆë‹¤.

```python
class SupportTicket:
    """ê³ ê° ì§€ì› í‹°ì¼“ ê´€ë¦¬"""

    def __init__(self, graph):
        self.graph = graph
        self.tickets = {}

    def create_ticket(self, customer_id: str, issue: str):
        """í‹°ì¼“ ìƒì„±"""
        ticket_id = f"TICKET-{len(self.tickets) + 1:04d}"

        self.tickets[ticket_id] = {
            "customer_id": customer_id,
            "issue": issue,
            "status": "open",
            "created_at": datetime.now(),
            "thread_id": f"ticket_{ticket_id}"
        }

        # ì´ˆê¸° ë©”ì‹œì§€ ì „ì†¡
        config = {"configurable": {"thread_id": f"ticket_{ticket_id}"}}
        self.graph.invoke({
            "messages": [HumanMessage(content=f"Issue: {issue}")]
        }, config)

        return ticket_id

    def add_message(self, ticket_id: str, message: str, role: str = "customer"):
        """í‹°ì¼“ì— ë©”ì‹œì§€ ì¶”ê°€"""
        if ticket_id not in self.tickets:
            raise ValueError("Invalid ticket ID")

        config = {"configurable": {"thread_id": f"ticket_{ticket_id}"}}

        if role == "customer":
            result = self.graph.invoke({
                "messages": [HumanMessage(content=message)]
            }, config)
            return result['messages'][-1].content
        else:
            # ì§€ì› ë‹´ë‹¹ì ë©”ì‹œì§€
            self.graph.update_state(config, {
                "messages": [AIMessage(content=message)]
            })
            return message

    def get_ticket_history(self, ticket_id: str):
        """í‹°ì¼“ ëŒ€í™” ì´ë ¥"""
        if ticket_id not in self.tickets:
            raise ValueError("Invalid ticket ID")

        config = {"configurable": {"thread_id": f"ticket_{ticket_id}"}}
        state = self.graph.get_state(config)

        ticket_info = self.tickets[ticket_id]
        messages = state.values['messages']

        return {
            "ticket_id": ticket_id,
            "customer_id": ticket_info["customer_id"],
            "status": ticket_info["status"],
            "created_at": ticket_info["created_at"],
            "message_count": len(messages),
            "messages": messages
        }

    def close_ticket(self, ticket_id: str):
        """í‹°ì¼“ ì¢…ë£Œ"""
        if ticket_id in self.tickets:
            self.tickets[ticket_id]["status"] = "closed"
            print(f"Ticket {ticket_id} closed")

# ì‚¬ìš© ì˜ˆì‹œ
support = SupportTicket(graph_memory)

# í‹°ì¼“ 1: ë©”ë‰´ ë¬¸ì˜
ticket1 = support.create_ticket("CUST-001", "ìŠ¤í…Œì´í¬ ë©”ë‰´ ì •ë³´ í•„ìš”")
print(support.add_message(ticket1, "ê°€ê²©ê³¼ ì¬ë£Œ ì•Œë ¤ì£¼ì„¸ìš”"))
print(support.add_message(ticket1, "ê°ì‚¬í•©ë‹ˆë‹¤"))

# í‹°ì¼“ 2: ì˜ˆì•½ ë¬¸ì˜
ticket2 = support.create_ticket("CUST-002", "4ëª… ì˜ˆì•½ ê°€ëŠ¥ ì‹œê°„")
print(support.add_message(ticket2, "ì´ë²ˆ ì£¼ ê¸ˆìš”ì¼ ì €ë… ê°€ëŠ¥í•œê°€ìš”?"))

# ì§€ì› ë‹´ë‹¹ì ë©”ì‹œì§€ ì¶”ê°€
support.add_message(ticket1, "ë„ì›€ì´ ë˜ì–´ ê¸°ì©ë‹ˆë‹¤. ì¶”ê°€ ë¬¸ì˜ì‚¬í•­ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”.", role="agent")

# í‹°ì¼“ ì´ë ¥ ì¡°íšŒ
history = support.get_ticket_history(ticket1)
print(f"\nTicket {history['ticket_id']}")
print(f"Customer: {history['customer_id']}")
print(f"Status: {history['status']}")
print(f"Messages: {history['message_count']}")

# í‹°ì¼“ ì¢…ë£Œ
support.close_ticket(ticket1)
```

### ì˜ˆì‹œ 3: A/B í…ŒìŠ¤íŠ¸ ë° ì‹¤í—˜ ì¶”ì 

ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ë‚˜ ì„¤ì •ì„ í…ŒìŠ¤íŠ¸í•˜ê³  ì¶”ì í•©ë‹ˆë‹¤.

```python
class ExperimentTracker:
    """A/B í…ŒìŠ¤íŠ¸ ë° ì‹¤í—˜ ì¶”ì """

    def __init__(self, graph_a, graph_b):
        self.graph_a = graph_a  # ë³€í˜• A
        self.graph_b = graph_b  # ë³€í˜• B
        self.experiments = {}

    def run_experiment(self, experiment_id: str, test_queries: List[str]):
        """ì‹¤í—˜ ì‹¤í–‰"""
        results = {
            "experiment_id": experiment_id,
            "variant_a": [],
            "variant_b": [],
            "timestamp": datetime.now()
        }

        for i, query in enumerate(test_queries):
            # ë³€í˜• A í…ŒìŠ¤íŠ¸
            config_a = {"configurable": {"thread_id": f"{experiment_id}_a_{i}"}}
            result_a = self.graph_a.invoke({
                "messages": [HumanMessage(content=query)]
            }, config_a)

            # ë³€í˜• B í…ŒìŠ¤íŠ¸
            config_b = {"configurable": {"thread_id": f"{experiment_id}_b_{i}"}}
            result_b = self.graph_b.invoke({
                "messages": [HumanMessage(content=query)]
            }, config_b)

            results["variant_a"].append({
                "query": query,
                "response": result_a['messages'][-1].content,
                "message_count": len(result_a['messages'])
            })

            results["variant_b"].append({
                "query": query,
                "response": result_b['messages'][-1].content,
                "message_count": len(result_b['messages'])
            })

        self.experiments[experiment_id] = results
        return results

    def compare_results(self, experiment_id: str):
        """ê²°ê³¼ ë¹„êµ"""
        if experiment_id not in self.experiments:
            raise ValueError("Experiment not found")

        exp = self.experiments[experiment_id]

        print(f"\n{'='*80}")
        print(f"Experiment: {experiment_id}")
        print('='*80)

        for i in range(len(exp["variant_a"])):
            print(f"\nQuery {i+1}: {exp['variant_a'][i]['query']}")
            print(f"\nVariant A Response:")
            print(f"  {exp['variant_a'][i]['response'][:100]}...")
            print(f"  Messages: {exp['variant_a'][i]['message_count']}")

            print(f"\nVariant B Response:")
            print(f"  {exp['variant_b'][i]['response'][:100]}...")
            print(f"  Messages: {exp['variant_b'][i]['message_count']}")
            print("-" * 80)

# ì‚¬ìš© ì˜ˆì‹œ
# ë‘ ê°€ì§€ í”„ë¡¬í”„íŠ¸ ë³€í˜•ìœ¼ë¡œ ê·¸ë˜í”„ ìƒì„±
# (ì‹¤ì œë¡œëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë‚˜ ì„¤ì •ì„ ë‹¤ë¥´ê²Œ)
tracker = ExperimentTracker(graph_memory, graph_memory)

# ì‹¤í—˜ ì‹¤í–‰
test_queries = [
    "ìŠ¤í…Œì´í¬ ë©”ë‰´ ì¶”ì²œí•´ì£¼ì„¸ìš”",
    "ì™€ì¸ í˜ì–´ë§ ì•Œë ¤ì£¼ì„¸ìš”",
    "ê°€ê²©ëŒ€ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"
]

results = tracker.run_experiment("exp_001", test_queries)
tracker.compare_results("exp_001")
```

## ğŸ“– ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [LangGraph Persistence ê°€ì´ë“œ](https://langchain-ai.github.io/langgraph/concepts/persistence/)
- [Memory and Checkpointing](https://langchain-ai.github.io/langgraph/how-tos/memory/)
- [MemorySaver API](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.MemorySaver)
- [Managing Message History](https://langchain-ai.github.io/langgraph/how-tos/manage-conversation-history/)

### ì²´í¬í¬ì¸í„° êµ¬í˜„
- [SqliteSaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.sqlite.SqliteSaver) - ë¡œì»¬ íŒŒì¼ ê¸°ë°˜
- [PostgresSaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.postgres.PostgresSaver) - ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜
- [ì»¤ìŠ¤í…€ ì²´í¬í¬ì¸í„° êµ¬í˜„](https://langchain-ai.github.io/langgraph/how-tos/persistence_postgres/)

### ë©”ì‹œì§€ ê´€ë¦¬ ì „ëµ
- [Trimming and Filtering Messages](https://langchain-ai.github.io/langgraph/how-tos/memory/manage-conversation-history/)
- [RemoveMessage ì‚¬ìš©ë²•](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.modifier.RemoveMessage.html)
- [ë©”ì‹œì§€ ìš”ì•½ ì „ëµ](https://langchain-ai.github.io/langgraph/how-tos/memory/summary/)

### ì¶”ê°€ í•™ìŠµ ìë£Œ
- [Time Travel and Replay](https://langchain-ai.github.io/langgraph/concepts/low_level/#time-travel)
- [Human-in-the-Loop with Checkpoints](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/review_tool_calls/)
- [Multi-User Applications](https://langchain-ai.github.io/langgraph/concepts/multi_tenancy/)

---

**ë‹¤ìŒ í•™ìŠµ**: [LangGraph ë©”ëª¨ë¦¬ ê´€ë¦¬ - Part 2: ì¥ê¸° ë©”ëª¨ë¦¬ (InMemoryStore, í¬ë¡œìŠ¤ ìŠ¤ë ˆë“œ ë©”ëª¨ë¦¬)]
