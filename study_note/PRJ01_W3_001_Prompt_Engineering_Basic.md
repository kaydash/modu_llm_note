# W3_001_Prompt_Engineering_Basic.md - í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê¸°ì´ˆ

## ğŸ¯ í•™ìŠµ ëª©í‘œ

- íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì˜ ê¸°ë³¸ êµ¬ì¡°ì™€ ì„¤ê³„ ì›ì¹™ì„ ì´í•´í•©ë‹ˆë‹¤
- ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ ìœ í˜•(ì§ˆë¬¸í˜•, ì§€ì‹œí˜•, ëŒ€í™”í˜•, ì¡°ê±´ë¶€, ì˜ˆì‹œ ê¸°ë°˜)ì„ ì‹¤ìŠµí•©ë‹ˆë‹¤
- LangChainì˜ PromptTemplateê³¼ ChatPromptTemplateì„ í™œìš©í•©ë‹ˆë‹¤
- ëª…í™•ì„±, ë§¥ë½ì„±, êµ¬ì¡°í™”ì˜ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ í•µì‹¬ ì›ì¹™ì„ ì ìš©í•©ë‹ˆë‹¤
- ë§ì¶¤í˜• í•™ìŠµ ë„ìš°ë¯¸ ì±—ë´‡ì„ êµ¬í˜„í•˜ì—¬ ì‹¤ë¬´ ì ìš© ëŠ¥ë ¥ì„ ê°œë°œí•©ë‹ˆë‹¤

## ğŸ“š í•µì‹¬ ê°œë…

### 1. í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì´ë€?

í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì€ AI ëª¨ë¸ì—ê²Œ íš¨ê³¼ì ì¸ ì§€ì‹œë¥¼ ì œê³µí•˜ì—¬ ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ì–»ì–´ë‚´ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ì…ë ¥(í”„ë¡¬í”„íŠ¸)ì„ ìµœì í™”í•˜ì—¬ ì¶œë ¥ì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ëŠ” ë°©ë²•ë¡ ìœ¼ë¡œ, í˜„ëŒ€ AI ê°œë°œì—ì„œ í•µì‹¬ì ì¸ ì—­í• ì„ í•©ë‹ˆë‹¤.

#### í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì˜ ì¤‘ìš”ì„±
```python
# ì¼ë°˜ì ì¸ í”„ë¡¬í”„íŠ¸ vs ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸

# ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
basic_prompt = "AIì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜"

# ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸
optimized_prompt = """
ì£¼ì œ: ì¸ê³µì§€ëŠ¥
ëŒ€ìƒ: ê³ ë“±í•™ìƒ
ëª©ì : ì§„ë¡œ ì„ íƒì„ ìœ„í•œ ê¸°ì´ˆ ì´í•´

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”:
1. ì •ì˜ (2ë¬¸ì¥)
2. ì£¼ìš” ë¶„ì•¼ 3ê°€ì§€ (ê°ê° 1ë¬¸ì¥ì”©)
3. ë¯¸ë˜ ì „ë§ (2ë¬¸ì¥)

ì´ 500ì ì´ë‚´ë¡œ ì‘ì„±í•˜ê³ , ì „ë¬¸ìš©ì–´ì—ëŠ” ê°„ë‹¨í•œ ì„¤ëª…ì„ ê´„í˜¸ ì•ˆì— í¬í•¨í•´ì£¼ì„¸ìš”.
"""
```

### 2. í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì˜ í•µì‹¬ ì›ì¹™

#### 2.1 ëª…í™•ì„±(Clarity)
ëª¨í˜¸í•˜ì§€ ì•Šì€ ëª…í™•í•œ ì§€ì‹œì‚¬í•­ì„ ì œê³µí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

**ë‚˜ìœ ì˜ˆì‹œ:**
```python
vague_prompt = "ìš”ì•½í•´ì£¼ì„¸ìš”"
```

**ì¢‹ì€ ì˜ˆì‹œ:**
```python
clear_prompt = """
ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ì •í™•íˆ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”:
- ê° ë¬¸ì¥ì€ 20ë‹¨ì–´ ì´ë‚´
- í•µì‹¬ ë‚´ìš©ë§Œ í¬í•¨
- ì „ë¬¸ìš©ì–´ëŠ” ì¼ë°˜ìš©ì–´ë¡œ ëŒ€ì²´
"""
```

#### 2.2 ë§¥ë½ì„±(Context)
ê´€ë ¨ ë°°ê²½ ì •ë³´ì™€ ì‚¬ìš© ëª©ì ì„ ëª…í™•íˆ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

```python
contextual_prompt = """
ë°°ê²½: 65ì„¸ ì´ìƒ ë…¸ì¸ ëŒ€ìƒ ìŠ¤ë§ˆíŠ¸í° êµìœ¡ í”„ë¡œê·¸ë¨
ëª©ì : ì²˜ìŒ ìŠ¤ë§ˆíŠ¸í°ì„ ì‚¬ìš©í•˜ëŠ” ë…¸ì¸ë“¤ì˜ ê¸°ë³¸ ê¸°ëŠ¥ í•™ìŠµ
ëŒ€ìƒ: ë””ì§€í„¸ ê¸°ê¸° ì‚¬ìš© ê²½í—˜ì´ ê±°ì˜ ì—†ëŠ” ë…¸ì¸

ìœ„ ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ìŠ¤ë§ˆíŠ¸í° ê¸°ë³¸ ê¸°ëŠ¥ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”:
- ì‰¬ìš´ ìš©ì–´ ì‚¬ìš©
- ë‹¨ê³„ë³„ ì„¤ëª…
- ì‹¤ìƒí™œ ì˜ˆì‹œ í¬í•¨
"""
```

#### 2.3 êµ¬ì¡°í™”(Structure)
ì²´ê³„ì ì¸ í˜•ì‹ê³¼ ë‹¨ê³„ë³„ ì§€ì‹œì‚¬í•­ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

```python
structured_prompt = """
[ì‘ì—… ë‹¨ê³„]
1. í…ìŠ¤íŠ¸ ë¶„ì„
2. í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
3. ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
4. ìš”ì•½ë¬¸ ì‘ì„±

[ì¶œë ¥ í˜•ì‹]
- í‚¤ì›Œë“œ: [í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, í‚¤ì›Œë“œ3]
- ì¹´í…Œê³ ë¦¬: [ë¶„ë¥˜ëª…]
- ìš”ì•½: [2ë¬¸ì¥ ìš”ì•½]

[ì œì•½ì‚¬í•­]
- ê°ê´€ì  ì‚¬ì‹¤ë§Œ í¬í•¨
- 200ì ì´ë‚´ ì‘ì„±
"""
```

### 3. í”„ë¡¬í”„íŠ¸ ìœ í˜•ë³„ íŠ¹ì„±

#### 3.1 ì§ˆë¬¸í˜• í”„ë¡¬í”„íŠ¸ (Question Prompts)
ì •ë³´ ì¶”ì¶œì— íš¨ê³¼ì ì´ë©° êµ¬ì²´ì ì¸ ë‹µë³€ì„ ìœ ë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**íŠ¹ì§•:**
- ëª…í™•í•œ ì •ë³´ ìš”ì²­
- êµ¬ì²´ì  ë‹µë³€ ìœ ë„
- ë¶„ì„ì  ì‚¬ê³  ì´‰ì§„

```python
question_types = {
    'factual': "ì–‘ì ì»´í“¨íŒ…ì˜ ì •ì˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
    'analytical': "ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ì£¼ìš” ë…¼ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    'comparative': "Aì™€ Bì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    'explanatory': "ì´ í˜„ìƒì´ ë°œìƒí•˜ëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
}
```

#### 3.2 ì§€ì‹œí˜• í”„ë¡¬í”„íŠ¸ (Instruction Prompts)
ëª…í™•í•œ ì‘ì—… ìˆ˜í–‰ì„ ì§€ì‹œí•˜ë©° ë‹¨ê³„ë³„ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

**íŠ¹ì§•:**
- êµ¬ì²´ì  ì‘ì—… ì§€ì‹œ
- ë‹¨ê³„ë³„ í”„ë¡œì„¸ìŠ¤
- ëª…í™•í•œ ì¶œë ¥ í˜•ì‹

```python
instruction_types = {
    'translation': "ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”",
    'summarization': "ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”",
    'analysis': "ë‹¤ìŒ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  íŒ¨í„´ì„ ì°¾ìœ¼ì„¸ìš”",
    'generation': "ì£¼ì–´ì§„ ì£¼ì œë¡œ ì—ì„¸ì´ë¥¼ ì‘ì„±í•˜ì„¸ìš”"
}
```

#### 3.3 ëŒ€í™”í˜• í”„ë¡¬í”„íŠ¸ (Conversational Prompts)
ìì—°ìŠ¤ëŸ¬ìš´ ìƒí˜¸ì‘ìš©ê³¼ ë¬¸ë§¥ ìœ ì§€ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

**íŠ¹ì§•:**
- ì—­í•  ê¸°ë°˜ ëŒ€í™”
- ë¬¸ë§¥ ì—°ì†ì„±
- ê°œì¸í™”ëœ ì‘ë‹µ

```python
conversation_roles = {
    'system': "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ê³ ê° ì„œë¹„ìŠ¤ ë‹´ë‹¹ìì…ë‹ˆë‹¤",
    'assistant': "ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” êµì‚¬ì…ë‹ˆë‹¤",
    'user': "êµ¬ì²´ì ì¸ ë„ì›€ì´ í•„ìš”í•œ í•™ìŠµìì…ë‹ˆë‹¤"
}
```

#### 3.4 ì¡°ê±´ë¶€ í”„ë¡¬í”„íŠ¸ (Conditional Prompts)
ì…ë ¥ì— ë”°ë¼ ë‹¤ë¥¸ ì²˜ë¦¬ ë°©ì‹ì„ ì ìš©í•©ë‹ˆë‹¤.

```python
conditional_logic = """
ì…ë ¥ ìœ í˜•ì— ë”°ë¥¸ ì²˜ë¦¬:
- ì§ˆë¬¸ì¸ ê²½ìš°: ëª…í™•í•œ ë‹µë³€ ì œê³µ
- ì§„ìˆ ë¬¸ì¸ ê²½ìš°: ì‚¬ì‹¤ ì—¬ë¶€ ê²€ì¦
- ìš”ì²­ì‚¬í•­ì¸ ê²½ìš°: ë‹¨ê³„ë³„ ë°©ë²• ì„¤ëª…
"""
```

#### 3.5 ì˜ˆì‹œ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ (Few-Shot Prompts)
êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ í†µí•´ ì›í•˜ëŠ” ì¶œë ¥ í˜•ì‹ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤.

```python
few_shot_example = """
ì˜ˆì‹œ 1:
ì…ë ¥: "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”"
ì¶œë ¥: ê°ì •=ê¸ì •, ì£¼ì œ=ë‚ ì”¨, ê°•ë„=ë†’ìŒ

ì˜ˆì‹œ 2:
ì…ë ¥: "êµí†µì´ ë„ˆë¬´ ë§‰í˜€ì„œ ì§œì¦ë‚˜ìš”"
ì¶œë ¥: ê°ì •=ë¶€ì •, ì£¼ì œ=êµí†µ, ê°•ë„=ë†’ìŒ

ì´ì œ ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”:
ì…ë ¥: {user_input}
ì¶œë ¥:
"""
```

## ğŸ”§ í™˜ê²½ ì„¤ì •

### 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

```bash
# uv ì‚¬ìš© (ê¶Œì¥)
uv add langchain langchain-openai python-dotenv

# pip ì‚¬ìš©
pip install langchain langchain-openai python-dotenv
```

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
# .env íŒŒì¼ì— ì¶”ê°€
OPENAI_API_KEY=your_openai_api_key_here

# Langfuse ì¶”ì  (ì„ íƒì‚¬í•­)
LANGFUSE_ENABLED=false
LANGFUSE_SECRET_KEY=your_secret_key
LANGFUSE_PUBLIC_KEY=your_public_key
LANGFUSE_HOST=https://cloud.langfuse.com
```

### 3. ê¸°ë³¸ ì„í¬íŠ¸

```python
import os
from dotenv import load_dotenv
from pprint import pprint
from typing import Dict, List, Any, Optional

# LangChain ê´€ë ¨
from langchain.prompts import PromptTemplate
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.prompts import HumanMessagePromptTemplate, SystemMessagePromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# LLM ì´ˆê¸°í™”
llm = ChatOpenAI(
    model="gpt-4.1-mini",
    temperature=0,
    api_key=os.getenv("OPENAI_API_KEY")
)
```

## ğŸ’» ì½”ë“œ ì˜ˆì œ

### 1. ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ í™œìš©

```python
class BasicPromptManager:
    def __init__(self, model_name: str = "gpt-4.1-mini", temperature: float = 0):
        """ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ì ì´ˆê¸°í™”"""
        self.llm = ChatOpenAI(model=model_name, temperature=temperature)

    def create_question_prompt(self, template: str, variables: List[str]) -> PromptTemplate:
        """ì§ˆë¬¸í˜• í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return PromptTemplate(
            template=template,
            input_variables=variables
        )

    def create_instruction_prompt(self, template: str, variables: List[str]) -> PromptTemplate:
        """ì§€ì‹œí˜• í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return PromptTemplate(
            template=template,
            input_variables=variables
        )

    def execute_chain(self, prompt: PromptTemplate, inputs: Dict[str, Any]) -> str:
        """í”„ë¡¬í”„íŠ¸ ì²´ì¸ ì‹¤í–‰"""
        chain = prompt | self.llm | StrOutputParser()
        return chain.invoke(inputs)

# ì‚¬ìš© ì˜ˆì‹œ
prompt_manager = BasicPromptManager()

# 1. ì§ˆë¬¸í˜• í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ
question_template = """
ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ì„¸ ê°€ì§€ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:

[ì£¼ì œ]
{topic}

[ë¶„ì„ ê´€ì ]
1. ê¸°ìˆ ì  ì¸¡ë©´
2. ê²½ì œì  ì¸¡ë©´
3. ì‚¬íšŒì  ì¸¡ë©´

ê° ê´€ì ë³„ë¡œ 2-3ë¬¸ì¥ì”© ì„¤ëª…í•´ì£¼ì„¸ìš”.
"""

question_prompt = prompt_manager.create_question_prompt(
    template=question_template,
    variables=["topic"]
)

result = prompt_manager.execute_chain(
    prompt=question_prompt,
    inputs={"topic": "ì¸ê³µì§€ëŠ¥ì˜ ë°œì „"}
)

print("=== ì§ˆë¬¸í˜• í”„ë¡¬í”„íŠ¸ ê²°ê³¼ ===")
print(result)

# 2. ì§€ì‹œí˜• í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ
instruction_template = """
ë‹¤ìŒ í…ìŠ¤íŠ¸ì— ëŒ€í•´ ì•„ë˜ ì‘ì—…ì„ ìˆœì„œëŒ€ë¡œ ìˆ˜í–‰í•˜ì„¸ìš”:

[í…ìŠ¤íŠ¸]
{text}

[ì‘ì—… ìˆœì„œ]
1. í…ìŠ¤íŠ¸ë¥¼ 1ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½
2. í•µì‹¬ í‚¤ì›Œë“œ 3ê°œ ì¶”ì¶œ
3. ê°ì • ë¶„ì„ ìˆ˜í–‰ (ê¸ì •/ë¶€ì •/ì¤‘ë¦½)
4. ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (ê¸°ìˆ /ê²½ì œ/ì‚¬íšŒ/ë¬¸í™”/ê¸°íƒ€)

[ì‘ì—… ê²°ê³¼]
ìš”ì•½:
í‚¤ì›Œë“œ:
ê°ì •:
ì¹´í…Œê³ ë¦¬:
"""

instruction_prompt = prompt_manager.create_instruction_prompt(
    template=instruction_template,
    variables=["text"]
)

text_input = """
ìµœê·¼ AI ê¸°ìˆ ì˜ ê¸‰ì†í•œ ë°œì „ìœ¼ë¡œ ë§ì€ ì‚°ì—… ë¶„ì•¼ì—ì„œ í˜ì‹ ì´ ì¼ì–´ë‚˜ê³  ìˆë‹¤.
íŠ¹íˆ ìì—°ì–´ ì²˜ë¦¬, ì»´í“¨í„° ë¹„ì „, ë¡œë´‡ ê³µí•™ ë“±ì˜ ì˜ì—­ì—ì„œ ë†€ë¼ìš´ ì„±ê³¼ë¥¼ ë³´ì´ê³  ìˆìœ¼ë©°,
ì´ëŠ” ìš°ë¦¬ì˜ ì¼ìƒìƒí™œê³¼ ì—…ë¬´ í™˜ê²½ì„ í¬ê²Œ ë³€í™”ì‹œí‚¤ê³  ìˆë‹¤.
"""

result = prompt_manager.execute_chain(
    prompt=instruction_prompt,
    inputs={"text": text_input}
)

print("\n=== ì§€ì‹œí˜• í”„ë¡¬í”„íŠ¸ ê²°ê³¼ ===")
print(result)
```

### 2. ëŒ€í™”í˜• í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ

```python
class ConversationalPromptSystem:
    def __init__(self, model_name: str = "gpt-4.1-mini", temperature: float = 0.1):
        """ëŒ€í™”í˜• í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.llm = ChatOpenAI(model=model_name, temperature=temperature)

    def create_chat_prompt(
        self,
        system_message: str,
        human_template: str,
        variables: List[str]
    ) -> ChatPromptTemplate:
        """ì±„íŒ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±"""
        return ChatPromptTemplate.from_messages([
            ("system", system_message),
            ("human", human_template)
        ])

    def create_role_based_prompt(
        self,
        system_template: str,
        human_template: str,
        system_variables: List[str] = None,
        human_variables: List[str] = None
    ) -> ChatPromptTemplate:
        """ì—­í•  ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        messages = [
            SystemMessagePromptTemplate.from_template(system_template),
            HumanMessagePromptTemplate.from_template(human_template)
        ]
        return ChatPromptTemplate.from_messages(messages)

    def execute_conversation(self, prompt: ChatPromptTemplate, inputs: Dict[str, Any]) -> str:
        """ëŒ€í™” ì‹¤í–‰"""
        chain = prompt | self.llm | StrOutputParser()
        return chain.invoke(inputs)

# ì‚¬ìš© ì˜ˆì‹œ
chat_system = ConversationalPromptSystem()

# 1. ê³ ê° ì„œë¹„ìŠ¤ ì±—ë´‡ ì˜ˆì‹œ
customer_service_prompt = chat_system.create_chat_prompt(
    system_message="ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ê³ ê° ì„œë¹„ìŠ¤ ë‹´ë‹¹ìì…ë‹ˆë‹¤. ê³ ê°ì˜ ë¬¸ì œë¥¼ ì •í™•íˆ íŒŒì•…í•˜ê³  í•´ê²°ì±…ì„ ì œì‹œí•´ì£¼ì„¸ìš”.",
    human_template="ê³ ê° ë¬¸ì˜: {customer_message}",
    variables=["customer_message"]
)

customer_response = chat_system.execute_conversation(
    prompt=customer_service_prompt,
    inputs={"customer_message": "ì œí’ˆ ë°°ì†¡ì´ ì§€ì—°ë˜ê³  ìˆëŠ”ë° ì–¸ì œì¯¤ ë°›ì„ ìˆ˜ ìˆì„ê¹Œìš”?"}
)

print("=== ê³ ê° ì„œë¹„ìŠ¤ ì‘ë‹µ ===")
print(customer_response)

# 2. êµìœ¡ íŠœí„° ì‹œìŠ¤í…œ ì˜ˆì‹œ
tutor_system_message = """
ë‹¹ì‹ ì€ ê²½í—˜ì´ í’ë¶€í•œ {subject} êµì‚¬ì…ë‹ˆë‹¤.
í•™ìƒì˜ ìˆ˜ì¤€: {level}
êµìœ¡ ëª©í‘œ: {goal}

ë‹¤ìŒ ì›ì¹™ì— ë”°ë¼ ê°€ë¥´ì³ì£¼ì„¸ìš”:
- í•™ìƒ ìˆ˜ì¤€ì— ë§ëŠ” ìš©ì–´ì™€ ì˜ˆì‹œ ì‚¬ìš©
- ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•˜ì—¬ ì´í•´ë¥¼ ë•ê¸°
- ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ì–¸ì œë“  ì§ˆë¬¸í•˜ë„ë¡ ê²©ë ¤
- ì‹¤ìƒí™œ ì˜ˆì‹œë¥¼ í†µí•œ ì´í•´ ì¦ì§„
"""

tutor_prompt = chat_system.create_role_based_prompt(
    system_template=tutor_system_message,
    human_template="í•™ìƒ ì§ˆë¬¸: {student_question}",
    system_variables=["subject", "level", "goal"],
    human_variables=["student_question"]
)

tutor_response = chat_system.execute_conversation(
    prompt=tutor_prompt,
    inputs={
        "subject": "ìˆ˜í•™",
        "level": "ì¤‘í•™êµ 2í•™ë…„",
        "goal": "ì´ì°¨í•¨ìˆ˜ì˜ ê¸°ë³¸ ê°œë… ì´í•´",
        "student_question": "ì´ì°¨í•¨ìˆ˜ê°€ ì™œ í¬ë¬¼ì„  ëª¨ì–‘ì´ ë˜ëŠ”ì§€ ì´í•´ê°€ ì•ˆë¼ìš”"
    }
)

print("\n=== êµìœ¡ íŠœí„° ì‘ë‹µ ===")
print(tutor_response)
```

### 3. ì¡°ê±´ë¶€ ë° Few-Shot í”„ë¡¬í”„íŠ¸

```python
class AdvancedPromptTechniques:
    def __init__(self, model_name: str = "gpt-4.1-mini", temperature: float = 0):
        """ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ê¸°ë²• í´ë˜ìŠ¤"""
        self.llm = ChatOpenAI(model=model_name, temperature=temperature)

    def create_conditional_prompt(self, template: str, variables: List[str]) -> PromptTemplate:
        """ì¡°ê±´ë¶€ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return PromptTemplate(template=template, input_variables=variables)

    def create_few_shot_prompt(
        self,
        examples: List[Dict[str, str]],
        input_template: str,
        variables: List[str]
    ) -> PromptTemplate:
        """Few-Shot í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        example_text = ""
        for i, example in enumerate(examples, 1):
            example_text += f"\nì˜ˆì‹œ {i}:\n"
            for key, value in example.items():
                example_text += f"{key}: {value}\n"

        full_template = f"{example_text}\nì´ì œ ë‹¤ìŒ ì…ë ¥ì„ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬í•´ì£¼ì„¸ìš”:\n{input_template}"

        return PromptTemplate(template=full_template, input_variables=variables)

    def execute_prompt(self, prompt: PromptTemplate, inputs: Dict[str, Any]) -> str:
        """í”„ë¡¬í”„íŠ¸ ì‹¤í–‰"""
        chain = prompt | self.llm | StrOutputParser()
        return chain.invoke(inputs)

# ì‚¬ìš© ì˜ˆì‹œ
advanced_prompts = AdvancedPromptTechniques()

# 1. ì¡°ê±´ë¶€ í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ
conditional_template = """
ì…ë ¥ í…ìŠ¤íŠ¸: {text}

ë‹¤ìŒ ì¡°ê±´ì— ë”°ë¼ ì²˜ë¦¬í•´ì£¼ì„¸ìš”:

ì¡°ê±´ 1: ì…ë ¥ì´ ì§ˆë¬¸ì¸ ê²½ìš°
â†’ ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ ë‹µë³€ ì œê³µ
â†’ í•„ìš”ì‹œ ì˜ˆì‹œ í¬í•¨

ì¡°ê±´ 2: ì…ë ¥ì´ ì§„ìˆ ë¬¸ì¸ ê²½ìš°
â†’ ì§„ìˆ ë¬¸ì˜ ì‚¬ì‹¤ ì—¬ë¶€ ê²€ì¦
â†’ ê·¼ê±°ì™€ ì¶œì²˜ ì œì‹œ

ì¡°ê±´ 3: ì…ë ¥ì´ ìš”ì²­ì‚¬í•­ì¸ ê²½ìš°
â†’ ìˆ˜í–‰ ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…
â†’ ì£¼ì˜ì‚¬í•­ì´ë‚˜ íŒ í¬í•¨

ì‘ë‹µ í˜•ì‹:
ìœ í˜•: [ì§ˆë¬¸/ì§„ìˆ ë¬¸/ìš”ì²­ì‚¬í•­]
ë‚´ìš©: [ìƒì„¸ ì‘ë‹µ]
ì¶”ê°€ ì •ë³´: [í•„ìš”í•œ ê²½ìš°ë§Œ]
"""

conditional_prompt = advanced_prompts.create_conditional_prompt(
    template=conditional_template,
    variables=["text"]
)

# í…ŒìŠ¤íŠ¸ ì…ë ¥ë“¤
test_inputs = [
    "ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",  # ì§ˆë¬¸
    "Pythonì€ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ì¤‘ì—ì„œ ê°€ì¥ ì‰¬ìš´ ì–¸ì–´ì´ë‹¤.",  # ì§„ìˆ ë¬¸
    "íŒŒì´ì¬ìœ¼ë¡œ ì›¹ í¬ë¡¤ë§ì„ ì‹œì‘í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”."  # ìš”ì²­ì‚¬í•­
]

print("=== ì¡°ê±´ë¶€ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ ===")
for i, test_input in enumerate(test_inputs, 1):
    result = advanced_prompts.execute_prompt(
        prompt=conditional_prompt,
        inputs={"text": test_input}
    )
    print(f"\n--- í…ŒìŠ¤íŠ¸ {i} ---")
    print(f"ì…ë ¥: {test_input}")
    print(f"ê²°ê³¼: {result}")

# 2. Few-Shot í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ
sentiment_examples = [
    {
        "ë¦¬ë·°": "ì´ ì œí’ˆ ì •ë§ ì¢‹ì•„ìš”! í’ˆì§ˆì´ í›Œë¥­í•˜ê³  ë°°ì†¡ë„ ë¹¨ëìŠµë‹ˆë‹¤.",
        "ë¶„ì„": "ê°ì •=ê¸ì •, ë§Œì¡±ë„=ë†’ìŒ, ì£¼ìš” ìš”ì†Œ=[í’ˆì§ˆ, ë°°ì†¡], í‰ì =5/5"
    },
    {
        "ë¦¬ë·°": "ê°€ê²© ëŒ€ë¹„ ê´œì°®ì€ í¸ì´ì§€ë§Œ ë””ìì¸ì´ ì•„ì‰¬ì›Œìš”.",
        "ë¶„ì„": "ê°ì •=ì¤‘ë¦½, ë§Œì¡±ë„=ë³´í†µ, ì£¼ìš” ìš”ì†Œ=[ê°€ê²©, ë””ìì¸], í‰ì =3/5"
    },
    {
        "ë¦¬ë·°": "ì™„ì „ ì‹¤ë§í–ˆìŠµë‹ˆë‹¤. í’ˆì§ˆë„ ì•ˆì¢‹ê³  ê³ ê°ì„œë¹„ìŠ¤ë„ ë¶ˆì¹œì ˆí•´ìš”.",
        "ë¶„ì„": "ê°ì •=ë¶€ì •, ë§Œì¡±ë„=ë‚®ìŒ, ì£¼ìš” ìš”ì†Œ=[í’ˆì§ˆ, ì„œë¹„ìŠ¤], í‰ì =1/5"
    }
]

few_shot_prompt = advanced_prompts.create_few_shot_prompt(
    examples=sentiment_examples,
    input_template="ë¦¬ë·°: {review}\në¶„ì„:",
    variables=["review"]
)

test_review = "ë°°ì†¡ì€ ë¹¨ëëŠ”ë° í¬ì¥ì´ ë„ˆë¬´ í—ˆìˆ í•´ì„œ ì œí’ˆì´ ì•½ê°„ ì†ìƒë˜ì—ˆì–´ìš”. ê·¸ë˜ë„ ì‚¬ìš©í•˜ëŠ”ë° ë¬¸ì œëŠ” ì—†ë„¤ìš”."

few_shot_result = advanced_prompts.execute_prompt(
    prompt=few_shot_prompt,
    inputs={"review": test_review}
)

print("\n\n=== Few-Shot í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ ===")
print(f"í…ŒìŠ¤íŠ¸ ë¦¬ë·°: {test_review}")
print(f"ë¶„ì„ ê²°ê³¼: {few_shot_result}")
```

### 4. í”„ë¡¬í”„íŠ¸ ìµœì í™” ì‹œìŠ¤í…œ

```python
class PromptOptimizer:
    def __init__(self, model_name: str = "gpt-4.1-mini"):
        """í”„ë¡¬í”„íŠ¸ ìµœì í™” ì‹œìŠ¤í…œ"""
        self.llm = ChatOpenAI(model=model_name, temperature=0)

    def analyze_prompt_quality(self, prompt_text: str) -> Dict[str, Any]:
        """í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ ë¶„ì„"""
        analysis_prompt = PromptTemplate(
            template="""
ë‹¤ìŒ í”„ë¡¬í”„íŠ¸ì˜ í’ˆì§ˆì„ ë¶„ì„í•˜ê³  ê°œì„ ì ì„ ì œì•ˆí•´ì£¼ì„¸ìš”:

[ë¶„ì„ ëŒ€ìƒ í”„ë¡¬í”„íŠ¸]
{prompt_text}

[ë¶„ì„ ê¸°ì¤€]
1. ëª…í™•ì„±: ì§€ì‹œì‚¬í•­ì´ ëª…í™•í•œê°€?
2. êµ¬ì²´ì„±: êµ¬ì²´ì ì¸ ìš”êµ¬ì‚¬í•­ì´ ìˆëŠ”ê°€?
3. êµ¬ì¡°í™”: ì²´ê³„ì ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆëŠ”ê°€?
4. ë§¥ë½ì„±: ì¶©ë¶„í•œ ë§¥ë½ ì •ë³´ê°€ ìˆëŠ”ê°€?

[ì¶œë ¥ í˜•ì‹]
ì ìˆ˜ (1-5ì ):
- ëª…í™•ì„±: X/5
- êµ¬ì²´ì„±: X/5
- êµ¬ì¡°í™”: X/5
- ë§¥ë½ì„±: X/5

ê°œì„ ì :
- [êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆ]

ê°œì„ ëœ í”„ë¡¬í”„íŠ¸:
[ìµœì í™”ëœ ë²„ì „]
""",
            input_variables=["prompt_text"]
        )

        chain = analysis_prompt | self.llm | StrOutputParser()
        return chain.invoke({"prompt_text": prompt_text})

    def create_optimized_prompt(
        self,
        task_description: str,
        target_audience: str,
        desired_output: str,
        constraints: List[str] = None
    ) -> str:
        """ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        optimization_template = """
ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

ì‘ì—… ì„¤ëª…: {task_description}
ëŒ€ìƒ ì‚¬ìš©ì: {target_audience}
ì›í•˜ëŠ” ì¶œë ¥: {desired_output}
ì œì•½ì‚¬í•­: {constraints}

í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ì›ì¹™ì„ ì ìš©í•˜ì—¬:
1. ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ ì§€ì‹œì‚¬í•­
2. ì ì ˆí•œ ë§¥ë½ ì •ë³´ í¬í•¨
3. ì²´ê³„ì ì¸ êµ¬ì¡°í™”
4. ì›í•˜ëŠ” ì¶œë ¥ í˜•ì‹ ëª…ì‹œ

ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸:
"""

        prompt = PromptTemplate(
            template=optimization_template,
            input_variables=["task_description", "target_audience", "desired_output", "constraints"]
        )

        chain = prompt | self.llm | StrOutputParser()

        constraints_text = ", ".join(constraints) if constraints else "ì—†ìŒ"

        return chain.invoke({
            "task_description": task_description,
            "target_audience": target_audience,
            "desired_output": desired_output,
            "constraints": constraints_text
        })

# ì‚¬ìš© ì˜ˆì‹œ
optimizer = PromptOptimizer()

# 1. ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ ë¶„ì„
existing_prompt = "AIì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”."

quality_analysis = optimizer.analyze_prompt_quality(existing_prompt)
print("=== í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ ë¶„ì„ ===")
print(quality_analysis)

# 2. ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
optimized_prompt = optimizer.create_optimized_prompt(
    task_description="ê³ ë“±í•™ìƒì„ ìœ„í•œ ì¸ê³µì§€ëŠ¥ ê°œë… ì„¤ëª…",
    target_audience="ì¸ê³µì§€ëŠ¥ì— ëŒ€í•œ ì‚¬ì „ ì§€ì‹ì´ ì—†ëŠ” ê³ ë“±í•™ìƒ",
    desired_output="ì •ì˜, ì‘ìš© ë¶„ì•¼, ë¯¸ë˜ ì „ë§ì„ í¬í•¨í•œ 500ì ì´ë‚´ ì„¤ëª…",
    constraints=["ì‰¬ìš´ ìš©ì–´ ì‚¬ìš©", "ì‹¤ìƒí™œ ì˜ˆì‹œ í¬í•¨", "ì§„ë¡œ ì—°ê²° ì •ë³´ ì œê³µ"]
)

print("\n=== ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ===")
print(optimized_prompt)
```

## ğŸš€ ì‹¤ìŠµí•´ë³´ê¸°

### ì‹¤ìŠµ 1: ë‹¤ë‹¨ê³„ ë¶„ì„ ì‹œìŠ¤í…œ

ë‘ ê°œì˜ ë¬¸ì¥ì„ ë¹„êµ ë¶„ì„í•˜ëŠ” ì²´ì¸ì„ êµ¬ì„±í•´ë³´ì„¸ìš”.

```python
# ë¬¸ì¥ ë¹„êµ ë¶„ì„ ì‹œìŠ¤í…œ êµ¬í˜„
class SentenceComparator:
    def __init__(self):
        # ì´ˆê¸°í™” ì½”ë“œ ì‘ì„±
        pass

    def create_comparison_prompt(self):
        # ë¹„êµ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì‘ì„±
        pass

    def analyze_sentences(self, sentence1, sentence2):
        # ë¬¸ì¥ ë¹„êµ ë¶„ì„ ì‹¤í–‰
        pass
```

### ì‹¤ìŠµ 2: ë¦¬ë·° ë¶„ì„ ì‹œìŠ¤í…œ

ìƒí’ˆ ë¦¬ë·°ë¥¼ ë¶„ì„í•˜ëŠ” ëŒ€í™”í˜• AI ì‹œìŠ¤í…œì„ êµ¬í˜„í•´ë³´ì„¸ìš”.

```python
# ë¦¬ë·° ë¶„ì„ ì „ë¬¸ê°€ ì‹œìŠ¤í…œ êµ¬í˜„
class ReviewAnalyzer:
    def __init__(self):
        # ì´ˆê¸°í™” ì½”ë“œ ì‘ì„±
        pass

    def create_review_analyzer(self):
        # ë¦¬ë·° ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì‘ì„±
        pass

    def analyze_multiple_reviews(self, reviews):
        # ë‹¤ì¤‘ ë¦¬ë·° ë¶„ì„
        pass
```

### ì‹¤ìŠµ 3: ë§ì¶¤í˜• í•™ìŠµ ë„ìš°ë¯¸

íŠ¹ì • ì£¼ì œì— ëŒ€í•œ í•™ìŠµì„ ë•ëŠ” ì±—ë´‡ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”.

```python
# í•™ìŠµ ë„ìš°ë¯¸ ì±—ë´‡ êµ¬í˜„
class LearningAssistant:
    def __init__(self, subject):
        # ì´ˆê¸°í™” ì½”ë“œ ì‘ì„±
        pass

    def create_quiz_system(self):
        # í€´ì¦ˆ ìƒì„± ì‹œìŠ¤í…œ êµ¬í˜„
        pass

    def create_explanation_system(self):
        # ê°œë… ì„¤ëª… ì‹œìŠ¤í…œ êµ¬í˜„
        pass
```

## ğŸ“‹ í•´ë‹µ

### ì‹¤ìŠµ 1: ë‹¤ë‹¨ê³„ ë¶„ì„ ì‹œìŠ¤í…œ

```python
class SentenceComparator:
    def __init__(self, model_name: str = "gpt-4.1-mini", temperature: float = 0):
        """ë¬¸ì¥ ë¹„êµ ë¶„ì„ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.llm = ChatOpenAI(model=model_name, temperature=temperature)

    def create_comparison_prompt(self) -> PromptTemplate:
        """ë¹„êµ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        template = """
ë‹¤ìŒ ë‘ ë¬¸ì¥ì˜ ë§¥ë½ ì¼ì¹˜ë„ë¥¼ ë‹¨ê³„ë³„ë¡œ ë¶„ì„í•˜ì„¸ìš”:

[Aë¬¸ì¥]
{sentence_a}

[Bë¬¸ì¥]
{sentence_b}

[ë¶„ì„ ë‹¨ê³„]
1. ê° ë¬¸ì¥ì„ 1ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ ìš”ì•½
2. ê° ë¬¸ì¥ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ 3ê°œ ì¶”ì¶œ
3. í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ë„ ë¶„ì„
4. ì˜ë¯¸ì  ë§¥ë½ ì¼ì¹˜ë„ íŒë‹¨
5. ìµœì¢… ê²°ë¡  (ì¼ì¹˜/ë¶€ë¶„ì¼ì¹˜/ë¶ˆì¼ì¹˜)

[ì¶œë ¥ í˜•ì‹]
**1ë‹¨ê³„ - ìš”ì•½**
Aë¬¸ì¥ ìš”ì•½:
Bë¬¸ì¥ ìš”ì•½:

**2ë‹¨ê³„ - í‚¤ì›Œë“œ ì¶”ì¶œ**
Aë¬¸ì¥ í‚¤ì›Œë“œ: [í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, í‚¤ì›Œë“œ3]
Bë¬¸ì¥ í‚¤ì›Œë“œ: [í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, í‚¤ì›Œë“œ3]

**3ë‹¨ê³„ - ìœ ì‚¬ë„ ë¶„ì„**
ê³µí†µ í‚¤ì›Œë“œ:
ê´€ë ¨ í‚¤ì›Œë“œ:
ì°¨ì´ì :

**4ë‹¨ê³„ - ë§¥ë½ ë¶„ì„**
ì£¼ì œ ì¼ì¹˜ë„:
ë…¼ì¡° ìœ ì‚¬ì„±:
ì˜ë„ ì¼ì¹˜ë„:

**5ë‹¨ê³„ - ìµœì¢… ê²°ë¡ **
ë§¥ë½ ì¼ì¹˜ë„: [ì¼ì¹˜/ë¶€ë¶„ì¼ì¹˜/ë¶ˆì¼ì¹˜]
ì¼ì¹˜ë„ ì ìˆ˜: X/10ì 
ê·¼ê±°:
"""
        return PromptTemplate(
            template=template,
            input_variables=["sentence_a", "sentence_b"]
        )

    def analyze_sentences(self, sentence1: str, sentence2: str) -> Dict[str, Any]:
        """ë¬¸ì¥ ë¹„êµ ë¶„ì„ ì‹¤í–‰"""
        prompt = self.create_comparison_prompt()
        chain = prompt | self.llm | StrOutputParser()

        result = chain.invoke({
            "sentence_a": sentence1,
            "sentence_b": sentence2
        })

        return {
            "sentence_a": sentence1,
            "sentence_b": sentence2,
            "analysis": result
        }

    def batch_comparison(self, sentence_pairs: List[tuple]) -> List[Dict[str, Any]]:
        """ë‹¤ì¤‘ ë¬¸ì¥ ìŒ ë¹„êµ"""
        results = []

        for i, (sent_a, sent_b) in enumerate(sentence_pairs, 1):
            print(f"\n=== ë¹„êµ ë¶„ì„ {i} ===")
            result = self.analyze_sentences(sent_a, sent_b)
            results.append(result)
            print(result['analysis'])

        return results

# ì‹¤ìŠµ 1 í…ŒìŠ¤íŠ¸
comparator = SentenceComparator()

test_pairs = [
    (
        "ì‚¬ëŒì€ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ì‚¬ì†Œí†µì„ í•œë‹¤.",
        "ì¸ê°„ì€ ì–¸ì–´ë¥¼ í†µí•´ ì„œë¡œ ì†Œí†µí•œë‹¤."
    ),
    (
        "ì¸ê³µì§€ëŠ¥ì€ ë¯¸ë˜ ì‚¬íšŒë¥¼ ë³€í™”ì‹œí‚¬ ê²ƒì´ë‹¤.",
        "ê³ ì–‘ì´ëŠ” ê·€ì—¬ìš´ ë™ë¬¼ì´ë‹¤."
    ),
    (
        "ê¸°ìˆ ì˜ ë°œì „ì€ ì¸ë¥˜ì—ê²Œ ë„ì›€ì´ ëœë‹¤.",
        "ê³¼í•™ ê¸°ìˆ ì˜ ì§„ë³´ëŠ” ì‚¬íšŒ ë°œì „ì— ê¸°ì—¬í•œë‹¤."
    )
]

comparison_results = comparator.batch_comparison(test_pairs)

# ê²°ê³¼ ìš”ì•½
print("\n=== ë¹„êµ ë¶„ì„ ìš”ì•½ ===")
for i, result in enumerate(comparison_results, 1):
    print(f"{i}. ë¬¸ì¥ ìŒì˜ ë§¥ë½ ì¼ì¹˜ ì—¬ë¶€ ë¶„ì„ ì™„ë£Œ")
```

### ì‹¤ìŠµ 2: ë¦¬ë·° ë¶„ì„ ì‹œìŠ¤í…œ

```python
class ReviewAnalyzer:
    def __init__(self, model_name: str = "gpt-4.1-mini", temperature: float = 0.1):
        """ë¦¬ë·° ë¶„ì„ ì „ë¬¸ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.llm = ChatOpenAI(model=model_name, temperature=temperature)

    def create_review_analyzer(self) -> ChatPromptTemplate:
        """ë¦¬ë·° ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        system_message = """
ë‹¹ì‹ ì€ ìƒí’ˆ ë¦¬ë·° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì€ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:

ë¶„ì„ ë²”ìœ„:
1. ê°ì • ë¶„ì„ (ê¸ì •/ì¤‘ë¦½/ë¶€ì •, ê°•ë„ 1-5)
2. ì£¼ìš” ì–¸ê¸‰ ìš”ì†Œ ì¶”ì¶œ (í’ˆì§ˆ, ê°€ê²©, ë°°ì†¡, ì„œë¹„ìŠ¤ ë“±)
3. ì¥ì ê³¼ ë‹¨ì  êµ¬ë¶„
4. êµ¬ë§¤ ê²°ì • ìš”ì¸ ë¶„ì„
5. ê°œì„ ì  ì œì•ˆ

ì¶œë ¥ í˜•ì‹:
**ê°ì • ë¶„ì„**
- ì „ì²´ ê°ì •: [ê¸ì •/ì¤‘ë¦½/ë¶€ì •]
- ê°ì • ê°•ë„: X/5
- ê°ì • ê·¼ê±°: [êµ¬ì²´ì  ê·¼ê±°]

**ì£¼ìš” ì–¸ê¸‰ ìš”ì†Œ**
- í’ˆì§ˆ: [ì–¸ê¸‰ë‚´ìš©/ë¯¸ì–¸ê¸‰]
- ê°€ê²©: [ì–¸ê¸‰ë‚´ìš©/ë¯¸ì–¸ê¸‰]
- ë°°ì†¡: [ì–¸ê¸‰ë‚´ìš©/ë¯¸ì–¸ê¸‰]
- ì„œë¹„ìŠ¤: [ì–¸ê¸‰ë‚´ìš©/ë¯¸ì–¸ê¸‰]
- ê¸°íƒ€: [ê¸°íƒ€ ìš”ì†Œë“¤]

**ì¥ë‹¨ì  ë¶„ì„**
- ì¥ì : [êµ¬ì²´ì  ì¥ì ë“¤]
- ë‹¨ì : [êµ¬ì²´ì  ë‹¨ì ë“¤]

**êµ¬ë§¤ ê²°ì • ìš”ì¸**
- ì£¼ìš” ê²°ì • ìš”ì¸: [í•µì‹¬ ìš”ì¸ë“¤]
- ë§ì„¤ì„ ìš”ì¸: [ìš°ë ¤ì‚¬í•­ë“¤]

**ì¢…í•© í‰ê°€**
- ì¶”ì²œë„: X/5
- í•µì‹¬ ë©”ì‹œì§€: [í•œ ë¬¸ì¥ ìš”ì•½]
- ê°œì„  ì œì•ˆ: [íŒë§¤ìë¥¼ ìœ„í•œ ì œì•ˆ]
"""

        return ChatPromptTemplate.from_messages([
            ("system", system_message),
            ("human", "ë‹¤ìŒ ë¦¬ë·°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n{review}")
        ])

    def analyze_single_review(self, review: str) -> Dict[str, Any]:
        """ë‹¨ì¼ ë¦¬ë·° ë¶„ì„"""
        prompt = self.create_review_analyzer()
        chain = prompt | self.llm | StrOutputParser()

        analysis = chain.invoke({"review": review})

        return {
            "original_review": review,
            "analysis": analysis,
            "review_length": len(review),
            "word_count": len(review.split())
        }

    def analyze_multiple_reviews(self, reviews: List[str]) -> Dict[str, Any]:
        """ë‹¤ì¤‘ ë¦¬ë·° ë¶„ì„"""
        individual_analyses = []

        for i, review in enumerate(reviews, 1):
            print(f"\n=== ë¦¬ë·° {i} ë¶„ì„ ì¤‘ ===")
            analysis = self.analyze_single_review(review)
            individual_analyses.append(analysis)
            print(f"ë¦¬ë·° ê¸¸ì´: {analysis['word_count']}ë‹¨ì–´")

        # ì¢…í•© ë¶„ì„
        summary = self._generate_summary_analysis(individual_analyses)

        return {
            "individual_analyses": individual_analyses,
            "summary_analysis": summary,
            "total_reviews": len(reviews)
        }

    def _generate_summary_analysis(self, analyses: List[Dict[str, Any]]) -> str:
        """ì¢…í•© ë¶„ì„ ìƒì„±"""
        summary_prompt = PromptTemplate(
            template="""
ë‹¤ìŒì€ {review_count}ê°œ ë¦¬ë·°ì˜ ê°œë³„ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:

{analyses_text}

ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¢…í•© ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:

**ì „ì²´ ê°ì • ë¶„í¬**
- ê¸ì •ì  ë¦¬ë·°: Xê°œ (X%)
- ì¤‘ë¦½ì  ë¦¬ë·°: Xê°œ (X%)
- ë¶€ì •ì  ë¦¬ë·°: Xê°œ (X%)

**ê³µí†µ ì–¸ê¸‰ ìš”ì†Œ**
- ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ ì¥ì :
- ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ ë‹¨ì :
- ì£¼ìš” ê´€ì‹¬ì‚¬:

**ì¢…í•© í‰ê°€**
- ì „ì²´ ë§Œì¡±ë„: X/5
- ì£¼ìš” ê°•ì :
- ê°œì„  í•„ìš”ì‚¬í•­:
- êµ¬ë§¤ ì¶”ì²œë„:

**ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸**
- ë§ˆì¼€íŒ… í¬ì¸íŠ¸:
- ì œí’ˆ ê°œì„  ë°©í–¥:
- ê³ ê° ì„œë¹„ìŠ¤ ê°œì„ ì :
""",
            input_variables=["review_count", "analyses_text"]
        )

        # ë¶„ì„ ê²°ê³¼ë“¤ì„ í…ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê¸°
        analyses_text = ""
        for i, analysis in enumerate(analyses, 1):
            analyses_text += f"\n--- ë¦¬ë·° {i} ë¶„ì„ ---\n"
            analyses_text += analysis["analysis"][:500] + "...\n"

        chain = summary_prompt | self.llm | StrOutputParser()

        return chain.invoke({
            "review_count": len(analyses),
            "analyses_text": analyses_text
        })

    def create_response_templates(self) -> Dict[str, ChatPromptTemplate]:
        """ê³ ê° ì‘ë‹µ í…œí”Œë¦¿ ìƒì„±"""
        templates = {}

        # ê¸ì •ì  ë¦¬ë·° ì‘ë‹µ
        templates['positive'] = ChatPromptTemplate.from_messages([
            ("system", "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ê³ ê° ì„œë¹„ìŠ¤ ë‹´ë‹¹ìì…ë‹ˆë‹¤. ê¸ì •ì ì¸ ë¦¬ë·°ì— ê°ì‚¬ ì¸ì‚¬ë¥¼ í‘œí˜„í•˜ì„¸ìš”."),
            ("human", "ë‹¤ìŒ ê¸ì •ì  ë¦¬ë·°ì— ëŒ€í•œ ê°ì‚¬ ì‘ë‹µì„ ì‘ì„±í•´ì£¼ì„¸ìš”:\n{review}")
        ])

        # ë¶€ì •ì  ë¦¬ë·° ì‘ë‹µ
        templates['negative'] = ChatPromptTemplate.from_messages([
            ("system", "ë‹¹ì‹ ì€ ë¬¸ì œ í•´ê²° ì „ë¬¸ ê³ ê° ì„œë¹„ìŠ¤ ë‹´ë‹¹ìì…ë‹ˆë‹¤. ë¶€ì •ì  ë¦¬ë·°ì— ëŒ€í•´ ì‚¬ê³¼í•˜ê³  í•´ê²°ì±…ì„ ì œì‹œí•˜ì„¸ìš”."),
            ("human", "ë‹¤ìŒ ë¶€ì •ì  ë¦¬ë·°ì— ëŒ€í•œ ì‚¬ê³¼ ë° í•´ê²° ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”:\n{review}")
        ])

        return templates

# ì‹¤ìŠµ 2 í…ŒìŠ¤íŠ¸
analyzer = ReviewAnalyzer()

sample_reviews = [
    "ì´ ë…¸íŠ¸ë¶ ì •ë§ ê°€ë³ê³  ì¢‹ì•„ìš”! ë°°í„°ë¦¬ë„ ì˜¤ë˜ê°€ê³  í™”ë©´ë„ ì„ ëª…í•´ìš”. ë‹¤ë§Œ ê°€ê²©ì´ ì¡°ê¸ˆ ë¹„ì‹¸ë„¤ìš”.",
    "ë°°ì†¡ì€ ë¹¨ëëŠ”ë° í¬ì¥ì´ ë„ˆë¬´ í—ˆìˆ í•´ì„œ ì œí’ˆì´ ì•½ê°„ ì†ìƒë˜ì—ˆì–´ìš”. ê·¸ë˜ë„ ì‚¬ìš©í•˜ëŠ”ë° ë¬¸ì œëŠ” ì—†ë„¤ìš”.",
    "ì™„ì „ ì‹¤ë§í–ˆìŠµë‹ˆë‹¤. ì„¤ëª…ê³¼ ë‹¤ë¥´ê³  í’ˆì§ˆë„ ì•ˆì¢‹ì•„ìš”. í™˜ë¶ˆ ìš”ì²­ë“œë¦½ë‹ˆë‹¤.",
    "ê°€ì„±ë¹„ ì¢‹ì€ ì œí’ˆì´ë„¤ìš”. ê¸°ëŒ€ë³´ë‹¤ í›¨ì”¬ ë§Œì¡±ìŠ¤ëŸ½ê³  ì¶”ì²œí•˜ê³  ì‹¶ì–´ìš”!",
    "ë³´í†µ ìˆ˜ì¤€ì´ì—ìš”. íŠ¹ë³„íˆ ì¢‹ì§€ë„ ë‚˜ì˜ì§€ë„ ì•Šì€ í‰ë²”í•œ ì œí’ˆì…ë‹ˆë‹¤."
]

# ë‹¤ì¤‘ ë¦¬ë·° ë¶„ì„ ì‹¤í–‰
analysis_results = analyzer.analyze_multiple_reviews(sample_reviews)

print("\n=== ì¢…í•© ë¶„ì„ ê²°ê³¼ ===")
print(analysis_results['summary_analysis'])

# ì‘ë‹µ í…œí”Œë¦¿ í…ŒìŠ¤íŠ¸
templates = analyzer.create_response_templates()
positive_response_chain = templates['positive'] | analyzer.llm | StrOutputParser()

positive_response = positive_response_chain.invoke({
    "review": sample_reviews[0]  # ì²« ë²ˆì§¸ ê¸ì •ì  ë¦¬ë·°
})

print("\n=== ê³ ê° ì‘ë‹µ ì˜ˆì‹œ ===")
print(positive_response)
```

### ì‹¤ìŠµ 3: ë§ì¶¤í˜• í•™ìŠµ ë„ìš°ë¯¸

```python
class LearningAssistant:
    def __init__(self, subject: str, model_name: str = "gpt-4.1-mini"):
        """í•™ìŠµ ë„ìš°ë¯¸ ì´ˆê¸°í™”"""
        self.subject = subject
        self.llm = ChatOpenAI(model=model_name, temperature=0.3)

    def create_quiz_system(self) -> Dict[str, ChatPromptTemplate]:
        """í€´ì¦ˆ ìƒì„± ì‹œìŠ¤í…œ êµ¬í˜„"""
        quiz_templates = {}

        # ê°ê´€ì‹ í€´ì¦ˆ ìƒì„±
        quiz_templates['multiple_choice'] = ChatPromptTemplate.from_messages([
            ("system", f"""
ë‹¹ì‹ ì€ {self.subject} ê³¼ëª©ì˜ ì „ë¬¸ êµìœ¡ìì…ë‹ˆë‹¤.
í•™ìŠµ íš¨ê³¼ë¥¼ ë†’ì´ëŠ” ê°ê´€ì‹ í€´ì¦ˆë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

í€´ì¦ˆ ìƒì„± ê·œì¹™:
1. ë¬¸ì œëŠ” ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±
2. ì •ë‹µ 1ê°œ, ì˜¤ë‹µ 3ê°œë¡œ ì´ 4ê°œ ì„ íƒì§€
3. ì˜¤ë‹µì€ ê·¸ëŸ´ë“¯í•˜ì§€ë§Œ í‹€ë¦° ë‚´ìš©ìœ¼ë¡œ êµ¬ì„±
4. ë‚œì´ë„ ì¡°ì ˆ: ê¸°ì´ˆ/ì¤‘ê¸‰/ê³ ê¸‰ ì¤‘ ì„ íƒ
5. í•´ì„¤ í¬í•¨: ì™œ ì •ë‹µì¸ì§€, ì˜¤ë‹µì€ ì™œ í‹€ë ¸ëŠ”ì§€ ì„¤ëª…

ì¶œë ¥ í˜•ì‹:
**ë¬¸ì œ**
[ë¬¸ì œ ë‚´ìš©]

**ì„ íƒì§€**
1) [ì„ íƒì§€ 1]
2) [ì„ íƒì§€ 2]
3) [ì„ íƒì§€ 3]
4) [ì„ íƒì§€ 4]

**ì •ë‹µ: Xë²ˆ**

**í•´ì„¤**
[ì •ë‹µ í•´ì„¤ ë° ì˜¤ë‹µ ë¶„ì„]
"""),
            ("human", "ì£¼ì œ: {topic}\në‚œì´ë„: {difficulty}\ní•™ìŠµ ëª©í‘œ: {objective}")
        ])

        # ì£¼ê´€ì‹ í€´ì¦ˆ ìƒì„±
        quiz_templates['short_answer'] = ChatPromptTemplate.from_messages([
            ("system", f"""
ë‹¹ì‹ ì€ {self.subject} ê³¼ëª©ì˜ ì „ë¬¸ êµìœ¡ìì…ë‹ˆë‹¤.
ì‚¬ê³ ë ¥ì„ ê¸°ë¥´ëŠ” ì£¼ê´€ì‹ ë¬¸ì œë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ë¬¸ì œ ìƒì„± ê·œì¹™:
1. ë‹¨ìˆœ ì•”ê¸°ê°€ ì•„ë‹Œ ì´í•´ì™€ ì‘ìš©ì„ ìš”êµ¬í•˜ëŠ” ë¬¸ì œ
2. ëª…í™•í•œ í‰ê°€ ê¸°ì¤€ ì œì‹œ
3. ì˜ˆì‹œ ë‹µì•ˆê³¼ ì±„ì  ê¸°ì¤€ í¬í•¨
4. í•™ìŠµì ìˆ˜ì¤€ì— ë§ëŠ” ì ì ˆí•œ ë‚œì´ë„

ì¶œë ¥ í˜•ì‹:
**ë¬¸ì œ**
[ì£¼ê´€ì‹ ë¬¸ì œ]

**ì˜ˆì‹œ ë‹µì•ˆ**
[ëª¨ë²” ë‹µì•ˆ ì˜ˆì‹œ]

**ì±„ì  ê¸°ì¤€**
- ë§Œì  ë‹µì•ˆ ìš”ê±´:
- ë¶€ë¶„ì ìˆ˜ ê¸°ì¤€:
- ì£¼ìš” ì²´í¬í¬ì¸íŠ¸:

**í•™ìŠµ íŒ**
[ë¬¸ì œ í•´ê²° ì ‘ê·¼ë²•]
"""),
            ("human", "ì£¼ì œ: {topic}\ní•™ìŠµ ëª©í‘œ: {objective}\nì œí•œ ì¡°ê±´: {constraints}")
        ])

        return quiz_templates

    def create_explanation_system(self) -> Dict[str, ChatPromptTemplate]:
        """ê°œë… ì„¤ëª… ì‹œìŠ¤í…œ êµ¬í˜„"""
        explanation_templates = {}

        # ê¸°ë³¸ ê°œë… ì„¤ëª…
        explanation_templates['basic_concept'] = ChatPromptTemplate.from_messages([
            ("system", f"""
ë‹¹ì‹ ì€ {self.subject} ë¶„ì•¼ì˜ ë›°ì–´ë‚œ êµì‚¬ì…ë‹ˆë‹¤.
ë³µì¡í•œ ê°œë…ì„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ê²ƒì´ ì „ë¬¸ ë¶„ì•¼ì…ë‹ˆë‹¤.

ì„¤ëª… ì›ì¹™:
1. í•™ìŠµì ìˆ˜ì¤€ì— ë§ëŠ” ìš©ì–´ ì‚¬ìš©
2. êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ ë¹„ìœ  í™œìš©
3. ë‹¨ê³„ë³„ ì„¤ëª…ìœ¼ë¡œ ì´í•´ë„ ì¦ì§„
4. ì‹¤ìƒí™œ ì—°ê²°ì„ í†µí•œ ì˜ë¯¸ ë¶€ì—¬
5. ì‹œê°ì  ì´í•´ë¥¼ ë•ëŠ” êµ¬ì¡°í™”

ì„¤ëª… êµ¬ì¡°:
**í•µì‹¬ ì •ì˜**
[ê°„ë‹¨ëª…ë£Œí•œ ì •ì˜]

**ì™œ ì¤‘ìš”í•œê°€ìš”?**
[ì‹¤ìƒí™œ ì—°ê²° ë° ì¤‘ìš”ì„±]

**ë‹¨ê³„ë³„ ì´í•´**
[ë³µì¡í•œ ê°œë…ì„ ë‹¨ê³„ë³„ë¡œ ë¶„í•´]

**êµ¬ì²´ì  ì˜ˆì‹œ**
[ì‹¤ì œ ì‚¬ë¡€ë‚˜ ì¼ìƒ ë¹„ìœ ]

**ì—°ê´€ ê°œë…**
[ê´€ë ¨ëœ ë‹¤ë¥¸ ê°œë…ë“¤ê³¼ì˜ ì—°ê²°]

**ê¸°ì–µ íŒ**
[ì•”ê¸°ë‚˜ ì´í•´ë¥¼ ë•ëŠ” ë°©ë²•]
"""),
            ("human", "ì„¤ëª…í•  ê°œë…: {concept}\ní•™ìŠµì ìˆ˜ì¤€: {level}\ní•™ìŠµ ëª©ì : {purpose}")
        ])

        # ë¹„êµ ì„¤ëª…
        explanation_templates['comparison'] = ChatPromptTemplate.from_messages([
            ("system", f"""
ë‹¹ì‹ ì€ {self.subject} êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì„œë¡œ ë‹¤ë¥¸ ê°œë…ë“¤ì„ ë¹„êµí•˜ì—¬ ëª…í™•í•œ ì´í•´ë¥¼ ë•ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë¹„êµ ì„¤ëª… êµ¬ì¡°:
**ê°œë… ì†Œê°œ**
[ê° ê°œë…ì˜ ê¸°ë³¸ ì •ì˜]

**ê³µí†µì **
[ë‘ ê°œë…ì˜ ìœ ì‚¬í•œ íŠ¹ì„±]

**ì°¨ì´ì  ë¶„ì„**
[í•µì‹¬ ì°¨ì´ì ë“¤ì„ í‘œë¡œ ì •ë¦¬]

**ì–¸ì œ ì‚¬ìš©í•˜ë‚˜ìš”?**
[ê° ê°œë…ì˜ ì ìš© ìƒí™©]

**ì‹¤ì œ ì˜ˆì‹œ**
[êµ¬ì²´ì  ì‚¬ë¡€ ë¹„êµ]

**í˜¼ë™ ì£¼ì˜ì‚¬í•­**
[ìì£¼ í—·ê°ˆë¦¬ëŠ” ë¶€ë¶„ê³¼ êµ¬ë¶„ë²•]
"""),
            ("human", "ë¹„êµí•  ê°œë…ë“¤: {concepts}\në¹„êµ ëª©ì : {purpose}\nì¤‘ì  ì‚¬í•­: {focus}")
        ])

        return explanation_templates

    def generate_quiz(self, topic: str, quiz_type: str = "multiple_choice", **kwargs) -> str:
        """í€´ì¦ˆ ìƒì„±"""
        quiz_templates = self.create_quiz_system()

        if quiz_type not in quiz_templates:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í€´ì¦ˆ ìœ í˜•: {quiz_type}")

        chain = quiz_templates[quiz_type] | self.llm | StrOutputParser()

        # ê¸°ë³¸ ë§¤ê°œë³€ìˆ˜ ì„¤ì •
        params = {
            "topic": topic,
            "difficulty": kwargs.get("difficulty", "ì¤‘ê¸‰"),
            "objective": kwargs.get("objective", f"{topic}ì— ëŒ€í•œ ì´í•´ë„ í‰ê°€"),
            "constraints": kwargs.get("constraints", "íŠ¹ë³„í•œ ì œí•œ ì—†ìŒ")
        }

        return chain.invoke(params)

    def explain_concept(self, concept: str, explanation_type: str = "basic_concept", **kwargs) -> str:
        """ê°œë… ì„¤ëª…"""
        explanation_templates = self.create_explanation_system()

        if explanation_type not in explanation_templates:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì„¤ëª… ìœ í˜•: {explanation_type}")

        chain = explanation_templates[explanation_type] | self.llm | StrOutputParser()

        # ê¸°ë³¸ ë§¤ê°œë³€ìˆ˜ ì„¤ì •
        params = {
            "concept": concept,
            "concepts": kwargs.get("concepts", concept),
            "level": kwargs.get("level", "ê³ ë“±í•™êµ"),
            "purpose": kwargs.get("purpose", "ê¸°ë³¸ ê°œë… ì´í•´"),
            "focus": kwargs.get("focus", "í•µì‹¬ ì°¨ì´ì ")
        }

        return chain.invoke(params)

    def create_study_plan(self, topics: List[str], study_period: str) -> str:
        """í•™ìŠµ ê³„íš ìƒì„±"""
        study_plan_prompt = ChatPromptTemplate.from_messages([
            ("system", f"""
ë‹¹ì‹ ì€ {self.subject} í•™ìŠµ ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
íš¨ê³¼ì ì¸ ê°œì¸ ë§ì¶¤ í•™ìŠµ ê³„íšì„ ìˆ˜ë¦½í•´ì£¼ì„¸ìš”.

í•™ìŠµ ê³„íš êµ¬ì„±ìš”ì†Œ:
1. ì „ì²´ í•™ìŠµ ë¡œë“œë§µ
2. ì£¼ì°¨ë³„ ì„¸ë¶€ ê³„íš
3. ê° ì£¼ì œë³„ í•™ìŠµ ë°©ë²•
4. ì¤‘ê°„ ì ê²€ ë° í‰ê°€ ë°©ë²•
5. í•™ìŠµ ë¦¬ì†ŒìŠ¤ ì¶”ì²œ

ì¶œë ¥ í˜•ì‹:
**í•™ìŠµ ëª©í‘œ**
[ì „ì²´ì ì¸ í•™ìŠµ ì„±ê³¼ ëª©í‘œ]

**í•™ìŠµ ë¡œë“œë§µ**
[ì£¼ì°¨ë³„ ì§„í–‰ ê³„íš]

**ì£¼ì œë³„ í•™ìŠµ ì „ëµ**
[ê° ì£¼ì œì˜ íš¨ê³¼ì  í•™ìŠµë²•]

**í‰ê°€ ë° ì ê²€**
[ì¤‘ê°„ í‰ê°€ ë°©ë²•ê³¼ ì‹œê¸°]

**ì¶”ì²œ ë¦¬ì†ŒìŠ¤**
[êµì¬, ì˜¨ë¼ì¸ ìë£Œ, ì‹¤ìŠµ ë„êµ¬]

**í•™ìŠµ íŒ**
[ë™ê¸° ìœ ì§€ì™€ íš¨ìœ¨ì„± í–¥ìƒ ë°©ë²•]
"""),
            ("human", "í•™ìŠµ ì£¼ì œë“¤: {topics}\ní•™ìŠµ ê¸°ê°„: {period}\ní˜„ì¬ ìˆ˜ì¤€: {current_level}\nëª©í‘œ ìˆ˜ì¤€: {target_level}")
        ])

        chain = study_plan_prompt | self.llm | StrOutputParser()

        return chain.invoke({
            "topics": ", ".join(topics),
            "period": study_period,
            "current_level": "ì´ˆê¸‰",
            "target_level": "ì¤‘ê¸‰"
        })

# ì‹¤ìŠµ 3 í…ŒìŠ¤íŠ¸
# ìˆ˜í•™ í•™ìŠµ ë„ìš°ë¯¸ ìƒì„±
math_assistant = LearningAssistant("ìˆ˜í•™")

# 1. í€´ì¦ˆ ìƒì„± í…ŒìŠ¤íŠ¸
print("=== ê°ê´€ì‹ í€´ì¦ˆ ìƒì„± ===")
math_quiz = math_assistant.generate_quiz(
    topic="ì´ì°¨í•¨ìˆ˜",
    quiz_type="multiple_choice",
    difficulty="ì¤‘ê¸‰",
    objective="ì´ì°¨í•¨ìˆ˜ì˜ ê¸°ë³¸ ì„±ì§ˆ ì´í•´"
)
print(math_quiz)

print("\n=== ì£¼ê´€ì‹ í€´ì¦ˆ ìƒì„± ===")
short_answer_quiz = math_assistant.generate_quiz(
    topic="ë¯¸ë¶„ì˜ ì˜ë¯¸",
    quiz_type="short_answer",
    objective="ë¯¸ë¶„ì˜ ê¸°í•˜í•™ì  ì˜ë¯¸ ì´í•´",
    constraints="ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ ì„¤ëª…í•˜ë„ë¡ ìš”êµ¬"
)
print(short_answer_quiz)

# 2. ê°œë… ì„¤ëª… í…ŒìŠ¤íŠ¸
print("\n=== ê¸°ë³¸ ê°œë… ì„¤ëª… ===")
concept_explanation = math_assistant.explain_concept(
    concept="ê·¹í•œ",
    explanation_type="basic_concept",
    level="ê³ ë“±í•™êµ 3í•™ë…„",
    purpose="ëŒ€í•™ ìˆ˜í•™ ì¤€ë¹„"
)
print(concept_explanation)

print("\n=== ê°œë… ë¹„êµ ì„¤ëª… ===")
comparison_explanation = math_assistant.explain_concept(
    concepts="ë¯¸ë¶„ê³¼ ì ë¶„",
    explanation_type="comparison",
    purpose="ë¯¸ì ë¶„ í†µí•© ì´í•´",
    focus="ì •ì˜ì™€ ì‘ìš©ì˜ ì°¨ì´ì "
)
print(comparison_explanation)

# 3. í•™ìŠµ ê³„íš ìƒì„± í…ŒìŠ¤íŠ¸
print("\n=== í•™ìŠµ ê³„íš ìƒì„± ===")
study_topics = ["í•¨ìˆ˜", "ë¯¸ë¶„", "ì ë¶„", "í™•ë¥ ê³¼ í†µê³„"]
study_plan = math_assistant.create_study_plan(
    topics=study_topics,
    study_period="12ì£¼"
)
print(study_plan)

# 4. ë‹¤ë¥¸ ê³¼ëª© í…ŒìŠ¤íŠ¸ - ë¬¼ë¦¬ í•™ìŠµ ë„ìš°ë¯¸
print("\n" + "="*50)
print("=== ë¬¼ë¦¬ í•™ìŠµ ë„ìš°ë¯¸ í…ŒìŠ¤íŠ¸ ===")

physics_assistant = LearningAssistant("ë¬¼ë¦¬")

physics_quiz = physics_assistant.generate_quiz(
    topic="ë‰´í„´ì˜ ìš´ë™ë²•ì¹™",
    quiz_type="multiple_choice",
    difficulty="ê¸°ì´ˆ",
    objective="ë¬¼ë¦¬í•™ ê¸°ë³¸ ì›ë¦¬ ì´í•´"
)

print(physics_quiz)
```

## ğŸ” ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [LangChain Prompt Templates](https://python.langchain.com/docs/modules/model_io/prompts/)
- [OpenAI GPT Best Practices](https://platform.openai.com/docs/guides/gpt-best-practices)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)

### í•™ìˆ  ìë£Œ
- Liu, P., et al. (2023). "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods"
- Reynolds, L., & McDonell, K. (2021). "Prompt Programming for Large Language Models"
- Wei, J., et al. (2022). "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"

### ì‹¤ë¬´ ê°€ì´ë“œ
- [Prompt Engineering Best Practices](https://example.com/prompt-engineering-guide)
- [LangChain Prompt Templates Guide](https://example.com/langchain-prompts)
- [Advanced Prompting Techniques](https://example.com/advanced-prompting)

### ë„êµ¬ ë° ë¦¬ì†ŒìŠ¤
- [Prompt Testing Platforms](https://example.com/prompt-testing)
- [Template Libraries](https://example.com/template-libraries)
- [Community Prompt Repositories](https://example.com/community-prompts)

---

**ë‹¤ìŒ í•™ìŠµ**: W3_002_Prompt_Engineering_Fewshot.md - Few-Shot í”„ë¡¬í”„íŒ…ê³¼ in-context learning ê¸°ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.