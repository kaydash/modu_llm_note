# W3_002_Prompt_Engineering_Fewshot.md - Few-Shot í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§

## ğŸ¯ í•™ìŠµ ëª©í‘œ

- Zero-shotê³¼ Few-shot í”„ë¡¬í”„íŒ… ê¸°ë²•ì˜ íŠ¹ì§•ê³¼ ì ìš© ë°©ë²•ì„ ì´í•´í•©ë‹ˆë‹¤
- One-shot, Few-shot, Dynamic Few-Shot í”„ë¡¬í”„íŒ…ì„ ì‹¤ìŠµí•©ë‹ˆë‹¤
- FewShotChatMessagePromptTemplateê³¼ SemanticSimilarityExampleSelectorë¥¼ í™œìš©í•©ë‹ˆë‹¤
- ìƒí™©ì— ë§ëŠ” ìµœì ì˜ í”„ë¡¬í”„íŒ… ì „ëµì„ ì„ íƒí•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ê°œë°œí•©ë‹ˆë‹¤
- ì‹¤ì œ ì—…ë¬´ì— ì ìš©í•  ìˆ˜ ìˆëŠ” ê³ ë„í™”ëœ í”„ë¡¬í”„íŒ… ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤

## ğŸ“š í•µì‹¬ ê°œë…

### 1. í”„ë¡¬í”„íŒ… ê¸°ë²•ì˜ ë¶„ë¥˜

#### 1.1 Zero-Shot í”„ë¡¬í”„íŒ…
ì˜ˆì‹œ ì—†ì´ ëª…í™•í•œ ì§€ì‹œì‚¬í•­ë§Œìœ¼ë¡œ AIê°€ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.

**íŠ¹ì§•:**
- ì‚¬ìš©ì´ ê°„ë‹¨í•˜ê³  ì§ê´€ì 
- í”„ë¡¬í”„íŠ¸ ê¸¸ì´ê°€ ì§§ì•„ ë¹„ìš© íš¨ìœ¨ì 
- ë‹¨ìˆœí•˜ê³  ì¼ë°˜ì ì¸ ì‘ì—…ì— ì í•©
- ë³µì¡í•œ ì‘ì—…ì—ì„œëŠ” ì„±ëŠ¥ í•œê³„ ì¡´ì¬

**ì ìš© ì‹œë‚˜ë¦¬ì˜¤:**
```python
zero_shot_examples = {
    "ë²ˆì—­": "ë‹¤ìŒ ë¬¸ì¥ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”: {text}",
    "ìš”ì•½": "ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”: {text}",
    "ë¶„ë¥˜": "ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ê¸ì •/ë¶€ì •ìœ¼ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”: {text}",
    "ì§ˆì˜ì‘ë‹µ": "ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”: {question}"
}
```

#### 1.2 One-Shot í”„ë¡¬í”„íŒ…
ë‹¨ì¼ ì˜ˆì‹œë¥¼ í†µí•´ íŒ¨í„´ì„ í•™ìŠµì‹œí‚¤ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.

**íŠ¹ì§•:**
- Zero-shotë³´ë‹¤ í–¥ìƒëœ ì„±ëŠ¥
- í˜•ì‹í™”ëœ ì‘ì—…ì— íŠ¹íˆ íš¨ê³¼ì 
- ì˜ˆì‹œ ì„ íƒì´ ê²°ê³¼ì— í° ì˜í–¥
- ê³¼ì˜ì¡´ ìœ„í—˜ ì¡´ì¬

**êµ¬ì¡°:**
```python
one_shot_structure = """
ì˜ˆì‹œ:
ì…ë ¥: {example_input}
ì¶œë ¥: {example_output}

ì´ì œ ë‹¤ìŒ ì…ë ¥ì„ ì²˜ë¦¬í•˜ì„¸ìš”:
ì…ë ¥: {user_input}
ì¶œë ¥:
"""
```

#### 1.3 Few-Shot í”„ë¡¬í”„íŒ…
2-5ê°œì˜ ì˜ˆì‹œë¥¼ ì œê³µí•˜ì—¬ íŒ¨í„´ì„ í•™ìŠµì‹œí‚¤ëŠ” ê³ ê¸‰ ê¸°ë²•ì…ë‹ˆë‹¤.

**íŠ¹ì§•:**
- ê°€ì¥ ë†’ì€ ì„±ëŠ¥ê³¼ ì¼ê´€ì„± ì œê³µ
- ë³µì¡í•œ ì‘ì—…ì— íš¨ê³¼ì 
- í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì¦ê°€ë¡œ ì¸í•œ ë¹„ìš© ìƒìŠ¹
- ì˜ˆì‹œ í’ˆì§ˆì´ ì„±ëŠ¥ì— ê²°ì •ì  ì˜í–¥

**ìµœì  ì˜ˆì‹œ ìˆ˜:**
```python
optimal_examples = {
    "simple_classification": 2-3,  # ê°ì • ë¶„ì„, ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
    "complex_analysis": 3-5,       # ë¬¸ì„œ ë¶„ì„, êµ¬ì¡°í™”ëœ ì¶”ì¶œ
    "creative_generation": 2-4,    # ì°½ì‘, ìŠ¤íƒ€ì¼ ëª¨ë°©
    "technical_tasks": 4-6         # ì½”ë“œ ìƒì„±, ê¸°ìˆ  ë¬¸ì„œ ì‘ì„±
}
```

### 2. Few-Shot í”„ë¡¬í”„íŒ…ì˜ ê³ ê¸‰ ê¸°ë²•

#### 2.1 Fixed Few-Shot
ë¯¸ë¦¬ ì •ì˜ëœ ê³ ì • ì˜ˆì‹œë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.

**ì¥ì :**
- ì¼ê´€ëœ ê²°ê³¼ ë³´ì¥
- ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì„±ëŠ¥
- êµ¬í˜„ì´ ë‹¨ìˆœ

**ë‹¨ì :**
- ìƒí™© ì ì‘ì„± ë¶€ì¡±
- ëª¨ë“  ì¼€ì´ìŠ¤ ì»¤ë²„ ì–´ë ¤ì›€

#### 2.2 Dynamic Few-Shot
ì…ë ¥ ìƒí™©ì— ë”°ë¼ ê°€ì¥ ì ì ˆí•œ ì˜ˆì‹œë¥¼ ë™ì ìœ¼ë¡œ ì„ íƒí•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.

**ì¥ì :**
- ìƒí™©ë³„ ìµœì í™”
- íš¨ìœ¨ì ì¸ í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ê´€ë¦¬
- ë†’ì€ ë²”ìš©ì„±

**ë‹¨ì :**
- êµ¬í˜„ ë³µì¡ì„± ì¦ê°€
- ì˜ˆì‹œ ì„ íƒ ì˜¤ë²„í—¤ë“œ
- ë²¡í„° ì €ì¥ì†Œ í•„ìš”

### 3. ì˜ˆì‹œ ì„ íƒ ì „ëµ

#### 3.1 ì˜ë¯¸ì  ìœ ì‚¬ë„ ê¸°ë°˜ ì„ íƒ
```python
similarity_selection_process = """
1. ì‚¬ìš©ì ì…ë ¥ ë²¡í„°í™”
2. ì˜ˆì‹œ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰
3. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
4. ìƒìœ„ Kê°œ ì˜ˆì‹œ ì„ íƒ
5. í”„ë¡¬í”„íŠ¸ì— í¬í•¨
"""
```

#### 3.2 ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ì„ íƒ
```python
category_selection = {
    "input_analysis": "ì…ë ¥ í…ìŠ¤íŠ¸ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜",
    "example_mapping": "ì¹´í…Œê³ ë¦¬ë³„ ì˜ˆì‹œ ë§¤í•‘",
    "selection": "í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ì˜ˆì‹œ ì„ íƒ"
}
```

#### 3.3 ë‚œì´ë„ ê¸°ë°˜ ì„ íƒ
```python
difficulty_based = {
    "complexity_analysis": "ì…ë ¥ ë³µì¡ë„ í‰ê°€",
    "example_matching": "ë³µì¡ë„ì— ë§ëŠ” ì˜ˆì‹œ ì„ íƒ",
    "gradual_learning": "ë‹¨ê³„ë³„ ì˜ˆì‹œ ì œê³µ"
}
```

## ğŸ”§ í™˜ê²½ ì„¤ì •

### 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

```bash
# uv ì‚¬ìš© (ê¶Œì¥)
uv add langchain langchain-openai langchain-ollama python-dotenv

# pip ì‚¬ìš©
pip install langchain langchain-openai langchain-ollama python-dotenv
```

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
# .env íŒŒì¼ì— ì¶”ê°€
OPENAI_API_KEY=your_openai_api_key_here
OLLAMA_HOST=http://localhost:11434  # Ollama ì„œë²„ ì£¼ì†Œ (ì„ íƒì‚¬í•­)
```

### 3. ê¸°ë³¸ ì„í¬íŠ¸

```python
import os
from dotenv import load_dotenv
from pprint import pprint
from typing import Dict, List, Any, Optional
from textwrap import dedent

# LangChain ê´€ë ¨
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate
from langchain_core.prompts import FewShotChatMessagePromptTemplate
from langchain_core.example_selectors import SemanticSimilarityExampleSelector
from langchain_core.vectorstores import InMemoryVectorStore
from langchain_openai import ChatOpenAI
from langchain_ollama import OllamaEmbeddings
from langchain_core.output_parsers import StrOutputParser

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# LLM ì´ˆê¸°í™”
llm = ChatOpenAI(
    model="gpt-4.1-mini",
    temperature=0.3,
    top_p=0.9
)
```

## ğŸ’» ì½”ë“œ ì˜ˆì œ

### 1. Zero-Shot vs One-Shot vs Few-Shot ë¹„êµ

```python
class PromptingMethodComparator:
    def __init__(self, model_name: str = "gpt-4.1-mini"):
        """í”„ë¡¬í”„íŒ… ê¸°ë²• ë¹„êµ í´ë˜ìŠ¤"""
        self.llm = ChatOpenAI(model=model_name, temperature=0.3)

    def create_zero_shot_prompt(self, task_description: str, input_variable: str = "input") -> PromptTemplate:
        """Zero-shot í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return PromptTemplate(
            input_variables=[input_variable],
            template=f"{task_description}: {{{input_variable}}}"
        )

    def create_one_shot_prompt(
        self,
        task_description: str,
        example_input: str,
        example_output: str,
        input_variable: str = "input"
    ) -> PromptTemplate:
        """One-shot í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        template = f"""ë‹¤ìŒì€ {task_description}ì˜ ì˜ˆì‹œì…ë‹ˆë‹¤:

ì…ë ¥: {example_input}
ì¶œë ¥: {example_output}

ì´ì œ ë‹¤ìŒì„ ì²˜ë¦¬í•˜ì„¸ìš”:
ì…ë ¥: {{{input_variable}}}
ì¶œë ¥:"""

        return PromptTemplate(
            input_variables=[input_variable],
            template=template
        )

    def create_few_shot_prompt(
        self,
        task_description: str,
        examples: List[Dict[str, str]],
        input_variable: str = "input"
    ) -> PromptTemplate:
        """Few-shot í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        examples_text = ""
        for i, example in enumerate(examples, 1):
            examples_text += f"\nì˜ˆì‹œ {i}:\nì…ë ¥: {example['input']}\nì¶œë ¥: {example['output']}\n"

        template = f"""ë‹¤ìŒì€ {task_description}ì˜ ì˜ˆì‹œë“¤ì…ë‹ˆë‹¤:
{examples_text}
ì´ì œ ë‹¤ìŒì„ ì²˜ë¦¬í•˜ì„¸ìš”:
ì…ë ¥: {{{input_variable}}}
ì¶œë ¥:"""

        return PromptTemplate(
            input_variables=[input_variable],
            template=template
        )

    def compare_methods(
        self,
        task_description: str,
        test_input: str,
        example_input: str,
        example_output: str,
        few_shot_examples: List[Dict[str, str]]
    ) -> Dict[str, Any]:
        """ì„¸ ê°€ì§€ ë°©ë²• ë¹„êµ ì‹¤í–‰"""

        # Zero-shot
        zero_shot_prompt = self.create_zero_shot_prompt(task_description)
        zero_shot_chain = zero_shot_prompt | self.llm | StrOutputParser()
        zero_shot_result = zero_shot_chain.invoke({"input": test_input})

        # One-shot
        one_shot_prompt = self.create_one_shot_prompt(
            task_description, example_input, example_output
        )
        one_shot_chain = one_shot_prompt | self.llm | StrOutputParser()
        one_shot_result = one_shot_chain.invoke({"input": test_input})

        # Few-shot
        few_shot_prompt = self.create_few_shot_prompt(task_description, few_shot_examples)
        few_shot_chain = few_shot_prompt | self.llm | StrOutputParser()
        few_shot_result = few_shot_chain.invoke({"input": test_input})

        return {
            "test_input": test_input,
            "results": {
                "zero_shot": zero_shot_result,
                "one_shot": one_shot_result,
                "few_shot": few_shot_result
            },
            "prompt_lengths": {
                "zero_shot": len(zero_shot_prompt.template),
                "one_shot": len(one_shot_prompt.template),
                "few_shot": len(few_shot_prompt.template)
            }
        }

# ì‚¬ìš© ì˜ˆì‹œ
comparator = PromptingMethodComparator()

# ê°ì • ë¶„ì„ ë¹„êµ
sentiment_examples = [
    {"input": "ì´ ì œí’ˆ ì •ë§ ë§Œì¡±ìŠ¤ëŸ½ê³  í’ˆì§ˆì´ ë›°ì–´ë‚˜ìš”!", "output": "ê¸ì •"},
    {"input": "ì„œë¹„ìŠ¤ê°€ ë„ˆë¬´ ëŠë¦¬ê³  ë¶ˆì¹œì ˆí•©ë‹ˆë‹¤.", "output": "ë¶€ì •"},
    {"input": "ì´ ìŒì‹ì€ ë§›ìˆê³  ê°€ê²©ë„ í•©ë¦¬ì ì…ë‹ˆë‹¤.", "output": "ê¸ì •"},
    {"input": "ë°°ì†¡ì´ ì§€ì—°ë˜ì–´ ë§¤ìš° ì‹¤ë§ìŠ¤ëŸ½ìŠµë‹ˆë‹¤.", "output": "ë¶€ì •"}
]

comparison_result = comparator.compare_methods(
    task_description="í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ê¸ì • ë˜ëŠ” ë¶€ì •ìœ¼ë¡œ ë¶„ë¥˜",
    test_input="ì œí’ˆì´ ê¸°ëŒ€ë³´ë‹¤ í›Œë¥­í•˜ê³  ì¶”ì²œí•˜ê³  ì‹¶ì–´ìš”!",
    example_input=sentiment_examples[0]["input"],
    example_output=sentiment_examples[0]["output"],
    few_shot_examples=sentiment_examples[:3]
)

print("=== í”„ë¡¬í”„íŒ… ë°©ë²• ë¹„êµ ê²°ê³¼ ===")
print(f"í…ŒìŠ¤íŠ¸ ì…ë ¥: {comparison_result['test_input']}")
print("\nê²°ê³¼:")
for method, result in comparison_result['results'].items():
    print(f"- {method}: {result}")

print("\ní”„ë¡¬í”„íŠ¸ ê¸¸ì´:")
for method, length in comparison_result['prompt_lengths'].items():
    print(f"- {method}: {length} characters")
```

### 2. ê³ ì • Few-Shot í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ

```python
class FixedFewShotSystem:
    def __init__(self, model_name: str = "gpt-4.1-mini"):
        """ê³ ì • Few-Shot ì‹œìŠ¤í…œ"""
        self.llm = ChatOpenAI(model=model_name, temperature=0.1)

    def create_news_keyword_extractor(self) -> ChatPromptTemplate:
        """ë‰´ìŠ¤ í‚¤ì›Œë“œ ì¶”ì¶œê¸° ìƒì„±"""
        examples = [
            {
                "input": dedent("""
                    ì •ë¶€ëŠ” ì˜ê³¼ëŒ€í•™ ì…í•™ ì •ì›ì„ 2000ëª… ì¦ê°€ì‹œí‚¬ ê³„íšì˜ ì„¸ë¶€ì‚¬í•­ì„ ì´ë‹¬ 20ì¼ì— ê³µê°œí•  ì˜ˆì •ì´ë‹¤.
                    ì§€ì—­ë³„ ì˜ë£Œ ì„œë¹„ìŠ¤ í–¥ìƒê³¼ ì†Œê·œëª¨ ì˜ê³¼ëŒ€í•™ì˜ ë°œì „ì„ ëª©í‘œë¡œ, ì§€ì—­ ì¤‘ì‹¬ì˜ êµ­ë¦½ëŒ€í•™ ë° ì†Œí˜• ì˜ê³¼ëŒ€í•™ì˜
                    ì…í•™ ì •ì›ì´ ìµœì†Œí•œ ë‘ ë°° ê°€ëŸ‰ í™•ëŒ€ë  ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.
                """),
                "output": "ì˜ëŒ€ | ì •ì› | í™•ëŒ€"
            },
            {
                "input": dedent("""
                    ì„¸ê³„ë³´ê±´ê¸°êµ¬(WHO)ëŠ” ìµœê·¼ ìƒˆë¡œìš´ ê±´ê°• ìœ„ê¸°ì— ëŒ€ì‘í•˜ê¸° ìœ„í•´ êµ­ì œ í˜‘ë ¥ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í–ˆë‹¤.
                    ì „ì—¼ë³‘ ëŒ€ì‘ ì—­ëŸ‰ì˜ ê°•í™”ì™€ ê¸€ë¡œë²Œ ë³´ê±´ ì‹œìŠ¤í…œì˜ ê°œì„ ì´ í•„ìš”í•˜ë‹¤ê³  ë°œí‘œí–ˆë‹¤.
                """),
                "output": "ì„¸ê³„ë³´ê±´ê¸°êµ¬ | ê±´ê°•ìœ„ê¸° | êµ­ì œí˜‘ë ¥"
            },
            {
                "input": dedent("""
                    ì‚¼ì„±ì „ìê°€ ë‚´ë…„ ì´ˆì— ìì²´ì ìœ¼ë¡œ ê°œë°œí•œ ì¸ê³µì§€ëŠ¥(AI) ê°€ì†ê¸°ë¥¼ ì²˜ìŒìœ¼ë¡œ ì¶œì‹œí•  ì˜ˆì •ì´ë‹¤.
                    ì´ëŠ” AI ë°˜ë„ì²´ ì‹œì¥ì—ì„œ ì§€ë°°ì ì¸ ìœ„ì¹˜ë¥¼ ì°¨ì§€í•˜ê³  ìˆëŠ” ì—”ë¹„ë””ì•„ì˜ ë…ì ì„ ë„ì „í•˜ë ¤ëŠ” ì‹œë„ì´ë‹¤.
                """),
                "output": "ì‚¼ì„±ì „ì | AIê°€ì†ê¸° | ë°˜ë„ì²´"
            }
        ]

        # ì˜ˆì‹œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        example_prompt = ChatPromptTemplate.from_messages([
            ("human", "{input}"),
            ("assistant", "{output}")
        ])

        # Few-shot í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        few_shot_prompt = FewShotChatMessagePromptTemplate(
            example_prompt=example_prompt,
            examples=examples
        )

        # ìµœì¢… í”„ë¡¬í”„íŠ¸
        final_prompt = ChatPromptTemplate.from_messages([
            ("system", """
ë‹¹ì‹ ì€ ë‰´ìŠ¤ í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ 3ê°œë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
í‚¤ì›Œë“œëŠ” '|'ë¡œ êµ¬ë¶„í•˜ì—¬ ì œì‹œí•˜ë©°, ê° í‚¤ì›Œë“œëŠ” ë‰´ìŠ¤ì˜ í•µì‹¬ ë‚´ìš©ì„ ëŒ€í‘œí•´ì•¼ í•©ë‹ˆë‹¤.
"""),
            few_shot_prompt,
            ("human", "{input}")
        ])

        return final_prompt

    def create_competitor_analyzer(self) -> PromptTemplate:
        """ê²½ìŸì‚¬ ë¶„ì„ê¸° ìƒì„±"""
        examples = """
ì‹œì¥: ìŠ¤ë§ˆíŠ¸í°
ê²½ìŸì—…ì²´:
- ì• í”Œ(ë¯¸êµ­): í”„ë¦¬ë¯¸ì—„ ì‹œì¥ ì£¼ë„, iPhoneìœ¼ë¡œ ê²½ìŸ
- ìƒ¤ì˜¤ë¯¸(ì¤‘êµ­): ì¤‘ì €ê°€ ì‹œì¥ ê°•ì„¸, ê¸€ë¡œë²Œ í™•ì¥ ì¤‘
- êµ¬ê¸€(ë¯¸êµ­): Pixelë¡œ AI ê¸°ëŠ¥ ê°•ì¡°

ì‹œì¥: TV
ê²½ìŸì—…ì²´:
- LGì „ì(í•œêµ­): OLED ê¸°ìˆ ë¡œ í”„ë¦¬ë¯¸ì—„ ì‹œì¥ ê²½ìŸ
- Sony(ì¼ë³¸): ê³ í’ˆì§ˆ ë””ìŠ¤í”Œë ˆì´ ê¸°ìˆ  ê²½ìŸ
- TCL(ì¤‘êµ­): ì¤‘ì €ê°€ ì‹œì¥ ê³µëµ

ì‹œì¥: ë©”ëª¨ë¦¬ ë°˜ë„ì²´
ê²½ìŸì—…ì²´:
- SKí•˜ì´ë‹‰ìŠ¤(í•œêµ­): DRAMê³¼ NAND í”Œë˜ì‹œ ê²½ìŸ
- ë§ˆì´í¬ë¡ (ë¯¸êµ­): ë©”ëª¨ë¦¬ ì†”ë£¨ì…˜ ì „ ë¶„ì•¼ ê²½ìŸ
- í‚¤ì˜¥ì‹œì•„(ì¼ë³¸): NAND í”Œë˜ì‹œ ì‹œì¥ ê²½ìŸ
"""

        return PromptTemplate(
            input_variables=["market"],
            template=f"""ë‹¤ìŒì€ ì—¬ëŸ¬ ì‹œì¥ì—ì„œ ì‚¼ì„±ì „ìì˜ ê²½ìŸì—…ì²´ë¥¼ ë¶„ì„í•œ ì˜ˆì‹œë“¤ì…ë‹ˆë‹¤:

{examples}

ì´ì œ ë‹¤ìŒ ì‹œì¥ì—ì„œ ì‚¼ì„±ì „ìì˜ ê²½ìŸì—…ì²´ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:
ì‹œì¥: {{market}}
ê²½ìŸì—…ì²´:"""
        )

    def execute_keyword_extraction(self, news_text: str) -> str:
        """í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤í–‰"""
        prompt = self.create_news_keyword_extractor()
        chain = prompt | self.llm | StrOutputParser()
        return chain.invoke({"input": news_text})

    def execute_competitor_analysis(self, market: str) -> str:
        """ê²½ìŸì‚¬ ë¶„ì„ ì‹¤í–‰"""
        prompt = self.create_competitor_analyzer()
        chain = prompt | self.llm | StrOutputParser()
        return chain.invoke({"market": market})

# ì‚¬ìš© ì˜ˆì‹œ
fixed_system = FixedFewShotSystem()

# í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
news_text = dedent("""
    ë„¤ì´ë²„ê°€ ìƒˆë¡œìš´ AI ê²€ìƒ‰ ì„œë¹„ìŠ¤ë¥¼ ì¶œì‹œí•˜ë©° êµ¬ê¸€ê³¼ì˜ ê²½ìŸì„ ë³¸ê²©í™”í•œë‹¤ê³  ë°œí‘œí–ˆë‹¤.
    ì´ ì„œë¹„ìŠ¤ëŠ” ìì—°ì–´ ì²˜ë¦¬ ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë” ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•  ì˜ˆì •ì´ë‹¤.
    ë„¤ì´ë²„ëŠ” ì´ë¥¼ í†µí•´ êµ­ë‚´ ê²€ìƒ‰ ì‹œì¥ì—ì„œì˜ ì ìœ ìœ¨ì„ ë”ìš± í™•ëŒ€í•  ê³„íšì´ë¼ê³  ë°í˜”ë‹¤.
""")

keywords = fixed_system.execute_keyword_extraction(news_text)
print("=== í‚¤ì›Œë“œ ì¶”ì¶œ ê²°ê³¼ ===")
print(keywords)

# ê²½ìŸì‚¬ ë¶„ì„ í…ŒìŠ¤íŠ¸
competitor_analysis = fixed_system.execute_competitor_analysis("ì¸ê³µì§€ëŠ¥ ë°˜ë„ì²´")
print("\n=== ê²½ìŸì‚¬ ë¶„ì„ ê²°ê³¼ ===")
print(competitor_analysis)
```

### 3. ë™ì  Few-Shot í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ

```python
class DynamicFewShotSystem:
    def __init__(self, model_name: str = "gpt-4.1-mini", embedding_model: str = "bge-m3"):
        """ë™ì  Few-Shot ì‹œìŠ¤í…œ"""
        self.llm = ChatOpenAI(model=model_name, temperature=0.1)
        self.embeddings = OllamaEmbeddings(model=embedding_model)

    def create_customer_service_bot(self, examples: List[Dict[str, str]]) -> ChatPromptTemplate:
        """ê³ ê° ì„œë¹„ìŠ¤ ë´‡ ìƒì„±"""

        # ì˜ˆì‹œë¥¼ ë²¡í„°í™”í•  í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        to_vectorize = [f"{example['input']} {example['output']}" for example in examples]

        # ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
        vector_store = InMemoryVectorStore.from_texts(
            to_vectorize,
            self.embeddings,
            metadatas=examples
        )

        # ì˜ë¯¸ì  ìœ ì‚¬ë„ ê¸°ë°˜ ì˜ˆì‹œ ì„ íƒê¸°
        example_selector = SemanticSimilarityExampleSelector(
            vectorstore=vector_store,
            k=2  # ìƒìœ„ 2ê°œ ì˜ˆì‹œ ì„ íƒ
        )

        # Few-shot í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        few_shot_prompt = FewShotChatMessagePromptTemplate(
            input_variables=["input"],
            example_selector=example_selector,
            example_prompt=ChatPromptTemplate.from_messages([
                ("human", "{input}"),
                ("assistant", "{output}")
            ])
        )

        # ìµœì¢… í”„ë¡¬í”„íŠ¸
        final_prompt = ChatPromptTemplate.from_messages([
            ("system", """
ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ê³ ê° ì„œë¹„ìŠ¤ ë‹´ë‹¹ìì…ë‹ˆë‹¤.
ê³ ê°ì˜ ë¬¸ì˜ì‚¬í•­ì— ëŒ€í•´ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ì‘ë‹µì„ ì œê³µí•´ì£¼ì„¸ìš”.
"""),
            few_shot_prompt,
            ("human", "{input}")
        ])

        return final_prompt, example_selector

    def create_technical_support_system(self) -> tuple:
        """ê¸°ìˆ  ì§€ì› ì‹œìŠ¤í…œ ìƒì„±"""
        technical_examples = [
            {
                "input": "ì¸í„°ë„·ì´ ê³„ì† ëŠì–´ì ¸ìš”",
                "output": "ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ í•´ê²°ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n1. ê³µìœ ê¸°ë¥¼ 30ì´ˆê°„ ë„ê³  ë‹¤ì‹œ ì¼œì£¼ì„¸ìš”\n2. ë„¤íŠ¸ì›Œí¬ ì¼€ì´ë¸” ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”\n3. ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ISPì— ë¬¸ì˜í•˜ì‹œê±°ë‚˜ ê¸°ìˆ ì§€ì›íŒ€ìœ¼ë¡œ ì—°ë½í•´ì£¼ì„¸ìš”."
            },
            {
                "input": "í”„ë¡œê·¸ë¨ì´ ì‹¤í–‰ë˜ì§€ ì•Šì•„ìš”",
                "output": "í”„ë¡œê·¸ë¨ ì‹¤í–‰ ë¬¸ì œë¥¼ í•´ê²°í•´ë³´ê² ìŠµë‹ˆë‹¤.\n1. í”„ë¡œê·¸ë¨ì„ ì™„ì „íˆ ì¢…ë£Œ í›„ ì¬ì‹œì‘í•´ì£¼ì„¸ìš”\n2. ê´€ë¦¬ì ê¶Œí•œìœ¼ë¡œ ì‹¤í–‰í•´ë³´ì„¸ìš”\n3. í˜¸í™˜ì„± ëª¨ë“œë¡œ ì‹¤í–‰í•´ë³´ì„¸ìš”\n4. ë¬¸ì œê°€ ê³„ì†ë˜ë©´ í”„ë¡œê·¸ë¨ì„ ì¬ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
            },
            {
                "input": "ì»´í“¨í„°ê°€ ë„ˆë¬´ ëŠë ¤ìš”",
                "output": "ì»´í“¨í„° ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ì¡°ì¹˜ë¥¼ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n1. ì‘ì—… ê´€ë¦¬ìì—ì„œ CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì„ í™•ì¸í•´ì£¼ì„¸ìš”\n2. ë¶ˆí•„ìš”í•œ ì‹œì‘í”„ë¡œê·¸ë¨ì„ ë¹„í™œì„±í™”í•´ì£¼ì„¸ìš”\n3. ë””ìŠ¤í¬ ì •ë¦¬ë¥¼ ìˆ˜í–‰í•´ì£¼ì„¸ìš”\n4. í•„ìš”ì‹œ ë©”ëª¨ë¦¬ ì—…ê·¸ë ˆì´ë“œë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš”."
            },
            {
                "input": "ë¹„ë°€ë²ˆí˜¸ë¥¼ ìŠì–´ë²„ë ¸ì–´ìš”",
                "output": "ë¹„ë°€ë²ˆí˜¸ ì¬ì„¤ì •ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n1. ë¡œê·¸ì¸ í˜ì´ì§€ì—ì„œ 'ë¹„ë°€ë²ˆí˜¸ ì°¾ê¸°'ë¥¼ í´ë¦­í•´ì£¼ì„¸ìš”\n2. ë“±ë¡ëœ ì´ë©”ì¼ ì£¼ì†Œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”\n3. ì´ë©”ì¼ë¡œ ë°œì†¡ëœ ì¬ì„¤ì • ë§í¬ë¥¼ í´ë¦­í•´ì£¼ì„¸ìš”\n4. ìƒˆë¡œìš´ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
            },
            {
                "input": "íŒŒì¼ì´ ì‚­ì œë˜ì—ˆì–´ìš”",
                "output": "ì‚­ì œëœ íŒŒì¼ ë³µêµ¬ë¥¼ ì‹œë„í•´ë³´ê² ìŠµë‹ˆë‹¤.\n1. íœ´ì§€í†µì—ì„œ íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”\n2. ì‹œìŠ¤í…œ ë³µì› ê¸°ëŠ¥ì„ ì´ìš©í•´ë³´ì„¸ìš”\n3. íŒŒì¼ íˆìŠ¤í† ë¦¬ë‚˜ ë°±ì—…ì—ì„œ ë³µì›í•´ë³´ì„¸ìš”\n4. ì „ë¬¸ ë³µêµ¬ ì†Œí”„íŠ¸ì›¨ì–´ ì‚¬ìš©ì„ ê³ ë ¤í•´ë³´ì„¸ìš”."
            },
            {
                "input": "í™”ë©´ì´ ê¹œë¹¡ê±°ë ¤ìš”",
                "output": "í™”ë©´ ê¹œë¹¡ì„ ë¬¸ì œ í•´ê²°ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n1. ëª¨ë‹ˆí„° ì¼€ì´ë¸” ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”\n2. í™”ë©´ í•´ìƒë„ì™€ ì£¼ì‚¬ìœ¨ì„ ì¡°ì •í•´ë³´ì„¸ìš”\n3. ê·¸ë˜í”½ ë“œë¼ì´ë²„ë¥¼ ì—…ë°ì´íŠ¸í•´ì£¼ì„¸ìš”\n4. ëª¨ë‹ˆí„° ì„¤ì •ì—ì„œ ìë™ ì¡°ì •ì„ ì‹¤í–‰í•´ë³´ì„¸ìš”."
            }
        ]

        return self.create_customer_service_bot(technical_examples)

    def create_product_support_system(self) -> tuple:
        """ì œí’ˆ ì§€ì› ì‹œìŠ¤í…œ ìƒì„±"""
        product_examples = [
            {
                "input": "í™˜ë¶ˆí•˜ê³  ì‹¶ì–´ìš”",
                "output": "í™˜ë¶ˆ ì ˆì°¨ë¥¼ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n1. ë§ˆì´í˜ì´ì§€ì—ì„œ ì£¼ë¬¸ ë‚´ì—­ì„ í™•ì¸í•´ì£¼ì„¸ìš”\n2. 'í™˜ë¶ˆ ì‹ ì²­' ë²„íŠ¼ì„ í´ë¦­í•´ì£¼ì„¸ìš”\n3. í™˜ë¶ˆ ì‚¬ìœ ë¥¼ ì„ íƒí•˜ê³  ìƒì„¸ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”\n4. ìƒí’ˆì„ ì›ë˜ í¬ì¥ ìƒíƒœë¡œ ë°˜ì†¡í•´ì£¼ì„¸ìš”\n5. ìƒí’ˆ í™•ì¸ í›„ 3-5ì¼ ë‚´ í™˜ë¶ˆ ì²˜ë¦¬ë©ë‹ˆë‹¤."
            },
            {
                "input": "êµí™˜í•˜ê³  ì‹¶ì–´ìš”",
                "output": "êµí™˜ ì ˆì°¨ë¥¼ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n1. 14ì¼ ì´ë‚´ êµí™˜ ì‹ ì²­ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤\n2. ìƒí’ˆì´ ë¯¸ì‚¬ìš© ìƒíƒœì—¬ì•¼ í•©ë‹ˆë‹¤\n3. êµí™˜ ì‹ ì²­ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”\n4. êµí™˜í•  ìƒí’ˆì˜ ì¬ê³ ë¥¼ í™•ì¸í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤\n5. êµí™˜ ìƒí’ˆ ë°œì†¡ í›„ ê¸°ì¡´ ìƒí’ˆì„ íšŒìˆ˜í•©ë‹ˆë‹¤."
            },
            {
                "input": "ë°°ì†¡ì´ ì§€ì—°ë˜ê³  ìˆì–´ìš”",
                "output": "ë°°ì†¡ ì§€ì—°ìœ¼ë¡œ ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤.\n1. ì£¼ë¬¸ë²ˆí˜¸ë¥¼ í™•ì¸í•´ì£¼ì‹œë©´ ë°°ì†¡ ìƒíƒœë¥¼ ì¡°íšŒí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤\n2. íƒë°°ì‚¬ ì‚¬ì •ìœ¼ë¡œ ì§€ì—°ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n3. ì˜ˆìƒ ë°°ì†¡ì¼ì„ ì¬ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤\n4. ì¶”ê°€ ì§€ì—° ì‹œ ì¦‰ì‹œ ì—°ë½ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
            },
            {
                "input": "ì‚¬ì´ì¦ˆê°€ ì•ˆ ë§ì•„ìš”",
                "output": "ì‚¬ì´ì¦ˆ ë¶ˆë§Œì¡±ìœ¼ë¡œ ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤.\n1. ë¬´ë£Œ ì‚¬ì´ì¦ˆ êµí™˜ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤\n2. ì‚¬ì´ì¦ˆ ê°€ì´ë“œë¥¼ ì°¸ê³ í•˜ì—¬ ì˜¬ë°”ë¥¸ ì‚¬ì´ì¦ˆë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”\n3. êµí™˜ ì‹ ì²­ í›„ ìƒˆ ìƒí’ˆ ë¨¼ì € ë°œì†¡í•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n4. ê¸°ì¡´ ìƒí’ˆì€ ìƒˆ ìƒí’ˆ ìˆ˜ë ¹ í›„ ë°˜ì†¡í•´ì£¼ì„¸ìš”."
            },
            {
                "input": "ì œí’ˆì— í•˜ìê°€ ìˆì–´ìš”",
                "output": "ì œí’ˆ í•˜ìë¡œ ë¶ˆí¸ì„ ë“œë ¤ ëŒ€ë‹¨íˆ ì£„ì†¡í•©ë‹ˆë‹¤.\n1. í•˜ì ë¶€ë¶„ì˜ ì‚¬ì§„ì„ ì°ì–´ 1:1 ë¬¸ì˜ë¡œ ë³´ë‚´ì£¼ì„¸ìš”\n2. ì¦‰ì‹œ ìƒˆ ì œí’ˆìœ¼ë¡œ êµì²´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤\n3. ë°°ì†¡ë¹„ëŠ” ì €í¬ê°€ ë¶€ë‹´í•˜ê² ìŠµë‹ˆë‹¤\n4. ì¶”ê°€ í”¼í•´ë‚˜ ë¶ˆí¸ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”."
            }
        ]

        return self.create_customer_service_bot(product_examples)

    def test_dynamic_selection(
        self,
        prompt_template: ChatPromptTemplate,
        example_selector: SemanticSimilarityExampleSelector,
        test_inputs: List[str]
    ) -> Dict[str, Any]:
        """ë™ì  ì„ íƒ í…ŒìŠ¤íŠ¸"""
        results = {}

        for test_input in test_inputs:
            # ì„ íƒëœ ì˜ˆì‹œ í™•ì¸
            selected_examples = example_selector.select_examples({"input": test_input})

            # ì‘ë‹µ ìƒì„±
            chain = prompt_template | self.llm | StrOutputParser()
            response = chain.invoke({"input": test_input})

            results[test_input] = {
                "selected_examples": selected_examples,
                "response": response
            }

        return results

# ì‚¬ìš© ì˜ˆì‹œ
dynamic_system = DynamicFewShotSystem()

# ê¸°ìˆ  ì§€ì› ì‹œìŠ¤í…œ ìƒì„±
tech_prompt, tech_selector = dynamic_system.create_technical_support_system()

# ì œí’ˆ ì§€ì› ì‹œìŠ¤í…œ ìƒì„±
product_prompt, product_selector = dynamic_system.create_product_support_system()

# ê¸°ìˆ  ì§€ì› í…ŒìŠ¤íŠ¸
tech_test_inputs = [
    "ì»´í“¨í„°ê°€ ë¶€íŒ…ì´ ì•ˆ ë¼ìš”",
    "ì™€ì´íŒŒì´ ì—°ê²°ì´ ì•ˆ ë¼ìš”",
    "í”„ë¡œê·¸ë¨ì´ ìê¾¸ ë©ˆì¶°ìš”"
]

tech_results = dynamic_system.test_dynamic_selection(
    tech_prompt, tech_selector, tech_test_inputs
)

print("=== ê¸°ìˆ  ì§€ì› ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ===")
for test_input, result in tech_results.items():
    print(f"\nì…ë ¥: {test_input}")
    print("ì„ íƒëœ ì˜ˆì‹œ:")
    for example in result["selected_examples"]:
        print(f"  - {example['input']}")
    print(f"ì‘ë‹µ: {result['response']}")

# ì œí’ˆ ì§€ì› í…ŒìŠ¤íŠ¸
product_test_inputs = [
    "ë°°ì†¡ ìƒí’ˆì´ íŒŒì†ë˜ì—ˆì–´ìš”",
    "ì£¼ë¬¸ì„ ì·¨ì†Œí•˜ê³  ì‹¶ì–´ìš”",
    "ë‹¤ë¥¸ ìƒ‰ìƒìœ¼ë¡œ ë°”ê¾¸ê³  ì‹¶ì–´ìš”"
]

product_results = dynamic_system.test_dynamic_selection(
    product_prompt, product_selector, product_test_inputs
)

print("\n\n=== ì œí’ˆ ì§€ì› ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ===")
for test_input, result in product_results.items():
    print(f"\nì…ë ¥: {test_input}")
    print("ì„ íƒëœ ì˜ˆì‹œ:")
    for example in result["selected_examples"]:
        print(f"  - {example['input']}")
    print(f"ì‘ë‹µ: {result['response']}")
```

### 4. ì„±ëŠ¥ ìµœì í™” Few-Shot ì‹œìŠ¤í…œ

```python
class OptimizedFewShotSystem:
    def __init__(self, model_name: str = "gpt-4.1-mini"):
        """ìµœì í™”ëœ Few-Shot ì‹œìŠ¤í…œ"""
        self.llm = ChatOpenAI(model=model_name, temperature=0.1)
        self.example_cache = {}
        self.performance_metrics = {}

    def create_adaptive_example_selector(
        self,
        examples: List[Dict[str, str]],
        max_examples: int = 3,
        min_similarity: float = 0.5
    ) -> SemanticSimilarityExampleSelector:
        """ì ì‘ì  ì˜ˆì‹œ ì„ íƒê¸° ìƒì„±"""

        # ìºì‹œ í‚¤ ìƒì„±
        cache_key = f"examples_{len(examples)}_{max_examples}"

        if cache_key in self.example_cache:
            return self.example_cache[cache_key]

        # ë²¡í„°í™”
        to_vectorize = [f"{ex['input']} {ex['output']}" for ex in examples]

        embeddings = OllamaEmbeddings(model="bge-m3")
        vector_store = InMemoryVectorStore.from_texts(
            to_vectorize, embeddings, metadatas=examples
        )

        # ì„ íƒê¸° ìƒì„±
        selector = SemanticSimilarityExampleSelector(
            vectorstore=vector_store,
            k=max_examples
        )

        # ìºì‹œ ì €ì¥
        self.example_cache[cache_key] = selector

        return selector

    def create_context_aware_prompt(
        self,
        task_name: str,
        system_message: str,
        examples: List[Dict[str, str]],
        context_variables: List[str] = None
    ) -> tuple:
        """ë¬¸ë§¥ ì¸ì‹ í”„ë¡¬í”„íŠ¸ ìƒì„±"""

        # ì˜ˆì‹œ ì„ íƒê¸° ìƒì„±
        selector = self.create_adaptive_example_selector(examples)

        # Few-shot í”„ë¡¬í”„íŠ¸
        few_shot_prompt = FewShotChatMessagePromptTemplate(
            input_variables=["input"],
            example_selector=selector,
            example_prompt=ChatPromptTemplate.from_messages([
                ("human", "{input}"),
                ("assistant", "{output}")
            ])
        )

        # ë¬¸ë§¥ ë³€ìˆ˜ê°€ ìˆëŠ” ê²½ìš°
        if context_variables:
            messages = [("system", system_message)]

            # ë¬¸ë§¥ ì •ë³´ ì¶”ê°€
            for var in context_variables:
                messages.append(("system", f"{var}: {{{var}}}"))

            messages.extend([few_shot_prompt, ("human", "{input}")])
        else:
            messages = [
                ("system", system_message),
                few_shot_prompt,
                ("human", "{input}")
            ]

        final_prompt = ChatPromptTemplate.from_messages(messages)

        return final_prompt, selector

    def create_multilingual_translator(self) -> tuple:
        """ë‹¤êµ­ì–´ ë²ˆì—­ê¸° ìƒì„±"""
        translation_examples = [
            {
                "input": "Hello, how are you? | Korean",
                "output": "ì•ˆë…•í•˜ì„¸ìš”, ì–´ë–»ê²Œ ì§€ë‚´ì„¸ìš”?"
            },
            {
                "input": "Thank you for your help | Korean",
                "output": "ë„ì›€ì„ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤"
            },
            {
                "input": "ì•ˆë…•í•˜ì„¸ìš”, ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤ | English",
                "output": "Hello, nice to meet you"
            },
            {
                "input": "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš” | English",
                "output": "The weather is really nice today"
            },
            {
                "input": "Â¿CÃ³mo estÃ¡ usted? | Korean",
                "output": "ì–´ë–»ê²Œ ì§€ë‚´ì„¸ìš”?"
            },
            {
                "input": "Gracias por todo | Korean",
                "output": "ëª¨ë“  ê²ƒì— ê°ì‚¬í•©ë‹ˆë‹¤"
            },
            {
                "input": "Je suis trÃ¨s content | Korean",
                "output": "ì €ëŠ” ë§¤ìš° ê¸°ì©ë‹ˆë‹¤"
            },
            {
                "input": "ì•ˆë…•íˆ ê°€ì„¸ìš” | Spanish",
                "output": "AdiÃ³s, que tenga un buen dÃ­a"
            }
        ]

        system_message = """
ë‹¹ì‹ ì€ ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­í•´ì£¼ì„¸ìš”.
ì…ë ¥ í˜•ì‹: [ë²ˆì—­í•  í…ìŠ¤íŠ¸] | [ëª©í‘œ ì–¸ì–´]
ë²ˆì—­ ì‹œ ë¬¸í™”ì  ë§¥ë½ê³¼ ë‰˜ì•™ìŠ¤ë¥¼ ê³ ë ¤í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ë²ˆì—­ì„ ì œê³µí•´ì£¼ì„¸ìš”.
"""

        return self.create_context_aware_prompt(
            "multilingual_translation",
            system_message,
            translation_examples
        )

    def create_sentiment_analyzer_with_confidence(self) -> tuple:
        """ì‹ ë¢°ë„ê°€ í¬í•¨ëœ ê°ì • ë¶„ì„ê¸° ìƒì„±"""
        sentiment_examples = [
            {
                "input": "ì´ ì œí’ˆ ì •ë§ í›Œë¥­í•˜ê³  ë§Œì¡±ìŠ¤ëŸ½ìŠµë‹ˆë‹¤!",
                "output": "ê°ì •: ê¸ì • | ì‹ ë¢°ë„: 95% | ê·¼ê±°: 'í›Œë¥­í•˜ê³ ', 'ë§Œì¡±ìŠ¤ëŸ½ìŠµë‹ˆë‹¤' ë“± ê°•í•œ ê¸ì • í‘œí˜„"
            },
            {
                "input": "ì„œë¹„ìŠ¤ê°€ ì—‰ë§ì´ê³  ì§ì›ë“¤ë„ ë¶ˆì¹œì ˆí•´ìš”",
                "output": "ê°ì •: ë¶€ì • | ì‹ ë¢°ë„: 90% | ê·¼ê±°: 'ì—‰ë§', 'ë¶ˆì¹œì ˆ' ë“± ëª…í™•í•œ ë¶€ì • í‘œí˜„"
            },
            {
                "input": "ê·¸ëƒ¥ ê·¸ì € ê·¸ëŸ° ê²ƒ ê°™ì•„ìš”",
                "output": "ê°ì •: ì¤‘ë¦½ | ì‹ ë¢°ë„: 85% | ê·¼ê±°: 'ê·¸ì € ê·¸ëŸ°' ë“± ì¤‘ë¦½ì  í‘œí˜„"
            },
            {
                "input": "ê°€ê²©ì€ ë¹„ì‹¸ì§€ë§Œ í’ˆì§ˆì€ ì¢‹ë„¤ìš”",
                "output": "ê°ì •: ì¤‘ë¦½ | ì‹ ë¢°ë„: 80% | ê·¼ê±°: ê¸ì •('í’ˆì§ˆ ì¢‹ìŒ')ê³¼ ë¶€ì •('ë¹„ìŒˆ') ìš”ì†Œ í˜¼ì¬"
            },
            {
                "input": "ìµœê³ ì˜ˆìš”! ë‹¤ì‹œ êµ¬ë§¤í•  ì˜í–¥ì´ ìˆìŠµë‹ˆë‹¤",
                "output": "ê°ì •: ê¸ì • | ì‹ ë¢°ë„: 98% | ê·¼ê±°: 'ìµœê³ ', 'ë‹¤ì‹œ êµ¬ë§¤' ë“± ë§¤ìš° ê°•í•œ ê¸ì • ì˜ë„"
            },
            {
                "input": "ì™„ì „ ì‹¤ë§í–ˆì–´ìš”. ëˆë§Œ ë²„ë ¸ë„¤ìš”",
                "output": "ê°ì •: ë¶€ì • | ì‹ ë¢°ë„: 95% | ê·¼ê±°: 'ì™„ì „ ì‹¤ë§', 'ëˆë§Œ ë²„ë ¸ë‹¤' ë“± ê°•í•œ ë¶€ì • ê°ì •"
            }
        ]

        system_message = """
ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì…ë ¥ëœ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ê³  ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

ê°ì •: [ê¸ì •/ë¶€ì •/ì¤‘ë¦½]
ì‹ ë¢°ë„: [0-100%]
ê·¼ê±°: [íŒë‹¨ ê·¼ê±°ì™€ í•µì‹¬ ë‹¨ì–´/êµ¬ë¬¸]

ê°ì • íŒë‹¨ ê¸°ì¤€:
- ê¸ì •: ë§Œì¡±, ê¸°ì¨, ì¹­ì°¬ ë“±ì˜ ê¸ì •ì  í‘œí˜„
- ë¶€ì •: ë¶ˆë§Œ, ì‹¤ë§, ë¹„íŒ ë“±ì˜ ë¶€ì •ì  í‘œí˜„
- ì¤‘ë¦½: ê°ê´€ì  ì„œìˆ ì´ë‚˜ ê¸ì •/ë¶€ì • ìš”ì†Œê°€ í˜¼ì¬ëœ ê²½ìš°
"""

        return self.create_context_aware_prompt(
            "sentiment_analysis",
            system_message,
            sentiment_examples
        )

    def measure_performance(
        self,
        prompt_template: ChatPromptTemplate,
        test_cases: List[Dict[str, str]],
        task_name: str
    ) -> Dict[str, Any]:
        """ì„±ëŠ¥ ì¸¡ì •"""
        import time

        chain = prompt_template | self.llm | StrOutputParser()

        start_time = time.time()
        results = []

        for test_case in test_cases:
            case_start = time.time()
            try:
                result = chain.invoke({"input": test_case["input"]})
                case_time = time.time() - case_start

                results.append({
                    "input": test_case["input"],
                    "output": result,
                    "expected": test_case.get("expected", ""),
                    "response_time": case_time,
                    "success": True
                })
            except Exception as e:
                results.append({
                    "input": test_case["input"],
                    "error": str(e),
                    "response_time": time.time() - case_start,
                    "success": False
                })

        total_time = time.time() - start_time
        success_rate = sum(1 for r in results if r["success"]) / len(results)
        avg_response_time = sum(r["response_time"] for r in results) / len(results)

        performance_report = {
            "task_name": task_name,
            "total_test_cases": len(test_cases),
            "success_rate": success_rate,
            "total_time": total_time,
            "average_response_time": avg_response_time,
            "results": results
        }

        self.performance_metrics[task_name] = performance_report
        return performance_report

# ì‚¬ìš© ì˜ˆì‹œ
optimized_system = OptimizedFewShotSystem()

# ë‹¤êµ­ì–´ ë²ˆì—­ê¸° ìƒì„± ë° í…ŒìŠ¤íŠ¸
translator_prompt, translator_selector = optimized_system.create_multilingual_translator()

translation_test_cases = [
    {"input": "Good morning, have a nice day! | Korean"},
    {"input": "ê°ì‚¬í•©ë‹ˆë‹¤, ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš” | English"},
    {"input": "Â¿DÃ³nde estÃ¡ el baÃ±o? | Korean"},
    {"input": "ì˜¤ëŠ˜ íšŒì˜ê°€ ëª‡ ì‹œì— ìˆë‚˜ìš”? | Spanish"}
]

print("=== ë‹¤êµ­ì–´ ë²ˆì—­ í…ŒìŠ¤íŠ¸ ===")
translation_chain = translator_prompt | optimized_system.llm | StrOutputParser()

for test_case in translation_test_cases:
    result = translation_chain.invoke({"input": test_case["input"]})
    print(f"ì…ë ¥: {test_case['input']}")
    print(f"ë²ˆì—­: {result}\n")

# ê°ì • ë¶„ì„ê¸° ìƒì„± ë° ì„±ëŠ¥ ì¸¡ì •
sentiment_prompt, sentiment_selector = optimized_system.create_sentiment_analyzer_with_confidence()

sentiment_test_cases = [
    {
        "input": "ì •ë§ ì™„ë²½í•œ ì„œë¹„ìŠ¤ì˜€ì–´ìš”! ê°•ë ¥ ì¶”ì²œí•©ë‹ˆë‹¤",
        "expected": "ê¸ì •"
    },
    {
        "input": "ìµœì•…ì˜ ê²½í—˜ì´ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹  ì´ìš© ì•ˆ í• ê²Œìš”",
        "expected": "ë¶€ì •"
    },
    {
        "input": "ë³´í†µ ìˆ˜ì¤€ì´ë„¤ìš”. ë‚˜ì˜ì§€ë„ ì¢‹ì§€ë„ ì•Šê³ ",
        "expected": "ì¤‘ë¦½"
    },
    {
        "input": "ë°°ì†¡ì€ ë¹¨ëëŠ”ë° í’ˆì§ˆì´ ì•„ì‰¬ì›Œìš”",
        "expected": "ì¤‘ë¦½"
    },
    {
        "input": "ì™€! ëŒ€ë°•ì´ì—ìš”! ì •ë§ ë§ˆìŒì— ë“¤ì–´ìš”",
        "expected": "ê¸ì •"
    }
]

# ì„±ëŠ¥ ì¸¡ì • ì‹¤í–‰
performance_report = optimized_system.measure_performance(
    sentiment_prompt,
    sentiment_test_cases,
    "sentiment_analysis_with_confidence"
)

print("=== ê°ì • ë¶„ì„ ì„±ëŠ¥ ë³´ê³ ì„œ ===")
print(f"ì‘ì—…ëª…: {performance_report['task_name']}")
print(f"í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìˆ˜: {performance_report['total_test_cases']}")
print(f"ì„±ê³µë¥ : {performance_report['success_rate']:.2%}")
print(f"í‰ê·  ì‘ë‹µ ì‹œê°„: {performance_report['average_response_time']:.2f}ì´ˆ")
print(f"ì „ì²´ ì‹¤í–‰ ì‹œê°„: {performance_report['total_time']:.2f}ì´ˆ")

print("\nìƒì„¸ ê²°ê³¼:")
for i, result in enumerate(performance_report['results'], 1):
    if result['success']:
        print(f"{i}. {result['input']}")
        print(f"   ê²°ê³¼: {result['output']}")
        print(f"   ì‹œê°„: {result['response_time']:.2f}ì´ˆ\n")
```

## ğŸš€ ì‹¤ìŠµí•´ë³´ê¸°

### ì‹¤ìŠµ 1: ê°ì • ë¶„ì„ê¸° êµ¬í˜„

Zero-shotê³¼ Few-shot ë°©ì‹ìœ¼ë¡œ ê°ì • ë¶„ì„ê¸°ë¥¼ êµ¬í˜„í•˜ê³  ì„±ëŠ¥ì„ ë¹„êµí•´ë³´ì„¸ìš”.

```python
# ê°ì • ë¶„ì„ê¸° ë¹„êµ ì‹œìŠ¤í…œ êµ¬í˜„
class SentimentAnalysisComparator:
    def __init__(self):
        # ì´ˆê¸°í™” ì½”ë“œ ì‘ì„±
        pass

    def create_zero_shot_analyzer(self):
        # Zero-shot ê°ì • ë¶„ì„ê¸° êµ¬í˜„
        pass

    def create_few_shot_analyzer(self):
        # Few-shot ê°ì • ë¶„ì„ê¸° êµ¬í˜„
        pass

    def compare_performance(self, test_texts):
        # ì„±ëŠ¥ ë¹„êµ ë¶„ì„
        pass
```

### ì‹¤ìŠµ 2: ë™ì  ê³ ê° ì„œë¹„ìŠ¤ ë´‡

ê³ ê° ë¬¸ì˜ ìœ í˜•ì— ë”°ë¼ ì ì ˆí•œ ì˜ˆì‹œë¥¼ ì„ íƒí•˜ëŠ” ë™ì  ì‹œìŠ¤í…œì„ êµ¬í˜„í•´ë³´ì„¸ìš”.

```python
# ë™ì  ê³ ê° ì„œë¹„ìŠ¤ ë´‡ êµ¬í˜„
class DynamicCustomerServiceBot:
    def __init__(self):
        # ì´ˆê¸°í™” ì½”ë“œ ì‘ì„±
        pass

    def setup_example_database(self):
        # ì˜ˆì‹œ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•
        pass

    def create_dynamic_selector(self):
        # ë™ì  ì˜ˆì‹œ ì„ íƒê¸° êµ¬í˜„
        pass

    def handle_customer_inquiry(self, inquiry):
        # ê³ ê° ë¬¸ì˜ ì²˜ë¦¬
        pass
```

### ì‹¤ìŠµ 3: ë©€í‹°íƒœìŠ¤í¬ Few-Shot ì‹œìŠ¤í…œ

í•˜ë‚˜ì˜ ì‹œìŠ¤í…œì—ì„œ ì—¬ëŸ¬ ì‘ì—…ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” Few-Shot ì‹œìŠ¤í…œì„ êµ¬í˜„í•´ë³´ì„¸ìš”.

```python
# ë©€í‹°íƒœìŠ¤í¬ Few-Shot ì‹œìŠ¤í…œ êµ¬í˜„
class MultiTaskFewShotSystem:
    def __init__(self):
        # ì´ˆê¸°í™” ì½”ë“œ ì‘ì„±
        pass

    def setup_task_router(self):
        # ì‘ì—… ìœ í˜• ë¼ìš°í„° êµ¬í˜„
        pass

    def create_task_specific_prompts(self):
        # ì‘ì—…ë³„ íŠ¹í™” í”„ë¡¬í”„íŠ¸ ìƒì„±
        pass

    def execute_task(self, input_text, task_type):
        # ì‘ì—… ì‹¤í–‰
        pass
```

## ğŸ“‹ í•´ë‹µ

### ì‹¤ìŠµ 1: ê°ì • ë¶„ì„ê¸° êµ¬í˜„

```python
class SentimentAnalysisComparator:
    def __init__(self, model_name: str = "gpt-4.1-mini"):
        """ê°ì • ë¶„ì„ê¸° ë¹„êµ ì‹œìŠ¤í…œ"""
        self.llm = ChatOpenAI(model=model_name, temperature=0.1)

    def create_zero_shot_analyzer(self) -> PromptTemplate:
        """Zero-shot ê°ì • ë¶„ì„ê¸° êµ¬í˜„"""
        return PromptTemplate(
            input_variables=["text"],
            template="""
ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ê³  ê¸ì •, ë¶€ì •, ì¤‘ë¦½ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.
ë˜í•œ íŒë‹¨ ê·¼ê±°ë¥¼ í•¨ê»˜ ì œì‹œí•´ì£¼ì„¸ìš”.

í…ìŠ¤íŠ¸: {text}

í˜•ì‹:
ê°ì •: [ê¸ì •/ë¶€ì •/ì¤‘ë¦½]
ê·¼ê±°: [íŒë‹¨ ì´ìœ ]
"""
        )

    def create_few_shot_analyzer(self) -> PromptTemplate:
        """Few-shot ê°ì • ë¶„ì„ê¸° êµ¬í˜„"""
        examples = """
ì˜ˆì‹œ 1:
í…ìŠ¤íŠ¸: ì´ ì œí’ˆ ì •ë§ ë§ˆìŒì— ë“¤ì–´ìš”! í’ˆì§ˆë„ ì¢‹ê³  ê°€ê²©ë„ í•©ë¦¬ì ì…ë‹ˆë‹¤.
ê°ì •: ê¸ì •
ê·¼ê±°: 'ë§ˆìŒì— ë“¤ì–´ìš”', 'í’ˆì§ˆë„ ì¢‹ê³ ', 'í•©ë¦¬ì ' ë“± ë§Œì¡±ê°ê³¼ ê¸ì •ì  í‰ê°€ í‘œí˜„

ì˜ˆì‹œ 2:
í…ìŠ¤íŠ¸: ì„œë¹„ìŠ¤ê°€ ë„ˆë¬´ ëŠë¦¬ê³  ì§ì›ë“¤ë„ ë¶ˆì¹œì ˆí•´ì„œ ì‹¤ë§í–ˆìŠµë‹ˆë‹¤.
ê°ì •: ë¶€ì •
ê·¼ê±°: 'ë„ˆë¬´ ëŠë¦¬ê³ ', 'ë¶ˆì¹œì ˆ', 'ì‹¤ë§' ë“± ë¶ˆë§Œê³¼ ë¶€ì •ì  ê²½í—˜ í‘œí˜„

ì˜ˆì‹œ 3:
í…ìŠ¤íŠ¸: ê·¸ëƒ¥ ë³´í†µ ìˆ˜ì¤€ì´ë„¤ìš”. íŠ¹ë³„íˆ ì¢‹ì§€ë„ ë‚˜ì˜ì§€ë„ ì•Šì•„ìš”.
ê°ì •: ì¤‘ë¦½
ê·¼ê±°: 'ë³´í†µ ìˆ˜ì¤€', 'ì¢‹ì§€ë„ ë‚˜ì˜ì§€ë„ ì•Šë‹¤' ë“± ì¤‘ë¦½ì ì´ê³  ê°ê´€ì ì¸ í‘œí˜„

ì˜ˆì‹œ 4:
í…ìŠ¤íŠ¸: ê°€ê²©ì€ ë¹„ì‹¸ì§€ë§Œ ê·¸ë˜ë„ í’ˆì§ˆì€ ê´œì°®ì€ í¸ì…ë‹ˆë‹¤.
ê°ì •: ì¤‘ë¦½
ê·¼ê±°: ë¶€ì • ìš”ì†Œ('ë¹„ì‹¸ë‹¤')ì™€ ê¸ì • ìš”ì†Œ('í’ˆì§ˆ ê´œì°®ë‹¤')ê°€ ê· í˜•ì„ ì´ë£¨ëŠ” í‘œí˜„
"""

        return PromptTemplate(
            input_variables=["text"],
            template=f"""
ë‹¤ìŒì€ í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„ì˜ ì˜ˆì‹œë“¤ì…ë‹ˆë‹¤:

{examples}

ì´ì œ ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

í…ìŠ¤íŠ¸: {{text}}

í˜•ì‹:
ê°ì •: [ê¸ì •/ë¶€ì •/ì¤‘ë¦½]
ê·¼ê±°: [íŒë‹¨ ì´ìœ ]
"""
        )

    def extract_sentiment(self, analysis_result: str) -> str:
        """ë¶„ì„ ê²°ê³¼ì—ì„œ ê°ì •ë§Œ ì¶”ì¶œ"""
        lines = analysis_result.split('\n')
        for line in lines:
            if line.startswith('ê°ì •:'):
                return line.replace('ê°ì •:', '').strip()
        return "ì•Œ ìˆ˜ ì—†ìŒ"

    def compare_performance(self, test_texts: List[Dict[str, str]]) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë¹„êµ ë¶„ì„"""
        zero_shot_prompt = self.create_zero_shot_analyzer()
        few_shot_prompt = self.create_few_shot_analyzer()

        zero_shot_chain = zero_shot_prompt | self.llm | StrOutputParser()
        few_shot_chain = few_shot_prompt | self.llm | StrOutputParser()

        results = {
            "test_cases": len(test_texts),
            "zero_shot": {"correct": 0, "total": 0, "results": []},
            "few_shot": {"correct": 0, "total": 0, "results": []},
            "detailed_comparison": []
        }

        for test_case in test_texts:
            text = test_case["text"]
            expected = test_case["expected"]

            # Zero-shot ë¶„ì„
            zero_shot_result = zero_shot_chain.invoke({"text": text})
            zero_shot_sentiment = self.extract_sentiment(zero_shot_result)
            zero_shot_correct = zero_shot_sentiment.lower() == expected.lower()

            # Few-shot ë¶„ì„
            few_shot_result = few_shot_chain.invoke({"text": text})
            few_shot_sentiment = self.extract_sentiment(few_shot_result)
            few_shot_correct = few_shot_sentiment.lower() == expected.lower()

            # ê²°ê³¼ ê¸°ë¡
            results["zero_shot"]["total"] += 1
            results["few_shot"]["total"] += 1

            if zero_shot_correct:
                results["zero_shot"]["correct"] += 1
            if few_shot_correct:
                results["few_shot"]["correct"] += 1

            results["zero_shot"]["results"].append({
                "text": text,
                "predicted": zero_shot_sentiment,
                "expected": expected,
                "correct": zero_shot_correct,
                "full_result": zero_shot_result
            })

            results["few_shot"]["results"].append({
                "text": text,
                "predicted": few_shot_sentiment,
                "expected": expected,
                "correct": few_shot_correct,
                "full_result": few_shot_result
            })

            results["detailed_comparison"].append({
                "text": text,
                "expected": expected,
                "zero_shot": zero_shot_sentiment,
                "few_shot": few_shot_sentiment,
                "zero_shot_correct": zero_shot_correct,
                "few_shot_correct": few_shot_correct
            })

        # ì •í™•ë„ ê³„ì‚°
        results["zero_shot"]["accuracy"] = results["zero_shot"]["correct"] / results["zero_shot"]["total"]
        results["few_shot"]["accuracy"] = results["few_shot"]["correct"] / results["few_shot"]["total"]

        return results

# ì‹¤ìŠµ 1 í…ŒìŠ¤íŠ¸
sentiment_comparator = SentimentAnalysisComparator()

test_cases = [
    {"text": "ì´ ìƒí’ˆ ì •ë§ ì™„ë²½í•´ìš”! ê°•ë ¥ ì¶”ì²œë“œë¦½ë‹ˆë‹¤!", "expected": "ê¸ì •"},
    {"text": "ìµœì•…ì˜ ì„œë¹„ìŠ¤ì˜€ì–´ìš”. ëˆë§Œ ì•„ê¹ìŠµë‹ˆë‹¤.", "expected": "ë¶€ì •"},
    {"text": "ê·¸ëƒ¥ ê·¸ì € ê·¸ëŸ° í‰ë²”í•œ ì œí’ˆì´ë„¤ìš”.", "expected": "ì¤‘ë¦½"},
    {"text": "ê°€ê²©ì€ ë¹„ì‹¸ì§€ë§Œ í’ˆì§ˆë§Œí¼ì€ í™•ì‹¤í•´ìš”.", "expected": "ì¤‘ë¦½"},
    {"text": "ì™„ì „ ëŒ€ë°•! ì§„ì§œ ë§ˆìŒì— ë“¤ì–´ìš”!", "expected": "ê¸ì •"},
    {"text": "ì‹¤ë§ìŠ¤ëŸ½ê³  í™”ê°€ ë‚˜ë„¤ìš”.", "expected": "ë¶€ì •"},
    {"text": "ë°°ì†¡ì€ ë¹¨ëëŠ”ë° í¬ì¥ì´ ì¡°ê¸ˆ ì•„ì‰¬ì›Œìš”.", "expected": "ì¤‘ë¦½"},
    {"text": "ì—†ì–´ì„œëŠ” ì•ˆ ë  í•„ìˆ˜í…œì´ì—ìš”!", "expected": "ê¸ì •"},
    {"text": "í™˜ë¶ˆí•˜ê³  ì‹¶ì„ ì •ë„ë¡œ í›„íšŒë©ë‹ˆë‹¤.", "expected": "ë¶€ì •"},
    {"text": "ë³´í†µ ìˆ˜ì¤€ì´ë¼ê³  ìƒê°í•©ë‹ˆë‹¤.", "expected": "ì¤‘ë¦½"}
]

comparison_results = sentiment_comparator.compare_performance(test_cases)

print("=== ê°ì • ë¶„ì„ê¸° ì„±ëŠ¥ ë¹„êµ ===")
print(f"í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìˆ˜: {comparison_results['test_cases']}")
print(f"Zero-shot ì •í™•ë„: {comparison_results['zero_shot']['accuracy']:.2%}")
print(f"Few-shot ì •í™•ë„: {comparison_results['few_shot']['accuracy']:.2%}")

print("\n=== ìƒì„¸ ë¹„êµ ê²°ê³¼ ===")
for i, comparison in enumerate(comparison_results['detailed_comparison'], 1):
    print(f"{i}. {comparison['text']}")
    print(f"   ì˜ˆìƒ: {comparison['expected']}")
    print(f"   Zero-shot: {comparison['zero_shot']} {'âœ“' if comparison['zero_shot_correct'] else 'âœ—'}")
    print(f"   Few-shot: {comparison['few_shot']} {'âœ“' if comparison['few_shot_correct'] else 'âœ—'}")
    print()
```

### ì‹¤ìŠµ 2: ë™ì  ê³ ê° ì„œë¹„ìŠ¤ ë´‡

```python
class DynamicCustomerServiceBot:
    def __init__(self, model_name: str = "gpt-4.1-mini"):
        """ë™ì  ê³ ê° ì„œë¹„ìŠ¤ ë´‡"""
        self.llm = ChatOpenAI(model=model_name, temperature=0.1)
        self.embeddings = OllamaEmbeddings(model="bge-m3")
        self.example_selectors = {}

    def setup_example_database(self) -> Dict[str, List[Dict[str, str]]]:
        """ì˜ˆì‹œ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•"""
        return {
            "product_inquiry": [
                {
                    "input": "ì´ ì œí’ˆì˜ ì‚¬ì–‘ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
                    "output": "ì œí’ˆ ì‚¬ì–‘ì„ ìƒì„¸íˆ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ë¶€ë¶„ì´ ê¶ê¸ˆí•˜ì‹ ì§€ ë§ì”€í•´ì£¼ì‹œë©´ ë” ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                },
                {
                    "input": "ì¬ê³ ê°€ ìˆë‚˜ìš”?",
                    "output": "ì¬ê³  í˜„í™©ì„ í™•ì¸í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ìƒí’ˆëª…ì´ë‚˜ ìƒí’ˆ ì½”ë“œë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ì¦‰ì‹œ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤."
                },
                {
                    "input": "ìƒ‰ìƒ ì˜µì…˜ì´ ìˆë‚˜ìš”?",
                    "output": "í•´ë‹¹ ì œí’ˆì˜ ìƒ‰ìƒ ì˜µì…˜ì„ í™•ì¸í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. í˜„ì¬ ì´ìš© ê°€ëŠ¥í•œ ìƒ‰ìƒê³¼ ì¬ê³  ìƒí™©ì„ í•¨ê»˜ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                }
            ],
            "shipping_inquiry": [
                {
                    "input": "ì–¸ì œ ë°°ì†¡ë˜ë‚˜ìš”?",
                    "output": "ì£¼ë¬¸ë²ˆí˜¸ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ì •í™•í•œ ë°°ì†¡ ì˜ˆì •ì¼ì„ í™•ì¸í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ì£¼ë¬¸ í›„ 1-2ì¼ ë‚´ ë°°ì†¡ë©ë‹ˆë‹¤."
                },
                {
                    "input": "ë°°ì†¡ë¹„ëŠ” ì–¼ë§ˆì¸ê°€ìš”?",
                    "output": "ë°°ì†¡ë¹„ëŠ” ì§€ì—­ê³¼ ì£¼ë¬¸ ê¸ˆì•¡ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤. 50,000ì› ì´ìƒ ì£¼ë¬¸ ì‹œ ë¬´ë£Œë°°ì†¡ì´ë©°, ê·¸ ì´í•˜ëŠ” 2,500ì›ì…ë‹ˆë‹¤."
                },
                {
                    "input": "ë°°ì†¡ ì¶”ì ì„ í•˜ê³  ì‹¶ì–´ìš”",
                    "output": "ìš´ì†¡ì¥ ë²ˆí˜¸ë¥¼ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì£¼ë¬¸ë²ˆí˜¸ë‚˜ ì£¼ë¬¸ìëª…ì„ ì•Œë ¤ì£¼ì‹œë©´ ë°°ì†¡ ìƒíƒœë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                }
            ],
            "return_exchange": [
                {
                    "input": "í™˜ë¶ˆí•˜ê³  ì‹¶ì–´ìš”",
                    "output": "í™˜ë¶ˆ ì ˆì°¨ë¥¼ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. êµ¬ë§¤ì¼ë¡œë¶€í„° 7ì¼ ì´ë‚´ ì‹ ì²­ ê°€ëŠ¥í•˜ë©°, ìƒí’ˆ ìƒíƒœ í™•ì¸ í›„ ì²˜ë¦¬ë©ë‹ˆë‹¤."
                },
                {
                    "input": "êµí™˜ ê°€ëŠ¥í•œê°€ìš”?",
                    "output": "êµí™˜ì€ êµ¬ë§¤ì¼ë¡œë¶€í„° 7ì¼ ì´ë‚´, ë¯¸ì‚¬ìš© ìƒíƒœì—ì„œ ê°€ëŠ¥í•©ë‹ˆë‹¤. êµí™˜ ì‚¬ìœ ì™€ í¬ë§ ìƒí’ˆì„ ì•Œë ¤ì£¼ì„¸ìš”."
                },
                {
                    "input": "ì‚¬ì´ì¦ˆê°€ ì•ˆ ë§ì•„ìš”",
                    "output": "ì‚¬ì´ì¦ˆ ë¶ˆì¼ì¹˜ë¡œ ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤. ë¬´ë£Œ ì‚¬ì´ì¦ˆ êµí™˜ì´ ê°€ëŠ¥í•˜ë‹ˆ í¬ë§í•˜ëŠ” ì‚¬ì´ì¦ˆë¥¼ ì•Œë ¤ì£¼ì„¸ìš”."
                }
            ],
            "technical_support": [
                {
                    "input": "ì„¤ì¹˜ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”",
                    "output": "ì œí’ˆ ì„¤ì¹˜ ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì œí’ˆ ë§¤ë‰´ì–¼ê³¼ í•¨ê»˜ ìì„¸í•œ ì„¤ëª…ì„ ì œê³µí•´ë“œë¦´ê²Œìš”."
                },
                {
                    "input": "ì‘ë™ì´ ì•ˆ ë¼ìš”",
                    "output": "ë¬¸ì œ ìƒí™©ì„ íŒŒì•…í•´ë³´ê² ìŠµë‹ˆë‹¤. ì–´ë–¤ ìƒí™©ì—ì„œ ì‘ë™í•˜ì§€ ì•ŠëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì‹œê² ì–´ìš”?"
                },
                {
                    "input": "ì˜¤ë¥˜ê°€ ë°œìƒí•´ìš”",
                    "output": "ì˜¤ë¥˜ ë©”ì‹œì§€ë‚˜ ìƒí™©ì„ ìì„¸íˆ ì•Œë ¤ì£¼ì„¸ìš”. ë‹¨ê³„ë³„ í•´ê²° ë°©ë²•ì„ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                }
            ]
        }

    def classify_inquiry_type(self, inquiry: str) -> str:
        """ë¬¸ì˜ ìœ í˜• ë¶„ë¥˜"""

        # í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜
        classification_keywords = {
            "product_inquiry": ["ì œí’ˆ", "ìƒí’ˆ", "ì‚¬ì–‘", "ê¸°ëŠ¥", "íŠ¹ì§•", "ì¬ê³ ", "ìƒ‰ìƒ", "ì˜µì…˜"],
            "shipping_inquiry": ["ë°°ì†¡", "íƒë°°", "ì–¸ì œ", "ë¹¨ë¦¬", "ìš´ì†¡", "ë„ì°©", "ë°°ì†¡ë¹„"],
            "return_exchange": ["í™˜ë¶ˆ", "êµí™˜", "ë°˜í’ˆ", "ì‚¬ì´ì¦ˆ", "ë¶ˆëŸ‰", "í•˜ì", "ì·¨ì†Œ"],
            "technical_support": ["ì„¤ì¹˜", "ì‚¬ìš©ë²•", "ì˜¤ë¥˜", "ê³ ì¥", "ì‘ë™", "ë¬¸ì œ", "ì„¤ì •"]
        }

        inquiry_lower = inquiry.lower()
        scores = {}

        for category, keywords in classification_keywords.items():
            score = sum(1 for keyword in keywords if keyword in inquiry_lower)
            scores[category] = score

        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì¹´í…Œê³ ë¦¬ ë°˜í™˜
        if max(scores.values()) > 0:
            return max(scores, key=scores.get)
        else:
            return "product_inquiry"  # ê¸°ë³¸ê°’

    def create_dynamic_selector(self, category: str, examples: List[Dict[str, str]]) -> SemanticSimilarityExampleSelector:
        """ë™ì  ì˜ˆì‹œ ì„ íƒê¸° êµ¬í˜„"""

        if category in self.example_selectors:
            return self.example_selectors[category]

        # ë²¡í„°í™”
        to_vectorize = [f"{ex['input']} {ex['output']}" for ex in examples]

        vector_store = InMemoryVectorStore.from_texts(
            to_vectorize, self.embeddings, metadatas=examples
        )

        # ì„ íƒê¸° ìƒì„±
        selector = SemanticSimilarityExampleSelector(
            vectorstore=vector_store,
            k=2  # ìƒìœ„ 2ê°œ ì˜ˆì‹œ ì„ íƒ
        )

        self.example_selectors[category] = selector
        return selector

    def create_category_prompt(self, category: str, examples: List[Dict[str, str]]) -> ChatPromptTemplate:
        """ì¹´í…Œê³ ë¦¬ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""

        selector = self.create_dynamic_selector(category, examples)

        few_shot_prompt = FewShotChatMessagePromptTemplate(
            input_variables=["input"],
            example_selector=selector,
            example_prompt=ChatPromptTemplate.from_messages([
                ("human", "{input}"),
                ("assistant", "{output}")
            ])
        )

        category_descriptions = {
            "product_inquiry": "ë‹¹ì‹ ì€ ì œí’ˆ ì •ë³´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê³ ê°ì˜ ì œí’ˆ ê´€ë ¨ ë¬¸ì˜ì— ì •í™•í•˜ê³  ìƒì„¸í•œ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.",
            "shipping_inquiry": "ë‹¹ì‹ ì€ ë°°ì†¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê³ ê°ì˜ ë°°ì†¡ ê´€ë ¨ ë¬¸ì˜ì— ëª…í™•í•œ ì •ë³´ì™€ í•´ê²°ì±…ì„ ì œê³µí•´ì£¼ì„¸ìš”.",
            "return_exchange": "ë‹¹ì‹ ì€ êµí™˜/í™˜ë¶ˆ ì²˜ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê³ ê°ì˜ ë¶ˆë§Œì‚¬í•­ì„ ì´í•´í•˜ê³  ì ì ˆí•œ í•´ê²°ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”.",
            "technical_support": "ë‹¹ì‹ ì€ ê¸°ìˆ  ì§€ì› ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê³ ê°ì˜ ê¸°ìˆ ì  ë¬¸ì œë¥¼ ë‹¨ê³„ë³„ë¡œ í•´ê²°í•´ì£¼ì„¸ìš”."
        }

        final_prompt = ChatPromptTemplate.from_messages([
            ("system", category_descriptions.get(category, "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ê³ ê° ì„œë¹„ìŠ¤ ë‹´ë‹¹ìì…ë‹ˆë‹¤.")),
            few_shot_prompt,
            ("human", "{input}")
        ])

        return final_prompt

    def handle_customer_inquiry(self, inquiry: str) -> Dict[str, Any]:
        """ê³ ê° ë¬¸ì˜ ì²˜ë¦¬"""

        # 1. ë¬¸ì˜ ìœ í˜• ë¶„ë¥˜
        category = self.classify_inquiry_type(inquiry)

        # 2. ì˜ˆì‹œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ì˜ˆì‹œ ê°€ì ¸ì˜¤ê¸°
        example_database = self.setup_example_database()
        examples = example_database.get(category, example_database["product_inquiry"])

        # 3. ì„ íƒëœ ì˜ˆì‹œ í™•ì¸
        selector = self.create_dynamic_selector(category, examples)
        selected_examples = selector.select_examples({"input": inquiry})

        # 4. í”„ë¡¬í”„íŠ¸ ìƒì„± ë° ì‘ë‹µ
        prompt = self.create_category_prompt(category, examples)
        chain = prompt | self.llm | StrOutputParser()
        response = chain.invoke({"input": inquiry})

        return {
            "inquiry": inquiry,
            "classified_category": category,
            "selected_examples": selected_examples,
            "response": response
        }

    def batch_handle_inquiries(self, inquiries: List[str]) -> List[Dict[str, Any]]:
        """ë‹¤ì¤‘ ë¬¸ì˜ ì¼ê´„ ì²˜ë¦¬"""
        results = []

        for inquiry in inquiries:
            result = self.handle_customer_inquiry(inquiry)
            results.append(result)

        return results

# ì‹¤ìŠµ 2 í…ŒìŠ¤íŠ¸
service_bot = DynamicCustomerServiceBot()

test_inquiries = [
    "ì´ ìŠ¤ë§ˆíŠ¸í°ì˜ ë°°í„°ë¦¬ ìš©ëŸ‰ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
    "ì£¼ë¬¸í•œ ìƒí’ˆì´ ì–¸ì œ ë„ì°©í•˜ë‚˜ìš”?",
    "ì œí’ˆì´ ë¶ˆëŸ‰ì¸ ê²ƒ ê°™ì•„ì„œ í™˜ë¶ˆë°›ê³  ì‹¶ì–´ìš”",
    "ì•±ì´ ê³„ì† êº¼ì ¸ì„œ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ìš”",
    "ë‹¤ë¥¸ ìƒ‰ìƒìœ¼ë¡œ êµí™˜ ê°€ëŠ¥í•œê°€ìš”?",
    "ë°°ì†¡ë¹„ëŠ” ì–¼ë§ˆì¸ê°€ìš”?",
    "ì„¤ì¹˜ ë§¤ë‰´ì–¼ì„ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?",
    "ì£¼ë¬¸ì„ ì·¨ì†Œí•˜ê³  ì‹¶ìŠµë‹ˆë‹¤"
]

print("=== ë™ì  ê³ ê° ì„œë¹„ìŠ¤ ë´‡ í…ŒìŠ¤íŠ¸ ===")
batch_results = service_bot.batch_handle_inquiries(test_inquiries)

for i, result in enumerate(batch_results, 1):
    print(f"\n{i}. ë¬¸ì˜: {result['inquiry']}")
    print(f"   ë¶„ë¥˜: {result['classified_category']}")
    print("   ì„ íƒëœ ì˜ˆì‹œ:")
    for example in result['selected_examples']:
        print(f"     - {example['input']}")
    print(f"   ì‘ë‹µ: {result['response']}")
    print("-" * 80)

# ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜ ì •í™•ë„ í™•ì¸
category_counts = {}
for result in batch_results:
    category = result['classified_category']
    category_counts[category] = category_counts.get(category, 0) + 1

print(f"\n=== ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜ ê²°ê³¼ ===")
for category, count in category_counts.items():
    print(f"{category}: {count}ê°œ")
```

### ì‹¤ìŠµ 3: ë©€í‹°íƒœìŠ¤í¬ Few-Shot ì‹œìŠ¤í…œ

```python
class MultiTaskFewShotSystem:
    def __init__(self, model_name: str = "gpt-4.1-mini"):
        """ë©€í‹°íƒœìŠ¤í¬ Few-Shot ì‹œìŠ¤í…œ"""
        self.llm = ChatOpenAI(model=model_name, temperature=0.1)
        self.embeddings = OllamaEmbeddings(model="bge-m3")
        self.task_prompts = {}
        self.task_selectors = {}

    def setup_task_router(self) -> Dict[str, List[str]]:
        """ì‘ì—… ìœ í˜• ë¼ìš°í„° êµ¬í˜„"""
        return {
            "translation": ["ë²ˆì—­", "translate", "ì˜ì–´ë¡œ", "í•œêµ­ì–´ë¡œ", "ì¤‘êµ­ì–´ë¡œ", "ì¼ë³¸ì–´ë¡œ"],
            "summarization": ["ìš”ì•½", "summary", "ì •ë¦¬", "ê°„ë‹¨íˆ", "í•µì‹¬ë§Œ"],
            "sentiment": ["ê°ì •", "sentiment", "ê¸ì •", "ë¶€ì •", "ê¸°ë¶„", "ëŠë‚Œ"],
            "classification": ["ë¶„ë¥˜", "category", "ì¹´í…Œê³ ë¦¬", "ìœ í˜•", "ì¢…ë¥˜"],
            "qa": ["ì§ˆë¬¸", "ë‹µë³€", "what", "why", "how", "ë¬´ì—‡", "ì™œ", "ì–´ë–»ê²Œ"],
            "generation": ["ì‘ì„±", "ìƒì„±", "ë§Œë“¤ì–´", "ì¨ì¤˜", "create", "generate"]
        }

    def identify_task_type(self, input_text: str) -> str:
        """ì…ë ¥ í…ìŠ¤íŠ¸ë¡œë¶€í„° ì‘ì—… ìœ í˜• ì‹ë³„"""
        task_keywords = self.setup_task_router()

        input_lower = input_text.lower()
        task_scores = {}

        for task_type, keywords in task_keywords.items():
            score = sum(1 for keyword in keywords if keyword in input_lower)
            task_scores[task_type] = score

        # íŒ¨í„´ ê¸°ë°˜ ì¶”ê°€ ì ìˆ˜
        if any(lang in input_lower for lang in ["ì˜ì–´ë¡œ", "english", "korean", "í•œêµ­ì–´ë¡œ"]):
            task_scores["translation"] = task_scores.get("translation", 0) + 2

        if any(word in input_lower for word in ["ìš”ì•½", "ê°„ë‹¨íˆ", "í•µì‹¬"]):
            task_scores["summarization"] = task_scores.get("summarization", 0) + 2

        if any(word in input_lower for word in ["ì–´ë–»ê²Œ", "ë°©ë²•", "ì–´ë–¤"]):
            task_scores["qa"] = task_scores.get("qa", 0) + 1

        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì‘ì—… ìœ í˜• ë°˜í™˜
        if max(task_scores.values()) > 0:
            return max(task_scores, key=task_scores.get)
        else:
            return "qa"  # ê¸°ë³¸ê°’

    def create_task_specific_prompts(self) -> Dict[str, Dict]:
        """ì‘ì—…ë³„ íŠ¹í™” í”„ë¡¬í”„íŠ¸ ìƒì„±"""

        task_examples = {
            "translation": [
                {
                    "input": "Hello, how are you? -> í•œêµ­ì–´ë¡œ",
                    "output": "ì•ˆë…•í•˜ì„¸ìš”, ì–´ë–»ê²Œ ì§€ë‚´ì„¸ìš”?"
                },
                {
                    "input": "ê°ì‚¬í•©ë‹ˆë‹¤ -> English",
                    "output": "Thank you"
                },
                {
                    "input": "ä»Šæ—¥ã¯å¤©æ°—ãŒã„ã„ã§ã™ã­ -> í•œêµ­ì–´ë¡œ",
                    "output": "ì˜¤ëŠ˜ì€ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”"
                }
            ],
            "summarization": [
                {
                    "input": "ì¸ê³µì§€ëŠ¥ì€ ì¸ê°„ì˜ í•™ìŠµëŠ¥ë ¥ê³¼ ì¶”ë¡ ëŠ¥ë ¥ì„ ì»´í“¨í„°ë¡œ êµ¬í˜„í•œ ê¸°ìˆ ì´ë‹¤. ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì„ í¬í•¨í•˜ë©° ììœ¨ì£¼í–‰, ìŒì„±ì¸ì‹, ì´ë¯¸ì§€ ì¸ì‹ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì— í™œìš©ë˜ê³  ìˆë‹¤. ìµœê·¼ì—ëŠ” GPTì™€ ê°™ì€ ëŒ€í™”í˜• AIê°€ ì£¼ëª©ë°›ê³  ìˆë‹¤.",
                    "output": "ì¸ê³µì§€ëŠ¥ì€ ì¸ê°„ì˜ í•™ìŠµê³¼ ì¶”ë¡  ëŠ¥ë ¥ì„ ì»´í“¨í„°ë¡œ êµ¬í˜„í•œ ê¸°ìˆ ë¡œ, ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì„ í¬í•¨í•˜ì—¬ ììœ¨ì£¼í–‰, ìŒì„±ì¸ì‹ ë“±ì— í™œìš©ë˜ë©°, ìµœê·¼ ëŒ€í™”í˜• AIê°€ ì£¼ëª©ë°›ê³  ìˆë‹¤."
                },
                {
                    "input": "ì „ììƒê±°ë˜ ì‹œì¥ì´ ê¸‰ì„±ì¥í•˜ë©´ì„œ ë°°ì†¡ì—…ê³„ì—ë„ í° ë³€í™”ê°€ ì¼ì–´ë‚˜ê³  ìˆë‹¤. ë‹¹ì¼ë°°ì†¡ê³¼ ìƒˆë²½ë°°ì†¡ ì„œë¹„ìŠ¤ê°€ ë³´í¸í™”ë˜ê³ , ë“œë¡ ê³¼ ë¡œë´‡ì„ í™œìš©í•œ ë¬´ì¸ë°°ì†¡ ê¸°ìˆ ë„ ë„ì…ë˜ê³  ìˆë‹¤. ì´ëŸ¬í•œ ë³€í™”ëŠ” ì†Œë¹„ìì˜ í¸ì˜ì„±ì„ ë†’ì´ê³  ìˆì§€ë§Œ, ë°°ì†¡ë¹„ ìƒìŠ¹ê³¼ í™˜ê²½ ë¬¸ì œë¼ëŠ” ìƒˆë¡œìš´ ê³¼ì œë„ ë§Œë“¤ê³  ìˆë‹¤.",
                    "output": "ì „ììƒê±°ë˜ ì„±ì¥ìœ¼ë¡œ ë‹¹ì¼ë°°ì†¡, ìƒˆë²½ë°°ì†¡ì´ ë³´í¸í™”ë˜ê³  ë¬´ì¸ë°°ì†¡ ê¸°ìˆ ì´ ë„ì…ë˜ì–´ ì†Œë¹„ì í¸ì˜ì„±ì€ ë†’ì•„ì¡Œìœ¼ë‚˜, ë°°ì†¡ë¹„ ìƒìŠ¹ê³¼ í™˜ê²½ ë¬¸ì œ ë“±ì˜ ê³¼ì œê°€ ë°œìƒí•˜ê³  ìˆë‹¤."
                }
            ],
            "sentiment": [
                {
                    "input": "ì´ ì œí’ˆ ì •ë§ ë§ˆìŒì— ë“¤ì–´ìš”! í’ˆì§ˆë„ ì¢‹ê³  ë””ìì¸ë„ ì˜ˆë»ìš”.",
                    "output": "ê¸ì • - 'ë§ˆìŒì— ë“¤ì–´ìš”', 'í’ˆì§ˆë„ ì¢‹ê³ ', 'ì˜ˆë»ìš”' ë“±ì˜ ë§Œì¡±ê³¼ í˜¸ê° í‘œí˜„"
                },
                {
                    "input": "ì„œë¹„ìŠ¤ê°€ ë„ˆë¬´ ëŠë¦¬ê³  ì§ì› íƒœë„ë„ ë¶ˆì¹œì ˆí•´ì„œ ì‹¤ë§ìŠ¤ëŸ¬ì›Œìš”.",
                    "output": "ë¶€ì • - 'ë„ˆë¬´ ëŠë¦¬ê³ ', 'ë¶ˆì¹œì ˆ', 'ì‹¤ë§ìŠ¤ëŸ¬ì›Œìš”' ë“±ì˜ ë¶ˆë§Œê³¼ ì‹¤ë§ í‘œí˜„"
                },
                {
                    "input": "ê·¸ëƒ¥ ë³´í†µ ìˆ˜ì¤€ì´ë„¤ìš”. íŠ¹ë³„í•  ê±´ ì—†ì–´ìš”.",
                    "output": "ì¤‘ë¦½ - 'ë³´í†µ ìˆ˜ì¤€', 'íŠ¹ë³„í•  ê±´ ì—†ë‹¤' ë“±ì˜ ê°ê´€ì ì´ê³  ì¤‘ë¦½ì ì¸ í‰ê°€"
                }
            ],
            "classification": [
                {
                    "input": "ì• í”Œ, ë°”ë‚˜ë‚˜, ì˜¤ë Œì§€ë¥¼ ë¶„ë¥˜í•´ì£¼ì„¸ìš”",
                    "output": "ê³¼ì¼ë¥˜ - ì• í”Œ(ì‚¬ê³¼), ë°”ë‚˜ë‚˜, ì˜¤ë Œì§€ ëª¨ë‘ ê³¼ì¼ì— í•´ë‹¹"
                },
                {
                    "input": "ì¶•êµ¬, ë†êµ¬, ìˆ˜ì˜ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë‚˜ëˆ ì£¼ì„¸ìš”",
                    "output": "ìŠ¤í¬ì¸  - ì¶•êµ¬(êµ¬ê¸°ì¢…ëª©), ë†êµ¬(êµ¬ê¸°ì¢…ëª©), ìˆ˜ì˜(ìˆ˜ìƒì¢…ëª©)"
                }
            ],
            "qa": [
                {
                    "input": "íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                    "output": "ë¦¬ìŠ¤íŠ¸ëŠ” ë³€ê²½ ê°€ëŠ¥í•œ(mutable) ìë£Œí˜•ìœ¼ë¡œ ìš”ì†Œë¥¼ ì¶”ê°€/ì‚­ì œ/ìˆ˜ì •í•  ìˆ˜ ìˆê³ , íŠœí”Œì€ ë³€ê²½ ë¶ˆê°€ëŠ¥í•œ(immutable) ìë£Œí˜•ìœ¼ë¡œ í•œ ë²ˆ ìƒì„±ë˜ë©´ ìš”ì†Œë¥¼ ë³€ê²½í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¦¬ìŠ¤íŠ¸ëŠ” []ë¡œ, íŠœí”Œì€ ()ë¡œ í‘œí˜„í•©ë‹ˆë‹¤."
                },
                {
                    "input": "ì¸ê³µì§€ëŠ¥ì´ ì™œ ì¤‘ìš”í•œê°€ìš”?",
                    "output": "ì¸ê³µì§€ëŠ¥ì€ ì¸ê°„ì˜ í•œê³„ë¥¼ ë³´ì™„í•˜ê³  ë³µì¡í•œ ë¬¸ì œë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆì–´ ìƒì‚°ì„± í–¥ìƒ, ìƒˆë¡œìš´ ì„œë¹„ìŠ¤ ì°½ì¶œ, ì‚¬íšŒ ë¬¸ì œ í•´ê²° ë“±ì— ê¸°ì—¬í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì¤‘ìš”í•©ë‹ˆë‹¤."
                }
            ],
            "generation": [
                {
                    "input": "ì—¬í–‰ ê³„íšì— ëŒ€í•œ ì§§ì€ ê¸€ì„ ì¨ì£¼ì„¸ìš”",
                    "output": "ì´ë²ˆ ì—¬ë¦„ ì œì£¼ë„ ì—¬í–‰ì„ ê³„íší•˜ê³  ìˆë‹¤. 3ë°• 4ì¼ ì¼ì •ìœ¼ë¡œ í•œë¼ì‚° ë“±ë°˜ê³¼ í•´ë³€ íœ´ì‹, ê·¸ë¦¬ê³  ë§›ìˆëŠ” í‘ë¼ì§€ì™€ í•´ì‚°ë¬¼ì„ ë§›ë³´ëŠ” ê²ƒì´ ì£¼ìš” ëª©í‘œë‹¤. ë Œí„°ì¹´ë¥¼ ë¹Œë ¤ ì„¬ ê³³ê³³ì„ ììœ ë¡­ê²Œ ëŒì•„ë‹¤ë‹ˆë©° ì•„ë¦„ë‹¤ìš´ í’ê²½ì„ ë§Œë½í•  ì˜ˆì •ì´ë‹¤."
                }
            ]
        }

        task_system_messages = {
            "translation": "ë‹¹ì‹ ì€ ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­í•´ì£¼ì„¸ìš”.",
            "summarization": "ë‹¹ì‹ ì€ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•µì‹¬ ë‚´ìš©ì„ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.",
            "sentiment": "ë‹¹ì‹ ì€ ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ê³  ê·¼ê±°ë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”.",
            "classification": "ë‹¹ì‹ ì€ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í•­ëª©ë“¤ì„ ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.",
            "qa": "ë‹¹ì‹ ì€ ì§ˆì˜ì‘ë‹µ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.",
            "generation": "ë‹¹ì‹ ì€ ì°½ì‘ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì£¼ì œì— ëŒ€í•´ ì°½ì˜ì ì´ê³  ìœ ìš©í•œ ì½˜í…ì¸ ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
        }

        # ê° ì‘ì—…ë³„ í”„ë¡¬í”„íŠ¸ì™€ ì„ íƒê¸° ìƒì„±
        for task_type, examples in task_examples.items():
            # ë²¡í„° ì €ì¥ì†Œ ìƒì„±
            to_vectorize = [f"{ex['input']} {ex['output']}" for ex in examples]
            vector_store = InMemoryVectorStore.from_texts(
                to_vectorize, self.embeddings, metadatas=examples
            )

            # ì˜ˆì‹œ ì„ íƒê¸° ìƒì„±
            selector = SemanticSimilarityExampleSelector(
                vectorstore=vector_store,
                k=2
            )

            # Few-shot í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
            few_shot_prompt = FewShotChatMessagePromptTemplate(
                input_variables=["input"],
                example_selector=selector,
                example_prompt=ChatPromptTemplate.from_messages([
                    ("human", "{input}"),
                    ("assistant", "{output}")
                ])
            )

            # ìµœì¢… í”„ë¡¬í”„íŠ¸
            final_prompt = ChatPromptTemplate.from_messages([
                ("system", task_system_messages[task_type]),
                few_shot_prompt,
                ("human", "{input}")
            ])

            self.task_prompts[task_type] = final_prompt
            self.task_selectors[task_type] = selector

        return task_examples

    def execute_task(self, input_text: str, task_type: str = None) -> Dict[str, Any]:
        """ì‘ì—… ì‹¤í–‰"""

        # ì‘ì—… ìœ í˜•ì´ ì§€ì •ë˜ì§€ ì•Šì€ ê²½ìš° ìë™ ì‹ë³„
        if task_type is None:
            task_type = self.identify_task_type(input_text)

        # ì‘ì—…ë³„ í”„ë¡¬í”„íŠ¸ê°€ ì—†ëŠ” ê²½ìš° ìƒì„±
        if task_type not in self.task_prompts:
            self.create_task_specific_prompts()

        # ì„ íƒëœ ì˜ˆì‹œ í™•ì¸
        selector = self.task_selectors.get(task_type)
        selected_examples = selector.select_examples({"input": input_text}) if selector else []

        # í”„ë¡¬í”„íŠ¸ ì‹¤í–‰
        prompt = self.task_prompts[task_type]
        chain = prompt | self.llm | StrOutputParser()
        result = chain.invoke({"input": input_text})

        return {
            "input": input_text,
            "identified_task": task_type,
            "selected_examples": selected_examples,
            "result": result
        }

    def batch_execute(self, inputs: List[str]) -> List[Dict[str, Any]]:
        """ë‹¤ì¤‘ ì‘ì—… ì¼ê´„ ì‹¤í–‰"""
        return [self.execute_task(input_text) for input_text in inputs]

    def get_task_statistics(self, results: List[Dict[str, Any]]) -> Dict[str, int]:
        """ì‘ì—… í†µê³„ ìƒì„±"""
        task_counts = {}
        for result in results:
            task = result["identified_task"]
            task_counts[task] = task_counts.get(task, 0) + 1
        return task_counts

# ì‹¤ìŠµ 3 í…ŒìŠ¤íŠ¸
multi_task_system = MultiTaskFewShotSystem()

# ì˜ˆì‹œ í”„ë¡¬í”„íŠ¸ ìƒì„±
multi_task_system.create_task_specific_prompts()

test_inputs = [
    "Hello, nice to meet you! -> í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”",
    "ì´ ê¸´ ë¬¸ì¥ì„ ê°„ë‹¨íˆ ìš”ì•½í•´ì£¼ì„¸ìš”: ê¸°í›„ë³€í™”ëŠ” ì§€êµ¬ì˜¨ë‚œí™”ë¡œ ì¸í•œ ê¸°ì˜¨ ìƒìŠ¹, í•´ìˆ˜ë©´ ìƒìŠ¹, ê·¹ì§€ë°© ë¹™í•˜ ê°ì†Œ ë“± ë‹¤ì–‘í•œ í™˜ê²½ ë³€í™”ë¥¼ ì˜ë¯¸í•œë‹¤. ì´ë¡œ ì¸í•´ ìƒíƒœê³„ íŒŒê´´, ë†ì—… ìƒì‚°ì„± ê°ì†Œ, ìì—°ì¬í•´ ì¦ê°€ ë“±ì˜ ë¬¸ì œê°€ ë°œìƒí•˜ê³  ìˆìœ¼ë©°, êµ­ì œì‚¬íšŒëŠ” ì˜¨ì‹¤ê°€ìŠ¤ ê°ì¶•ì„ ìœ„í•œ ë‹¤ì–‘í•œ ë…¸ë ¥ì„ ê¸°ìš¸ì´ê³  ìˆë‹¤.",
    "ì´ ë¦¬ë·°ì˜ ê°ì •ì„ ë¶„ì„í•´ì£¼ì„¸ìš”: ì œí’ˆì´ ê¸°ëŒ€í–ˆë˜ ê²ƒë³´ë‹¤ í›¨ì”¬ ì¢‹ë„¤ìš”! ë””ìì¸ë„ ì˜ˆì˜ê³  ê¸°ëŠ¥ë„ ë§Œì¡±ìŠ¤ëŸ¬ì›Œìš”",
    "ì‚¬ê³¼, ë‹¹ê·¼, ë¸Œë¡œì½œë¦¬, ë°”ë‚˜ë‚˜ë¥¼ ì±„ì†Œì™€ ê³¼ì¼ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”",
    "ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´ì ì´ ë¬´ì—‡ì¸ê°€ìš”?",
    "ë´„ì— ëŒ€í•œ ì§§ì€ ì‹œë¥¼ ì¨ì£¼ì„¸ìš”",
    "ê°ì‚¬í•©ë‹ˆë‹¤ -> Englishë¡œ ë²ˆì—­",
    "ê¸ì •ì ì¸ ë§ˆìŒê°€ì§ì´ ì¤‘ìš”í•œ ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”",
    "ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì€? 'ì„œë¹„ìŠ¤ê°€ ë³„ë¡œì˜€ì–´ìš”. ë‹¤ìŒì—” ë‹¤ë¥¸ ê³³ì„ ì´ìš©í•  ê²ƒ ê°™ì•„ìš”.'",
    "ì—¬í–‰ ë¸”ë¡œê·¸ í¬ìŠ¤íŒ… ì œëª© 5ê°œë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”"
]

print("=== ë©€í‹°íƒœìŠ¤í¬ Few-Shot ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ===")
batch_results = multi_task_system.batch_execute(test_inputs)

for i, result in enumerate(batch_results, 1):
    print(f"\n{i}. ì…ë ¥: {result['input']}")
    print(f"   ì‹ë³„ëœ ì‘ì—…: {result['identified_task']}")
    print("   ì„ íƒëœ ì˜ˆì‹œ:")
    for example in result['selected_examples']:
        print(f"     ì…ë ¥: {example['input'][:50]}...")
    print(f"   ê²°ê³¼: {result['result']}")
    print("-" * 100)

# ì‘ì—… í†µê³„ ì¶œë ¥
task_stats = multi_task_system.get_task_statistics(batch_results)
print(f"\n=== ì‘ì—… ìœ í˜•ë³„ í†µê³„ ===")
for task_type, count in task_stats.items():
    print(f"{task_type}: {count}ê°œ")

# ì‘ì—… ìœ í˜•ë³„ ì •í™•ë„ í‰ê°€ (ìˆ˜ë™ ê²€ì¦ í•„ìš”)
print(f"\n=== ì‘ì—… ì‹ë³„ ì •í™•ë„ ê²€ì¦ ===")
expected_tasks = [
    "translation", "summarization", "sentiment", "classification",
    "qa", "generation", "translation", "qa", "sentiment", "generation"
]

correct_identifications = 0
for i, (result, expected) in enumerate(zip(batch_results, expected_tasks)):
    identified = result['identified_task']
    is_correct = identified == expected
    correct_identifications += is_correct
    print(f"{i+1}. ì˜ˆìƒ: {expected}, ì‹ë³„: {identified} {'âœ“' if is_correct else 'âœ—'}")

accuracy = correct_identifications / len(expected_tasks)
print(f"\nì‘ì—… ì‹ë³„ ì •í™•ë„: {accuracy:.2%}")
```

## ğŸ” ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [LangChain Few-Shot Prompting](https://python.langchain.com/docs/modules/model_io/prompts/few_shot_examples/)
- [OpenAI Few-Shot Learning](https://platform.openai.com/docs/guides/gpt-best-practices/strategy-provide-examples)
- [LangChain Example Selectors](https://python.langchain.com/docs/modules/model_io/prompts/example_selectors/)

### í•™ìˆ  ìë£Œ
- Brown, T., et al. (2020). "Language Models are Few-Shot Learners"
- Min, S., et al. (2022). "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?"
- Dong, Q., et al. (2023). "A Survey for In-context Learning"

### ì‹¤ë¬´ ê°€ì´ë“œ
- [Few-Shot Prompting Best Practices](https://example.com/few-shot-guide)
- [Dynamic Example Selection Strategies](https://example.com/dynamic-examples)
- [Prompt Engineering for Production](https://example.com/production-prompting)

### ë„êµ¬ ë° ë¦¬ì†ŒìŠ¤
- [LangChain Example Selector Documentation](https://example.com/example-selectors)
- [Vector Store Integration Guide](https://example.com/vector-stores)
- [Performance Optimization Techniques](https://example.com/optimization)

---

**ë‹¤ìŒ í•™ìŠµ**: W3_003_Prompt_Engineering_CoT.md - Chain of Thought í”„ë¡¬í”„íŒ…ê³¼ ì¶”ë¡  ëŠ¥ë ¥ í–¥ìƒ ê¸°ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.