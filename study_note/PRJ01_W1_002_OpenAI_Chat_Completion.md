# OpenAI Chat Completion API í™œìš© ê°€ì´ë“œ

## ğŸ“š í•™ìŠµ ëª©í‘œ
LLMì˜ ê¸°ë³¸ ì›ë¦¬ë¥¼ ì´í•´í•˜ê³  OpenAI Chat Completion APIë¥¼ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ AI ì‘ìš© í”„ë¡œê·¸ë¨ì„ ê°œë°œí•  ìˆ˜ ìˆë‹¤.

## ğŸ“– ì£¼ìš” ë‚´ìš©
1. LLM(ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸) ê¸°ë³¸ ê°œë…
2. OpenAI API í•µì‹¬ êµ¬ì„± ìš”ì†Œ
3. Chat Completion API í™œìš©ë²•
4. ë©€í‹°ëª¨ë‹¬(í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤) ì²˜ë¦¬
5. ë§¤ê°œë³€ìˆ˜ ìµœì í™” ì „ëµ

---

# 1. LLM ê¸°ë³¸ ê°œë…

## 1.1 LLM(Large Language Model)ì˜ ìƒì„± ì›ë¦¬

### í•µì‹¬ ê°œë…
**LLMì€ ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜ìš”?**
- **íŠ¸ëœìŠ¤í¬ë¨¸ êµ¬ì¡°**: ëŒ€í™”í˜• AIì˜ í•µì‹¬ ì•„í‚¤í…ì²˜
- **í† í° ì˜ˆì¸¡**: ë‹¤ìŒì— ì˜¬ ê°€ì¥ ì ì ˆí•œ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡
- **í•™ìŠµ ë°©ì‹**: ì¸í„°ë„·ì˜ ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì‚¬ì „ í›ˆë ¨

### í•µì‹¬ í”„ë¡œì„¸ìŠ¤
1. **í† í°í™”**: í…ìŠ¤íŠ¸ë¥¼ ì‘ì€ ë‹¨ìœ„(í† í°)ë¡œ ë¶„í• 
2. **í™•ë¥  ê³„ì‚°**: ê° í† í°ì´ ë‹¤ìŒì— ì˜¬ í™•ë¥  ê³„ì‚°
3. **í† í° ìƒì„±**: í™•ë¥  ë¶„í¬ì— ë”°ë¼ í† í° ì„ íƒ
4. **ë°˜ë³µ**: ì¢…ë£Œ ì¡°ê±´ê¹Œì§€ ê³¼ì • ë°˜ë³µ

### íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜
- **ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°**: ì…ë ¥ê³¼ ì¶œë ¥ì„ ë™ì‹œì— ì²˜ë¦¬
- **ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜**: ì…ë ¥ì˜ ëª¨ë“  ë¶€ë¶„ì„ ë™ì‹œì— ê³ ë ¤í•˜ì—¬ ì¤‘ìš”í•œ ì •ë³´ì— ì§‘ì¤‘

![íŠ¸ëœìŠ¤í¬ë¨¸ êµ¬ì¡°](https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Transformer%2C_full_architecture.png/440px-Transformer%2C_full_architecture.png)

---

# 2. OpenAI API í•µì‹¬ ê°œë…

## 2.1 ì£¼ìš” êµ¬ì„± ìš”ì†Œ

### ë©”ì‹œì§€ í˜•ì‹
```python
messages = [
    {"role": "system", "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
    {"role": "user", "content": "íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”."},
    {"role": "assistant", "content": "sort() ë©”ì„œë“œë‚˜ sorted() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."}
]
```

### í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ì£¼ìš” ëª¨ë¸ (2025ë…„ ê¸°ì¤€)
- **gpt-4.1**: ìµœê³  ì„±ëŠ¥, ë³µì¡í•œ ì‘ì—…ìš©
- **gpt-4.1-mini**: ë¹ ë¥¸ ì†ë„, ë¹„ìš© íš¨ìœ¨ì 
- **gpt-4.1-nano**: ì´ˆê³ ì†, ìµœì € ë¹„ìš©
- **o3, o4-mini**: ë³µì¡í•œ ì¶”ë¡  ì‘ì—…ìš©
- **gpt-4o**: ë©€í‹°ëª¨ë‹¬ (í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤)

### API ì‘ë‹µ êµ¬ì¡°
```json
{
  "id": "chatcmpl-...",
  "object": "chat.completion",
  "model": "gpt-4.1-mini",
  "choices": [
    {
      "message": {
        "role": "assistant",
        "content": "ìƒì„±ëœ í…ìŠ¤íŠ¸"
      }
    }
  ],
  "usage": {
    "prompt_tokens": 10,
    "completion_tokens": 50,
    "total_tokens": 60
  }
}
```

## 2.2 í™˜ê²½ ì„¤ì •

### í”„ë¡œì íŠ¸ ì„¤ì •
```bash
# uv ì‚¬ìš© (ê¶Œì¥)
uv init my_ai_project
uv venv --python=3.12
uv add langchain langchain_openai python-dotenv ipykernel

# pip ì‚¬ìš©
pip install langchain langchain_openai python-dotenv ipykernel
```

### API í‚¤ ì„¤ì •
```python
# .env íŒŒì¼ ìƒì„±
OPENAI_API_KEY=your_api_key_here

# Pythonì—ì„œ ë¡œë“œ
from dotenv import load_dotenv
import os

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
```

---

# 3. Chat Completion API í™œìš©ë²•

## 3.1 ê¸°ë³¸ í…ìŠ¤íŠ¸ ìƒì„±

### í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ë° ìš”ì²­
```python
from openai import OpenAI

# í´ë¼ì´ì–¸íŠ¸ ìƒì„±
client = OpenAI()  # API í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ ë¡œë“œ

# Chat Completion ìš”ì²­
response = client.chat.completions.create(
    model="gpt-4.1-mini",
    messages=[
        {"role": "system", "content": "You are a helpful programming assistant."},
        {"role": "user", "content": "íŒŒì´ì¬ì—ì„œ íŒŒì¼ì„ ì½ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”."},
    ],
    temperature=0.7,
    max_tokens=1000,
)

# ì‘ë‹µ ì²˜ë¦¬
print("ìƒì„±ëœ í…ìŠ¤íŠ¸:")
print(response.choices[0].message.content)
print(f"í† í° ì‚¬ìš©ëŸ‰: {response.usage.total_tokens}")
```

### ì‘ë‹µ êµ¬ì¡° ì´í•´
```python
# ì‘ë‹µì˜ ì£¼ìš” ìš”ì†Œ
response_id = response.id                           # ì‘ë‹µ ê³ ìœ  ID
model_used = response.model                         # ì‚¬ìš©ëœ ëª¨ë¸
generated_text = response.choices[0].message.content # ìƒì„±ëœ í…ìŠ¤íŠ¸
token_usage = response.usage                        # í† í° ì‚¬ìš©ëŸ‰ ì •ë³´
```

## 3.2 êµ¬ì¡°í™”ëœ JSON ì¶œë ¥

### JSON Schemaë¥¼ í™œìš©í•œ êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ
```python
from typing import Dict, Any
import json

def extract_product_info(product_text: str) -> Dict[str, Any]:
    """
    ìƒí’ˆ ì •ë³´ë¥¼ êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜

    Args:
        product_text: ìƒí’ˆ ì •ë³´ê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸

    Returns:
        êµ¬ì¡°í™”ëœ ìƒí’ˆ ì •ë³´ ë”•ì…”ë„ˆë¦¬
    """
    client = OpenAI()

    response = client.chat.completions.create(
        model="gpt-4.1",
        messages=[
            {
                "role": "system",
                "content": "ìƒí’ˆ ì •ë³´ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì¶”ì¶œí•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤."
            },
            {
                "role": "user",
                "content": product_text
            }
        ],
        response_format={
            "type": "json_schema",
            "json_schema": {
                "name": "product_schema",
                "description": "ìƒí’ˆì˜ ìƒì„¸ ì •ë³´ë¥¼ êµ¬ì¡°í™”í•˜ê¸° ìœ„í•œ ìŠ¤í‚¤ë§ˆ",
                "schema": {
                    "type": "object",
                    "properties": {
                        "brand": {
                            "type": "string",
                            "description": "ì œì¡°ì‚¬ ë˜ëŠ” ë¸Œëœë“œ ì´ë¦„"
                        },
                        "model": {
                            "type": "string",
                            "description": "ì œí’ˆì˜ ëª¨ë¸ëª… ë˜ëŠ” ì‹œë¦¬ì¦ˆëª…"
                        },
                        "capacity": {
                            "type": "string",
                            "description": "ì €ì¥ ìš©ëŸ‰ ë˜ëŠ” ê·œê²©"
                        },
                        "color": {
                            "type": "string",
                            "description": "ì œí’ˆì˜ ìƒ‰ìƒ"
                        },
                        "price": {
                            "type": "number",
                            "description": "ì œí’ˆì˜ ê°€ê²© (ë‹¨ìœ„: ì›)",
                            "minimum": 0
                        },
                        "category": {
                            "type": "string",
                            "description": "ì œí’ˆì˜ ì¹´í…Œê³ ë¦¬"
                        }
                    },
                    "required": ["brand", "model", "price"],
                    "additionalProperties": False
                }
            }
        }
    )

    return json.loads(response.choices[0].message.content)

# ì‚¬ìš© ì˜ˆì‹œ
product_text = "ì• í”Œ ì•„ì´í° 15 í”„ë¡œ 256GB (ë¸”ë™) - 1,500,000ì›"
product_info = extract_product_info(product_text)
print(product_info)
# ì¶œë ¥: {'brand': 'ì• í”Œ', 'model': 'ì•„ì´í° 15 í”„ë¡œ', 'capacity': '256GB', 'color': 'ë¸”ë™', 'price': 1500000, 'category': 'ìŠ¤ë§ˆíŠ¸í°'}
```

---

# 4. ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬

## 4.1 ì´ë¯¸ì§€ ë¶„ì„

### URLì„ í†µí•œ ì´ë¯¸ì§€ ë¶„ì„
```python
from typing import Optional
import httpx
from PIL import Image
from io import BytesIO

async def analyze_image_from_url(image_url: str, question: str = "ì´ë¯¸ì§€ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.") -> str:
    """
    URLì˜ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” í•¨ìˆ˜

    Args:
        image_url: ë¶„ì„í•  ì´ë¯¸ì§€ URL
        question: ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸

    Returns:
        ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼
    """
    client = OpenAI()

    response = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": f"{question} í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."},
                    {"type": "image_url", "image_url": {"url": image_url}}
                ]
            }
        ]
    )

    return response.choices[0].message.content

# ì‚¬ìš© ì˜ˆì‹œ
image_url = "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
result = await analyze_image_from_url(image_url, "ì´ ì´ë¯¸ì§€ì—ì„œ ë³¼ ìˆ˜ ìˆëŠ” ìì—° ìš”ì†Œë“¤ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.")
print(result)
```

### Base64 ì¸ì½”ë”©ì„ í†µí•œ ë¡œì»¬ ì´ë¯¸ì§€ ë¶„ì„
```python
import base64
from pathlib import Path

def encode_image(image_path: str) -> str:
    """ì´ë¯¸ì§€ íŒŒì¼ì„ Base64ë¡œ ì¸ì½”ë”©"""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")

def analyze_local_image(image_path: str, analysis_prompt: str) -> str:
    """
    ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ì„ ë¶„ì„í•˜ëŠ” í•¨ìˆ˜

    Args:
        image_path: ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        analysis_prompt: ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸

    Returns:
        ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼
    """
    client = OpenAI()

    # ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”©
    base64_image = encode_image(image_path)

    response = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": analysis_prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_image}"
                        }
                    }
                ]
            }
        ]
    )

    return response.choices[0].message.content

# ì‚¬ìš© ì˜ˆì‹œ
chart_analysis = analyze_local_image(
    "data/sales_chart.jpg",
    "ì´ ì°¨íŠ¸ì—ì„œ ë³´ì´ëŠ” ì£¼ìš” íŠ¸ë Œë“œì™€ íŒ¨í„´ì„ ë¶„ì„í•´ì£¼ì„¸ìš”."
)
print(chart_analysis)
```

## 4.2 ì˜¤ë””ì˜¤ ìƒì„± (Text-to-Speech)

### ìŒì„± ìƒì„± ë° ì €ì¥
```python
import base64
from pathlib import Path

def generate_speech(text: str, output_path: str = "output.wav", voice: str = "alloy") -> None:
    """
    í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜

    Args:
        text: ìŒì„±ìœ¼ë¡œ ë³€í™˜í•  í…ìŠ¤íŠ¸
        output_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
        voice: ìŒì„± ì¢…ë¥˜ ("alloy", "echo", "fable", "onyx", "nova", "shimmer")
    """
    client = OpenAI()

    completion = client.chat.completions.create(
        model="gpt-4o-mini-audio-preview",
        modalities=["text", "audio"],
        audio={"voice": voice, "format": "wav"},
        messages=[
            {
                "role": "user",
                "content": text
            }
        ]
    )

    # ì˜¤ë””ì˜¤ ë°ì´í„° ë””ì½”ë”© ë° ì €ì¥
    wav_bytes = base64.b64decode(completion.choices[0].message.audio.data)
    with open(output_path, "wb") as f:
        f.write(wav_bytes)

    print(f"ìŒì„± íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")

    # í…ìŠ¤íŠ¸ ì‘ë‹µë„ ë°˜í™˜
    return completion.choices[0].message.content

# ì‚¬ìš© ì˜ˆì‹œ
response_text = generate_speech(
    "ì•ˆë…•í•˜ì„¸ìš”. OpenAIì˜ ìŒì„± ìƒì„± ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
    "greeting.wav",
    "alloy"
)
print(f"í…ìŠ¤íŠ¸ ì‘ë‹µ: {response_text}")
```

---

# 5. ë§¤ê°œë³€ìˆ˜ ìµœì í™”

## 5.1 í•µì‹¬ ë§¤ê°œë³€ìˆ˜ ê°€ì´ë“œ

| ë§¤ê°œë³€ìˆ˜ | ë²”ìœ„ | ìš©ë„ | ì¶”ì²œê°’ |
|---------|------|------|--------|
| `temperature` | 0~2 | ì°½ì˜ì„± ì¡°ì ˆ | 0.3 (ì •í™•ì„±), 0.7 (ê· í˜•), 1.2 (ì°½ì˜ì„±) |
| `top_p` | 0~1 | ì‘ë‹µ ë‹¤ì–‘ì„± | 0.9 (ê¸°ë³¸), 0.3 (ì§‘ì¤‘ì ) |
| `max_tokens` | 1~8192+ | ìµœëŒ€ ê¸¸ì´ | ì‘ì—…ì— ë”°ë¼ ì¡°ì ˆ |
| `frequency_penalty` | -2~2 | ë°˜ë³µ ì–µì œ | 0.3~0.6 |
| `presence_penalty` | -2~2 | ìƒˆ ì£¼ì œ ë„ì… | 0.3~0.6 |

## 5.2 ì‹œë‚˜ë¦¬ì˜¤ë³„ ì„¤ì •

### ì •í™•í•œ ì •ë³´ ì œê³µ
```python
def get_factual_response(question: str) -> str:
    """ì •í™•í•œ ì •ë³´ ì œê³µì„ ìœ„í•œ ì„¤ì •"""
    client = OpenAI()

    response = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[{"role": "user", "content": question}],
        temperature=0.2,    # ë‚®ì€ ì°½ì˜ì„±
        top_p=0.3,         # ì§‘ì¤‘ì  ì‘ë‹µ
        max_tokens=500
    )

    return response.choices[0].message.content

# ì‚¬ìš© ì˜ˆì‹œ
factual_info = get_factual_response("íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬ ë©”ì„œë“œë“¤ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.")
print(factual_info)
```

### ì°½ì˜ì  ê¸€ì“°ê¸°
```python
def generate_creative_content(prompt: str) -> str:
    """ì°½ì˜ì  ì½˜í…ì¸  ìƒì„±ì„ ìœ„í•œ ì„¤ì •"""
    client = OpenAI()

    response = client.chat.completions.create(
        model="gpt-4.1",
        messages=[{"role": "user", "content": prompt}],
        temperature=1.1,           # ë†’ì€ ì°½ì˜ì„±
        top_p=0.9,                # ë‹¤ì–‘í•œ í‘œí˜„
        max_tokens=1000,
        frequency_penalty=0.5     # ë°˜ë³µ ë°©ì§€
    )

    return response.choices[0].message.content

# ì‚¬ìš© ì˜ˆì‹œ
creative_story = generate_creative_content("ìš°ì£¼ ì •ê±°ì¥ì—ì„œì˜ í•˜ë£¨ë¥¼ ì†Œì„¤ë¡œ ì¨ì£¼ì„¸ìš”.")
print(creative_story)
```

### ì½”ë“œ ìƒì„±
```python
def generate_code(description: str) -> str:
    """ì½”ë“œ ìƒì„±ì„ ìœ„í•œ ìµœì í™”ëœ ì„¤ì •"""
    client = OpenAI()

    response = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[{"role": "user", "content": description}],
        temperature=0.4,    # ì•½ê°„ì˜ ì°½ì˜ì„±
        max_tokens=800
    )

    return response.choices[0].message.content

# ì‚¬ìš© ì˜ˆì‹œ
code_example = generate_code("ì›¹ ìŠ¤í¬ë˜í•‘ì„ ìœ„í•œ Python í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.")
print(code_example)
```

---

# 6. ì‹¤ìŠµ ë¬¸ì œ

## ë¬¸ì œ 1: ì–¸ì–´ ë²ˆì—­ê¸° ë§Œë“¤ê¸°

### ì‹¤ìŠµí•´ë³´ê¸°
```python
from typing import Optional
from openai import OpenAI

def translator(text: str, target_language: str) -> Optional[str]:
    """
    í…ìŠ¤íŠ¸ë¥¼ ì§€ì •ëœ ì–¸ì–´ë¡œ ë²ˆì—­í•˜ëŠ” í•¨ìˆ˜

    Args:
        text: ë²ˆì—­í•  í…ìŠ¤íŠ¸
        target_language: ëª©í‘œ ì–¸ì–´

    Returns:
        ë²ˆì—­ëœ í…ìŠ¤íŠ¸ ë˜ëŠ” None (ì˜¤ë¥˜ ì‹œ)
    """
    # ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”
    pass

# í…ŒìŠ¤íŠ¸ ì½”ë“œ
result = translator("ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”!", "ì˜ì–´")
print(result)  # ì˜ˆìƒ ì¶œë ¥: Hello, the weather is nice today!
```

### í•´ë‹µ
```python
from typing import Optional
from openai import OpenAI

def translator(text: str, target_language: str) -> Optional[str]:
    """
    í…ìŠ¤íŠ¸ë¥¼ ì§€ì •ëœ ì–¸ì–´ë¡œ ë²ˆì—­í•˜ëŠ” í•¨ìˆ˜

    Args:
        text: ë²ˆì—­í•  í…ìŠ¤íŠ¸
        target_language: ëª©í‘œ ì–¸ì–´

    Returns:
        ë²ˆì—­ëœ í…ìŠ¤íŠ¸ ë˜ëŠ” None (ì˜¤ë¥˜ ì‹œ)
    """
    try:
        client = OpenAI()

        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {
                    "role": "system",
                    "content": f"You are a professional translator. Translate the given text to {target_language}. Only return the translated text, no explanations."
                },
                {
                    "role": "user",
                    "content": text
                }
            ],
            temperature=0.3,
            max_tokens=500
        )

        return response.choices[0].message.content.strip()

    except Exception as e:
        print(f"ë²ˆì—­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# í…ŒìŠ¤íŠ¸ ì½”ë“œ
result = translator("ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”!", "ì˜ì–´")
print(result)  # ì¶œë ¥: Hello, the weather is nice today!
```

## ë¬¸ì œ 2: ê°ì • ë¶„ì„ê¸°

### ì‹¤ìŠµí•´ë³´ê¸°
```python
from typing import Dict, Optional
import json

def analyze_sentiment(text: str) -> Optional[Dict[str, any]]:
    """
    í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ì—¬ JSON í˜•íƒœë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜

    Args:
        text: ë¶„ì„í•  í…ìŠ¤íŠ¸

    Returns:
        {"sentiment": "positive/negative/neutral", "confidence": float} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    # ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”
    # íŒíŠ¸: response_formatê³¼ json_schemaë¥¼ í™œìš©í•˜ì„¸ìš”
    pass

# í…ŒìŠ¤íŠ¸ ì½”ë“œ
result = analyze_sentiment("ì˜¤ëŠ˜ ì‹œí—˜ì„ ì˜ ë´¤ì–´ìš”! ì •ë§ ê¸°ì©ë‹ˆë‹¤.")
print(result)  # ì˜ˆìƒ ì¶œë ¥: {'sentiment': 'positive', 'confidence': 0.95}
```

### í•´ë‹µ
```python
from typing import Dict, Optional
import json

def analyze_sentiment(text: str) -> Optional[Dict[str, any]]:
    """
    í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ì—¬ JSON í˜•íƒœë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜

    Args:
        text: ë¶„ì„í•  í…ìŠ¤íŠ¸

    Returns:
        {"sentiment": "positive/negative/neutral", "confidence": float} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    try:
        client = OpenAI()

        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {
                    "role": "system",
                    "content": "You are a sentiment analysis expert. Analyze the sentiment of the given text and provide confidence score."
                },
                {
                    "role": "user",
                    "content": text
                }
            ],
            response_format={
                "type": "json_schema",
                "json_schema": {
                    "name": "sentiment_analysis",
                    "description": "ê°ì • ë¶„ì„ ê²°ê³¼",
                    "schema": {
                        "type": "object",
                        "properties": {
                            "sentiment": {
                                "type": "string",
                                "enum": ["positive", "negative", "neutral"],
                                "description": "ê°ì • ë¶„ë¥˜"
                            },
                            "confidence": {
                                "type": "number",
                                "minimum": 0,
                                "maximum": 1,
                                "description": "ì‹ ë¢°ë„ (0~1)"
                            }
                        },
                        "required": ["sentiment", "confidence"],
                        "additionalProperties": False
                    }
                }
            }
        )

        return json.loads(response.choices[0].message.content)

    except Exception as e:
        print(f"ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# í…ŒìŠ¤íŠ¸ ì½”ë“œ
result = analyze_sentiment("ì˜¤ëŠ˜ ì‹œí—˜ì„ ì˜ ë´¤ì–´ìš”! ì •ë§ ê¸°ì©ë‹ˆë‹¤.")
print(result)  # ì¶œë ¥: {'sentiment': 'positive', 'confidence': 0.95}
```

---

# ğŸ¯ í•µì‹¬ ìš”ì•½

## Chat Completion API í™œìš© ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] í™˜ê²½ë³€ìˆ˜ë¥¼ í†µí•œ ì•ˆì „í•œ API í‚¤ ê´€ë¦¬
- [ ] ì ì ˆí•œ ëª¨ë¸ ì„ íƒ (ì‘ì—… ë³µì¡ë„ì— ë”°ë¼)
- [ ] ë©”ì‹œì§€ ì—­í• (system, user, assistant) êµ¬ë¶„
- [ ] ë§¤ê°œë³€ìˆ˜ ìµœì í™” (temperature, max_tokens ë“±)
- [ ] êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ìœ„í•œ JSON Schema í™œìš©
- [ ] ë©€í‹°ëª¨ë‹¬ ê¸°ëŠ¥ (ì´ë¯¸ì§€, ì˜¤ë””ì˜¤) í™œìš©
- [ ] ì˜ˆì™¸ ì²˜ë¦¬ ë° ì˜¤ë¥˜ ê´€ë¦¬

## ì‹¤ë¬´ ì ìš© íŒ
1. **í† í° ê´€ë¦¬**: ë¹„ìš© ìµœì í™”ë¥¼ ìœ„í•œ í† í° ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
2. **ì‘ë‹µ í’ˆì§ˆ**: ì ì ˆí•œ temperature ì„¤ì •ìœ¼ë¡œ ì¼ê´€ì„± í™•ë³´
3. **êµ¬ì¡°í™”**: JSON Schemaë¥¼ í™œìš©í•œ ì•ˆì •ì ì¸ ë°ì´í„° ì¶”ì¶œ
4. **ë³´ì•ˆ**: API í‚¤ëŠ” ì ˆëŒ€ ì½”ë“œì— ì§ì ‘ í¬í•¨í•˜ì§€ ì•Šê¸°
5. **ì„±ëŠ¥**: ë°°ì¹˜ ì²˜ë¦¬ì™€ ë¹„ë™ê¸° ì²˜ë¦¬ í™œìš©

---

# ğŸ“š ì°¸ê³  ìë£Œ

## ê³µì‹ ë¬¸ì„œ
- [OpenAI API ê³µì‹ ë¬¸ì„œ](https://platform.openai.com/docs)
- [Chat Completions API ê°€ì´ë“œ](https://platform.openai.com/docs/guides/text-generation)
- [OpenAI í† í° ê³„ì‚°ê¸°](https://platform.openai.com/tokenizer)

## ì¶”ê°€ í•™ìŠµ ìë£Œ
- [í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê°€ì´ë“œ](https://platform.openai.com/docs/guides/prompt-engineering)
- [OpenAI Python ë¼ì´ë¸ŒëŸ¬ë¦¬](https://github.com/openai/openai-python)
- [OpenAI ëª¨ë¸ ë¹„êµ](https://platform.openai.com/docs/models)

## ë„êµ¬ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬
- **HTTP í´ë¼ì´ì–¸íŠ¸**: `httpx` (ë¹„ë™ê¸°), `requests` (ë™ê¸°)
- **ì´ë¯¸ì§€ ì²˜ë¦¬**: `Pillow` (PIL)
- **í™˜ê²½ ë³€ìˆ˜**: `python-dotenv`
- **ë¹„ë™ê¸° ì²˜ë¦¬**: `asyncio`

---

**ğŸ“ ë‹¤ìŒ í•™ìŠµ:** W1_003_Langchain_Components.md