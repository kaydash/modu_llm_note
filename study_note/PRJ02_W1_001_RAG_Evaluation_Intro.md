# PRJ02_W1_001 RAG ì„±ëŠ¥í‰ê°€ ê°œìš” ë§¤ë‰´ì–¼

## ğŸ“‹ ê°œìš”

ì´ ë…¸íŠ¸ë¶ì€ RAGAS(Retrieval Augmented Generation Assessment)ë¥¼ ì‚¬ìš©í•œ RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€ì˜ ì „ì²´ì ì¸ í”„ë¡œì„¸ìŠ¤ë¥¼ ë‹¤ë£¨ëŠ” ì…ë¬¸ ê³¼ì •ì…ë‹ˆë‹¤. RAG ì‹œìŠ¤í…œì˜ ê²€ìƒ‰ê³¼ ìƒì„± ë‹¨ê³„ë¥¼ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ë°©ë²•ë¡ ì„ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ¯ í•™ìŠµ ëª©í‘œ
- RAGASë¥¼ ì‚¬ìš©í•œ RAG ì„±ëŠ¥ í‰ê°€ í”„ë¡œì„¸ìŠ¤ ì´í•´
- RAG ì‹œìŠ¤í…œì˜ ê²€ìƒ‰ ë° ìƒì„± ë‹¨ê³„ë³„ í‰ê°€ ë°©ë²• í•™ìŠµ
- í‰ê°€ ë°ì´í„°ì…‹ êµ¬ì¶• ë° í™œìš© ë°©ë²• ìŠµë“

## ğŸ› ï¸ í™˜ê²½ ì„¤ì •

### 1. í•„ìˆ˜ íŒ¨í‚¤ì§€
```python
# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv

# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os, glob, json
import pandas as pd
import numpy as np
from pprint import pprint

# LangChain ê´€ë ¨
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# RAGAS ê´€ë ¨
from ragas.testset.persona import Persona
from ragas.testset import TestsetGenerator
from ragas.llms import LangchainLLMWrapper
from ragas.embeddings import LangchainEmbeddingsWrapper
from ragas import evaluate, EvaluationDataset
from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness

# Langfuse íŠ¸ë ˆì´ì‹±
from langfuse.langchain import CallbackHandler
```

### 2. API í‚¤ ì„¤ì •
```bash
# .env íŒŒì¼ì— ë‹¤ìŒ í‚¤ë“¤ì„ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤:
OPENAI_API_KEY=your_openai_api_key
LANGFUSE_SECRET_KEY=your_langfuse_secret_key
LANGFUSE_PUBLIC_KEY=your_langfuse_public_key
LANGFUSE_HOST=your_langfuse_host
```

## ğŸ—ï¸ RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€ ê°œë…

### í‰ê°€ ì²´ê³„
RAG ì‹œìŠ¤í…œ í‰ê°€ëŠ” í¬ê²Œ ë‘ ë‹¨ê³„ë¡œ êµ¬ë¶„ë©ë‹ˆë‹¤:

#### 1. ê²€ìƒ‰(Retrieval) ë‹¨ê³„ í‰ê°€
- **ê´€ë ¨ì„±(Relevance)**: ê²€ìƒ‰ëœ ë¬¸ì„œì™€ ì¿¼ë¦¬ ê°„ì˜ ì—°ê´€ì„±
- **ì •í™•ì„±(Accuracy)**: ì ì ˆí•œ ë¬¸ì„œë¥¼ ì‹ë³„í•˜ëŠ” ëŠ¥ë ¥

#### 2. ìƒì„±(Generation) ë‹¨ê³„ í‰ê°€
- **ì—°ê´€ì„±(Relevance)**: ì‘ë‹µê³¼ ì¿¼ë¦¬ì˜ ê´€ë ¨ì„±
- **ì¶©ì‹¤ë„(Faithfulness)**: ì‘ë‹µê³¼ ê´€ë ¨ ë¬¸ì„œ ê°„ì˜ ì¼ì¹˜ë„
- **ì •í™•ì„±(Correctness)**: ì‘ë‹µê³¼ ì •ë‹µ ê°„ì˜ ì •í™•ë„

### í•µì‹¬ ì„±ëŠ¥ ì§€í‘œ
- **Latency**: ì‘ë‹µ ì†ë„
- **Diversity**: ê²€ìƒ‰ ë‹¤ì–‘ì„±
- **Noise Robustness**: ì¡ìŒ ë‚´êµ¬ì„±
- **Safety**: ì•ˆì „ì„± í‰ê°€ (ì˜¤ì •ë³´ ì‹ë³„, ìœ í•´ì„± ë“±)

## ğŸ“Š ë°ì´í„° ì¤€ë¹„ ë° ì²˜ë¦¬

### 1. ë¬¸ì„œ ë¡œë“œ ë° ì „ì²˜ë¦¬

```python
# í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ í•¨ìˆ˜
def load_text_files(txt_files):
    data = []
    for text_file in txt_files:
        loader = TextLoader(text_file, encoding='utf-8')
        data += loader.load()
    return data

# í•œêµ­ì–´ ë¬¸ì„œ ë¡œë“œ
korean_txt_files = glob(os.path.join('data', '*_KR.md'))
korean_data = load_text_files(korean_txt_files)
```

### 2. ë¬¸ì„œ ë¶„í•  (Text Splitting)

```python
# í† í° ê¸°ë°˜ ë¬¸ì„œ ë¶„í• 
text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
    encoding_name="cl100k_base",
    separators=['\n\n', '\n', r'(?<=[.!?])\s+'],
    chunk_size=300,  # 300 í† í° ë‹¨ìœ„ë¡œ ë¶„í• 
    chunk_overlap=0,
    is_separator_regex=True,
    keep_separator=True,
)

korean_docs = text_splitter.split_documents(korean_data)
```

### 3. ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶•

```python
# OpenAI ì„ë² ë”© ëª¨ë¸ ì„¤ì •
embedding_model = OpenAIEmbeddings(model="text-embedding-3-small")

# Chroma ë²¡í„° ì €ì¥ì†Œ ìƒì„±
vector_store = Chroma.from_documents(
    documents=korean_docs,
    embedding=embedding_model,
    collection_name="db_korean_cosine",
    persist_directory="./chroma_db",
    collection_metadata={'hnsw:space': 'cosine'}
)
```

## ğŸ§ª í‰ê°€ ë°ì´í„°ì…‹ êµ¬ì¶•

### 1. Persona ì •ì˜
ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ì§ˆë¬¸ì„ ìƒì„±í•˜ê¸° ìœ„í•´ í˜ë¥´ì†Œë‚˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤:

```python
personas = [
    Persona(
        name="graduate_researcher",
        role_description="ë¯¸êµ­ ì „ê¸°ì°¨ ì‹œì¥ì„ ì—°êµ¬í•˜ëŠ” í•œêµ­ì¸ ë°•ì‚¬ê³¼ì • ì—°êµ¬ì›ìœ¼ë¡œ, ì „ê¸°ì°¨ ì •ì±…ê³¼ ì‹œì¥ ë™í–¥ì— ëŒ€í•´ ê¹Šì´ ìˆëŠ” ë¶„ì„ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤. í•œêµ­ì–´ë§Œì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
    ),
    Persona(
        name="masters_student",
        role_description="ì „ê¸°ì°¨ ì‚°ì—…ì„ ê³µë¶€í•˜ëŠ” í•œêµ­ì¸ ì„ì‚¬ê³¼ì • í•™ìƒìœ¼ë¡œ, ë¯¸êµ­ ì „ê¸°ì°¨ ì‹œì¥ì˜ ê¸°ì´ˆì ì¸ ê°œë…ê³¼ íŠ¸ë Œë“œë¥¼ ì´í•´í•˜ë ¤ ë…¸ë ¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. í•œêµ­ì–´ë§Œì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
    ),
    # ... ì¶”ê°€ í˜ë¥´ì†Œë‚˜ë“¤
]
```

### 2. í•©ì„± ë°ì´í„° ìƒì„±

```python
# LLM ë° ì„ë² ë”© ë˜í¼ ì„¤ì •
generator_llm = LangchainLLMWrapper(ChatOpenAI(model="gpt-4.1-mini"))
generator_embeddings = LangchainEmbeddingsWrapper(
    OpenAIEmbeddings(model="text-embedding-3-small")
)

# í…ŒìŠ¤íŠ¸ì…‹ ìƒì„±ê¸°
generator = TestsetGenerator(
    llm=generator_llm,
    embedding_model=generator_embeddings,
    persona_list=personas
)

# í•©ì„± ë°ì´í„° ìƒì„±
dataset = generator.generate_with_langchain_docs(
    korean_docs,
    testset_size=50
)
```

## ğŸ” RAG ì²´ì¸ êµ¬ì„±

### 1. RAG ì²´ì¸ êµ¬ì„±

```python
# ê²€ìƒ‰ê¸° ìƒì„±
retriever = vector_store.as_retriever(search_kwargs={"k": 5})

# LLM ë° í”„ë¡¬í”„íŠ¸ ì„¤ì •
llm = ChatOpenAI(model="gpt-4.1-mini", temperature=0)

template = """Answer the question based only on the following context:

[Context]
{context}

[Question]
{query}

[Answer]
"""

prompt = ChatPromptTemplate.from_template(template)
qa_chain = prompt | llm | StrOutputParser()

def format_docs(relevant_docs):
    return "\n".join(doc.page_content for doc in relevant_docs)
```

### 2. RAG ì²´ì¸ ì‹¤í–‰ ì˜ˆì‹œ

```python
query = "TeslaëŠ” ì–¸ì œ ëˆ„ê°€ ë§Œë“¤ì—ˆë‚˜?"
relevant_docs = retriever.invoke(query)
response = qa_chain.invoke({
    "context": format_docs(relevant_docs),
    "query": query
})
```

## ğŸ“ˆ í‰ê°€ ìˆ˜í–‰

### 1. í‰ê°€ ë°ì´í„°ì…‹ ì¤€ë¹„

```python
# í‰ê°€ìš© ë°ì´í„°ì…‹ êµ¬ì„±
dataset = []
for row in testset.itertuples():
    query = row.user_input
    reference = row.reference
    relevant_docs = retriever.invoke(query)
    response = qa_chain.invoke({
        "context": format_docs(relevant_docs),
        "query": query,
    }, config={"callbacks": [langfuse_handler]})

    dataset.append({
        "user_input": query,
        "retrieved_contexts": [rdoc.page_content for rdoc in relevant_docs],
        "response": response,
        "reference": reference,
    })

evaluation_dataset = EvaluationDataset.from_list(dataset)
```

### 2. RAGAS í‰ê°€ ì‹¤í–‰

```python
# í‰ê°€ì LLM ì„¤ì •
evaluator_llm = LangchainLLMWrapper(llm)

# í‰ê°€ ìˆ˜í–‰
result = evaluate(
    dataset=evaluation_dataset,
    metrics=[
        LLMContextRecall(),      # ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì„±ëŠ¥
        Faithfulness(),          # ì‘ë‹µ ì¶©ì‹¤ë„
        FactualCorrectness()     # ì‚¬ì‹¤ ì •í™•ì„±
    ],
    llm=evaluator_llm,
    callbacks=[langfuse_handler]
)
```

### 3. í‰ê°€ ê²°ê³¼ í•´ì„

í‰ê°€ ê²°ê³¼ëŠ” 0~1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ì œê³µë©ë‹ˆë‹¤:

- **Context Recall (0.8633)**: ê²€ìƒ‰ ì„±ëŠ¥ì´ ìš°ìˆ˜í•¨
- **Faithfulness (0.8941)**: ìƒì„±ëœ ë‹µë³€ì´ ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ì— ì¶©ì‹¤í•¨
- **Factual Correctness (0.6329)**: ì‚¬ì‹¤ ì •í™•ì„±ì€ ê°œì„  ì—¬ì§€ ìˆìŒ

## ğŸ’¡ ì£¼ìš” ê¸°ëŠ¥ ë° í™œìš©ë²•

### 1. ë‹¤êµ­ì–´ ì§€ì›
- í•œêµ­ì–´ì™€ ì˜ì–´ ë¬¸ì„œ ëª¨ë‘ ì²˜ë¦¬ ê°€ëŠ¥
- ì–¸ì–´ë³„ ì ì ˆí•œ ì „ì²˜ë¦¬ ì ìš©

### 2. íŠ¸ë ˆì´ì‹± ë° ëª¨ë‹ˆí„°ë§
- Langfuseë¥¼ í†µí•œ ì‹¤ì‹œê°„ ì¶”ì 
- ê° ë‹¨ê³„ë³„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### 3. ëª¨ë“ˆí™”ëœ êµ¬ì¡°
- ê° êµ¬ì„±ìš”ì†Œë¥¼ ë…ë¦½ì ìœ¼ë¡œ êµì²´ ê°€ëŠ¥
- ë‹¤ì–‘í•œ ì‹¤í—˜ ì„¤ì • ì§€ì›

## ğŸ”§ ë¬¸ì œ í•´ê²°

### ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ë“¤

1. **API í‚¤ ì˜¤ë¥˜**
   ```python
   # .env íŒŒì¼ í™•ì¸ ë° ì¬ë¡œë“œ
   load_dotenv()
   ```

2. **ë©”ëª¨ë¦¬ ë¶€ì¡±**
   ```python
   # ì²­í¬ í¬ê¸° ì¶•ì†Œ
   chunk_size=200  # 300ì—ì„œ 200ìœ¼ë¡œ ê°ì†Œ
   ```

3. **ê²€ìƒ‰ ì„±ëŠ¥ ì €í•˜**
   ```python
   # ì„ë² ë”© ëª¨ë¸ ë³€ê²½ ê³ ë ¤
   embedding_model = OpenAIEmbeddings(model="text-embedding-ada-002")
   ```

## ğŸ“š ì°¸ê³  ìë£Œ

- [RAGAS ê³µì‹ ë¬¸ì„œ](https://docs.ragas.io/)
- [LangChain ë¬¸ì„œ](https://python.langchain.com/)
- [OpenAI API ë¬¸ì„œ](https://platform.openai.com/docs)

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

1. **PRJ02_W1_002**: ê²€ìƒ‰ í‰ê°€ ì§€í‘œ (Hit Rate, MRR, NDCG) í•™ìŠµ
2. **PRJ02_W1_003**: í‚¤ì›Œë“œ ê²€ìƒ‰ ë° í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤ìŠµ
3. **PRJ02_W1_004**: ì¿¼ë¦¬ í™•ì¥ ê¸°ë²• í•™ìŠµ

---

**ğŸ’¡ íŒ**: ì´ ë…¸íŠ¸ë¶ì„ ì‹¤í–‰í•˜ê¸° ì „ì— ëª¨ë“  í™˜ê²½ë³€ìˆ˜ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³ , ë°ì´í„° í´ë”ì— í•„ìš”í•œ ë¬¸ì„œ íŒŒì¼ë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.